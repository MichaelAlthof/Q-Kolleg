BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2010-015
Estimation of the characteristics of a LÈvy
process observed at arbitrary frequency
Johanna Kappus* Markus Reiﬂ*
* Humboldt-Universit‰t zu Berlin, Germany
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universit‰t zu Berlin Spandauer Straﬂe 1, D-10178 Berlin

Estimation of the characteristics of a L¥evy process observed at arbitrary frequency

Johanna Kappus

Markus Reiﬂ

Institute of Mathematics Humboldt-Universit®at zu Berlin
kappus@math.hu-berlin.de

Institute of Mathematics Humboldt-Universit®at zu Berlin
mreiss@math.hu-berlin.de

February 4, 2010

Abstract
A L¥evy process is observed at time points of distance  until time T . We construct an estimator of the L¥evy-Khinchine characteristics of the process and derive optimal rates of convergence simultaneously in T and . Thereby, we encompass the usual low- and high-frequency assumptions and obtain also asymptotics in the mid-frequency regime.
Keywords: L¥evy process ∑ L¥evy-Khinchine characteristics ∑ Nonparametric estimation ∑ Inverse problem∑ Optimal rates of convergence
MSC (2010): 60G51 ∑ 60J75 ∑ 62G05
JEL Classification: G13 ∑ C14
1 Introduction
L¥evy processes are the main building blocks for stochastic continuous-time jump models, which become more and more popular in applications. One important task is thus to provide estimation methods for the characteristics of a L¥evy process.
There exist two fundamentally different estimation approaches, depending on the nature of observations. If we can assume high-frequency observations of the L¥evy process, we can discretize a natural estimator based on continuous-time observations, where the jumps and the diffusion part are observed directly [9, 7, 5]. Alternatively, the low-frequency setting is considered where the observation distance does not tend to zero and even
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
1

asymptotically we cannot observe the diffusion and the jumps directly. Not surprisingly, in that case we face a more complicated inference problem leading to a deconvolution-type inverse problem [14, 4, 12, 11]. A very similar structure occurs in the estimation for L¥evy-Ornstein-Uhlenbeck processes [13] and in the calibration of financial derivatives (European options) to L¥evy models [2].
Here, we want to bridge the gap between high- and low-frequency estimation methods by allowing the time distance  between observations to remain constant or to converge to zero at an arbitrary speed. First results into that direction have been obtained by [4] for specific models. In any case, the observation time T tends to infinity because only this allows identification of the drift and the jump part in the limit. We extend the approach for general L¥evy processes by [14] to arbitrary observation distances .
First we introduce the setup in Section 2. Then in Section 3 we propose our estimator based on a minimum-distance criterion. The correct distance relies upon uniform convergence properties of the empirical characteristic function. The main result is an asymptotic upper bound for the estimator of the jump measure. Particularly interesting is the fact that we recover simultaneously the convergence rates for the high- and low-frequency setup, without any prescription for the estimator. As a minimax lower bound proves, also our intermediate (mid-frequency) risk bounds are asymptotically optimal. All proofs are postponed to Section 4.

2 Statistical model and estimation strategy

A L¥evy process (Xt, t 0) is observed at the n equidistant time points , ∑ ∑ ∑ , n = T . It is well known that the characteristic function of X has the form
(u) = E eiuX = e(u),
where the characteristic exponent  reads as

(u) = iub - 2 u2 + 2

eiux - 1 - iux1(|x|  1) ( dx),

with volatility   0, drift b  R and jump measure , where  is a -finite Borel measure on R with R \{0}(x2  1)( dx) < . Throughout the text we shall assume that X1 has finite moments up to order 4 +  for some positive
constant . Then we even have (cf. Thm. 25.3 [15])

x2( dx) < .
R \{0}
We can thus give the following reparametrization of the characteristic exponent in terms of the finite measure ( dx) := 20( dx) + x2( dx) and

2

b := b + x 1(|x| > 1)( dx):

eiux - 1 - iux

(u) = iub +
R

x2

( dx),

where the integrand is continuously extended to -u2/2 at x = 0. The L¥evy

process is fully described by the parameters b (which is equal to the mean

value of X1) and . The motivation for considering the above parametrization comes from the following fundamental result (see e.g. Theorem 8.7 in

[15]):

2.1 Proposition. Let P(b,) and P(bn,n ) nN denote infinitely divisible laws with the corresponding characteristics. Then weak convergence P(bn,n )  P(b,) takes place if and only if bn  b and n  .
Using the fact that the increments of a L¥evy process are independent and identically distributed, we can define the empirical characteristic function

1 ^,T (u) := n

n

eiu(Xk-X(k-1)).

k=1

(2.1)

Pointwise convergence of ^,T to  suggests to choose the estimators of the parameters of interest such that the corresponding characteristic function approximately minimizes the distance to the empirical characteristic function. Consequently, we define

^b,T , ^,T := arginf(~b,~) d ^,T ,  ∑; ~b, ~

(2.2)

for an appropriate choice of the metric d. It was shown in [14] that for equidistant observations with  fixed, the estimators of b and  defined according to (2.2) are strongly consistent under rather general conditions on the choice of the metric d. Moreover, optimal rates of convergence are obtained if b and  are chosen to fit the weighted empirical characteristic function and its first and second derivative.
The motivation for considering not only the characteristic function, but also its derivatives comes from the fact that the Fourier transform of the finite measure  can be expressed as

F(u) := eiux( dx) = - (u),
R

which gives

F (u)

=

1(u)2 1(u)2

-

1(u) , 1(u)

and in terms of :

F (u)

=

1 

(u)2 (u)2

-

(u) (u)

(2.3) (2.4)

3

Note that by formula (2.3) and (2.4) there is a strong resemblance of the
problem of estimating  with a deconvolution problem. The optimal rates of convergence depend on the decay behaviour of the characteristic function.
To obtain an estimator which is rate optimal for T   with arbitrary
observation distance , the appropriate choice of a distance function will have to depend on . Because of the moment sizes E[X2k] = O(1k) (see p.9 for a proof), it turns out that the distance function

2

d (, ) :=

-

1k 2

k=0

(k) - (k) L(w)

is appropriate, where

(2.5)

f L(w) := sup |f (u)| w(u)
uR
for a weight function w : R  R+ specified later. Since we cannot guarantee that the infimum is always attained, our estimators ^b,T and ^,T are chosen such that

d ^,T ,  ∑; ^b,T , ^,T

inf d (^,T ,  (∑; b, )) + T (2.6)
(b, )

with T = o

1/2

T

-

1 2

. In what follows, we will use the notation

,T :=  ∑; ^b,T , ^,T .

3 Rate optimality of the estimation procedure

3.1 Convergence of the empirical characteristic function

The main technical tool needed to prove rate optimality in T and  is the following result giving control of the weighted empirical characteristic function on the whole real line uniformly in . In an abstract sense, the statement below will tell us that the Donsker property holds for the empirical characteristic function uniformly over the class of distributions (P)1 , where P denotes the distribution of X.
Let the normalized version of the k-th derivative of the empirical characteristic function process be defined by

C(k,)T (u)

:=

n-

1 2

-

k1 2

n

dk duk

j=1

eiu(Xj-X(j-1)) - E eiuX

.

(3.1)

We can now formulate the main result of this section, which is proved in Section 4.

4

3.1 Theorem. For k  N0 let X be a L¥evy process with finite (2k + )-th moment and choose w(u) = (log(e+ | u |))-1/2- for some constants ,  >
0. Then for C(k,)T , defined by (3.1), we have

sup E C(k,)T L(w) < .
n1,1

With the distance d defined according to (2.5), the above theorem tells us that in terms of T , the empirical characteristic function ^,T satisfies

E

-

1 2

d

(^,T

,



)

=

O(T

-

1 2

).

(3.2)

An application of the triangle inequality gives d (,T , )  2d (^,T , ) + o(1/2T -1/2),

so (3.2) remains true if we replace the empirical characteristic function ^,T by the minimum distance fit ,T .

3.2 Asymptotic risk bounds
We are now ready to prove upper bounds for convergence in probability. We consider in particular the following decay scenarios for the characteristic function:

a) The characteristic function of X satisfies |(u)|  Ce-c|u|

(3.3)

for some 0    2 and C, c > 0. This is equivalent to stating that X posesses at most a supersmooth density with parameters c and  (if a density exists at all).
Any infinitely divisible distribution having nonzero Gaussian part is supersmooth with  = 2. Examples of distributions which are supersmooth with  < 2 are tempered stable laws with index of stability  (e.g. [6], Chapter 4.5). Note that stable distributions do not fit in our setting, as they do not match the required moment condition. Normal inverse Gaussian processes which fulfill (3.3) with  = 1 have been used for financial modelling, see e.g. [1]. Another example of processes in finance matching condition (3.3) with  = 1 are Meixner-processes, see e.g. [16].

b) We have at most polynomial decay of the characteristic function:

|(u)|  C (1 + |u|)-

(3.4)

5

for C > 0 and  0. This means that if X possesses a density at all, this can be no smoother than ordinary smooth with parameter .
Typical examples of infinitely divisible random variables with ordinary smooth densities are Gamma distributions. Compound Poisson distributions, which do not posess a distributional density, fulfill (3.4) for  = 0. Another typical example of processes fulfilling (3.4) are variance gamma processes, which have been used to model the logarithm of stock prices, see, for example [3].
Inspired by the weak convergence in Proposition 2.1, the performance of the estimator of the finite measure  is measured by an integral criterion. For s > 0 define the space of test functions

Fs := f  L1(R) : |Ff (u)| (1 + |u|)s du < 1. .

The corresponding loss for an estimator ^ of  is then defined to be

s (^, ) := sup f d - f d^ .
f Fs

3.2 Theorem. Assume E |X|4+ <  for some  > 0. Let ^,T and ^b,T be defined according to (2.6). Then

E |^b,T - b| = O

T

-

1 2

.

For ^,T , we obtain the following rates of convergence in probability:

a) For distributions with tail behaviour |(u)|  Ce-c|u| we have

s ^,T ,  = OP

log T

-

s 



T

-

1 2

.



Especially,

the

parametric

rate

T

-

1 2

,

is

attained

for

T





and

si-

multaneously T  0 provided

T = O

T

-

 2s

log

T

.

b) For distributions with tail behaviour |(u)|  C(1 + |u|)- we have

s ^,T ,  = OP

T-

s 2

s(1/2+)
(log(e + T )) 



T

-

1 2

.

Especially,

the

parametric

rate

T

-

1 2

,

is

attained

for

T





under

the

non-asymptotic condition

s

T

<

. 

6

By standard parametric theory, all parameters cannot be estimated at a better rate than T -1/2. Therefore the next result shows that our rates of
convergence are minimax optimal (at least up to a logarithmic factor for
(b)) within a nonparametric class.

3.3 Theorem (Minimax lower bounds). Let us introduce the following nonparametric classes for :

A(C, c, ) : = B(C, ) : =

 : |(u)|  Ce-c|u|  : |(u)|  C(1 + |u|)- .

Then we obtain the following minimax lower bounds uniformly for |b|  B, where B is some positive constant:

 > 0 : lim inf inf

T  T (0,1]

T ,T

sup Pb,
 A(C,c,)

log T T

s





T

1 2

s T ,T ,  >  > 0,

 > 0 : lim inf inf
T  ,T T (0,1]

sup Pb,
 B(C,)

Ts 2T





1 2

s

T ,T , 

>

> 0,

where the infimum is taken over all estimators T ,T of  based on observations of X with distance T up to time T .

The proof follows along the same lines as the proof in [14], but the control of the dependence on  requires additional and rather tedious calculations, whence it is omitted.

3.3 Discussion
The convergence rates for  can be understood in terms of a deconvolution or statistical inverse problem. The degree of ill-posedness, i.e. the amplification of the noise, is governed by the decay of the characteristic function . For fixed  and the exponential decay of  in (a) we therefore face a severely ill-posed problem with logarithmic rates of convergence. On the other hand, the risk is smaller for smoother test functions. If we had looked also at analytic test functions, where the Fourier transform decays exponentially fast, then we would also in (a) obtain polynomial rates for fixed . Observe that our estimator does neither rely on the knowledge of the decay behaviour of the unknown characteristic function nor on the test function class considered nor on the asymptotics of the observation distance.
The parametric rate is always attained when the smoothness of the test function sufficiently counterbalances the ill-posedness of the problem. It is remarkable that in all cases a condition on the observation distance of the type  = O(T -p) suffices. In the polynomial decay case (b) the ill-posedness is of degree  which is smaller than the smoothness s exactly under the

7

condition  < s/ and we need not assume high-frequency observations.
Very roughly and intuitively, there is an analogy with estimating the deriva-
tive of order  of a regression function and calculating the integral with
an s-smooth test function of compact support, which by partial integration equals the integral of the regression function itself with an (s - )-smooth test function. This L2-continuous linear functional can be estimated with a
parametric rate, see e.g. [10]. Like in [9], we might consider the model that  possesses a density g  Cr
which we want to estimate. The kernel smoothing argument in [14] then
yields in the polynomial decay case (b) a convergence rate for the pointwise risk of order O(hr + h--1/2T -1/2) (modulo a log factor, which is
suppressed in the following), where h denotes the kernel bandwidth. An optimal bandwidth choice yields the rate O(T -r/(2r+2+1)). Under this loss we attain the high-frequency rate of convergence O(T -r/(2r+1)) under the condition  c(log T )-1 with c > 0 sufficiently small. This logarithmic
decay condition should be compared to [7] and [5] where in the compound
Poisson case a polynomial condition is required for the critical observation
distance .

4 Proofs

4.1 Proof of Theorem 3.1

We start by recalling some definitions from empirical process theory. Let a probability space (X, A, P) be given. For measurable functions u, l : X  R, the set
[l, u] := {h : X  R | l  h  u}
is called an -bracket, if
(u - l)2dP < 2.

Given some class F of measurable, real-valued functions on X, we denote by N[ ] , F, L2(P) the minimal number of -brackets which are needed to
cover F. The entropy integral is defined by

J[ ] , F, L2(P) :=


log N[ ] , F, L2(P)

1
2 d.

0

Finally, a function F  0 is called an envelope function for F, if

f  F : |f |  F.

Proof of Theorem 3.1 . We decompose C(k,)T in its real and imaginary part and introduce the set of functions

Fk :=

-

1k 2

dk duk

cos ux

:

u



R



-

1k 2

dk duk

sin ux

:

u



R

.

8

Denote by P the distribution of X. An application of Corollary 19.35 in [17] gives for any  > 0:

sup E C(k,)T L(w) < CJ[ ] E F 2(X) , F(k), L2(P) ,
T

(4.1)

for any envelope function F = Fk of Fk and a universal constant C which does not depend on . It is shown in [14] that the right hand side of 4.1 is
finite. To make the result uniform in , it remains to consider the behaviour
of the entropy integral for   (0, 1] varying. To cover Fk with brackets of size , we define for grid points u,j specified
later the bracket functions

g±,j (z)

=

-

1k 2

w(u,j )

dk duk

cos(u,j z)

±

|z|k

I[-M

.M

]

(z

)±-

1k 2

|z

|k

I[-M

,M

]c

(z

)

and

h±,j (z)

=

-

1k 2

w(u,j )

dk duk

sin(u,j z)

±

|z|k

I[-M.M

]

(z

)±-

1k 2

|z

|k

I[-M,M

]c

(z

),

with M := M (, , k) := inf m : -(1k)E|X|2kI{|X|>m}  2 .
By definition of M , the size of the brackets is E g+,j (X) - g-,j (X) 2  42 -(1k)EX2k + 1 .

For   1, the expression on the right is uniformly bounded above by c2
for some c > 0. This is obvious for k = 0. For k  1, this is a consequence of the well known fact that E X2k  c for some c > 0, which is seen by using the formula

E X2k

=

i-2k (2k) (0)

=

i-2k

d2k du2k

e(u)

.
u=0

An analogous argument gives:

E h+,j (X) - h-,j (X) 2  c2.

For

a

function

gu(∑)

:=

-

1k 2

w(u)

k uk

cos(u∑)



Fk

to

be

contained

in

[g-,j, g+,j], we have to ensure

dk |w(u) duk

cos(uz)

-

dk w(u,j) duk

cos(u,j z )|



|z|k

z  [-M, M ].

(4.2)

9

With the estimate

|w(u) cos(uz) - w(uj) cos(ujz)|I[-M,M](z)  (w(u) + w(uj)) 
|w(u) cos(uz) - w(u) cos(ujz)| I[-M,M](z) + |w(u) cos(ujz) - w(uj) cos(ujz)| I[-M,M](z)  (w(u) + w(uj))  (M |u - uj| + Lip(w)|u - uj|) ,

where Lip(w) is the Lipschitz-constant of w, and with the analogous inequality for the sine-function, (4.2) is seen to hold for any u  R such that

min {|u - u,j|(Lip(w) + M ), w(u) + w(u,j)}  .

Hence to cover Fk with brackets of P-size c2, we need grid

points u1, ∑ ∑ ∑ , uJ() such that w(u1)



 2

,

w(uJ () )



 2

and

|uj

-

uj+1|



 Lip(w)+M

(,,k)

.

For

the

minimal

number

J ()

of

c-brackets

needed to cover F,k, this yields the estimate

J()  2U ()(Lip(w) + M (, , k))/,

with

U () := inf

u



R

:

w(u)



 2

exp - for some  < 2.

The generalized Markov inequality yields for some c > 0:

M (, , k)  E |X|2k+ /1k2 1/ < c -2/ .

The second inequality applies the fact that we have the moment bound E |X|2k+ = O (), which is a consequence of Theorem 1.1 in [8].
The entropy with bracketing is

log

N[

]

(,

F,k ,

L2(P))



log

U

(

 c

)

+

log

c (Lip(w) + M (/c, , k)) 

.

The upper limit in the entropy integral appearing in (4.1), E[F2 ,k(X)], is again bounded above uniformly in  < 1. We have thus shown that up to some universal constant

sup sup E C(k,)T L(w)
1 T
11
 log(U ()) d +
00

log Lip(w)/ + -(2/+1) d. (4.3)

Now (4.3) is finite since log U () - for some  < 2. This completes the proof.

10

4.2 Proof of Theorem 3.2
To prove the upper bounds, we establish a number of technical lemmas giving control on the characteristic exponent and its derivatives. First, we formulate a result which connects the tail behaviour of the characteristic function (which corresponds to the smoothnes of the density) to the jump activity round the origin, extending a result from [14]:

4.1 Lemma. Let an infinitely divisible law with characteristics (b, 0, ) be given such that its characteristic function satisfies
|(u)|  Ce-c|u|

for some 0 <  < 2 and C, c > 0. Then for any  >  the integral

1
|x| ( dx)
-1

is finite.

Proof. Setting  := inf1<x2 (1 - cos x) > 0, we have the series of inequalities

1

|x| ( dx) =

|x| ( dx)

-1 m=0 {2-(m+1)<|x|2-m}



 -1 2- m 1 - cos(2m+1x) ( dx)

m=0 
= -1 2- m -Re(2m+1)

m=0

 -1 2c 2-( -)m - log C 2- m < .

m=0

m=0

4.2 Lemma. In the situation of the preceding lemma, let   [1, 2) and assume finite moments for the law of order  > . Then the following bound on the derivative of the characteristic exponent holds for   (, 2):

u  R : | (u)|  K(1 + |u| -1)

(4.4)

for some K > 0.

For  < 1 the derivative of the characteristic exponent is always uni-

formly bounded:

sup  (u) < .
uR

(4.5)

11

Proof. Since the diffusion part is zero by assumption, we obtain | (u)| = ib + i eiux - 1 x( dx)

(4.6)

 |b| + (2  |ux|) |x|( dx)  |b| + 22- |u| -1 |x| ( dx).

(4.7) (4.8)

and the integral appearing in (4.8) is finite by Lemma 4.1 together with the moment assumption. We have thus shown (4.4). To see (4.5) , we can estimate

 (u)  |b| + 2 |x|( dx)

(4.9)

and this expression is finite for  < 1 by Lemma 4.1.

Next, we focus on the exponential decay behaviour. We first need a result concerning the minimum distance fit of the characteristic function.

4.3 Lemma. Let |(u)|  Ce-c|u|. With

11

I,T := [-U,T , U,T ] := -

log T 3


,

log T 3


.

we find for any observation distance  = T  (0, 1]

lim P
T 

u  I,T

:

|,T (u)| 

C e-cu 2

= 1.

Proof. øFrom Theorem 3.1 we infer by Markov's inequality

P

u



I,T

:

|,T (u)|

<

C e-c|u| 2



P

u  I,T

:

|,T (u) - (u)| >

C e-c|u| 2

=

P

sup
uI,T

|,T (u)

-

(u)|

2 ec|u| C

>

1



w(U,T

)-1

2 C

e|U,T

|



1 2

O

T

-

1 2

.

The choice of U,T ensures that this expression tends to zero for T  , whatever  is.

Let  := (u) denote the characteristic exponent of the true characteristic function  and ,T the characteristic exponent of the minimum distance fit ,T . The next two results give control on the deviation of ,T from  and of its second derivatives.

12

4.4 Lemma. Let |(u)|  Ce-c|u|. With K > 0 from (4.4) the following bound in probability is valid:

,T (u) - (u)

sup

uI,T w(u)-1ec|u|

1

+



1 2

K

(1

+

|u|

 2

)

=

OP(T

-

1 2

).

(4.10)

Moreover,

,T (u)

sup
uI,T

w(u)-1ec|u| K(1

+

|u|

 2

)

=

OP(1).

Proof. We have, with probability tending to one, for all u  U;T :

(4.11)

,T (u) - (u)

=

,T (u) - (u) ,T (u) (u)



|,T (u) - (u)| + |,T (u)|

,T (u)

|,T (u) - (u)| |,T (u)|



ec|u|

w(u)-1

+

K

(1

+

|u|

 2

)ec|u|

w(u)-1

1 2

-

1 2

d

(,T

,



)

,

where the last inequality is a consequence of Lemma 4.2 and Lemma 4.3. Another application of Theorem 3.1 gives (4.10). Now (4.11) follows from (4.10), using Lemma 4.4 and the estimate

,T (u)  (u) + ,T (u) - (u) .

4.5 Lemma. Let |(u)|  Ce-c|u|. For the second derivative of the characteristic exponent we have

sup ,T (u) - (u) = OP(1).
uR

Moreover, we can give the following bound in probability uniformly on I,T :

sup ,T (u) - (u)

uI,T Cec|u| w(u)-1

1

+



1 2

(1

+

|u|

 2

)

+



3 2

(1

+

|u|)

= OP

T

-

1 2

(4.12)

Proof. To see the first statement of the lemma, recall that the second derivative of the characteristic exponent is always bounded above:

u  R : (u) =  -2 + eiuxx2( dx)   2 + |x|2( dx) < .

13

Then apply the series of inequalities

,T (u) - (u)  4 |(0)| + ,T (0) - (0)  4 |(0)| + ,T (0) - (0) + (,T (0))2 - ((0))2 = 4 |(0)| + ,T (0) - (0) + 2 |(0)| ,T (0) - (0) + ,T (0) - (0) 2

=

OP

1

+

T

-

1 2

+

T

-

1 2

+ T -1

= OP (1) .

Next, (4.12) can be seen by estimating

,T (u) - (u)

=

,T (u) - ,T (u)

,T (u)

2

-

(u) (u)

+

(u) 2



,T (u) - (u) |(u)|

+

,T (u)

|,T (u) - (u)| |(u)|

+ ,T (u) + (u) ,T (u) - (u) .

The desired bound is an immediate consequence of Lemma 4.4.

For distributions with characteristic functions decaying at most polynomially, we can prove auxiliary results analogous to Lemmas 4.1-4.5. As the proofs run in a completely analogous way, we omit the details and only state the main result:
4.6 Lemma. Let |(u)|  C(1 + |u|)-. Define

I,T :=

-T

1 2

(log(e

+

T

))-

1/2+2 

, +T

1 2

(log

T

)-

1/2+2 

.

Then we have

,T (u) - (u)

sup
uI,T

C(1 + |u|)w(u)-1

=

OP

T

-

1 2

.

The proof of the upper bound result can now easily be obtained as a consequence of the preceding lemmas.

Proof of Theorem 3.2: The result for ^b,T is an immediate consequence of Theorem 3.1, using |^b,T - b| = -1|,T (0) - (0)|. For the estimator of

14

, applying Parseval's identity, the loss satisfies

s ^,T , 

= sup f (x)^,T ( dx) - f (x)( dx)
f Fs

1 = sup
2 f Fs

Ff (u) F^,T (u) - F(u) du

11

 sup 2 f Fs

|Ff (u)| 

(u) - ,T (u)

du



1 sup (1 + |u|)-s 1

2 uR



,T (u) - (u)

.

By an application of Lemma 4.5 and Lemma 4.6, we can estimate

a) for |(u)|  Ce-c|u| :

sup (1 + |u|)-s 1 uR 

,T (u) - (u)

 sup (1 + |u|)-s
uI,T

1

+

1
2

(1

+

|u|

 2

)

+

3
2

(1

+

|u|)

e-c|u| w(u)

= OP

T

-

1 2



log T 

-

s 

.

OP

T

-

1 2

 (1 + U,T )-s

b) for |(u)|  C(1 + |u|)-:

sup (1 + |u|)-s 1 uR 

,T (u) - (u)

=

OP

T-

s 2

(log (e

+

s(1/2+)
T )) 



T

-

1 2

.

References
[1] Ole E. Barndorff-Nielsen. Processes of normal inverse Gaussian type. Finance Stoch., 2(1):41≠68, 1998.
[2] Denis Belomestny and Markus Reiﬂ. Spectral calibration of exponential L¥evy models. Finance Stoch., 10(4):449≠474, 2006.
[3] Peter Carr and Dillip Madan. Option valuation using the fast Fourier transform. Journal of Computational Finance, 2:61≠73, 1998.
[4] Fabienne Comte and Valentine Genon-Catalot. Nonparametric adaptive estimation for pure jump L¥evy processes. Annales de l'I. H. P., Probability and Statistics (to appear).
15

[5] Fabienne Comte and Valentine Genon-Catalot. Nonparametric estimation for pure jump L¥evy processes based on high frequency data. Stochastic processes and their applications (to appear).
[6] Rama Cont and Peter Tankov. Financial modelling with jump processes. Chapman & Hall/CRC Financial Mathematics Series. Boca Raton, 2004.
[7] Jos¥e Figueroa-Lopez. Nonparametric estimation for L¥evy models based on discrete sampling. IMS Lecture Notes of the 3rd E.L. Lehmann Symposium, 57:117≠146, 2009.
[8] Jos¥e E. Figueroa-L¥opez. Small-time moment asymptotics for L¥evy processes. Stat. Probab. Lett., 78(18):3355≠3365, 2008.
[9] Jos¥e E. Figueroa-Lo¥pez and Christian Houdr¥e. Risk bounds for the non-parametric estimation of L¥evy processes. Gin¥e, Evarist (ed.) et al., High dimensional probability. Institute of Mathematical Statistics Lecture Notes - Monograph Series 51, 96-116, 2006.
[10] L. Goldstein and K. Messer. Optimal plug-in estimators for nonparametric functional estimation. Ann. Statist., 20(3):1306≠1328, 1992.
[11] Shota Gugushvili. Nonparametric estimation for discretely sampled L¥evy processes. arXiv:0908.3121v2, 2009.
[12] Shota Gugushvili. Nonparametric estimation of the characteristic triplet of a discretely observed L¥evy process. J. Nonparametric Stat., 21(3):321≠343, 2009.
[13] Geurt Jongbloed, Frank H. van der Meulen, and Aad.W. van der Vaart. Nonparametric inference for L¥evy-driven Ornstein-Uhlenbeck processes. Bernoulli, 11(5):759≠791, 2005.
[14] Michael Neumann and Markus Reiﬂ. Nonparametric estimation for L¥evy processes from low frequency observations. Bernoulli, 15(1):223≠ 248, 2009.
[15] Ken-Iti Sato. L¥evy processes and infinitely divisible distributions. Cambridge University Press, 1999.
[16] Wim Schoutens and Jozef L. Teugels. L¥evy processes, polynomials and martingales. Commun. Stat., Stochastic Models, 14(1-2):335≠349, 1998.
[17] Aad W. Van der Vaart. Asymptotic statistics. Cambridge University Press, 1998.
16

SFB 649 Discussion Paper Series 2010
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "Volatility Investing with Variance Swaps" by Wolfgang Karl H‰rdle and Elena Silyakova, January 2010.
002 "Partial Linear Quantile Regression and Bootstrap Confidence Bands" by Wolfgang Karl H‰rdle, Ya'acov Ritov and Song Song, January 2010.
003 "Uniform confidence bands for pricing kernels" by Wolfgang Karl H‰rdle, Yarema Okhrin and Weining Wang, January 2010.
004 "Bayesian Inference in a Stochastic Volatility Nelson-Siegel Model" by Nikolaus Hautsch and Fuyu Yang, January 2010.
005 "The Impact of Macroeconomic News on Quote Adjustments, Noise, and Informational Volatility" by Nikolaus Hautsch, Dieter Hess and David Veredas, January 2010.
006 "Bayesian Estimation and Model Selection in the Generalised Stochastic Unit Root Model" by Fuyu Yang and Roberto Leon-Gonzalez, January 2010.
007 "Two-sided Certification: The market for Rating Agencies" by Erik R. Fasten and Dirk Hofmann, January 2010.
008 "Characterising Equilibrium Selection in Global Games with Strategic Complementarities" by Christian Basteck, Tijmen R. Daniels and Frank Heinemann, January 2010.
009 "Predicting extreme VaR: Nonparametric quantile regression with refinements from extreme value theory" by Julia Schaumburg, February 2010.
010 "On Securitization, Market Completion and Equilibrium Risk Transfer" by Ulrich Horst, Traian A. Pirvu and GonÁalo Dos Reis, February 2010.
011 "Illiquidity and Derivative Valuation" by Ulrich Horst and Felix Naujokat, February 2010.
012 "Dynamic Systems of Social Interactions" by Ulrich Horst, February 2010.
013 "The dynamics of hourly electricity prices" by Wolfgang Karl H‰rdle and Stefan Tr¸ck, February 2010.
014 "Crisis? What Crisis? Currency vs. Banking in the Financial Crisis of 1931" by Albrecht Ritschl and Samad Sarferaz, February 2010.
015 "Estimation of the characteristics of a LÈvy process observed at arbitrary frequency" by Johanna Kappusl and Markus Reiﬂ, February 2010.

