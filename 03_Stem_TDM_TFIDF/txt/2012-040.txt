BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2012-040
Location, location, location: Extracting
location value from house prices
Jens Kolbe* Rainer Schulz** Martin Wersing*** Axel Werwatz***
* Deutsches Institut für Wirtschaftsforschung, Berlin ** University of Aberdeen Business School, UK
*** Technische Universität Berlin, Institut für Volkswirtschaftslehre und Wirtschaftsrecht
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universität zu Berlin Spandauer Straße 1, D-10178 Berlin

Location, location, location: Extracting location value from house prices
Jens Kolbe, Rainer Schulz, Martin Wersing, and Axel Werwatz May, 2012
Kolbe: Deutsches Institut fu¨r Wirtschaftsforschung, Mohrenstrasse 58, 10117 Berlin Germany. Email: jkolbe@diw.de. Schulz: University of Aberdeen Business School, Edward Wright Building, Dunbar Street, Aberdeen AB24 3QY, United Kingdom. Email: r.schulz@abdn.ac.uk. Wersing and Werwatz: Technische Universita¨t Berlin, Institut fu¨r Volkswirtschaftslehre und Wirtschaftsrecht, Straße des 17. Juni 135, 10623 Berlin, Germany, and Collaborative Research Center 649 Economic Risk, Humboldt-Universita¨t zu Berlin. Emails: martin.wersing@tu-berlin.de and axel.werwatz@tuberlin.de. Financial support from the Deutsche Forschungsgemeinschaft, CRC 649 Economic Risk, and the Wissenschaftsgemeinschaft Gottfried Wilhelm Leibniz, Pakt Econs, is gratefully acknowledged. The usual disclaimer applies.
1

Abstract The price for a single-family house depends both on the characteristics of the building and on its location. We propose a novel semiparametric method to extract location values from house prices. After splitting house prices into building and land components, location values are estimated with adaptive weight smoothing. The adaptive estimator requires neither strong smoothness assumptions nor local symmetry. We apply the method to house transactions from Berlin, Germany. The estimated surface of location values is highly correlated with expert-based land values and location ratings. The semiparametric method can therefore be used for applications where no other location value information exists or where this information is not reliable. Keywords: location value, adaptive weight smoothing, spatial modeling JEL Classification: R31, C14
2

1 Introduction
When asking a real estate professional about the three most important characteristics of a house, the likely answer will be `location, location, location'.1 Naturally, the characteristics of the building itself also play a role in its desirability, but the phrase emphasizes the importance of the surrounding area. The nicest villa in an otherwise run-down neighborhood is much less desirable than the very same building in a nice suburban area with shady forests, quiet lakes, and good schools. Based on this reasoning, we expect that the house will fetch a higher price when located in a nice area than when located in a run-down area. Seen differently, the difference between the prices of the villa in the two different areas gives the location value of the nice area relative to the run-down area. Once buildings differ with respect to their characteristics, such a simple price comparison is no longer sufficient to learn about the relative value of a location. But the general notion remains: house prices contain information on the value of the location.
Location values are of interest for several reasons. They can be used for spatial analysis with respect to the influence of amenities and externalities. They can be used for studying the impact of regulation, such as zoning. They can be used to measure the effects of policy interventions, such as regeneration and revitalization. Location values can be estimated directly from transactions of undeveloped land (Colwell and Munneke, 2003). However, particularly in densely populated urban areas, few (if any) transactions of undeveloped land may occur. House sales are typically more frequent.
In this paper, we propose a flexible method to estimate location values from house prices. At the first stage, we use the semiparametric estimator of Yatchew (1997) and Wang et al. (2011) to split the house price into components related to the building and the location. At the second stage, we use adaptive weight smoothing
1The phrase is in use at least since the 1920ties, see William Safire's `On language: location, location, location' in The New York Times, June 28, 2009.
3

(AWS) as pioneered by Polzehl and Spokoiny (2000, 2006) to estimate the location value surface. AWS is flexible regarding the shape of the surface and does not require smoothness assumptions. AWS identifies areas with homogenous location values by an adaptive iterative algorithm that is based on nonparametric smoothing. Unlike standard smoothers such as kernel regression, the algorithm does not require that the local areas have the same shape (e.g. rectangular or radial) at different locations.
We illustrate the methodology in an empirical application to data of geo-coded single-family house transactions from Germany's capital Berlin. Our estimated location surface provides a comprehensive characterization of the location values of Berlin's residential areas. The shape and size of areas with similar location values are completely data-driven and need not adhere to administrative boundaries. Since the true location values are not observed, we assess the adequacy of our estimates by comparing them with expert-based land values and expert-based ordinal location ratings. We find that our semiparametric method estimates location values that are highly correlated with the expert-based land values and location ratings.
Only a few previous studies have modeled location values from house price information. Cheshire and Sheppard (1995), Rosenthal (1999), and Rossi-Hansberg et al. (2010) are examples; none of these studies compares the estimated location values with benchmarks as we do.2 Anglin and Gencay (1996) and Clapp (2004) also fitted semiparametric models to house prices, but with more restrictive and less flexible value functions.
In summary, the novel method proposed in this paper allows us to estimate location values from house prices. We find that the estimated location values are reliable in the sense that they show agreement with expert assessments based on different information. The method should prove useful for applications where location values are needed and no expert-based information is available or where such information should be complemented by data-driven flexible location value estimates.
2Lack of such a benchmark is the reason why location values have to be imputed in the first place.
4

2 Methodology and estimation

We start with the assumption that the price of a house can be split into the value B of the building and the value L of land, so that P = B + L. Such a zero-profit condition holds for new houses if they are produced by a competitive construction industry using a constant returns to scale technology. In the case of old houses, the condition should hold once the building value is adjusted for depreciation; the condition corresponds then to the depreciated cost approach (Bourassa et al., 2011). To make explicit that houses are heterogenous, we write

P = B(xB) + L(xL) ,

(1)

where the vectors xB and xL collect building and land characteristics. We specify the building component as B(xB) = xB. Building characteristics include continuous variables such as floor area and age and discrete variable such as cellar and building type. The land component is specified as L(xL) = sa(l), where s measures lot size in square meters. The location value a(l) depends on the Cartesian location coordinates l = (l1, l2), but is otherwise unspecified and flexible. The coefficient vector  and the location value function a(l) are not known and have to be estimated.

Dividing both sides of Eq. 1 by the lot size s and adding the term  for unobserved

characteristics and idiosyncratic effects during the transaction, we obtain the partial-

linear regression model

p = z  + a(l) +  .

(2)

Here, p and z denote the house price and the building characteristics per square meter lot size.3 We assume E(|z, l) = 0.

In order to estimate the nonparametric location value function, we first remove the building value from the house price. Specifically, we obtain a consistent estimate of the parametric component in Eq. 2 and compute the residual u = p - z , which
3The continuous building characteristics may be transformed further to capture non-linearities in the hedonic price function.

5

equals the sum of the location value plus the transaction noise term . We then separate the residual into the latter two terms using AWS.
We note that our method does not allow the identification of separate constants for the building and the location value component. We can therefore estimate the relative location value surface, but additional information is required to convert the surface into levels.4
2.1 Data description
Our main data is provided by Berlin's Committee of Valuation Experts (GAA, Gutachterausschuss fu¨r Grundstu¨ckswerte) from their transaction database (AKS, Automatisierte Kaufpreissammlung).5 The data covers arms-length transactions of single-family houses during the years 1996-2010. The data contains information on the transaction price, geographic location coordinates, and numerous building characteristics.
Each transaction has an expert-based land value, which is the notional value of land as if it were undeveloped. The value assumes that land is not contaminated or burdened with unusual legal covenants. The land values are computed by GAA appraisers using the sales comparison approach based on information from transactions of undeveloped land. Expert-based land values are expressed in Euros per square meter. Each transaction has also an expert-based location rating, which is provided by Berlin's Senate Department for Urban Development and the Environment. The ordinal rating uses four levels to summarize the quality of a location. For this rating, the experts consider the amount of natural amenities such as lakes and forests, the quality of existing buildings, and the access to public transport and shopping facilities.
4Observing the price for undeveloped land at the location where a(l) reaches, say, its minimum would be sufficient to calibrate the surface.
5The GAA is entitled by law to request and collect information on all real estate transactions occurring in Berlin.
6

Table 1 gives summary statistics for the 19,283 observations. House prices and expert-based land values are converted into year 2000 Euros using constant-quality price and land value indices, respectively.6 As indicated by the standard deviation, house prices show substantial variation. This is in line with the substantial variation of building characteristics, such as floor size, number of storeys, age of the building, and building type. There is also substantial variation regarding the size of the lot. Unusual features of the house in Table 1 include physical aspects such as structural damage or flooding risk and legal aspects such as rights of way or use for pipes or cables. Such easements are rather common.
[Table 1 about here]
Another important source of variation is the location of a house within the city, as indicated by the map plotted in Figure 1.
[Figure 1 about here]
The area of Berlin is 891 km2, where the distance from west to east is 45 km (left to right) and 38 km from south to north (bottom to top). The map shows that the amount of lakes, rivers, parks, and forests differs between suburban areas. Modern Berlin was created by incorporating many formerly independent smaller cities and towns, some of which have kept their own distinctive character, which adds to the variation of location characteristics.
The last part of Table 1 presents summary statistics for the expert-based land values and the expert-based location ratings. The expert-based values and ratings are not unrelated, because GAA appraisers will use the location ratings for their land values and the experts of the Senate department might use information on land values for their location rating exercise. But the experts will also use different
6The indices are estimated using the hedonic regression methodology described in Schulz and Werwatz (2011).
7

information differently and we do not expect that the two expert-based assessments always conform. Panel A of Table 2 gives the matching frequencies of the two expertbased location assessments once the expert-based land values are converted into an ordinal rating. In this conversion, the 2% largest land values receive the rating `excellent', the next 20% values the rating `high' and so forth. Constructed this way, the land value rating has the same marginal distribution as the expert-based location rating.
[Table 2 about here.]
If the two ordinal location ratings were identical, then the contingency matrix would have the marginal frequencies on the diagonal and zeros elsewhere. In Panel A, this is not the case. The two expert-based ratings are also not independent, as a comparison with Panel C shows. The panel gives the frequencies we would expect if matching were random. The null hypothesis of the chi-square test for statistical independence is rejected at the usual significance levels. Measures of strength of the relationship between the two ratings are Goodman and Kruskal's , and Kendall's  , respectively. Both statistics range from -1 (perfect inversion) to +1 (perfect agreement). In Panel A, we estimate  = 0.634 ( = 0.438), indicating the expected positive relationship between both expert-based ratings.
Figure 2 shows in its left panel box plots of the expert-based land values for each of the four levels of the expert-based location ratings.
[Figure 2 about here.]
The median land values increase in line with the level of the expert-based rating, but the quartiles of the land values for locations with low and medium rating overlap to a large extend. The separation for the top two levels of the expert-based rating is more pronounced.
8

2.2 Estimation of the building component

We use the estimator proposed by Yatchew (1997) and Wang et al. (2011) for the estimation of . The basic idea of the estimator is that a(l) can be neglected when working with the differences of the variables of close observations. This requires that the data are ordered to be geographically close to each other. We follow Yatchew (1997) and order the observations along a path created from the nearest-neighbor algorithm. The Appendix explains the algorithm.
Taking the differences of two nearby observations i and i - 1 yields

pi - pi-1 = (zi - zi-1)  + a(li) - a(li-1) + i - i-1 .

(3)

If the location value function is sufficiently smooth, a(li)-a(li-1) becomes negligible, because li and li-1 are geographically close. The coefficient vector  can then be estimated consistently with ordinary least squares.7

Whereas Eq. 3 is ideal for providing intuition, a version of this regression equa-

tion with weighted higher order differences will lead to a more efficient estimator.

Letting myi 

m s=0

dsyi-s,

where

yi

can

be

a

scalar

or

a

vector,

and

denoting

the

differencing weights with ds, the improved estimation equation is

mpi = (mzi)  + ma(li) + mi .

(4)

The weights fulfill the two restrictions

mm

ds = 0 and

d2s = 1 ,

s=0 s=0

(5)

where the first restriction ensures that the location value function vanishes as the

sample size increases and the locations become close. The second ensures that

Var[m] = 2, i.e. the variance of the differenced error equals the variance of .
7Wang et al. (2011) provide a technical discussion of what minimal smoothness assumptions are required for consistency. Moreover, their Monte Carlo simulations show that the estimator works well even if the unknown function a(·) is bumpy or has sharp boundaries.

9

The ordinary least squares estimator m of Eq. 4 approaches asymptotic efficiency when m is chosen sufficiently large. Optimal weights for different values of m are tabulated in Hall et al. (1990, Table 1).
Table 3 presents the ordinary least squares estimates for the coefficients of Eq. 4, with m set to 10.8 The standard errors are calculated with a heteroscedasticityrobust sandwich estimator.
[Table 3 about here.]
The overall fit for Eq. 4 is remarkably good with an R2 = 0.830.9 Moreover, all of the estimated coefficients have reasonably signs and most of them are statistically significant at the usual levels. The price for a house increases, for instance, with both the floor size and the size and volume of all base areas in all storeys. The significant coefficients on the corresponding squared terms imply that these effects have diminishing rates. The age of the building, on the other hand, has a negative impact on the house price. The significant coefficient for the squared age term implies a decreasing depreciation rate, which stays positive over the whole range of the age variable (when evaluated at the mean value of the size variables). The magnitudes of the estimated effects of the binary indicator variables are reasonable in sign and magnitude as well. Relative to the price of building with a normal state of repair buildings with a poor (good) state of repair, for instance, demand a price rebate (premium).
The estimator m depends not only on m, but also on the ordering of observations regarding their geographical closeness. In the presented results the average distance between observations is about 95 meters with a standard deviation of 394 meters. To assess the impact of the nearest-neighbor algorithm on the estimated
8A difference order of m = 10 produces coefficient estimates that achieve approximately 95 percent efficiency relative to an estimator with the optimal rate of convergence (Yatchew, 1997).
9R2 is computed with 1 - s2m/sp2, where sm2 = (N - m)-1 Ni=-1m(mpi - zim )2, s2p is the variance of p, and N is the number of observations (Yatchew, 1997, Proposition 1).
10

building values, we re-ran the regressions 50 times, each time with a different ordering. The within standard deviation of predicted building component for these runs is approximately 3% of the (average) building value.10 Moreover, the coefficient of correlation between predicted building values from any two different runs is always well above 0.96. The results presented here are thus robust towards the specific ordering of observations.
Given m, we can adjust the per-square meter house prices for the buildung component and obtain the residuals ui = pi - zim. These first-stage residuals contain the location values to be extracted by the second stage of our method. Figure 3 shows box plots of these residuals for Berlin's districts.11 For the plot, the residuals are normalized to the unit interval and the districts are ordered according to the median of the expert-based location ranking.
[Figure 3 about here.]
Within each district, the residuals show substantial variation. This suggests that location values vary among areas within any given district.
2.3 Estimation of the location value surface
The second-stage of our method has two aims: (1) to separate the location values contained in the first-stage residuals ui from the transaction-specific noise and (2) to form areas with homogenous location values. To achieve these aims, we apply adaptive weights smoothing (AWS), a regression method developed by Polzehl and Spokoiny (2000, 2006) in the context of image denoising. AWS allows to separate
10We assume that the building value accounts for 50% of the house price. Taking the mean house price and floor size in Table 1 then leads to an average building value per sqm of 935 Euros. The within standard deviation of the predicted building component is 27 Euro.
11The inner-city district of Kreuzberg-Friedrichshain has no single-family house neighborhoods and is not part of the plot.
11

the underlying structure in the data (e.g. the shape of an organ in an X-ray or ultrasonic image) from the distorting noise. AWS does not impose a priori assumptions on the form of this underlying structure (i.e. the regression function). Rather, AWS recovers the unknown regression function contained in the noisy data by an iterative, locally adaptive smoothing algorithm. In this algorithm, the local regression estimate is successively improved by searching for the largest vicinity of a nearly constant level of the regression function.

In our application, this amounts to finding the largest area around each location

li in which the expected location value can be approximated well by a constant level.

We denote this level at li by a(li). Similar to well-known smoothing methods such as

kernel regression or nearest-neighbor estimation, AWS estimates a(li) by weighted

local averaging over ujs at li. However, to determine the weight of observation j

in forming the estimate of a(li), AWS does not only consider the distance between

lj and li (like other standard nonparametric smoothers do), but also adds a level

penalty. Formally, the estimator at location li in the k-th iteration is defined as

(k)
a(li) =

N j=1

wi(jk)uj

N j=1

wi(jk)

,

(6)

where the weights are computed as

wi(jk) = Kdist disti(jk) × Klev levi(jk) .

(7)

The weight of observation j in the average formed at i is thus determined by a product of two kernel functions K. Both kernel functions are nonnegative and nonincreasing on the positive semi-axis. That is, they give maximum weight if their respective argument is zero and declining weights as their arguments increase. The arguments of these kernel functions are the distance penalty distij and the level penalty levij, respectively. The distance penalty in iteration k is given by dist(ijk) = |(li, lj)/h(k)|2 where (li, lj) is the Euclidean distance between the locations of observations i and j and h(k) is the bandwidth in iteration k. Hence, as in standard nonparametric regression, observation j will receive the more weight in the estimate

12

at i, the closer its location to that of i. The level penalty in iteration k is computed

as

levi(jk) = -1 Ai(k-1)

(k-1)

(k-1) 2

a(li) - a(lj)

,

(8)

Ti(jk)
This penalty is based on the comparison of the regression estimates at lj and li in the previous iteration (k - 1). Hence, observation j will receive the more weight in

iteration k, the closer its estimated level has been to that of observation i in the

previous step. The term

n

A(ik-1) =

wi(jk)

j=1

(9)

equals the sum of the weights at i from the previous step and can be viewed as

(k-1)

(k-1)

the local sample size that rescales the squared distance a(li) - a(lj) . The

product of these two terms, Ti(jk), can be viewed as a test statistic of the hypothesis

a(li) = a(lj). Finally, the parameter  chosen by the econometrician acts as a critical

value for this test statistic: the larger , the smaller the impact of a particular

deviation of a(li) from a(lj) on the level penalty.

By amending the distance penalty of standard nonparametric estimation with a level penalty, AWS achieves both an extension of the scope of regression relations it can successfully tackle as well as an an increase in estimation efficiency. Both advantages will become clear when we complete our description of AWS by sketching the steps of its iterative algorithm. Further details are given in the Appendix.

In the initial step (k = 0), the AWS estimator at li behaves like a standard kernel estimator by setting wi(j0) = Kdist disti(j0) . That is, only the distance penalty is considered for determining the weight of any observation j. In subsequent steps, the distance penalty is relaxed by successively increasing the location bandwidth according to the rule h(k) = ch(k-1). The iterative algorithm terminates if ch(k-1) h where the parameter c controls the bandwidth growth. We set the initial bandwidth h(0) and c according to the suggestions in Polzehl and Spokoiny (details are given in the Appendix).

13

Hence, successively more distant observations are considered for forming the local average at li. The level penalty, which kicks in at iteration k = 1, ensures that this is justified. More distant observations may belong to locations where the the expected location value may be quite different from a(li), resulting in a biased estimate. This, however, is prevented by a large level penalty which effectively leads
(k)
to the exclusion of such an observation from the computation of a(li) . If, on the other hand, the current assessment of the expected location value at observation
(k-1)
j, i.e. a(lj) , is close to that at observation i, then observation j does receive weight despite its potentially substantial distance in location from li.
By relaxing the distance penalty and at the same time enforcing the level penalty, AWS identifies at any location the largest contiguous area of a nearly constant level of the expected location value. Unlike standard nonparametric smoothers, it thus allows more distant observations to be included in an estimate at any location as long as this is justified by homogeneity in expected location values. This not only increases the efficiency of the estimate (from the resulting increase in the local sample size), it also enables to identify shapes of regression relations that standard smoothers can not pick up. This modeling advantage is most pronounced in situations where the underlying regression function allows a piecewise constant approximation with large homogenous regions that are allowed to sharply differ at the boundaries.
The flexible AWS procedure involves several parameters that must be specified, in particular the smoothing parameters of both penalties.12 Since the location penalty is successively relaxed during the algorithm, the choice of its bandwidth, h, is much less important for AWS than for standard Kernel regression. The key parameter of AWS is , the factor that scales the level penalty. Too small values of  will result in an over-penalization of level differences between neighboring bins. As a result, areas of homogeneous location values may not be properly identified. Too large values of , on the other hand, will result in a loss of sensitivity towards
12Details on our choices of AWS' parameters are given in the Appendix
14

discontinuities in location values. Neighboring bins may be joined in this case to form an area of a common level of location values when this is not warranted. To resolve this trade-off, Polzehl and Spokoiny consider the (hypothetical) situation of a constant value surface. In this case, the final estimate of AWS should coincide with high probability with the globally constant location value. They suggest using the minimal value of  that ensures this `propagation condition'. This value of  does not depend on the particular globally constant location value and can be obtained from Monte Carlo simulations. This is the default value of  in the contributed package `aws' of the R-Project for Statistical Computing (Polzehl, 2011). We use this package to implement AWS.
AWS is designed to work on matrices. In our application, the matrix is a grid with the two dimensions `latitude' and `longitude' placed over the map of Berlin. A matrix where each of the 19,283 observations has its own bin has over 1.5 billion entries. This matrix is too large for the algorithm. To reduce the size of the matrix, we use binning (Fan and Marron, 1994). We generate a 300 × 300 = 90, 000 grid and allocate the observations to bins with the grid points as centers. Each bin has an approximate size of 171 × 114 meters. Applied to the data, 7,704 bins contain at least one observation, 3,354 bins contain exactly one, the average count per bin is 2.5 observations, and the maximum is 49.
Figure 4 plots the estimated location values a(l) for the bins within a map of Berlin. Estimates are normalized to the unit interval and coloring is used to represent their magnitudes.
[Figure 4 about here.]
The plot illustrates both the functioning and the advantages of AWS. Binning is visible from the somewhat angular appearance of similar colored areas but otherwise the colors, shapes and size of these areas is data-driven and locally adaptive. AWS identified these areas by relaxing the location penalty in successive iterations and
15

implicitly testing for local homogeneity of location values. As long as the location values are sufficiently similar, relaxing the location penalty is justified and adjacent bins are subsumed into an area.
3 Comparison with expert-based location assessments
Section 2.1 showed that the expert-based land values and location ratings agree in many cases regarding their assessment of the value of a location. We also expect a strong positive relationship between the expert-based assessments and the estimated location values, a(l). As the expert-based assessments do not agree in all instances, we will compare our estimated location values with each of them.
Figure 2 shows in its right panel box plots of the estimated location value, a(l), for the four levels of the expert-based rating. Similar to the expert-based land values (shown in the left panel of the figure), the medians of the estimated location values increase in line with the expert-based location rating; the quartiles of the estimated location values for locations with low and medium rating overlap also. The variance of the estimated location values is higher than the variance of the expert-based land values, except for locations with low rating. This is attributable to few first stage residuals that are rather large or small. These residuals could be the result of mis-specifications of the first stage regression or could be the result of aberrant idiosyncratic effects during the transaction.
Table 2 shows in Panel B the matching frequencies for the estimated location values and the expert-based location rating. As in Section 2.1, the estimated location values are converted into an ordinal rating. Even though the matching is not perfect, the majority of pairs lie on the diagonal of the contingency table. The statistic for the chi-square independence test is 10, 521, which is a highly unlikely realization under a 2(9)-distribution. We therefore reject the null of statistical independence between the two ratings at the usual significance levels. Estimates of Goodman and
16

Kruskal's  ( = 0.644) and Kendall's  ( = 0.466) indicate the expected positive relationship between both location assessments.
In order to compare the estimated location values with the expert-based land values, we rescale a(l) so that its median equals the median of the expert-based land values. The estimated location values and the expert-based land values are both estimates of the true but unobserved location value and we expect a strong positive correlation between them. Figure 5 shows a sunflower plot of the estimated location value and the expert-based land value. To work at the same level of geographical detail, the plot uses averages of the expert-based land values within bins.13 The plot represents the density of observations using stylized sunflowers. In a light sunflower, each petal represents one observation. In a dark sunflower, each petal represents several observations.14
[Figure 5 about here.]
The expected positive correlation between both location assessments is visible and strong, with a coefficient of correlation 0.840.15 The majority of paired observations lie on the 45 degree line, although a few particulary large (small) outliers are apparent again.
4 Conclusion
In this paper, we proposed a novel semiparametric method to extract location values out of house prices. The first stage of the method separates the price into a building
13The binning procedure removes potentially variation in the estimated location values that is still present in the expert-based land values. In particular, differences in the quality of locales within a bin, as well as differences in the time trend of land values between bins are a priori removed by binning and discounting with a Berlin-wide quality-adjusted land value index. Both effects are rather small as indicated by the average standard deviation of the expert-based land value within bins, which is only 13.31 Euros.
14A dark sunflower with p petals represents between p96 - 96/2 and p96 + 96/2 observations. 15Using the 19,283 individual observations gives a coefficient of correlation of 0.836.
17

component and a land component. The second stage employs adaptive weights smoothing (AWS), a nonparametric method to separate the residual from the first stage into the location value and a noise term. Using AWS has several advantages over standard nonparametric regression. It allows the size and shape of areas with a common location value to be completely determined by the data. They need not be symmetric or adhere to a particular shape. Moreover, unlike kernel regression, AWS does not require the location value surface to be smooth.
We apply the method to single-family house transactions from Berlin and obtain reliable results in the sense that they show agreement with expert-based location assessments. In particular, the estimated location values are highly correlated with, both, land values and ordinal location ratings that are provided by real estate experts. In summary, the estimated surface provides a comprehensive characterization of the relative location values of Berlin's residential areas. The methodology should thus prove useful for applications where location values are needed and no expertbased information is available or where such information should be complemented by data-driven flexible location value estimates.
A Appendix
A.1 Nearest-neighbor algorithm
The nearest-neighbor algorithm used in the estimation of the building component works as follows:
1. Initialization: Start with an arbitrary observation.
2. Iteration: Find its nearest neighbor with respect to their Euclidian distance and mark the observation as visited.
3. Stopping: Go back to Step 2 until all observations have been visited.
18

The resulting sequence of the visited locations provides the ordered observations. The nearest neighbor algorithm is easy to implement and computationally fast, but can lead to slightly different ordering sequences depending on the initial observation.

A.2 AWS algorithm

The AWS algorithm can be summarized as follows:

1. Initialization: The parameters , h(0), c and h are selected and the location

weights

wij = Kdist

 (li, lj) 2 h(0)

and presmoothed estimates

are calculated for all i, j.

(0)
a (li) =

j wi(j0)u^j j wi(j0)

2. Iteration: In each iteration k the following steps are performed for every design point, li, on the grid.

· Calculate the adaptive weights: For every point lj within the bandwidth

h(k) around point li the penalties

disti(jk) =

 (li, lj) h(k)

2
,

levi(jk) = -1Ai(k-1)

(k-1)

(k-1)

a (li) - a (li)

2
,

n

A(ik-1) =

wi(jk-1)

j=1

are computed and the weights are formed by wij = Kdist disti(jk) × Klev levi(jk) .

· Estimation: For every design point li the updated estimate

(k)
a (li) =

j wi(jk)u^j , j wi(jk)

and the sum of weights Ai(k) are calculated.

19

3. Stopping: If ch(k)  h, the algorithm terminates. Otherwise the bandwidth is set to h(k) = ch(k-1) and the algorithm continues with step 2.
A.3 AWS parameters
Several parameters affect the performance of the AWS estimation procedure. These parameters control constituent features of the method and should be chosen cautiously in light of the application at hand. In the following, we describe the choice of parameters for our application.
c, h(0), h(1), h, k: The number of iterations of AWS is determined by the maximal bandwidth h. With every iteration k the bandwith is incremented by the
1
factor c = (1.25) d where d = 2 is the dimension of the sample space. The algorithm terminates if ch(k-1)  h. Unlike classical nonparametric approaches, AWS does not necessarily suffer from oversmoothing. A relatively large maximal bandwidth h will, however, result in more iterations and thus increases the computational complexity. We set h to 15 which allows that quite far away points lj are (potentially) used to form an estimate for point li, but keeps the computional complexity reasonably low. With respect to the initial bandwidth h(0) and subsequent bandwiths h(1) we follow the suggestions in Polzehl and Spokoiny. In particular, we select h(0) = 9.6 and h(1) = 0.74, respectively. Both bandwidths are small enough so that the former i contains a sufficient number of design points in the initial iteration and the latter does not increase the bandwidth too much in every iteration.
Kdist, Klev: The kernel functions are defined on the positive semiaxis and fulfill Kdist (0) = Klev (0) = 1 for the case of a perfect match (in distance or level). In general, Kdist scales the distance penalty and is non-decreasing, whereas Klev decreases on the positive semiaxis. For both kernel functions we use the triangular kernel with
Kdist (distij) = (1 - distij) 1{+} and Klev (levij) = (1 - levij) 1{levij1} , (A1)
20

where levij is always positive (see Eq. 8).

: The parameter  scales the level penalty and is hence the most critical parameter of AWS. We follow Polzehl and Spokoiny and obtain  = 21.96 by monte carlo simulations. In particular, we compare the standard deviations of two estimates for a model with a (known) globally constant parameter value a (li) = a for all i. The first estimate, a (li), is obtained by AWS given a certain ; the second estimator, a (li), uses a very large value of  so that the AWS estimator converges to a nonadaptive kernel estimator. We search for the smallest  which fulfills the following inequality

kk
E a (li) - a (li)  (1 + ) E a (li) - a (li) , with  = 0.05.

(A2)

The intuition of this approach is to choose the minimal  so that AWS still recovers the global constant parameter value (with a probability ) while using the most adaptive bandwidth choice.

References
Anglin, P., and Gencay, R.: 1996, Semiparametric estimation of a hedonic price function, Journal of Applied Econometrics, 11, 633­648.
Bourassa, S. C., Hoesli, M., Scognamiglio, D. and Zhang, S.: 2011, Land leverage and house prices, Regional Science and Urban Economics, 41, 134­144.
Cheshire, P. and Sheppard, S.: 1995, On the price of land and the value of amenities, Economica, 62, 247­267.
Clapp, J. M.: 2004, A semiparametric method for estimating local house price indices, Real Estate Economics, 32, 127­160.
Colwell, P. F. and Munneke, H. J.: 2003, Estimating a price surface for vacant land in an urban area, Land Economics, 79, 15­28.
21

Fan, J. and Marron, J. S.: 1994, Fast implementations of nonparametric curve estimators, Journal of Computational and Graphical Statistics, 3, 35­56.
Hall, P., Kay, J. W. and Titterington, D. M.: 1990, Asymptotically optimal difference-based estimation of variance in nonparametric regression, Biometrika, 77, 521­528.
Polzehl, J.: 2011, AWS: adaptive weights smoothing, R package version 1.7-1, http://CRAN.R-project.org/package=aws.
Polzehl, J. and Spokoiny, V.: 2000, Adaptive weights smoothing with applications to image restoration, Journal of the Royal Statistical Society Series B, 62, 335­354.
Polzehl, J. and Spokoiny, V.: 2006, Propagation-separation approach for local likelihood estimation, Probability Theory and Related Fields, 135, 335­362.
Rosenthal, S. S.: 1999, Residential buildings and the cost of construction: New evidence on the efficiency of the housing market, Review of Economics and Statistics 81, 288­302.
Rossi-Hansberg, E., Sarte, P.-D. and Owen III, R. O.: 2010, Housing externalities, Journal of Political Economy, 118, 485­535.
Schulz, R. and Werwatz, A.: 2011, Is there an equilibrating relationship between house prices and replacement cost? Empirical evidence from Berlin, Journal of Urban Economics, 69, 288­302.
Wang, L., Brown, L. D., and Cai, T. T.: 2011, A difference based approach to the semiparametric partial linear model, Electronic Journal of Statistics, 5, 619­641.
Yatchew, A.: 1997, An elementary estimator of the partial linear model, Economic Letters, 57, 135­143.
22

23

Figure 1: Transacted houses in Berlin, 1996-2010. Figure shows the location of the transacted single-family houses within in the city. Number of observations is 19,283. Solid lines represent the borders of Berlin's 12 administrative districts (as of the year 2000). Shaded blue areas are lakes and rivers. Shaded green areas are parks and forests.

Low Low

Medium

Medium

High

High

24

Excellent

Excellent

-1,000 -500

0 500 1,000 1,500 2,000 2,500 3,000 Expert-based land value

-1,000 -500

0 500 1,000 1,500 2,000 2,500 3,000 Estimated location value

Figure 2: Box plots of expert-based land value and estimated location value. Left panel shows box plots of the expert-based land value for each of the four levels of the expert-based location rating. Right panel shows box plots of the estimated location value for each of the four levels of the expert-based location rating. Number of observations is 19,283. Line that separates the box is the median. Lower (upper) hinge of box represents 25th (75th) percentile. Length of whiskers is 1.5 times the IQR below (above) the 25th (75th) percentile.

Charlottenburg-Wilmersdorf Steglitz-Zehlendorf Reinickendorf Lichtenberg-Hohenschoenhausen Treptow-Koepenick Tempelhof-Schoeneberg Spandau Pankow Marzahn-Hellersdorf Neukoelln Mitte 0 .2 .4 .6 .8 1 Normalized land value
Figure 3: First-stage residuals by district. Shows box plots for the normalized firststage residuals for Berlin's administrative districts. Number of observations is 19,283. Districts are sorted in descending order with respect to the median of the expert-based location rating. Line that separates the box is the median. Lower (upper) hinge of box represents 25th (75th) percentile. Length of whiskers is 1.5 times the IQR below (above) the 25th (75th) percentile.
25

26

Figure 4: Estimated location value surface. Map of Berlin with the estimated location values a(l).

1500

Expert-based land value

1000

500

0 -1000 -500

0 500 1000 1500 2000 2500 3000 Estimated location value

Figure 5: Sunflower plot of expert-based land values and estimated location value. Shows sunflower plot of the bin average of expert-based land value and estimated location value, a(l). Both figures are in real (year 2000) Euros. Number of observations is 7,704. Each petal of a light sunflower represents 1 observation. Each petal of a dark sunflower represents several observations. Circles represent individual observation in low density region.

27

Table 1: Summary statistics for transacted single-family houses. Number of observations is 19,283. Prices and land values are in year 2000 Euros. Floor size, gross base, and lot size are in square meters. Gross volume is in cubic meters. Gross area is the sum of all base areas in all storeys, gross volume is the corresponding volume. 8,259 objects have information on the gross volume and 15,325 on the gross base. Age of the building in years at the transaction date. Attic storey means that the attic is upgraded for living. Expert-based land value per square meter is the appraised value as if land were undeveloped. Expert-based location rating is an ordinal ranking of the neighborhood of the house.

Mean Median Std. Dev.

House price

273,168 231,176 177,337

Building characteristics

Floor size

145.99 135.00

56.23

Gross area

244.24 228.00

95.69

Gross volume

666.83 612.00

262.78

Storeys

1.5 1.0

0.6

Age

42 42

29

Type

Detached

0.55

Semi-detached

0.22

Row-house

0.23

Attic storey

0.55

Flat roof

0.12

No cellar

0.13

Part cellar

0.12

State of repair

Poor

0.08

Normal

0.61

Good

0.31

Land characteristics

Lot size

578.56 525.00

313.33

Unusual features of the house

Physical

0.03

Legal

0.18

Expert-based land values and location ratings

Land value

284.97 256.46

148.41

Location rating

Low 0.29

Medium

0.49

High

0.20

Excellent

0.02

28

Table 2: Contingency tables for ordinal assessments. Panel A gives the relative

frequencies of the matches of the expert-based ratings and the converted ordinal expert-

based land values. Panel B gives the relative frequencies of the matches of the expert-based

ratings and the converted ordinal location values a(l). The Panel C gives the expected

relative frequencies if expert-based ratings were randomly allocated onto itself. Pearson's

2-statistic is for the null that rows and columns are statistically independent. P-value is

for

a

2(9)-distribution.

Goodman

and

Kruskal's



is

calculated

as

Ns -Nd Ns +Nd

where

Ns

is

the

number of pairs of cases ranked in the same order and Nd is the number of pairs ranked

differently. Kendall's  is calculated as 

Ns -Nd

(N 2- Nc2)(N 2-

Nr2) where Nc2 and Nr2 are the

squared column and row marginals, respectively.

Panel A: Expert-based land values

Expert-based rating

Low Medium High Excellent

Low 0.131 0.151 0.011

0.000

Medium

0.140

0.287 0.058

0.000

High

0.022

0.048 0.131

0.002

Excellent

0.000

0.000 0.003

0.016

Total

0.293

0.486 0.202

0.019

2-stat. 2.1e+04

 0.634

P-value

0.000

 0.438

Panel B : Estimated location values

Expert-based rating

Low Medium High Excellent

Low 0.129 0.158 0.006

0.000

Medium

0.142

0.289 0.055

0.000

High

0.023

0.039 0.129

0.012

Excellent

0.000

0.000 0.012

0.007

Total

0.293

2-stat. 1.1e+04

0.486 0.202  0.644

0.019

P-value

0.000

 0.446

Panel C : Random allocation, expected frequencies

Expert-based rating

Low Medium High Excellent

Low 0.086 0.142 0.059

0.006

Medium

0.142

0.236 0.098

0.009

High

0.059

0.098 0.041

0.004

Excellent

0.006

0.009 0.004

0.001

Total 2-stat.

0.293 0.018

0.486 0.202  0.000

0.019

P-value

1.000

 0.000

Total 0.293 0.486 0.202 0.019 1.000
Total 0.293 0.486 0.202 0.019 1.000
Total 0.293 0.486 0.202 0.019 1.000

29

Table 3: Effect of building characteristics on house price. Table reports ordinary least squares estimates of Eq. 4. Continuous explanatory variables--floor size, gross area, gross volume, and age--are per sqm lot size. The gross volume of a building is used whenever the gross area was missing. Standard errors are calculated with heteroscedasticity robust sandwich estimator. *** significant at 1%-level ** significant at 5%-level * significant at 10%-level.

Dependent variable: Price per sqm lot size

Floor size Floor size squared Gross area Gross area squared Gross volume Gross volume squared Floor size × age Gross area × age Gross volume × age Floor size × gross area Floor size × gross volume Age Age squared Semi-detached Row house Good state of repair Poor state of repair 2 storeys 3 storeys Attic storey Flat roof No cellar Part cellar Unusual legal circumstances Unusual physical circumstances

Coef. 500.710
-0.784 688.681
-0.630 248.891
-0.060 -0.884 -4.421 -1.604 1.287 0.315 -198.249 9.235 2.497 -1.075 86.035 -73.713 4.425 73.323 10.301 10.664 23.197 -2.990 -7.848 -24.015 Obs. 19,273

Std. Err. 64.624 0.446 36.731
0.101 18.367
0.020 0.806 0.507 0.201 0.388 0.210 106.371 1.144 3.492 5.563 3.672 3.977 3.973 16.431 3.241 4.215 4.311 3.620 3.472 6.204 R2 0.830

30

SFB 649 Discussion Paper Series 2012
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "HMM in dynamic HAC models" by Wolfgang Karl Härdle, Ostap Okhrin and Weining Wang, January 2012.
002 "Dynamic Activity Analysis Model Based Win-Win Development Forecasting Under the Environmental Regulation in China" by Shiyi Chen and Wolfgang Karl Härdle, January 2012.
003 "A Donsker Theorem for Lévy Measures" by Richard Nickl and Markus Reiß, January 2012.
004 "Computational Statistics (Journal)" by Wolfgang Karl Härdle, Yuichi Mori and Jürgen Symanzik, January 2012.
005 "Implementing quotas in university admissions: An experimental analysis" by Sebastian Braun, Nadja Dwenger, Dorothea Kübler and Alexander Westkamp, January 2012.
006 "Quantile Regression in Risk Calibration" by Shih-Kang Chao, Wolfgang Karl Härdle and Weining Wang, January 2012.
007 "Total Work and Gender: Facts and Possible Explanations" by Michael Burda, Daniel S. Hamermesh and Philippe Weil, February 2012.
008 "Does Basel II Pillar 3 Risk Exposure Data help to Identify Risky Banks?" by Ralf Sabiwalsky, February 2012.
009 "Comparability Effects of Mandatory IFRS Adoption" by Stefano Cascino and Joachim Gassen, February 2012.
010 "Fair Value Reclassifications of Financial Assets during the Financial Crisis" by Jannis Bischof, Ulf Brüggemann and Holger Daske, February 2012.
011 "Intended and unintended consequences of mandatory IFRS adoption: A review of extant evidence and suggestions for future research" by Ulf Brüggemann, Jörg-Markus Hitz and Thorsten Sellhorn, February 2012.
012 "Confidence sets in nonparametric calibration of exponential Lévy models" by Jakob Söhl, February 2012.
013 "The Polarization of Employment in German Local Labor Markets" by Charlotte Senftleben and Hanna Wielandt, February 2012.
014 "On the Dark Side of the Market: Identifying and Analyzing Hidden Order Placements" by Nikolaus Hautsch and Ruihong Huang, February 2012.
015 "Existence and Uniqueness of Perturbation Solutions to DSGE Models" by Hong Lan and Alexander Meyer-Gohde, February 2012.
016 "Nonparametric adaptive estimation of linear functionals for low frequency observed Lévy processes" by Johanna Kappus, February 2012.
017 "Option calibration of exponential Lévy models: Implementation and empirical results" by Jakob Söhl und Mathias Trabs, February 2012.
018 "Managerial Overconfidence and Corporate Risk Management" by Tim R. Adam, Chitru S. Fernando and Evgenia Golubeva, February 2012.
019 "Why Do Firms Engage in Selective Hedging?" by Tim R. Adam, Chitru S. Fernando and Jesus M. Salas, February 2012.
020 "A Slab in the Face: Building Quality and Neighborhood Effects" by Rainer Schulz and Martin Wersing, February 2012.
021 "A Strategy Perspective on the Performance Relevance of the CFO" by Andreas Venus and Andreas Engelen, February 2012.
022 "Assessing the Anchoring of Inflation Expectations" by Till Strohsal and Lars Winkelmann, February 2012.
SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

SFB 649 Discussion Paper Series 2012
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
023 "Hidden Liquidity: Determinants and Impact" by Gökhan Cebiroglu and Ulrich Horst, March 2012.
024 "Bye Bye, G.I. - The Impact of the U.S. Military Drawdown on Local German Labor Markets" by Jan Peter aus dem Moore and Alexandra Spitz-Oener, March 2012.
025 "Is socially responsible investing just screening? Evidence from mutual funds" by Markus Hirschberger, Ralph E. Steuer, Sebastian Utz and Maximilian Wimmer, March 2012.
026 "Explaining regional unemployment differences in Germany: a spatial panel data analysis" by Franziska Lottmann, March 2012.
027 "Forecast based Pricing of Weather Derivatives" by Wolfgang Karl Härdle, Brenda López-Cabrera and Matthias Ritter, March 2012.
028 "Does umbrella branding really work? Investigating cross-category brand loyalty" by Nadja Silberhorn and Lutz Hildebrandt, April 2012.
029 "Statistical Modelling of Temperature Risk" by Zografia Anastasiadou, and Brenda López-Cabrera, April 2012.
030 "Support Vector Machines with Evolutionary Feature Selection for Default Prediction" by Wolfgang Karl Härdle, Dedy Dwi Prastyo and Christian Hafner, April 2012.
031 "Local Adaptive Multiplicative Error Models for High-Frequency Forecasts" by Wolfgang Karl Härdle, Nikolaus Hautsch and Andrija Mihoci, April 2012.
032 "Copula Dynamics in CDOs." by Barbara Choro-Tomczyk, Wolfgang Karl Härdle and Ludger Overbeck, May 2012.
033 "Simultaneous Statistical Inference in Dynamic Factor Models" by Thorsten Dickhaus, May 2012.
034 "Realized Copula" by Matthias R. Fengler and Ostap Okhrin, Mai 2012. 035 "Correlated Trades and Herd Behavior in the Stock Market" by Simon
Jurkatis, Stephanie Kremer and Dieter Nautz, May 2012 036 "Hierarchical Archimedean Copulae: The HAC Package" by Ostap Okhrin
and Alexander Ristig, May 2012. 037 "Do Japanese Stock Prices Reflect Macro Fundamentals?" by Wenjuan
Chen and Anton Velinov, May 2012. 038 "The Aging Investor: Insights from Neuroeconomics" by Peter N. C. Mohr
and Hauke R. Heekeren, May 2012. 039 "Volatility of price indices for heterogeneous goods" by Fabian Y.R.P.
Bocart and Christian M. Hafner, May 2012. 040 "Location, location, location: Extracting location value from house
prices" by Jens Kolbe, Rainer Schulz, Martin Wersing and Axel Werwatz, May 2012.
SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

