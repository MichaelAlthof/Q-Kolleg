BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2014-005
Functional stable limit theorems for efficient
spectral covolatility estimators
Randolf Altmeyer* Markus Bibinger*
* Humboldt-Universit‰t zu Berlin, Germany
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universit‰t zu Berlin Spandauer Straﬂe 1, D-10178 Berlin

Functional stable limit theorems for efficient spectral covolatility estimators
Randolf Altmeyer & Markus Bibinger1
Institut fu®r Mathematik, Humboldt-Universita®t zu Berlin, Unter den Linden 6, 10099 Berlin, Germany
Abstract We consider noisy non-synchronous discrete observations of a continuous semimartingale. Functional stable central limit theorems are established under high-frequency asymptotics in three setups: onedimensional for the spectral estimator of integrated volatility, from two-dimensional asynchronous observations for a bivariate spectral covolatility estimator and multivariate for a local method of moments. The results demonstrate that local adaptivity and smoothing noise dilution in the Fourier domain facilitate substantial efficiency gains compared to previous approaches. In particular, the derived asymptotic variances coincide with the benchmarks of semiparametric Crame¥r-Rao lower bounds and the considered estimators are thus asymptotically efficient in idealized sub-experiments. Feasible central limit theorems allowing for confidence are provided. Keywords: adaptive estimation, asymptotic efficiency, local parametric estimation, microstructure noise, integrated volatility, non-synchronous observations, spectral estimation, stable limit theorem AMS 2000 subject classification: 62G05, 62G20, 62M10 JEL classes: C14, C32
1. Introduction
The estimation of integrated volatility and integrated covolatility (sometimes referred to as integrated variance and covariance) from high-frequency data is a vibrant current research topic in statistics for stochastic processes. Semimartingale log-price models are widely used in financial economics. Its pivotal role for portfolio optimization and risk management makes the integrated covolatility matrix a key quantity of interest in econometrics and finance. During the last decade the increasing availability of data from high-frequency recordings of trades or orders has provided the statistician with rich data sets. Yet, the consequence of this richness of data is double-edged. On the one hand, high-frequency observations are almost close to continuous-time observations which should allow for a very precise and highly efficient semiparametric estimation of integrated covolatilities. On the other hand, it has turned out that a traditional pure semimartingale model has several limitations in describing stylized facts of the high-frequency data and therefore does not afford a suitable risk estimation. It is nowadays well-known that effects ascribed to market microstructure frictions interfere at high frequencies with a latent price evolution that can be appropriately described by a semimartingale. Also, non-synchronous observations in a multi-dimensional setup require a thorough handling or can cause unwanted effects.
1Financial support from the Deutsche Forschungsgemeinschaft via SFB 649 `O® konomisches Risiko', HumboldtUniversita®t zu Berlin, is gratefully acknowledged.
1

A prominent model that accounts for market microstructure in high-frequency observations is an additive noise model, in which a continuous semimartingale is observed with i.i.d. observation errors. The problem of estimating the integrated volatility in the one-dimensional model with noise, as well as multi-dimensional covolatility matrix estimation from noisy and non-synchronous observations, have attracted a lot of attention in recent years and stimulated numerous research contributions from different areas. While the importance for applications is one driving impulse, the model allures researchers from stochastic calculus and mathematical statistics foremost with its intriguing intrinsic properties and surprising new effects. In this work, we establish central limit theorems for estimators in a general setup, with noisy discrete observations of a continuous semimartingale in the one-dimensional case and noisy and non-synchronous observations multi-dimensional. The vital novelty is that the obtained asymptotic variances of the spectral estimators are smaller than for previous estimation approaches and coincide with the lower Crame¥r-Rao-type bounds in simplified sub-models. The estimators are thus asymptotically efficient in these sub-models in which the notion of efficiency is meaningful and explored in the literature. Stability of weak convergence and feasible limit theorems allow for confidence intervals.

There exist two major objectives in the strand of literature on volatility estimation:

1. Providing methods for feasible inference in general and flexible models. 2. Attaining the lowest possible asymptotic variance.

The one-dimensional parametric experiment in which the volatility  is a constant parameter and

without drift and with Gaussian i.i.d. noise has been well understood by a LAN (local asymptotic nor-

mality) result by Gloter and Jacod (2001). While it is commonly known that for n regularly spaced discrete observations n1/2 is the optimal convergence rate in absence of noise and 24 the variance lower bound, Gloter and Jacod (2001) showed that the optimal rate with noise declines to n1/4 and the lower variance bound is 83, when 2 is the variance of the noise. Recent years have witnessed

the development and suggestion of various estimation methods in a nonparametric framework that

can provide consistent rate-optimal estimators. Stable central limit theorems have been proved. Let

us mention the prominent approaches by Zhang (2006), Barndorff-Nielsen et al. (2008), Jacod et al.

(2009) and Xiu (2010) for the one-dimensional case and A®it-Sahalia et al. (2010), Barndorff-Nielsen

et al. (2011), Bibinger (2011) and Christensen et al. (2013) for the general multi-dimensional setup.

A major focus has been to attain a minimum (asymptotic) variance among all proposed estimators

which at the slow optimal convergence rate could result in substantial finite-sample precision gains.

For instance Barndorff-Nielsen et al. (2008) have put emphasis on the construction of a version of their kernel estimator which asymptotically attains the bound 83 in the parametric sub-experiment.

Nonparametric efficiency is considered by Reiﬂ (2011) in the one-dimensional setup and recently by

Bibinger et al. (2013) in a multi-dimensional non-synchronous framework. Also for the nonpara-

metric experiment without observational noise efficiency is subject of current research, see Renault

et al. (2013) and Cle¥ment et al. (2013) for recent advances. Jacod and Mykland (2013) have pro-

posed an adaptive version of their pre-average estimator which achieves an asymptotic variance of

ca. 1.07 ∑ 8

t 0

s3

ds

and

8

t 0

s3

ds

is

the

nonparametric

lower

bound.

Reiﬂ (2011) introduced a spectral approach motivated by an equivalence of the nonparametric and a

locally parametric experiment using a local method of moments. In contrast to all previous estimation

techniques, the spectral estimator in Reiﬂ (2011) attains the Crame¥r-Rao efficiency lower bound for the

asymptotic variance. The estimator has been extended to the multi-dimensional setting in Bibinger

and Reiﬂ (2013) and Bibinger et al. (2013). However, the notion of nonparametric efficiency and

the construction of the estimators have been restricted to the simplified statistical experiment where a

2

continuous martingale without drift and with time-varying but deterministic volatility is observed with additive Gaussian noise. The main contribution of this work is to investigate the spectral approach under model misspecification in the general nonparametric standard setup, i.e. with drift, a general random volatility process and a more general error distribution. We show that the estimators significantly improve upon existing estimation methods also in more complex models which are of central interest in finance and econometrics. We pursue a high-frequency asymptotic distribution theory. The main results are functional stable limit theorems with optimal convergence rates and with variances that coincide with the lower bounds in the sub-experiments. The asymptotic analysis combines the theory to prove stable limit theorems by Jacod (1997), applied in similar context also in Fukasawa (2010) and Hayashi and Yoshida (2011), with Fourier analysis, matrix algebra and proofs of tightness results. Those pop up by the fact that the efficient spectral estimation employs smoothing in the Fourier domain, because the method of moments is based on multi-dimensional Fisher information matrix calculus and because the estimation is carried out in a two-stage approach where in a first step the local covolatility matrix is pre-estimated from the same data. This article is structured into six sections. Following this introduction, Section 2 introduces the statistical model and outlines all main results in a concise overview. Section 3 revisits the elements of the spectral estimation approach and the multivariate local method of moments. In Section 4 we explain the main steps of the strategy of proofs of the functional central limit theorems. Mathematical details are given in Section 6. In Section 5 we present a Monte Carlo study.

2. Statistical model & Main results
Let us first introduce the statistical model, fix the notation and gather all assumptions for the oneand the multi-dimensional setup.

2.1. Theoretical setup and assumptions First, consider a one-dimensional Ito^ semimartingale

tt
Xt = X0 + bs ds + s dWs ,
00

(1)

on a filtered probability space , F , (Ft)t0, P .

Assumption (H-1). We pursue the asymptotic analysis under two structural hypotheses for the volatility process of which one must be satisfied:

( - 1) There exists a random variable L with at least four finite moments, i.e. with E L4 < , such that t  t is almost surely -Ho®lder continuous on [0, 1] for  > 1/2 and Ho®lder constant L, i.e. |t - s|  L |t - s| , 0  t, s  1, almost surely.

( - 2) The process  is itself a continuous Ito^ semimartingale, i.e. there exist a random variable 0 and adapted ca`dla`g processes ~b = ~bt 0t1, ~ = (~t)0t1 and ~ = (~t)0t1 such that

tt

t

t = 0 + ~bs ds + ~s dWs + ~s dWs.

00

0

(2)

W is an (Ft)0t1-Brownian motion which is independent of W .

3

Furthermore, suppose there exists a constant  > 0 such that |t| >  uniformly for 0  t  1. For the drift process, assume there exists a random variable L with E (L )2 <  such that t  bt
is almost surely -Ho®lder continuous on [0, 1] for  > 0 and Ho®lder constant L , i.e. |bt - bs|  L |t - s|, 0  t, s  1, almost surely.

We work within the model where we have indirect observations of X diluted by noise.

Assumption (Obs-1). The semimartingale X is observed at regular times i/n, i = 0, . . . , n, with observational noise:

Yi = Xi/n + i, i = 0, . . . , n .

(3)

The discrete-time noise process ( i)i=0,...,n is a sequence of i.i.d. real random variables with E[ i] = 0, variance 2 and having finite eighth moments. We assume the noise process is independent of F. Set
Gt = Ft  ( 0, . . . , l : l/n  t, l  N) for 0  t  1, and the filtered probability space (, G, (Gt)0t1, P) which accommodates the signal and the noise process.

For the multi-dimensional case, we focus on a d-dimensional continuous Ito^ semimartingale

tt
Xt = X0 + bs ds + s dWs
00

(4)

on a filtered probability space (, F , (Ft), P) with (Ft) being a right-continuous and complete fil-

tration and W being here a d-dimensional (Ft)-adapted standard Brownian motion. The integrated

covolatility matrix is denoted

t 0

s

ds,

s

=

ss

.

It

coincides

with

the

quadratic

covariation

ma-

trix [X, X]t of the semimartingale X. We denote the spectral norm by ∑ and define f  :=

supt[0,1] f (t) . Consider Ho®lder balls of order   (0, 1] and with radius R > 0:

C(R) = {f  C([0, 1], Rd◊d )| f C  R} ,

f C :=

f  + sup
x=y

f (x) - f (y) |x - y|

.

We assume the following regularity conditions.

Assumption (H-d). The drift b is a d-dimensional (Ft)-adapted process with b  C(R) for some R > 0,  > 0 and the stochastic instantaneous volatility process  is a (d ◊ d )-dimensional (Ft)adapted process satisfying one of the following regularity conditions:

( - 1)   C(R) for some R > 0 and with Ho®lder exponent  > 1/2.

( - 2)  is a continuous Ito^ semimartingale of the form (4) whose characteristics are assumed to be ca` dla` g.

Furthermore, we assume that the positive definite matrix s satisfies s  Ed, uniformly, in the sense of Lo®wner ordering of positive definite matrices. This is the analogue of "bounded from below" for d = 1.

We consider a very general framework with noise and in which observations come at non-synchronous sampling times.

4

Assumption (Obs-d). The signal process X of the form (4) is discretely and non-synchronously observed on [0, 1]. Observation times ti(l), 0  i  nl, l = 1, . . . , d, are described by quantile transformations t(il) = Fl-1(i/nl), 0  i  nl, 1  l  d, with differentiable distribution functions Fl, 1  l  d, Fl(0) = 0, Fl(1) = 1 and Fl  C([0, 1], [0, 1]) with F C bounded for some  > 1/2 and Fl strictly positive. The observation times are independent of X. We pursue asymptotics as there exists a sequence n such that np/n  cp with constants 0 < cp <  for all p = 1, . . . , d.
Observations are subject to an additive noise:

Yi(l) = Xt((ill)) +

(l) i

,

i

=

0,

.

.

.

,

nl

.

The

observation

errors

are

assumed

to

be

i.i.d. with

expectation

zero

and

l2

=

Var(

(l) i

)

and

inde-

pendent of X and the observation times. Furthermore, the errors are mutually independent for all

components and eighth moments exist. Again, we shall write (, G, (Gt), P) for the probability space

that accommodates Y .

Our analysis includes deterministic and random observation times which are independent of Y . Though Assumption (Obs-d) displays to some extent still an idealization of realistic market microstructure dynamics, our observation model constitutes the established setup in related literature and captures the main ingredients of realistic log-price models. We aim at exploring the semiparametric efficient methods by Reiﬂ (2011) and Bibinger et al. (2013) in this benchmark model.

2.2. Mathematical concepts and notation
Denote ni Y (l) = Yi(l) - Yi(-l)1, 1  i  nl, l = 1, . . . , d, the increments of Y (l) and analogously for X and other processes. In the one-dimensional case, we write nY = (ni Y )1in  Rn for the vector of increments. We shall write Zn = OP(n) (Zn = OP(n)) for real random variables, to express that the sequence n-1Zn is bounded (tends to zero) in probability under P. Analogously O and O are used for deterministic sequences. To express that terms are of the same asymptotic order we write Zn pYn if Zn = OP(Yn) and Yn = OP(Zn) and likewise for deterministic terms. Also, we use the short notation An Bn for An = O(Bn). Convergence in probability and weak convergence are denoted by P and -d;-st refers to stable weak convergence with respect to G - if not further specified. We write Xn -ucp X for processes Xn, X to express shortly that supt[0,1] |Xtn - Xt| P 0. lm is Kronecker's delta, i.e. lm = 1 for l = m, lm = 0 else. For functional convergence of processes we focus on the space D ([0, 1]), the space of ca`dla`g functions (right-continuous with left
limits).
Recall the definition of stable weak convergence which is an essential concept in asymptotic theory for volatility estimation. For a sub--field A  F, a sequence of random variables (Xn) taking values in a Polish space (E, E) converges A-stably, if

lim
n

E

[Z f

(Xn)]

=

µ(d, dx)Z()f (x)
◊E

with a random probability measure µ on ( ◊ E, A  E) and for all continuous and bounded f and A-measurable bounded random variables Z. The definition is equivalent to joint weak convergence of (Z, Xn) for every A-measurable random variable Z. Thus F-stable weak convergence means limn E [f (Xn)Z] = E [f (X)Z] for all bounded continuous f and bounded measurable Z, where the limit X of (Xn) is defined on an extended probability space ( , F , P ). In our setup, the extended space will be given by the orthogonal product of (, F, P) and an auxiliary space (~ , F~, P~).

5

We refer to Podolskij and Vetter (2010) for more information on stable convergence.

For the multi-dimensional setting the vec-operator and Kronecker products of matrices will be important. For a matrix A  Rd◊d we write the entries Apq, 1  p  d, 1  q  d, and the vector of its
entries obtained by stacking its columns one below each other

vec(A) = A11, A21, . . . , Ad1, A12, A22, . . . , Ad2, . . . , Ad(d-1), Add  Rd2 .

The transpose of a matrix A is denoted by A . For matrix functions in time , for instance the covolatility matrix, we write the entries A(tpq). The Kronecker product A  B  Rd2◊d2 for A, B  Rd◊d is defined as
(A  B)d(p-1)+q,d(p -1)+q = App Bqq , p, q, p , q = 1, . . . , d.
In the multivariate limit theorems, we account for effects by non-commutativity of matrix multiplication. It will be useful to standardize limit theorems such that the matrix

Z = COV(vec(ZZ )), for Z  N (0, Ed) standard Gaussian,

(5)

appears as variance-covariance matrix of the standardized form instead of the identity matrix. This matrix is the sum of the d2-dimensional identity matrix Ed2 and the so-called commutation matrix Cd,d that maps a (d ◊ d) matrix to the vec of its transpose Cd,d vec(A) = vec(A ). The matrix Z/2
is idempotent and introduced in Abadir and Magnus (2009), Chapter 11, as the symmetrizer matrix.

Note that in the multi-dimensional experiment under equidistant synchronous non-noisy observations of X, the sample realised covolatility matrix IC = in=1(Xi/n -X(i-1)/n)(Xi/n -X(i-1)/n) obeys
the central limit theorem:

1
vec n1/2 IC - s ds
0

1

-st N 0,

s  s Z ds ,

0

(6)

where similarly as in our result below the matrix Z appears as one factor in the asymptotic vari-

ance and remains after standardization. For background information on matrix algebra, especially

tensor calculus using the Kronecker product and vec-operator we refer interested readers to Abadir

and Magnus (2009). Note the crucial relation between the Kronecker product and the vec-operator vec(ABC) = (C  A) vec(B). In the multi-dimensional setup we introduce a diagonal matrix function of noise levels H(t) = diag l l(Fl-1) (t) 1/2 1ld incorporating constants l when n/nl  l and by a locally constant approximation of the observation frequencies a bin-wise locally constant approximation of H:

Hnk = diag(l2l(Fl-1) ((k - 1)hn) 1ld = diag(Hlkhn )1ld .

(7)

We employ the notion of empirical scalar products in the fashion of Bibinger and Reiﬂ (2013), which is recalled in Definition 1 in the Appendix, along with some useful properties.

2.3. Outline of the main results
In the sequel, we present the three major results of this work in Theorem 1, Theorem 2 and Theorem 3 and concisely discuss the consequences. Theorems 1 and 2 establish functional stable central limit theorems in a general semimartingale setting for the spectral integrated volatility and covolatility estimator by Bibinger and Reiﬂ (2013). Theorem 3 gives a multivariate limit theorem for the localized method of moment approach by Bibinger et al. (2013). These methods developed in Reiﬂ (2011), Bibinger and Reiﬂ (2013) and Bibinger et al. (2013) and briefly explained in a nutshell in Section 3.1 attain asymptotic efficiency lower variance bounds in the simplified model without drift, with independent volatility and covolatility processes and normally distributed noise.

6

Theorem 1. In the one-dimensional experiment, on Assumption (H-1) and Assumption (Obs-1), for the adaptive spectral estimator of integrated squared volatility IVn,t, stated in (22a) below, the functional stable weak convergence

tt

1
n4

IVn,t -

s2 ds -st

8 |s3| dBs

00

(8)

applies as n   on D [0, 1], where B is a Brownian motion defined on an extension of the original probability space (, G, (Gt)0t1, P), independent of the original -algebra G. Moreover, the implicitly obtained variance estimator VnI,Vt in (22b) provides for 0  t  1 the feasible central limit theorem:

t
VnI,Vt -1/2 IVn,t - s2 ds -d N (0, 1) .
0

(9)

Remark 1. The convergence rate in (8) and (9) is optimal, already in the parametric subexperiment,

see Gloter and Jacod (2001). IVn,1 is asymptotically mixed normally distributed with random asymp-

totic variance

1 0

8

s3

ds. This asymptotic variance coincides with the lower bound derived by Reiﬂ

(2011) in the subexperiment with time-varying but deterministic volatility, without drift and Gaussian

error distribution. The spectral estimator of squared integrated volatility is hence asymptotically effi-

cient in this setting. For the general semimartingale experiment the concept of asymptotic efficiency

is not developed yet, it is conjectured that the lower bound has analogous structure, see Jacod and

Mykland (2013). Theorem 1 establishes that the asymptotic variance of the estimator has the same

form in the very general framework and stable convergence holds true. The feasible limit theorem (9)

allows to provide confidence bands and is of pivotal importance for practical capability.

Theorem 2. In the multi-dimensional experiment, on Assumption (H-d) and Assumption (Obs-d),
(p,q)
for the adaptive spectral estimator of integrated covolatility ICVn,t , stated in (25a) below, the functional stable weak convergence

1
n4

(p,q)
ICVn,t -

t
s(pq) ds -st

t
vs(p,q) dBs

00

(10)

applies for np/n  cp and nq/n  cq with 0 < cp < , 0 < cq < , as n   on D [0, 1], where B is a Brownian motion defined on an extension of the original probability space (, G, (Gt)0t1, P), independent of the original -algebra G. The asymptotic variance process is given by

vs(p,q) 2 = 2 (Fp-1) (s)(Fq-1) (s)cp-1cq-1(As2 - Bs)Bs 1/2

with the terms

◊ As + A2s - Bs - sgn(A2s - Bs) As - As2 - Bs ,

As

=

(spp)

(Fq-1) (Fp-1)

(s)cp (s)cq

+

(sqq)

(Fp-1) (Fq-1)

(s)cq (s)cp

,

Bs = 4 s(pp)s(qq) + s(pq) 2 .

(11)

Moreover,

the

implicitly

obtained

variance

estimator

V ICV(p,q)
n,t

in

(25b)

provides

for

0



t



1

the

feasible central limit theorem:

V ICV(p,q) -1/2
n,t

(p,q)
ICVn,t -

t
(spq) ds

-d N (0, 1) .

0

(12)

7

Remark 2. The bivariate extension of the spectral method outperforms by its local adaptivity and

Fourier domain smoothing previous approaches in most cases, see Bibinger and Reiﬂ (2013) for a

detailed discussion and survey on the different methods. Yet, it attains the multi-dimensional variance

lower bound for estimating the integrated covolatility

1 0

s(pq)

ds

only

in

case

that

[W (p), W (q)]



0. On the other hand the estimator already achieves a high efficiency and since it does not involve

Fisher information weight matrices, it is less computationally costly than the efficient local method of

moments approach. The general form of the asymptotic variance given in (11) is a bit complicated. In

case that [W (p), W (q)]  0 and for equal volatilities t(11) = t(22) = t it simplifies to

t 0

4|s3|

ds,

being efficient for this setup. By its implicitly obtained rescaled version (12) allowing for confidence,

the estimator is of high practical value.

Theorem 3. In the multi-dimensional experiment, on Assumption (H-d) and Assumption (Obs-d), for the local method of moments estimator of the integrated covolatility matrix LMMn,t, stated in (29a) below, the functional stable weak convergence

1
n4

LMMn,t - vec

t
s ds
0

-st

t1
s2 

Hs

1 4

ZdBs +

t

Hs

11
4  s2

Z dBs

(13)

00

applies, with H(t) = diag(pp1/2Fp(t)-1/2)p  Rd◊d and H 1/4 the matrix square root of H 1/2 := H(H-1H-1)1/2H, as n   and n/np  p for p = 1, . . . , d, on D [0, 1], where Z is the matrix defined in (5) and B and B are two independent d2-dimensional Brownian motions,
both defined on an extension of the original probability space (, G, (Gt)0t1, P), independent of the
original -algebra G. The point-wise marginal central limit theorem reads

1
n4

LMMn,1 - vec

1
s ds
0

-st M N 0, I-1Z ,

(14)

where M N means mixed normal distribution, with the asymptotic variance-covariance matrix

1
I-1 = 2 (s  Hs 1/2 + sH 1/2  s) ds .
0

(15)

Moreover, the implicitly obtained variance-covariance matrix estimator In-,1t in (29b) provides for 0  t  1 the feasible central limit theorem:

I1n/,t2 LMMn,t - vec

t
s ds
0

-d N (0, Z) .

(16)

Remark 3. The local method of moments attains the lower asymptotic variance bound derived in Bibinger et al. (2013) for a nonparametric experiment with deterministic covolatility matrix, without drift and Gaussian error distribution. Thus, the local method of moments is asymptotically efficient in this subexperiment. The asymptotic variance of estimating an integrated volatility decreases as the information inherent in the observation of correlated components can be exploited. In the multi-dimensional observation model the attained minimum asymptotic variance of estimating integrated squared volatility can become much smaller than the boundin (8) for d = 1. In an idealized parametric model with  > 0, the variance can be reduced up to (8/ d)3 in comparison to the one-dimensional lower bound 83, see Bibinger et al. (2013) for a deeper discussion of the lower bound.

8

3. Spectral estimation of integrated volatility and the integrated covolatility matrix

3.1. Elements of spectral estimation

We shall concisely recapitulate the building blocks of spectral estimation in the sequel. For sim-

plicity we start with the one-dimensional framework, d = 1. We partition the time span [0, 1] into equidistant bins [(k - 1)hn, khn], k = 1, . . . , hn-1  N, hn  0 as n  . For the ease of exposition, suppose without loss of generality nhn  N, the number of observations on each bin. Consider

a statistical experiment in which we approximate t by a locally constant function. Then, presume

on each bin [(k - 1)hn, khn] a locally constant squared volatility (2k-1)hn. Consequently, in this ex-

periment we estimate

khn (k-1)hn

s2

ds

by

hn^(2k-1)hn

,

solving

locally

parametric

estimation

problems.

For this purpose, Reiﬂ (2011) motivated to smooth noisy data bin-wise in the Fourier domain and

construct an efficient estimator by a linear combination of smoothed spectral statistics over different frequencies. Thereto, consider the L2([0, 1])-orthonormal systems of trigonometric functions:

jk (t) =

2 sin
hn

jh-n 1 (t - (k - 1) hn)

1[(k-1)hn,khn] (t) ,

j  1, 0  t  1 ,

(17a)

jk (t) = 2n

2 sin
hn

j 2nhn

cos jhn-1 (t - (k - 1) hn) 1[(k-1)hn,khn] (t) .

(17b)

Those provide weight functions for the spectral statistics:

n
Sjk = ni Y jk(i/n) , j = 1, . . . , nhn - 1, k = 1, . . . , hn-1.
i=1

(18)

The spectral statistics are the principal element of the considered estimation techniques. They are

related to the pre-averages of Jacod et al. (2009) which have been designed for our one-dimensional

estimation problem, as well. A main difference is that we keep the bins fixed which makes the con-

struction of the spectral approach simple. Bin-wise the spectral estimation profits from an advanced

smoothing method in the Fourier domain, i.e. using the weight function of a discrete sine transfor-

mation. The spectral statistics hence de-correlate the observations and form their bin-wise principal

components. Reiﬂ (2011) showed that this leads to a semiparametrically efficient estimation approach

of squared integrated volatility in a nonparametric setup with deterministic volatility, without drift and normally distributed noise. The bin-width is chosen as hn n-1/2 log n to attain the optimal
convergence rates and for the results in Section 2.1. This becomes clear in the proofs in Section 6. The

log-factor plays a role in the convergence of the sum of variances over different frequencies. The leading asymptotic order n-1/2 for the bin-width is analogous to the pre-average and kernel bandwidths,

cf. Jacod et al. (2009) and Barndorff-Nielsen et al. (2008), and balances the error by discretization

which increases with increasing hn and the error due to noise which decreases as hn increases. Let us point out that the basis functions (17a) and (17b) are slightly scaled versions of the respective basis

functions in Bibinger and Reiﬂ (2013) and Bibinger et al. (2013) for a more convenient exposition,

but these factors which equal the empirical norms of the jk have to be considered when translating expressions.

3.2. The spectral estimator of integrated volatility
Locally parametric estimates for the squared volatility ^(2k-1)hn are obtained by linear combinations with weights wjk of bias-corrected squared spectral statistics:

nhn-1

^(2k-1)hn =

wjk

Sj2k

-

[j k ,

j k ]n

2 n

j=1

.

(19)

9

The correction for the bias due to noise incorporates the empirical norm from Definition 1 and the

noise level  which is in general unknown ≠ but can be consistently estimated from the data with

n1/2 convergence rate, e. g. by ^2 = (2n)-1

n i=1

(ni Y

)2

,

see

Zhang

et

al.

(2005)

for

an

asymptotic

analysis of this estimator.

The estimator of the integrated squared volatility

t 0

s2

ds

is

constructed

as

Riemann

sum

thn-1 k=1

hn^(2k-1)hn =

th-n 1 k=1

nhn-1
hn wjk
j=1

Sj2k

-

[jk, jk]n

2 n

,

(20)

such that the estimator at t = 1 becomes simply the average of local estimates in the case of equi-

spaced bins. Set Ijk = Var Sj2k -1 and Ik =

nhn-1 j=1

Ij k .

The variance of the above estimator

becomes minimal and equal to

th-n 1 k=1

Ik-1 for the oracle weights

wjk = Ik-1Ijk =

(2k-1)hn

+

2 n

[jk, jk]n

-2

nhn-1 m=1

(2k-1)hn

+

2 n

[mk ,

mk ]n

-2

(21)

for k = 1, . . . , hn-1 and j = 1, . . . , nhn - 1, when the noise is Gaussian. For general noise distribution it turns out that the first-order variance remains invariant. It is essential to develop an adaptive
version of the estimator, for which we replace the oracle optimal weights by data-driven estimated
optimal weights. Additionally to the estimated noise variance, a bin-wise consistent estimator of the local volatilities (2k-1)hn with some convergence rate suffices. Local pre-estimates of the volatilities (2k-1)hn can be constructed by using the same ansatz as in (19), but involving only a small number Jn nhn - 1 of frequencies and constant weights wjk = Jn-1 and then averaging over Kn n1/4 bins in a neighborhood of (k - 1)hn. This estimator attains at least a n1/8 rate of convergence, the latter in case of   1/2 under ( - 1) or under ( - 2) in Assumption (H-1). For a smoother
volatility, Kn is chosen larger leading to a faster convergence rate, see also Bibinger and Reiﬂ (2013)
for a discussion on the estimation of the instantaneous volatility. Since plugging in the pre-estimates of local squared volatilities and of the noise variance implicitly provides estimates I^jk, I^k for Ijk, Ik and thus also w^jk = I^k-1I^jk for wjk as well, we can define the final adaptive spectral estimator of
volatility and the estimator for its variance based on a two-stage approach:

IVn,t =

thn-1

nhn-1
hn w^jk

Sj2k

-

[jk, jk]n

^2 n

k=1 j=1

th-n 1

VnI,Vt =

h2n I^k-1 .

k=1

,

(22a) (22b)

3.3. The spectral covolatility estimator
The spectral covolatility estimator from Bibinger and Reiﬂ (2013) is the obvious extension of the one-dimensional estimator using cross-products of spectral statistics:

np

Sj(kp) =

ni Y (p)jk

i=1

ti(p) + ti(-p)1 2

, j  1, p = 1, . . . , d, k = 1, . . . , hn-1.

(23)

10

The basis functions (jk) (17b) the factor in front of

are the

cdoesfiinneedtoatshiens(i1m7pal)e. rUenxdperersnsoionn-syn2chjrhonn-o3u/2s,

observations we such that jk =

modify in jk. This

meets the original idea by Reiﬂ (2011) to use orthogonal systems of functions and their derivatives.

While in the case of regular observations on the grid i/n, i = 0, . . . , n, we can slightly profit by the

discrete Fourier analysis, we use for non-synchronous observations from now on the continuous-time

analogues which coincide with the first-order discrete expressions. Starting from an asymptotically

equivalent continuous-time observation model, where we set Sj(kp) = jk(t)dY (p)(t) as in Bibinger

et al. (2013), integration by parts leads to the more natural discrete-time approximation (23) here

where the jk are evaluated at mid-times (t(i+p)1 - ti(p))/2 (see Bibinger et al. (2013) for details). The

standardization is [jk, jk] =

1 0

j2k

(t)

dt

=

h-n 22j2.

The

weights

wjpk,q

=

(Ik(p,q))-1Ij(kp,q) ,

Ij((pk,q+)1) = (kphpn)(kqhqn)+((kphqn))2+Hpkhn Hqkhn[jk, jk]2 + (kphpn)Hqkhn + k(qhqn)Hpkhn [jk, jk] -1

depend on the volatilities, covolatility and noise levels of the considered components as defined in (7). The local noise level combines the global noise variance p2 and local observation densities. It can be estimated with

H^pkhn =

np i=1

iY (p)

2hn

2
t(vp) - tv(p-)1
khntv(p)(k+1)hn

2,

(24)

see the asymptotic identity (43) below. The bivariate spectral covolatility estimator with adaptive weights for p = q, p, q  {1, . . . , d} is

(p,q)
ICVn,t =

thn-1 k=1

nhn-1
hn w^j(pk,q)
j=1

Sj(kp)Sj(kq)

,

(25a)

where we choose the sequence n such that nhn  N, and the estimator for its variance:

th-n 1

V =ICV(p,q)
n,t

hn2 (I^k)(p,q) -1 .

k=1

(25b)

A more general version of the spectral covolatility estimator for a model including cross-correlation of the noise (in a synchronous framework) can be found in Bibinger and Reiﬂ (2013). For a simpler exposition and since this notion of cross-correlation is not adequate for the more important nonsynchronous case, we restrict ourselves here to noise according to Assumption (Obs-d).

3.4. Local method of moments Consider the vectors of spectral statistics:

Sjk =

np

Yi(p) - Yi(-p1)

jk

t(i-p)1 + ti(p) 2

i=1

,
1pd

(26)

for all k = 1, . . . , hn-1 and j  1. Averaging empirical covariances SjkSjk over different spectral frequencies j = 1, . . . , Jn and over a set of (2Kn + 1) adjacent bins yields a consistent estimator of
the instantaneous covolatility matrix:

sh-n 1 +Kn

Jn

^ psilot = (2Kn + 1)-1

Jn-1

k= sh-n 1 -Kn

j=1

SjkSjk - H^ kn

,

(27)

11

with H^ nk the estimated noise levels matrix (7), not discussing end effects for s < Knhn and s > 1 - Knhn here.
The fundamental novelty of the local method of moments approach is to involve multivariate Fisher informations as optimal weight matrices which are (d2 ◊ d2) matrices of the following form:

Wjk = Ik-1Ijk = nhn-1 (k-1)hn + [uk, uk]Hnk -2 -1 (k-1)hn + [jk, jk]Hnk -2, (28)
u=1

nhn  N, where A2 = A  A denotes the Kronecker product of a matrix with itself and A-2 = (A2)-1 = (A-1)2. With the pilot estimates and estimators for the noise level at hand, we derive

estimated optimal weight matrices for building a linear combination over spectral frequencies j =

1, . . . , nhn - 1, similar as above. The final estimator of the vectorization of the integrated covolatility

matrix vec(

t 0

s

ds),

becomes

LMMn,t =

th-n 1

nhn-1

hn W^ jk vec

k=1 j=1

SjkSjk - H^ nk

,

(29a)

and the implicitly derived estimator of its variance-covariance matrix:

th-n 1

^In-,1t =

hn2

k=0

nhn-1
I^jk
j=1

-1
.

(29b)

4. Asymptotic theory

We start with the one-dimensional experiment first. We decompose X using a locally constant approximation of the volatility path and the approximation error:

Xt = X0 + X~t + (Xt - X0 - X~t) ,

(30a)

where we define

t
X~t = 0  shn-1 hn dWs ,

(30b)

as a simplified process without drift and with locally constant volatility. The asymptotic theory is conducted for oracle versions of the spectral estimators first with optimal oracle weights. Below the effect of a pre-estimation for the fully adaptive estimator is shown to be asymptotically negligible
or
at first order. In the following, we distinguish between IVn,t(Y ), the oracle version of the spectral volatility estimator (22a) from noisy observations, and IVnor,t(X~ + ) for the oracle estimator in a simplified experiment in which X~ instead of X is observed with noise. It turns out that both have the same asymptotic limiting distribution. In order to establish a functional limit theorem, we decompose the estimation error of the oracle version of (22a) in the following way:

or
IVn,t

(Y

)

-

t s2 ds = IVonr,t(X~ +
0

)-

t

0

2sh-n 1

ds
hn

+

or
IVn,t(Y

)

-

IVnor,t(X~

+

)-

t 0

s2 - 2sh-n 1 hn

ds .

(31a) (31b)

12

The proof of the functional central limit theorem (CLT) falls into three major parts. First, we prove the result of Theorem 1 for the right-hand side of (31a). In the second step the approximation error in (31b) is shown to be asymptotically negligible. Finally, we establish that the same functional stable CLT carries over to the adaptive estimators by proving that the error of the plug-in estimation of optimal weights is asymptotically negligible.

Proposition 4.1. On the assumptions of Theorem 1, it holds true that

1
n4

th-n 1

IVnor,t(X~ + ) - hn

(2k-1)hn

-st

t

8 |s3| dBs ,

k=1 0

(32)

as n   on D [0, 1] where B is a Brownian motion defined on an extension of the original probability space (, G, (Gt)0t1, P), independent of the original -algebra G.

Proposition 4.2. On the assumptions of Theorem 1, it holds true that:

1
n4

or
IVn,t(Y

)

-

or
IVn,t

(X~

+

)-

t
0 s2 - 2sh-n 1 hn ds

-ucp 0 as n   .

(33)

Theorem 1 is then an immediate consequence of the following proposition:

Proposition 4.3. On the assumptions of Theorem 1:

1
n4

or
IVn,t - IVn,t(Y )

-ucp 0

as n   .

(34)

Finally, by consistency of the variance estimators and Slutsky's Lemma the feasible limit theorems for the adaptive estimators are valid. The proof of the functional stable CLT is based on the asymptotic theory developed by Jacod (1997). In order to apply Theorem 3≠1 of Jacod (1997) (or equivalently Theorem 2.6 of Podolskij and Vetter (2010), we illustrate the rescaled estimation error as a sum of increments:

th-n 1

thn-1

1
n4

IVnor,t(X~ + ) - hn

(2k-1)hn =

kn ,

k=1 k=1

nhn-1

kn

=

1
n 4 hn

wjk S~j2k - E S~j2k|G(k-1)hn , k = 1, . . . , h-n 1.

j=1

(35) (36)

with S~jk being spectral statistics build from observations of X~ + . For the proof of the functional stable CLT, we need to verify the following five conditions:

th-n 1
(J1) E kn G(k-1)hn -ucp 0 .
k=1
Convergence of the sum of conditional variances

th-n 1

t

(J2) E (kn)2 G(k-1)hn P vs2 ds ,

k=1 0

13

with a predictable process vs, and a Lyapunov-type condition

th-n 1
(J3) E (kn)4 G(k-1)hn P 0 .
k=1

Finally, stability of weak convergence is ensured if

th-n 1
(J4) E kn(Wkhn - W(k-1)hn ) G(k-1)hn P 0 ,
k=1

where W is the Brownian motion driving the signal process X and

thn-1
(J5) E kn(Nkhn - N(k-1)hn ) G(k-1)hn P 0 ,
k=1

for all bounded martingales N which are orthogonal to W . Next, we strive for a stable CLT for the estimation errors of the covolatility estimator (25a) and the local method of moments approach (29a). A non-degenerate asymptotic variance is obtained when n/np  p with 0 < p <  as n   for all p  {1, . . . , d}. We transform the non-synchronous observation model from Assumption (Obsd) to a synchronous observation model and show that the first order asymptotics of the considered estimators remain invariant. Hence, the effect of non-synchronous sampling on the spectral estimators is shown to be asymptotically negligible. In the idealized martingale framework Bibinger et al. (2013) have found that non-synchronicity effects are asymptotically immaterial in terms of the information content of underlying experiments by a (strong) asymptotic equivalence in the sense of Le Cam of the discrete non-synchronous and a continuous-time observation model. This constitutes a fundamental difference to the non-noisy case where the asymptotic variance of the prominent Hayashi-Yoshida estimator in the functional CLT hinges on interpolation effects, see Hayashi and Yoshida (2011). In the presence of the dominant noise part, however, at the slower optimal convergence rate, the influence of sampling schemes boils down to local observation densities. These time-varying local observation densities are shifted to locally time-varying noise levels (indeed locally increased noise is equivalent to locally less frequent observations). Here, we shall explicitly prove that if we pass from a non-synchronous to a synchronous reference scheme the transformation errors of the estimators are asymptotically negligible.

Lemma 4.4. Denote tØ(il) = t(il) + t(i-l)1 /2, l = 1, . . . , d. On Assumptions (H-d) and (Obs-d), we can work under synchronous sampling when considering the signal part X, i.e. for l, m  {1, . . . , d}
uniformly in t for both, wjl,km as in Section 3.3 or defined as entries of (28):

th-n 1
hn

nl
wjl,km

k=1 j1

v=1

Xt((vll))

-

X (l)
tv(l-) 1

nm
j k (tØv(l) )
i=1

Xt((imm))

-

X (m)
t(i-m1)

jk(tØ(im)) + OP(n-1/4)

th-n 1
= hn

nl
wjl,km

k=1 j1

v=1

Xt(v(ll))

-

X (l)
t(vl-) 1

nl
j k (tØ(vl) )
i=1

Xt((iml))

-

X (m)
ti(-l)1

jk(tØi(l)) .

Note that (Fl-1) , (Fm-1) affect the asymptotics of our estimators as can be seen in (11), but are treated as part of the summands due to noise.

14

Under a synchronous reference observation scheme the strategy of the asymptotic analysis is similar as for the one-dimensional setup. Analogous decompositions in leading terms from the simplified model without drift and with a locally constant covolatility matrix and remainders are considered for the multivariate method of moments estimator (29a) and the spectral covolatility estimator (25a). In order to prove Theorem 2 for instance, we apply Jacod's limit theorem to the sum of increments

kn

=

1
n4

hn

wjpk,q S~j(kp)S~j(kq) - E S~j(kp)S~j(kq) G(k-1)hn

j1

,

(38)

for k = 1, . . . , h-n 1 with S~j(kp) as defined in (23), but based on observations of X~ + . By including the case p = q with a bias correction the one-dimensional result is generalized to non-equidistant sampling. The asymptotic negligibility of the plug-in estimation in Proposition 4.3 is proven in Section 6 exploiting a uniform bound on the derivative of the weights as function of t. In fact, it turns out that the weights are robust enough in misspecification of the pre-estimated local volatility to render the difference between oracle and adaptive estimator asymptotically negligible. This carries over to the multivariate methods.

5. Simulations

In the sequel, the one-dimensional spectral integrated volatility estimator's (22a) finite sample per-
formance is investigated in a random volatility simulation scenario. We sample regular observations Y1, . . . , Yn as in (3) with i iid N (0, 2) and the simulated diffusion

tt
Xt = b ds + s dWs .
00

In a first baseline scenario configuration we set s = 1 constant, and then

t2 =

tt

~ ∑  dWs +

1 - 2 ∑ ~ dWs ∑ f (t) ,

00

(39)

with W  a standard Brownian motion independent of W and f a deterministic seasonality function

f (t)

=

0.1(1

-

1
t3

+

0.5

∑

t2) .

The drift is set b = 0.1 and ~ = 0.01. The superposition of a continuous semimartingale as random component with a time-varying seasonality modeling volatility's typical U-shape mimics very general realistic volatility characteristics. We implement the oracle version of the estimator (22a) and the adaptive two-stage procedure with pre-estimated optimal weights. Table 1 presents Monte Carlo results for different scenario configurations. In particular, we consider different tuning parameters (bin-widths) and possible dependence of the finite-sample behavior on the leverage magnitude and the magnitude of the noise variance. We compute the estimators' root mean square errors (RMSE) at t = 1, for each configuration based on 1000 Monte Carlo iterations, and fix in each configuration one realization of a volatility path to compare the RMSEs to the theoretical asymptotic counterparts in the realized relative efficiency (RE):

RE(IVn,1) =

(mean(IVn,1) -

1 0

s2

ds)2

+

Var(IVn,1)

8

1 0

s3

ds

 ∑n
.

(40)

15

n

 hn-1



or
 RE(IVn,1) RE(IVn,1)

30000 1

25 0.01 ≠

1.01

1.43

5000 1 25 0.01 ≠

1.02

1.47

30000 (39) 25 0.01 0.5

1.09

1.75

30000 (39) 25 0.01 0.2

1.06

1.77

30000 (39) 25 0.01 0.8

1.09

1.75

30000 (39) 25 0.001 0.5

1.62

1.88

30000 (39) 25

0.1 0.5

1.20

1.69

30000 (39) 50 0.01 0.5

1.09

1.84

30000 (39) 10 0.01 0.5

1.16

1.86

5000 (39) 25 0.01 0.5

1.13

1.92

5000 (39) 50 0.01 0.5

1.08

1.75

5000 (39) 10 0.01 0.5

1.09

1.87

Table 1: Relative Efficiencies (RE) of oracle and adaptive spectral integrated volatility estimator in finite-sample Monte Carlo study.

Our standard sample size is n = 30000, a realistic number of observations in usual high-frequency applications as number of ticks over one trading day for liquid assets at NASDAQ. We also focus on smaller samples, n = 5000. Throughout all simulations we fix a maximum spectral cut-off Jp = 100 in the pre-estimation step and J = 150 for the final estimator, which is large enough to render the approximation error by neglecting higher frequencies negligible. In summary, the Monte Carlo study confirms that the estimator performs well in practice and the Monte Carlo variances come very close to the theoretical lower bound, even in the complex wiggly volatility setting. The fully adaptive approach performs less well than the oracle estimator which is in light of previous results on related estimation approaches not surprising, see e.g. Bibinger and Reiﬂ (2013) for a study including an adaptive multi-scale estimator (global smoothing parameter, but chosen data-driven). Still the adaptive estimator's performance is remarkably well in almost all configurations. Under very small noise level, the relative efficiency is not as close to 1 any more. Apart from this case, the RE comes very close to 1 for the oracle estimator, not depending on the magnitude of leverage, also for small samples, and being very robust with respect to different bin-widths. A simulation study of the multivariate method of moments estimator in a random volatility setup can be found in Bibinger et al. (2013).

6. Proofs
6.1. Preliminaries ∑ Empirical scalar products:

16

Definition 1. Let f, g : [0, 1]  R be functions and z = (zi)1in  Rn. We call the

quantities

1n

i

i

f, g n = n

fg , nn

i=1

1n

i

z, g n = n zi g n ,

i=1

the empirical scalar product of f , g and of z, g, respectively. We further define the "shifted" empirical scalar products

1n [f, g]n = n f

i

-

1 2

n

g

i

-

1 2

n

i=1

1n [z, g]n = n zi g

i

-

1 2

n

.

i=1

,

Recall the notation nY = inY 1in  Rn, the vector of increments and analogously nX and let = ( i)0i(n-1).

Lemma 6.1. It holds that

jk, mk n = jm ,

(41a)

[jk, mk]n = jm4n2 sin2

j 2nh

.

(41b)

Moreover, we have the summation by parts decomposition of spectral statistics:

n nY, jk n = n nX, jk n - [ , jk]n .

(41c)

Proof. The proofs of the orthogonality relations (41a) and (41b) are similar and we restrict ourselves to prove (41b). In the following we use the shortcut N = nhn and without loss of generality we consider the first bin k = 1. We make use of the trigonometric addition formulas which yield for N  j  r  1:

cos(jN

-1 (l +

1 2

))

cos(rN

-1 (l +

1 2

))

=

cos((j

+r)N

-1 (l +

1 2

))+cos((j

-r)N

-1 (l +

1 2

))

.

The empirical norm for j = r readily follows by cos(0) = 1 and the following. We show that

N -1 i=0

cos(mN -1(i

+

1 2

))

=

0

for

m



N.

First,

consider

m

odd:

N -1

(N -2)/2

N -1

cos(mN -1(i

+

1 2

))

=

cos(mN -1(i

+

1 2

))

+

cos(mN -1(i

+

1 2

))

i=0 i=0 i= N/2

(N -2)/2
=
i=0

cos(mN -1(i

+

1 2

))

+

cos(mN -1(N

-

(i

+

1 2

)))

= 0,

since cos(x + m) = - cos(x) for m odd. Note that for i = (N - 1)/2  N, we leave out one addend which equals cos(m/2) = 0, and also that for m even by cos(x) = cos(x + m) the

17

two sums are equal. For m  N with m even, we differentiate the cases N = 4k, k  N; N = 4k + 2, k  N and N = 2k + 1, k  N. If N = 4k + 2, we decompose the sum as follows:

N -1

2k

4k+1

cos(mN

-1(i+

1 2

))

=

cos(m(4k

+2)-1(i+

1 2

))+

cos(m(4k

+2)-1

(i+

1 2

))

.

i=0 i=0

i=2k+1

The addends of the left-hand sum are symmetric around the point m/4 at i = k and of the

right-hand sum around 3m/4 at i = 3k + 1. Thereby, both sums equal zero by symmetry.

More precisely, for m being not a multiple of 4 the sums directly yield zero. If m is a multiple

of 4, we can split the sum into two or more sums which then equal zero again.

This observation for the first sum readily implies

N -1 i=0

cos(mN -1(i

+

1 2

))

=

0 for N

=

2k + 1, since in this case

2k 2k

cos(mN -1(i

+

1 2

))

=

cos(2m(4k

+

2)-1(i

+

1 2

))

=

0

.

i=0 i=1

For N = 4k, we may as well exploit symmetry relations of the cosine. Decompose the sum

N -1

2k-1

4k-1

cos(mN -1(i

+

1 2

))

=

cos(m(4k)-1(i

+

1 2

))

+

cos(m(4k)-1(i

+

1 2

))

.

i=0 i=0

i=2k

Symmetry around m/4 and 3m/4 is similar as above, but these points lie off the discrete
grid this time. Yet, analogous reasoning as above yields that both sums equal zero again, what
completes the proof of (41b). Applying summation by parts to n n , jk n and using jk(1) = jk(0) = 0 yields

n
n n , jk n =

n l

jk

l n

n
=-

l-1 jk

l n

- jk

l-1 n

l=1 l=1

.

The equality sin (x + h) - sin (x) = 2 sin

h 2

cos

x

+

h 2

for x, h  R gives

jk

l n

- jk

l-1 n

1 = n jk

l

-

1 2

n

what yields the claim.

∑ Basic estimates for drift and Brownian terms: For all p  1 and s, (s + t)  [(k - 1)hn, khn] for some k = 1, . . . , h-n 1:

E X~s+t - X~s p Gs  Kptp/2 ,

(42a)

with X~s = (k-1)hn

s (k-1)hn

dWt,

introduced

in

Section

4,

E Xs+t - X~s+t - Xs + X~s p Gs  KpE

p
s+t 2
 - s 2 d Gs  Kptp , (42b)
t

18

E

s+t p
bu du Gs

 Kptp,

s

(42c)

with generic constant Kp depending on p by Ito^ isometry, Cauchy-Schwarz and BurkholderDavis Gundy inequalities with Assumption (H-1) and Assumption (H-d), respectively.

∑ Local quadratic variations of time:

t(il) - t(i-l)1 2
(k-1)hnti(l)khn

Hlkhn l-2n-l 1 t(il) - ti(-l)1 = Hlkhn l-2n-l 1hn. (43)
(k-1)hnti(l)khn

The left-hand side is a localized measure of variation in observation times in the vein of the
quadratic variation of time by Zhang et al. (2005). It appears in the variance of the estimator and is used to estimate (Fl-1) ((k - 1)hn). Under Fl  C with  > 1/2 the approximation error by Hlkhn is O(n-1/4). The asymptotic identity applies to deterministic observation times in deterministic manner and to random exogenous sampling in terms of convergence in probability.

∑ Extending local to uniform boundedness:
On the compact time span [0, 1], we can strengthen the structural Assumption (H-1) and assume bs and s, ~bs, ~s are uniformly bounded. This is based on the localization procedure given in Jacod (2012), Lemma 6. 6 in Section 6. 3.

∑ Order of optimal weights: Recall the definition of the optimal weights (21). An upper bound for these weights is

wjk

Ijk =

(2k-1)hn

+

2 n

[j k ,

j k ]n

-2

j2 -2

1 + nhn2



1 j-4n2hn4

for j  nhn for j > nhn

(44)

what also gives

nhn-1
wjk

(2k-1)hn

+

2 n

[jk, jk]n

j=1



nhn j2

j=1 1 + h2nn

 nhn

+

nh2n

.

nhn-1
+
 j= nhn

j2 1 + nh2n

j-4n2h4n (45)

6.2. Proof of Proposition 4.1 Recall the definition of spectral statistics (18) and denote for j = 1, . . . , nhn - 1, k = 1, . . . , hn-1:

S~jk = n( nX~ +

n ), jk =
n

nnX~ , jk n - [ , jk]n ,

where X~ is the signal process in the locally parametric experiment. It holds that

E S~j2k G(k-1)hn

=E =E

n nX~ , jk n - [ , jk]n 2 G(k-1)hn

n

nX~ , jk

2
-2

n

n

nX~ , jk

[
n

, jk]n

+[

, jk]2n

G(k-1)hn

19

=E

n

nX~ , jk

2 n

G(k-1)hn

+ E [ , jk]2n G(k-1)hn

=

(2k-1)hn

+

2 n

[jk, jk]n

.

We have defined kn above such that

(46)

th-n 1

1
n4

IVn,t - hn

(2k-1)hn

k=1

th-n 1
1
= n 4 hn

nhn-1
wjk

S~j2k

-

2 n

[j k ,

jk]n- (2k-1)hn

k=1 j=1

th-n 1
= kn
k=1

when we shortly express IVn,t = IVonr,t(X~ + ). We have to verify (J1)-(J5). (J1) is trivial as the

kn are centered conditional on G(k-1)hn. The proof of (J2) is done in two steps. In paragraph 6.2.1

we calculate explicitly the variance which is the left-hand side of (J2). For this we consider at first

general weights wjk  0,

nhn-1 j=1

wjk

=

1

which

satisfy

wjk



G(k-1)hn

for

all

k

=

1, . . . , h-n 1,

j

=

1, . . . , nhn - 1. After that we find optimal weights minimizing the variance. In paragraph 6.2.2 we

let n   and calculate the resulting limiting asymptotic variance. The proofs of (J3), (J4) and (J5)

follow in paragraph 6.2.3.

6.2.1. Computation of the variance

E (kn)2 G(k-1)hn

nhn-1

=

n

1 2

hn2

wjkwmk E

j,m=1

S~j2k - E S~j2k G(k-1)hn

∑ S~m2 k - E S~m2 k G(k-1)hn G(k-1)hn

nhn-1

=

n

1 2

h2n

wjkwmk Tjn,m,k(1) + Tjn,m,k(2) + Tjn,m,k(3) ,

j,m=1

with the following three addends:

Tjn,m,k (1) = E

n

nX~ , jk

2 n

-

(2k-1)hn

n

nX~ , mk

2 n

-

(2k-1)hn

G(k-1)hn ,

Tjn,m,k (2) = E Tjn,m,k (3) = E

4

n

nX~ , jk

[
n

, jk]n

n

[

, jk]2n

-

2 n

[jk, jk]n

nX~ , mk

[
n

, mk]n

G(k-1)hn

,

[

, mk]n2

-

2 n

[mk, mk]n

G(k-1)hn

for frequencies j, m. Independence of the noise and of the Brownian increments yield the identities

2 E [ , jk]n [ , mk]n = n [jk, mk]n ,

E

n

nX~ , jk
n

n

nX~ , mk n G(k-1)hn

= jm(2k-1)hn ,

which already imply

Tjn,m,k

(2)

=

4

2 n

jm

[j k ,

mk ]n

(2k-1)hn

,

20

because noise and signal are independent. We further obtain by another polynomial expansion

E [ , jk]n2 [ , mk]2n

n
= n-4

E

l,l ,p,p =1

ll pp

jk

l

-

1 2

n

jk

l

-

1 2

n

mk

p

-

1 2

n

mk

p

-

1 2

n

.

Only the cases l = l = p = p , l = p = l = p , l = p = l = p or l = l = p = p produce non-zero results in the expectation. Hence, denoting by  = E[ 41] the fourth moment of the observation errors, we end up with

E

[ , jk]2n [ , mk]n2

1 = n4

4 ll pp + lpl p + lp l p +  lpl p ll - 34lpl p ll

l,l ,p,p

4 = n2

∑

jk

l

-

1 2

n

jk

l

-

1 2

n

mk

p

-

1 2

n

mk

[jk, jk]n [mk, mk]n + 2 [jk, mk]n2

 - 34 + n4

n

2jk

l

-

1 2

n

l=1

p

-

1 2

n

m2 k

l

-

1 2

n

.

Arguing similarly and using that E[( lnW )4] = 3 E[( nl W )2] for l  N, we obtain

E

n

nX~ , jk 2
n

n

nX~ , mk

2 n

G(k-1)hn

= (4k-1)hn

jk, jk

n

mk, mk

n+2

jk, mk

2 n

= (4k-1)hn (1 + 2jm) .

From the identities so far we obtain

Tjn,m,k (1) = E

n

nX~ , jk 2
n

n

nX~ , mk

2 n

G(k-1)hn

-E

n

nX~ , jk

2 n

G(k-1)hn

E

n

nX~ , mk

2 n

G(k-1)hn

= (4k-1)hn (1 + 2mj ) - (4k-1)hn = 2jm(4k-1)hn ,

Tjn,m,k (3) = E

[

, jk]2n

-

2 n

[jk, jk]n

[

, mk]n2

-

2 n

[mk, mk]n

=E

[ , jk]n2 [ , mk]2n

4 - n2 [jk, jk]n [mk, mk]n

=

24 n2

[j k ,

mk ]n2

+



- 34 n3

j2k, m2 k n .

In all, the conditional variance is given by

E (kn)2 G(k-1)hn



=

nhn2

nhn-1


wj2k

j=1

2(4k-1)hn

+

4

2 n

(2k-1)hn

[j k ,

j k ]n

+

24 n2

[j k ,

j k ]2n

  + Rn

= nh2n nhn-1 wj2k 2

(2k-1)hn

+

2 n

[j k ,

j k ]n

2
+ Rn

j=1

21

with remainder Rn

=



-34 n3

[2jk

,

2mk

]n

.

Observe

that

Rn

=

0 for Gaussian noise.

In this case,

analogous to Bibinger and Reiﬂ (2013), we find that the optimal weights minimizing the variance,

under the constraint

nhn-1 j=1

wjk

=

1,

which assures unbiasedness of the estimator,

are given by

(21). The optimization can be done with Lagrange multipliers. Rn is then a remainder in case that

 = 34. With the weights (21) and using (45), we can bound Rn by:



Rn = nh2n 

- 34 n n4 

nhn-1
 wjk2jk

i=1 j=1

i

-

1 2

n

2 



nhn2

1 n4

n

n hn

2 nhn-1
 wjk
j=1

n-1/2

 nhn

+

nhn2

2

=

O(1) .

(2k-1)hn

+

2 n

[j k ,

j k ]n

2 

We therefore obtain

thn-1
E
k=1

(kn)2 G(k-1)hn

= nh2n

thn-1

nhn-1
(Ik-2 Ij2k )Ij-k1

+

O(1)

=

nhn2

th-n 1

Ik-1 + O(1)

k=1 j=1

k=1

as variance of the estimator.

6.2.2. The asymptotic variance of the estimator The key to the asymptotic variance is to recognize

(nhn)-1Ik

=

1 nhn

nhn-1 j=1

1 2

(2k-1)hn

+

2 n

[j k ,

j k ]n

-2

as a Riemann scaling factor

(sumnh, ne)n-d1inigs

up the

with right

the "double-Riemann-sum" choice for the first Riemann

thn-1 k=1

hn ((nhn )-1 Ik )-1 .

sum which becomes clear after

The two

Taylor expansions. First, expanding the sine for each frequency j we find 0  j  j/(2nhn) with



Ijk

=

1 2

(2k-1)hn

+

42n

j - j3 2nhn 6

2-2 .

Second,

we

expand

x



1 2

(2k-1)hn + 42nx2

-2

which yields

j 2nhn

-

j3 6



j



j 2nhn

such that

Ijk = I~jk + Rjk

with

Rjk

=

42nj ((2k-1)hn + 42nj2)3

j3 6

(47)

where

we

define

I~jk

=

1 2

((2k-1)hn

+



2

(

j 2 nhn

)2

)-2.

Now

it

becomes

clear

that

 nhn

is

indeed

the

right factor because

1 nhn

nhn-1 j=1

I~jk

-

1
n-

1 nhn

02

(2k-1)hn + 22x2

-2
dx

22

nhn-1
=
j=1

j nhn
j-1 nhn

1 2

(2k-1)hn + 22j2h-n 2n-1

-2 - 1 2

(2k-1)hn + 22x2

-2

dx

nhn-1 j=1

j nhn
j-1 nhn

x- j nhn

dx max

j-1 nhn

y

j nhn

y (2k-1)hn + 22y2 -3





1 nhn

2 nhn-1

j=1

max

j-1 nhn

y

j nhn

y (2k-1)hn + 22y2 -3



=

1 nhn


2

 nhn


j=1

j

nhn-1
+

nhn 

j= nhn

 nhn


5

j-1 

1 nhn

 2

 nhn-1- nhn

 nhn +

j=1

 nhn
j + nhn


5
C

1

2
.

nhn

for some positive constant C which does neither depend on (2k-1)hn nor on n. We choose hn such that nhn  . Though we consider all possible spectral frequencies j = 1, . . . , nhn - 1, we

shall see in the following that the Ijk for j  nhn become asymptotically negligible for a suitable

0   < 1. By virtue of monotonicity of the sine on

0,

 2

and sin(x) 

x/2 for 0  x  1, it

follows that

 1 nhn-1 nhn j= nhn

Ijk

 1 nhn-1 nhn j= nhn

n sin2 nhn 2nhn

-2



1 nhn

nhn

n sin2

n hn  2nhn

-2



 n

n

n-1

2 -2

4

n

1 2

-4+2

=

n

5 2

-4

.

We

deduce

that

1 nhn

nhn-1 j= n hn

Ijk = O (1), for every 5/8 <  < 1. Moreover, we obtain for the

first nhn summands of the remainder term

1 nhn

n hn j=1

Rjk

=

1

n hn

nhn j=1

 n

n hn

nhn j=1

42nj

j3

(2k-1)hn + 42nj2 3 6

n

n hn

nhn j=1

j3j

j 4 nhn

1 nhn

n

hnn4(-1)+1

=

n5

-

7 2

.

Hence

1 nhn

n hn j=1

Rjk

= O (1) for every 

< 7/10.

As the tails are asymptotic negligible we

thus

have

1 nhn

nhn-1 j=1

Rjk

=

O (1)

and,

in

particular,

1 nhn

nhn-1
Ijk
j=1

=

1
n-

1 nhn

02

(2k-1)hn + 22x2

-2
dx + O (1) .

23

Substitution and an application of the recursion formula

y
(b2 +(x - a)2)-k dx =
0

2(k - 1)b2

x-a b2 +(x - a)2

k-1

y
2k - 3 + 2 (k - 1) b2
0

y
b2+(x - a)2
0

1-k dx

for y  0, k = 2, a = 0 and b = 1, yields

y1 02

(2k-1)hn + 22x2

-2
dx

y1

 2 -2

= 0 2(4k-1)hn

1+

x (k-1)hn

dx

1 = 2 (k-1)hn 3

| | y (k-1)hn

1 + x2 -2 dx

0

1 = 2 (k-1)hn 3


|(k-1)hn

|

y

2 1+


|(k-1)hn

|

y

2

1 +
2

| | y (k-1)hn
0

1 + x2 -1 dx

= 4 (k-1)hn 4

y 1+

2


|(k-1)hn

|

y

1

+ 4

(k-1)hn

3 arctan

 y.
(k-1)hn

Asn-<|n1hsn|

< C uniformly for all 0    as n  , we have

s



1

and

because

arctan

(x)



/2

as

x



,

as

well

as

1 nhn

nhn-1
Ijk
j=1

=

4

(k-1)hn

4

 n

-

1 nhn

1+


| |(k-1)hn

 n

-

1 nhn

2

1

+ 4

(k-1)hn

3 arctan

1

= 8

(k-1)hn

3

+ O (1) .

 (k-1)hn

 n

-

1

nhn

+ O (1)

The final step in the proof is another Taylor approximation:

th-n 1
E
k=1

(kn)2 G(k-1)hn

= nh2n

th-n 1 k=1

Ik-1 = hn

thn-1 k=1

 -1

 1 nhn

nhn-1 j=1

Ij k 

th-n 1
= hn
k=1

-1
1 8 (k-1)hn 3 + O (1)

 th-n 1



= hn

8

(k-1)hn

3


+

O

(1)

.

k=1

24

The last equality is true by Taylor and because  is uniformly bounded. Because  is continuous we obtain the claim by Riemann approximation, i.e.

th-n 1
E
k=1

(kn)2 G(k-1)hn

 8

t
|s|3 ds
0

almost surely as n   establishing (J2) with the asymptotic expression of Theorem 1.

6.2.3. Lyapunov's criterion and stability of convergence
So far, we have proved (J1) and (J2). Next, we shall prove that the Lyapunov condition (J3) is satisfied. For the sum of fourth moments, we obtain by Minkowski's inequality, Jensen's inequality and wjk  G(k-1)hn for all k = 1, . . . , hn-1 and j = 1, . . . , nhn - 1:

E (kn)4 G(k-1)hn

 
nhn-1

= nh4n E  

wjk S~j2k - E S~j2k G(k-1)hn

j=1

4   G(k-1)hn 


nhn-1

 nh4n 

wjk E

j=1

S~j2k - E S~j2k G(k-1)hn

4
G(k-1)hn

1 4
4



nhn-1

nhn4 

wjk

j=1

(8k-1)hn

+

8 n4

[jk, jk]4n

1 4
4



nhn-1

nhn4 

wjk E S~j8k G(k-1)hn

j=1

4
1 4


If we can show

E

n

nX~ , jk

8 n

G(k-1)hn

E [ , jk]8n

(8k-1)hn ,

8

[j k , n4

jk

]4n

,

(48) (49)

then we are able to conclude that

E S~j8k G(k-1)hn

E

nnX~ , jk

8 n

G(k-1)hn

(8k-1)hn

+

8 n4

[j k ,

j k ]4n



+ E [ , jk]n8

(2k-1)hn

+

2 n

[j k ,

j k ]n

4
.

(50)

Hence, we obtain by (45)

hn-1
E
k=1

(kn)4 G(k-1)hn

hn-1


nhn-1

nh4n 

wjk

k=1 j=1

4

(2k-1)hn

+

2 n

[j k ,

j k ]n



n2hn6 = O (1)

which proves (J3). We are therefore left with proving (48) and (49). The first inequality holds because n nX~ , jk n is N (0, (2k-1)hn)-distributed conditional on G(k-1)hn. Higher moments of

25

the noise term can be treated with techniques as in the proofs of method of moments, see for in-

stance Tao (2012). In order to see why the second inequality is satisfied, let gl = ((k-1)nhn+l)

jk

(k-1)nhn

+l-

1 2

n

for l = 1, . . . , nhn, such that Polynomial expansion yields

E [ , jk]8n = n-8

E [gl1 ∑ ∑ ∑ gl8 ] .

1l1,...,l8nhn

(51)

As the first eight moments of the noise exist, we obtain for each summand the same bound

|E [gl1 ∑ ∑ ∑ gl8 ]|

8 jk

l1

-

1 2

n

∑ ∑ ∑ jk

l8

-

1 2

n

8

[jk, jk hn4

]4n

.

Moreover, the gl are centered and independent. Therefore, we only have to consider summands where each gl appears at least twice. In particular, in every summand there are at most four distinct gl. Thus, our problem simplifies to

E [ , jk]n8

n-8

8

[jk, jk h4n

]n4

4
Nr
r=0

,

(52)

where Nr is the number of ways one can assign integers l1, . . . , l8 in {1, . . . , nhn} such that each li appears at least twice, and such that exactly (4 - r) integers appear. A crude bound can be obtained
by combinatorial considerations and Stirling's formula such that

Nr  (enhn)4-r 44+r n4hn4 .

Inserting this into (52) yields the claim in (49). It remains to verify (J4) and (J5). Consider the telescoping sum

knhn
Wkhn - W(k-1)hn =
m=(k-1)nhn+1

n m

W.

By linearity it is enough to consider only one summand

n m

W

for

some

m

=

(k - 1) nhn +

1, . . . , knhn:

E kn

n m

W

|

G(k-1)hn

nhn-1

= n1/4hn

wj k E

j=1

S~j2k

nhn-1

= n1/4hn

wjkE n

j=1

nmW G(k-1)hn - E S~j2k G(k-1)hn E

n m

W

|

G(k-1)hn

nX~ , jk 2
n

n m

W

-

2

n

nX~ , jk

[
n

, jk]n

n m

W

+ [ , jk]n2 mn W G(k-1)hn

nhn-1
= n1/4hn
j=1

wj k E

n nX~ , jk 2
n

mn W G(k-1)hn

.

26

The second equality holds because the mn W are centered. The last one holds because the noise is centered and because noise and signal are independent. The expectation, however, vanishes for all
frequencies j which follows by independence of the Brownian increments:

E

n nX~ , jk 2
n

n m

W

G(k-1)hn

n
= (2k-1)hn E
l,p=1

n l

W

pnW

mn W

jk

l n

jk

p n

= 0.

th-n 1

Therefore

E kn

hn-1 k

W

G(k-1)hn

=0

for all 0  t  1.

k=1
Let N be a bounded (Gt)0t1-martingale with N0 = 0 and W, N  0. For the telescoping sum

knh
Nkhn - N(k-1)hn =
m=(k-1)nh+1

mn N

by linearity it is enough to consider E kn mn N | G(k-1)hn for some m = (k - 1) nhn+1, . . . , knhn. Just like above we end up with

E kn mn N | G(k-1)hn

nhn-1

= n1/4hn

wj k E

j=1

n nX~ , jk 2
n

n m

N

G(k-1)hn

.

The expectation

E

n nX~ , jk 2
n

nmN G(k-1)hn =

n
(2k-1)hn E

l,p=1

lnW

np W

nmN

jk

l n

jk

p .
n

vanishes, except for l = p = m, p < l = m or l < p = m. The last two cases are handled similarly. For instance, for l < p = m, the process (WsNs)0s1 is a (Gs)0s1-martingale because N, W  0 such that

E

lnW pnW mn N G(k-1)hn = E

n l

W

E

mn W

n m

N

|

G

m-1

n

G(k-1)hn = 0.

With respect to the first case we obtain by Ito^'s formula

E

(

n l

W

)2

lnN G(k-1)hn = E

( lnW )2 -

1 n

1 +E n

nl N G(k-1)hn = E

l n
Ws dWs
l-1 n

nl N G(k-1)hn lnN G(k-1)hn .

However,

t 0

Ws

dWs

∑ Nt is also a (Gt)0t1-martingale because
0t1

t 0

Wsd

W, N

s = 0. As for the last two cases above, this implies

∑ 0

Ws

dWs,

N

t

=

E ( nl W )2 lnN G(k-1)hn = 0.

This completes the proof of Proposition 4.1.

27

6.3. Proof of Proposition 4.2
We first give a general outline of the proof, deferring some technical details to the end of this section. By Taylor we have for all k = 1, . . . , h-n 1 and j = 1, . . . , nhn - 1, the existence of random variables jk such that Sj2k - S~j2k = 2S~jk(Sjk - S~jk) + 2(jk - S~jk)(Sjk - S~jk) and |jk - S~jk|  |Sjk - S~jk|. This yields

1
n4

or
IVn,t(Y

)

-

IVonr,t(X~

+

)

1
= n4

th-n 1 nhn-1
hn wjk

Sj2k - S~j2k

k=1 j=1

th-n 1 nhn-1

1
= n 4 hn

wjk 2S~jk Sjk - S~jk

k=1 j=1

th-n 1 nhn-1

1
+ n 4 hn

wjk jk - S~jk

Sjk - S~jk

k=1 j=1

.

For the second sum above, which we denote by Ztn, we obtain by the Markov inequality and Step 1 below for any  > 0

P sup |Ztn| > 
0t1

P

h-n 1 nhn-1

1

n 4 hn

wjk

Sjk - S~jk 2

>

k=1 j=1

h-n 1 nhn-1



-1

n

1 4

hn

wj k E

Sjk - S~jk 2

k=1 j=1

-1

n

1 4

hn



0.

Let Tjnk =

nhn j=1

-1

wj

k

2S~jk

Sjk - S~jk

and write the first sum above as Mtn + Rtn with

thn-1

Mtn

=

1
n 4 hn

Tjnk - E Tjnk G(k-1)hn

k=1

th-n 1

Rtn

=

1
n 4 hn

E Tjnk G(k-1)hn .

k=1

,

In Step 2 we show that

th-n 1
E
k=1

n

1 4

hn

Tjnk

2

- 0,

n - .

A well known result thereby yields Mtn -u-cp 0. Finally, observe that

E 2S~jk Sjk - S~jk G(k-1)hn

= E 2 n nX~ , jk n - [ , jk]n n n X - X~ , jk n G(k-1)hn

=E

2

n

nX~ , jk
n

n

n

X - X~

, jk n G(k-1)hn

,

28

i.e. the noise terms vanish, thereby simplifying the following calculations. Write E[(2S~jk(Sjk - S~jk))|G(k-1)hn ] as the sum Djnk + Vjnk with

n

Djnk

=

E

2n

nX~ , jk
n

l=1

n

Vjnk

=

E

2n

nX~ , jk
n

l=1

l

nl

bs ds
l-1

jk

n

n

l n
l-1 s - (k-1)hn
n

G(k-1)hn , l
dWs jk n

G(k-1)hn .

In Step 3 we show that |Djk + Vjk| hn for some  > 1/2. This yields immediately

h-n 1 nhn-1

sup |Rtn|



1
n 4 hn

wjk Djnk + Vjnk

0t1

k=1 j=1

1
n4

hn

=

O

(1)

,

implying ucp-convergence. We therefore conclude that

1
n4

or
IVn,t(Y

)

-

IVnor,t(X~

+

)

-u-cp 0, n - .

The second claim follows from Step 4 and

t 0

s2 - 2sh-n 1 hn

ds -u-cp 0,

n - 


t

thn-1



P  sup
0t1

1
n4 

0

s2 ds - hn

k=1

(2k-1)hn 

> 



 th-n 1

1
P  sup n 4

0t1

k=1

khn
(k-1)hn s2 - (2k-1)hn

  ds >  2

+

1
P sup n 4
0t1

t thn-1

hn

s2 ds

>

 2

hn-1

-1n

1 4

E

k=1

khn
(k-1)hn s2 - (2k-1)hn

ds

+ -1

1
sup n 4

t-

thn-1 hn

0t1

-1n

1 4

hn

for any  > 0 and some  > 1/2 what proves Proposition 4.2. We end this section with detailed proofs of Steps 1 ≠ 4.
Step 1: E[(Sjk - S~jk)4] h2n Using the decomposition

Sjk - S~jk = n
n
=
l=1

n(X - X~ ), jk
n

l
nl

bs ds
l-1

jk

n

n

n
+
l=1

(53)
l
nl l-1 s - (k-1)hn dWs jk n
n

29

into drift and volatility terms we obtain

E Sjk - S~jk 4


n
E
l=1

n
+E
l=1

l

nl

bs ds
l-1

jk

n

n

4 

l
nl l-1 s - (k-1)hn dWs jk n
n

4 .

l

The first addend is bounded by h2n. For the second let l =

n l-1

s - (k-1)hn

dWs, such that

n


n
E
l=1

l

n
l-1 s - (k-1)hn dWs

jk

l n

n

4 

l l pp = E ll pp jk n jk n jk n jk n .
l,l ,p,p

Properties of the conditional expectation show that the only choices for l, l , p, p with non-trivial results are l, l < p = p , l < l = p = p and l = l = p = p . In all three cases we can conclude by the Burkholder inequality and (42b) that

l l pp E ll pp jk n jk n jk n jk n

n-4h-n 2.

Observe that in any of the three mentioned cases we find at least two identical integers l, l , p or p . In

all, there are nhn ∑

nhn-1 2

∑ 4! possibilities to choose such indices. Hence, we obtain


n
E
l=1

l
nl l-1 s - (k-1)hn dWs jk n
n

4  (nhn)3 n-4hn-2 = n-1hn h2n

and therefore the claim holds.

Step 2:

thn-1 k=1

1
E[(n 4

hn Tjnk )2 ]

-

0,

n - 

Applying the Minkowski and Cauchy-Schwarz inequalities, we obtain

nhn-1

1

n 4 hn

wjk

j=1



nhn-1



1
n2

h2n



j=1

2S~jk Sjk - S~jk

2 L2(P)

2

wjk 2S~jk Sjk - S~jk


L2(P)



nhn-1



1
n2

h2n



wjk

j=1

E S~j4k

1
4
E

Sjk - S~jk 4

1 2
4
.

By Step 1 we already know that E Sjk - S~jk 4 bound

E S~j4k



1
E2

E

S~j8k G(k-1)hn

hn2 . Because  is bounded, we obtain by (50) the

1
E2

(2k-1)hn

+

2 n

[j k ,

j k ]n

4

30

2 1 + n [jk, jk]n

2


2 4 1 + n [jk, jk]n .

Together with (45) it follows that

thn-1
E
k=1

n

1 4

hnTjnk

2

th-n 1


nhn-1

n

1 2

hn3

 wjk

k=1 j=1

1
n2

h2n

∑

n2hn4

=

O

(1)

.

2 2 1 + n [jk, jk]n 

Step 3: |Djk + Vjk| hn for some  > 1/2 Expanding the sums in Vjk and Ito^ isometry yield

|Vjk| = =

n

E

n l

X~

m n
m-1 s - (k-1)hn dWs

G(k-1)hn jk

l n

jk

m n

l,m=1

n

n
E
l=1

l n
l-1 (k-1)hn s - (k-1)hn
n

ds 2jk

l n

.

Observe that we have in the semimartingale case for  that

E (k-1)hn s - (k-1)hn

ds = E (k-1)hn E s - (k-1)hn G(k-1)hn

s

= E (k-1)hn

~br dr

(k-1)hn

hn,

ds

because  and ~b are bounded. In the Ho®lder case, on the other hand, it holds similarly that

E (k-1)hn s - (k-1)hn ds

hn .

Hence, we can conclude in any case by Fubini that

(54)

E (k-1)hn s - (k-1)hn ds

hn

for some  > 1/2 such that |Vjk| hn , as well. With respect to Djnk, we need an additional approximation. By Assumption (H-1) and the boundedness of E[| n nX~ , jk n|], see (48):

l

E

n

nX~ , jk
n

n

bs ds
l-1

G(k-1)hn

n

l

E

n

nX~ , jk
n

n l-1

bs - b(k-1)hn

n

+

b(k-1)hn nE

n nX~ , jk n G(k-1)hn

ds G(k-1)hn hnn-1.

Using this bound, we find with (bs) being -Ho®lder that

Djnk

nl



E

2

n

nX~ , jk
n

n l-1

bs - b(k-1)hn

ds G(k-1)hn

l=1 n

l jk n

31

hn

1n n

jk

l n

l=1

hn+

1 2

.

We obtain the claim with  = min



+

1 2

,



. This is the only time we need the Ho®lder smoothness

of the drift in Assumption (H-1).

Step 4: E

khn (k-1)hn

s2 - (2k-1)hn

ds

hn1+ for some  > 1/2.

For each block k = 1, . . . , hn-1, and all 0  s  1, we can find random variables k,s with

s2 - (2k-1)hn = 2(k-1)h s - (k-1)hn + 2 k,s - (k-1)hn s - (k-1)hn

and k,s - (k-1)hn  s - (k-1)hn . Note that this implies in the semimartingale case for  by (54) that

E s2 - (2k-1)hn

E (k-1)hn E s - (k-1)hn hn + E s - (k-1)hn 2 .

G(k-1)hn

+ E s - (k-1)hn 2

Hence, we see by Fubini and (42b) that

khn
E s2 - (2k-1)hn ds
(k-1)hn

h2n + E

khn s - (k-1)hn 2 ds
(k-1)hn

h2n.

In the Ho®lder case we obtain directly by the boundedness of :

khn
E (k-1)hn s2 - (2k-1)hn ds

E

khn (k-1)hn

s - (k-1)hn

ds

hn1+.

Because  > 1/2, we obtain the claim with  = min(, 1).

6.4. Proofs of Theorem 2 and Theorem 3 for oracle estimation We decompose X similarly as in the proof of Theorem 1:

Xt = X0 + BØt + B~t + CØt + C~t ,

where we denote

tt
BØt = 0 b shn-1 hn ds , B~t = 0 (bs - b sh-n 1 hn ) ds ,

(55) (56a)

tt
CØt = 0  sh-n 1 hn dWs , C~t = 0 (s -  shn-1 hn ) dWs .

(56b)

In order to establish a functional CLT, we decompose the estimation errors of (29a) (and likewise (25a)) in the following way:

LMMonr,t(Y ) - vec

t
s ds = LMMnor,t(CØ + ) - vec
0

t
0  sh-n 1 hn ds

(57a)

32

+ LMMonr,t(Y ) - LMMonr,t(CØ + ) - vec

t
0 s -  sh-n 1 hn ds .

(57b)

One crucial step to cope with multi-dimensional non-synchronous data is Lemma 4.4 which is proved next. Below, we give a concise proof of the functional CLTs for the estimators (29a) and (25a), where after restricting to a synchronous reference scheme many steps develop as direct extensions of the one-dimensional case. The stable CLTs for the leading terms, namely the right-hand side of (57a) and the analogue for estimator (25a), are established in paragraph 6.4.2. The remainder terms (57b) and their analogues are handled in paragraph 6.4.3.

6.4.1. Proof of Lemma 4.4 Consider for (l, m)  {1, . . . , d}2, observation times t(il) = Fl-1(i/nl) and ti(m) = Fm-1(i/nm)
and suppose without loss of generality nm  nl. Define a next-tick interpolation function by
t(+l)(s) = min t(vl), 0  v  nl|t(vl)  s , l = 1, . . . , d,

and analogously a previous-tick interpolation function by

t-(l)(s) = max t(vl), 0  v  nl|t(vl)  s , l = 1, . . . , d.

We decompose increments of X(l) between adjacent observation times tv(l-) 1, tv(l), v = 1, . . . , nl, in the sum of increments of X(l) over all time intervals [ti(-m1), t(im)] contained in [t(vl-) 1, tv(l)] and the remaining time intervals at the left t(vl-) 1, t(+m) tv(l-) 1 and the right border t-(m) tv(l) , tv(l) :

Xt(v(ll))

-

X (l)
t(vl-) 1

=

Xt((vll))

-

X (l)
t(-m) (t(vl) )

+
it(m)v t(l)

Xt((ilm) )

-

X (l)
t(i-m1)

+

X - X(l)
t+(m)(tv(l-) 1)

(l) t(vl-) 1

.

If there is only one observation of X(m) in [tv(l-) 1, tv(l)], set

it(m)v t(l)

Xt((ilm) )

-

X (l)
t(i-m1)

= 0.

If there is no observation of X(m) in [t(vl-) 1, tv(l)] we take the union of a set of intervals vV [tv(l-) 1, tv(l)]

which contains at least one observation time of X(m). We use an expansion of jk(t) - jk(s) .

By virtue of sin(t) - sin(s) = 2 cos((t + s)/2) sin((t - s)/2) and the sine expansion, we obtain for

s, t  [khn, (k + 1)hn): jk(t) - jk(s)

2hn-3/2j cos

jh-n 1(

t+s 2

-

khn)

(t - s) .

(58)

In particular, for (t - s) = O(n-1) we have that

jk(t) - jk(s)

=O

jk

(

t+s 2

)n-1

.

With uv(m) = (1/2)(t(+m)(t(vl)) - t(-m)(tv(l))) and u~v(m) = (1/2)(t(+m)(tv(l-) 1) - t-(m)(t(vl-) 1)), we infer

thn-1
hn

nl nm

wjl,km

i X (l) j k (tØi(l) )

v X (m) j k (tØ(vm) )

k=1 j1

i=1

v=1

thn-1
= hn

nl
wjl,km

k=1 j1

i=1

Xt((ill))

-

X (l)
t(i-l)1

nl
j k (tØ(i l) )
v=1

Xt((vml))

-

X (m)
t(vl-) 1

thn-1
+ hn

nl
wjl,km

k=1 j1

v=1

Xt(v(ll))

-

X (l)
t(vl-) 1

j k (tØ(vl) )

j k (tØ(vl) )

33

◊

it(m)v t(l)

Xt((imm))

-

X (m)
ti(-m1)

(jk(tØi(m)) - jk(tØ(vl)))+

X - X(m)
t(+m)(tv(l-) 1)

(m) tv(l-) 1

jk(u~(vm)) - jk(tØv(l))

+

Xt(v(ml))

-

X (m)
t-(m) (tv(l) )

jk(u(vm)) - jk(tØv(l)) .

Applying the bound (58), we find that the order of the last summand is k hn j wjl,kmj/(nhn) and since for all weights the bound (44) holds we conclude that the approximation error is uniformly of order OP(hn) = OP(n-1/4).

6.4.2. Leading terms This paragraph develops the asymptotics for the right-hand side of (57a) and the sum of the incre-
ments in (38). Observe that

nl-1
j2k t(il)
i=1

ti(+l)1-t(i-l)1 2 2

 tnl-1
2

(l) t(i+l)1-ti(-l)1 Hlkhn

jk i

2 l2nl

i=1

1
2jk(t) dt
0

.Hlkhn
l2 nl

(59)

The left approximation uses (t(i+l)1 -ti(l))/2 = (Hlkhn +O(hn))/(l2nl) as in (43) with  > 1/2 by Assumption (Obs-d). Writing the integral on the right-hand side as sum over the subintervals and using mean value theorem, the differences when passing to the arguments (ti(l))i induce approximation errors of order jh-n 1n-1. Thus, the total approximation errors are of order (hn + j(nhn)-1)j2(nhn2 )-1. We focus on the oracle versions of (29a) and (25a) with their deterministic optimal weights. The
proof follows the same methodology as the proof of Proposition 4.1 after restricting to a synchronous
reference observation scheme. We concisely go through the details for cross terms and the proof for
the bivariate spectral covolatility estimator.
We apply Theorem 3-1 of Jacod (1997) (or equivalently Theorem 2.6 in Podolskij and Vetter (2010))
again. For the spectral estimator (25a), consider

kn = n1/4 hn

wjpk,qj(kpq) - ((pkq-)1)hn ,

j1

(60)

with the random variables

 np j(kpq) =  inCØ(p)jk tØi(p)
i=1

np-1

-

(p) i

jk

t(ip)

i=1

t(i+p)1 - ti(-p)1 2

(61)

nq
◊ vnCØ(q)jk tØ(vq)

nq -1
-

v(q)jk t(vq)



tv(q+)1

- 2

tv(q-)1

-

2j2h-n 2p,qH^pkhn np-1

.

v=1 v=1

The accordance with (38) follows from a generalization of the summation by parts identity(41c):

Sj(kp)

np-1
p - Yv(p) jk tØv(p+)1 - jk tØ(vp)

v=1

p

- np-1 Yv(p)jk(t(vp)) t(vp+)1

- 2

t(vp-)1

,

v=1

where the first remainder, which is only due to end-effects when t0(p) = 0 or t(npp) = 1, and the second remainder by application of mean value theorem and passing to arguments tv(p) are asymptotically

34

negligible. This is obvious for the first remainder and the second is treated analogously as for the
approximation between discrete and continuous-time norm of the (jk) in the following. By Lemma 4.4 we may without loss of generality work under synchronous observations ti, i = 0, . . . , n, when considering the signal part X. Set tØi = (ti+1 - ti)/2. We shall write in the sequel terms of the signal part as coming from observations on a synchronous grid (ti), while keeping to the actual grids for the noise terms. For the expectation we have

n

E j(kpq) =

2jk(tØi)E inCØ(p)inCØ(q)

i=1

(np nq )-1
+E
i,v=1

(p) i

(q) i

jk

ti(p)

 tti(+p)1-ti(-p)1
2

(q) jk v

tv(q+)1 -tv(q-) 1 2

-

2j2hn-2

[p,q E H^pkhn
np

]

n
= j2k(tØi)(ti+1 - ti)((pkq-)1)hn + p,q
i=1

np
p2 j2k t(ip)
i=1

ti(+p)1 -t(i-p)1 2

2

-

2

j

2

h-n 2

Hpkhn np

= ((kpq-)1)hn + Rn,k

by Ito^ isometry. The remainders due to the approximation (59) satisfy with (44) uniformly

Rn,k

 nhn
j2n-1h-n 2 hn + jn-1h-n 1
j=1

nhn-1
+
 nhn

j-1hn + j-2h2nnhn

= O n-1/4

.

Since j1 wjpk,q = 1, asymptotic unbiasedness is ensured:

th-n 1
E kn G(k-1)hn
k=1

thn-1
= n1/4hn
k=1

wjpk,qE[j(kpq)] - ((pkq-)1)hn
j1

-ucp 0 .

We now determine the asymptotic variance expression in (11):

Var j(kpq) =

n 2jk(tØi)(ti+1 - ti) 2
i=1

((kpq-)1)hn 2 + ((pkp-)1)hn ((kqq-)1)hn

np-1

+ p2q2

2jk t(ip)

ti(+p)1-ti(-p)1 2 2

nq -1
2jk t(iq)

ti(+q)1-ti(-q)1 2 2

i=1 i=1

+

n np-1

2jk(tØi)(ti+1 - ti) p2((kqq-)1)hn

j2k t(ip)

t(i+p)1-ti(-p)1 2 2

i=1 i=1

nq -1

+ m2 ((pkp-)1)hn

j2k ti(q)

i=1

ti(+q)1-ti(-q)1 2 2

((pkq-)1)hn 2 + ((pkp-)1)hn ((kqq-)1)hn + 2j2hn-2 Hpkhn n-p 1((qkq-)1)hn + Hqkhn n-q 1((kpp-)1)hn

+ 4j4h-n 4np-1nq-1Hpkhn Hqkhn ,

where the remainder is negligible by the same bounds as for the bias above. The sum of conditional variances with wjpk,q = Ik-1Ijk, Ik = j1 Ijk, thus yields

th-n 1
E
k=1

(kn)2 G(k-1)hn

+ O(1) =

th-n 1
hn2 n1/2
k=1 j1

wj(pkq) 2Var j(kpq)

35

th-n 1

thn-1

=

hn2 n1/2

IjkIk-2 =

hn2 n1/2Ik-1.

k=1 j1

k=1

 As hn n  , we obtain an asymptotic expression as the solution of an integral

thn-1
E (kn)2 G(k-1)hn
k=1

= th-n 1 hn(nhn)Ik-1 
k=1

t 0

 -1
(f (, H(t), cp, cq; z))-1dz ds
0

with a continuous limit function f which is the same as in Bibinger and Reiﬂ (2013). Computing the

solution of the integral using the explicit form of Ik and f yields the variance

t 0

vs(p,q) 2 ds with

vs(p,q) 2 = 2 (Fp-1) (s)(Fq-1) (s)cp-1c-q 1(A2s - Bs)Bs 1/2

and the terms

◊ As + As2 - Bs - sgn(A2s - Bs) As -

As

=

(spp)

(Fq-1) (Fp-1)

(s)cp (s)cq

+

s(qq)

(Fp-1) (Fq-1)

(s)cq (s)cp

,

As2 - Bs ,

Bs = 4 (spp)s(qq) + (spq) 2 .

The detailed computation is carried out in Bibinger and Reiﬂ (2013) and we omit it here. sgn denotes the sign taking values in {-1, +1} and ensuring that the value of vs(p,q) 2 is always a positive real number. Contrarily to the one-dimensional case, in the cross term there is no effect of non-Gaussian
noise on the variance because fourth noise moments do not occur and component-wise independence.
The Lyapunov criterion follows from

E j(kpq) 4|G(k-1)hn

3 wjpk,q 4Ij-k2
j1

3 Ik-4 Ij2k = O(1)
j1

thn-1
E
k=1

kn

4
G(k-1)hn

thn-1

=O n

hn4

k=1

= O n-1/4

.

By Cauchy-Schwarz and Burkholder-Davis-Gundy inequalities, we deduce


n


n

E hn

wjpk,q

inCØ(p)ni CØ(q)2jk(tØi)

ni W

(p)


j1 i=1

i=1

n

= hn

wjpk,q

E inCØ(p)ni CØ(q)inW (p) 2jk(tØi)

j1 i=1

n

 hn

wjpk,q

(ti - ti-1)3/22jk(tØi) = O n-1/4 .

j1 i=1

By the analogous estimate with inW (q) the stability conditions are valid. This proves stable convergence of the leading term to the limit given in Theorem 2.
The heart of the proof of Theorem 3 is the asymptotic theory for the leading term (57a), namely the
analysis of the asymptotic variance-covariance structure. This is carried out in detail in Bibinger et al.

36

(2013) for the idealized locally parametric experiment using bin-wise orthogonal transformation to a

diagonal covariance structure. The only difference between our main term and the setup considered in

Bibinger et al. (2013) is the Gaussianity of the noise component. Yet, in the deduction of the variance

this only effects the terms with fourth noise moments where E[

4 i

]

=

3E[

2i ] in general.

Above we

explicitly proved that the resulting remainder converges to zero for the one-dimensional estimator and

this directly extends to the diagonal elements here. An intuitive heuristic reason why this holds is that

the smoothed statistics are asymptotically still close to a normal distribution, though the normality

which could have been used in Bibinger et al. (2013) does not hold here for fixed n in general. Based

on the expressions of variances for cross products and squared spectral statistics above, coinciding

their counterparts in the normal noise model when separating the remainder induced for the squares,

we can pursue the asymptotics along the same lines as the proof of Corollary 4.3 in Bibinger et al.

(2013). At this stage, we restrict to shed light on the connection between the expressions in (13) and

the asymptotic variance-covariance matrix. Observe that (A  B) = A  B for matrices A, B,

ZZ = 2Z and that (A  B)(C  D) = (AC  BD) for matrices A, B, C, D, such that

1
s2 

sH

1 4

Z

1
s2 

Hs

1 4

Z

=

1
s2 

Hs

1 4

2Z

1
s2 

sH

1 4

=2

s 

sH

1 2

Z,

since Z commutes with

1
s2 

Hs

1 4

. Therefore, the expression in (13) is natural for the matrix

square root of the asymptotic variance-covariance, where we use two independent terms because of

non-commutativity of matrix multiplication. Conditions (J1) and (J3) and the stability conditions

(J4) and (J5) can be analogously showed by element-wise adopting the results for squared and cross

products of spectral statistics from above. Since any component of the estimator is a weighted sum of

the entries of SjkSjk, bias-corrected on the diagonal, the convergences to zero in probability follow likewise.

6.4.3. Remainder terms After applying triangular inequality to (57b), it suffices to prove that
n1/4 LMMnor,t(Y ) - LMMonr,t(CØ + ) -ucp 0 ,

(62)

n1/4

t
0 vec s -  sh-n 1 hn

ds

-ucp 0 .

For A, B  Rd, we use in the following several times the elementary bound:

(63)

AA - BB = B(A - B ) + (A - B)A  A + B A - B . (64)

Define analogously as above S~jk =

np i=1

ni CØ(p)jk

tØ(ip)

1pd, the spectral statistics in the

locally constant volatility experiment. Then we can bound uniformly for all t:

LMMnor,t(Y ) - LMMonr,t(CØ + )

37

hn-1
 hn
k=1

nhn-1
Wjk vec SjkSjk - S~jkS~jk
j=1

h-n 1

nhn-1

 hn

k=1 j=1

Wjk

Sjk + S~jk

Sjk - S~jk

hn-1

nhn-1

hn

k=1 j=1

j2 1 + nh2n

-2 Sjk - S~jk

= OP hn

= OP(n-1/4 ,

what yields (62). We have used Lemma C.1 from Bibinger et al. (2013) for the magnitude of Wjk , the bound (64) and a bound for the sum over j, for which holds

 1 nhn-1 nhn j=1

j2 1 + nhn2

-2   2

by an analogous integral approximation as used in the limiting variance before. Drift terms and

cross terms including the drift are asymptotically negligible and are handled similarly as before. Di-

rectly
np i=1

neglecting drift ni C~(p)jk(tØi)

terms, we deduce with (42b). (63) is

Sjk - S~jk = equivalent to

OP(hn)

uniformly

from

(Sjk

-

S~j k )(p)

p

h-n 1
n1/4

khn

s - (k-1)hn ds -ucp 0 .

k=1 (k-1)hn

(65)

For ( - 1) on Assumption (H-d), we have

h-n 1 khn

h-n 1

s - (k-1)hn ds  hn

sup

s - (k-1)hn = hn = O(n-1/4)

k=1 (k-1)hn

k=1 (k-1)hnskhn

uniformly, since  > 1/2, by (64) and boundedness of  on [0, 1]. For ( - 2) on Assumption (H-d), consider the decomposition:

s - (k-1)hn = ss - (k-1)hn (k-1)hn = (s - (k-1)hn )(k-1)hn + (k-1)hn (s - (k-1)hn ) + (s - (k-1)hn )(s - (k-1)hn )

for s  [(k - 1)hn, khn]. Here we derive uniformly the magnitude hn = OP(n-1/4) for all addends after application of the triangular inequality, since we can use that (s -(k-1)hn) is a semimartingale starting in zero w.r.t the filtration restricted to the time subinterval and analogously for the second addend. Standard bounds for their first two moments then readily render the magnitudes and we conclude (63). For the spectral covolatility estimator (25a) we may conduct an analysis of the remainder similarly as in the proof of Proposition 4.2. One can as well employ integration by parts of Ito^ integrals after supposing again a synchronous observation design ti, i = 0, . . . , n, possible according to Lemma 4.4:

inC~(p)ni C~(q) -

ti ti-1

s(pq) - (psqh)-n 1 hn ds

38

= ti C~s(p) - C~t(ip-)1 dC~s(q) + ti C~s(q) - C~t(iq-)1 dC~s(p) .

ti-1

ti-1

with C~ approximation errors as in (56b). Consider the random variables

(66)

nn

~j(kpq) =

i C~ (p) j k (tØi )

vC~(q)jk(tØv) ,

i=1 v=1

~kn = hn

wjpk,q~j(kpq) -

j1

(k+1)hn khn

(spq) - (psqh)-n 1 hn ds .

Inserting (66) for ni C~(p)ni C~(q), using [ Z dX, Z dX] = Z2 d[X, X] for Ito^ integrals and applying Burkholder-Davis-Gundy inequalities and using the bound (42b) for E ni C~(p) 2 , E inC~(q) 2 , it follows that E ~kn 2 = O(n-1). Bounds for cross terms with C~ and CØ readily follow by standard estimates and we conclude our claim.

6.5. Proofs for adaptive estimation We carry out the proof of Proposition 4.3 in the case d = 1 explicitly. We need to show that

n1/4

or
IVn,t - IVn,t(Y )

-ucp 0

as n   .

(67)

Since the noise constitutes the dominant component in observed increments ni Y = ni X + ( i - i-1), it is a simple task to show that the effect of estimating the noise level  is asymptotically
negligible. We shall concentrate on the harder problem of analyzing the plug-in estimation of the estimated instantaneous squared volatility process t2 in the weights. We have to bound

IVn,t

-

or
IVn,t(Y

)

=

thn-1

nhn-1

hn w^jk - wjk

k=1 j=1

Sj2k

-

[j k ,

j k ]n

2 n

,

uniformly with wjk the optimal oracle weights (21) and w^jk their adaptive estimates. We introduce a coarse grid of blocks of lengths rn such that rnhn-1   as n  . We analyze the above absolute value of the difference in this double asymptotic framework, where the plug-in estimators
are evaluated on the coarse grid first:

IVn,t

-

or
IVn,t(Y

)

=

trn-1

mrnh-n 1

nhn-1

hn

m=1

k=(m-1)rnh-n 1+1 j=1

wj (^(2m-1)rn ) - wj ((2m-1)rn )

Zjk

with Zjk = Sj2k - [jk, jk]n2/n - (2k-1)hn , because the weights as function of 2:

wjk =

w^jk = 1 and where we write

wj(2) = We conclude the uniform upper bound

2 +

2 n

[jk

,

j

k

]n

-2

nhn-1 l=1

2

+

2 n

[lk ,

lk ]n

-2 .

IVn,t

-

or
IVn,t(Y

)



rn-1 nhn-1
hn

wj (^(2m-1)rn ) - wj ((2m-1)rn )

m=1

j=1

mrnh-n 1
Zjk
k=(m-1)rnh-n 1+1

,

39

since the weights depend here on the same block of the coarse grid not on k. We prove that the right-
hand side is OP(n-1/4) in two steps: The above terms is OP(n-1/4) and also the remainder induced by the difference of a plug-in estimator on the coarse and finer grid is OP(n-1/4). Covariances of the Zjk are asymptotically negligible. We may directly consider Z~jk = S~j2k - [jk, jk]n2/n - (2k-1)hn, the statistics under locally parametric volatility and without drift by the asymptotic negligibility of the remainder proved above in Proposition 4.2. Then, the observation

E[Z~jkZ~j(k-l)] = E[E[Z~jkZ~j(k-l)|G(k-1)hn ]] = E[Z~j(k-l)E[Z~jk|G(k-1)hn ]] = 0 ,

for all k = 1, . . . , h-n 1, l = 1, . . . , (k - 1), by (46) shows that Var( k Z~jk) = k Var(Z~jk) and thus Var( k Zjk) = k Var(Zjk) + O(1). The crucial property to ensure tightness of the adaptive approach is a uniform bound on the first derivatives of the weight functions: wj(2) is continuously differentiable with the derivatives satisfying:

wj 2

wj 2 log2 (n) .

(68)

In

fact,

wj (2 )

is

well-defined

on

(-

2 n

[1k ,

1k ]n

,

)

and

the

differentiability

is

clear.

To keep

notation

simple

set

cj

=

2 n

[jk, jk]n.

Then,

we

have

wj (x)

-2 (x + cj)-3

nh-1 m=1

(x

+

cm)-2

-

(x

+

cj )-2

nh-1 m=1

(-2) (x + cm)-3

=

nh-1 m=1

(x

+

cm)-2

2

 2wj (x)

nh-1 m=1

(x

+

cm)-2

(x + cj)-1 - (x + cm)-1

nh-1 m=1

(x

+

cm

)-2

wj (x) log2(n)

for n sufficiently large. The last inequality follows from

(x + cj)-1 - (x + cm)-1

1+ 1 cj cm

1 = O log2 (n) . c1

The plug-in estimator established in Bibinger and Reiﬂ (2013) satisfies ^2 - 2 L1 = OP n for the L1-norm ∑ L1. Observe that with (44):

nhn-1
wj k (Va r(Z~j k ))1/2
j=1

nhn-1 j-4(nhn)4  1 1  j2(nhn)-2
j=1

log2 (n) .

(69)

Therefore, using -method we obtain that uniformly

or
IVn,t - IVn,t(Y ) = OP

hn rn

(log

n)4n

,

with the order |wj(^(2m-1)rn - wj((2m-1)rn )| = OP(wj((2m-1)rn )n log2(n)) using (68), n-1 being the convergence rate of the plug-in estimator which is n1/8 or faster, the negligibility of correlations of the (Zjk)k and (69). Here, we require that rn  0 not too fast, i.e. rn-1 n1/4(log n)-9.

40

Consider the remainder by the difference of coarse and finer grid. Since both versions are unbiased it is enough to bound the variance of the difference by:

rn-1

mrnh-n 1


nhn-1

h2n 

m=1 k=(m-1)rnh-n 1+1

j=1

E

wj ((2k-1)hn ) - wj ((2m-1)rn ) 2Z~j2k

2
1/2


hnrn log6 (n) ,

using (68) and (69), such that we require rn  0 fast enough that rn log6 (n)  0. In fact, we can easily find some rn  0 to render the above errors negligible. The proofs that Theorem 2 and Theorem 3 extend from the oracle to the adaptive versions of the
estimators (25a) and (29a) can be conducted in an analogous way. For covariation matrix estimation,
the key ingredient is the uniform bound on the norm of the matrix derivative of the weight matrix function Wj() w.r.t. , which is a matrix with d6 entries and requires a notion of matrix derivatives, see Lemma C.2 in Bibinger et al. (2013). The proof is then almost along the same lines as the proof
of Theorem 4.4 in Bibinger et al. (2013), with the only difference in the construction being that the
Zjk are not independent, but still have negligible correlations. The adaptivity in the proof of Theorem 4.4 of Bibinger et al. (2013) is proved under more delicate asymptotics of asymptotically separating
sample sizes. For this reason, but at the same time not having the remainders, the restrictions on rn are different there.

References
Abadir, K. M., Magnus, J. R., 2009. Matrix algebra, Vol. 1, Econometric Exercises. Cambridge University Press.
A®it-Sahalia, Y., Fan, J., Xiu, D., 2010. High-frequency estimates with noisy and asynchronous financial data. Journal of the American Statistical Association 105 (492), 1504≠1516.
Barndorff-Nielsen, O. E., Hansen, P. R., Lunde, A., Shephard, N., 2008. Designing realised kernels to measure the ex-post variation of equity prices in the presence of noise. Econometrica 76 (6), 1481≠1536.
Barndorff-Nielsen, O. E., Hansen, P. R., Lunde, A., Shephard, N., 2011. Multivariate realised kernels: consistent positive semi-definite estimators of the covariation of equity prices with noise and nonsynchronous trading. Journal of Econometrics 162 (2), 149≠169.
Bibinger, M., 2011. Efficient covariance estimation for asynchronous noisy high-frequency data. Scandinavian Journal of Statistics 38, 23≠45.
Bibinger, M., Hautsch, N., Malec, P., Reiﬂ, M., 2013. Estimating the quadratic covariation matrix from noisy observations: Local method of moments and efficiency. preprint, HU Berlin.
Bibinger, M., Reiﬂ, M., 2013. Spectral estimation of covolatility from noisy observations using local weights. Scandinavian Journal of Statistics, forthcoming.
Christensen, K., Podolskij, M., Vetter, M., 2013. On covariation estimation for multivariate continuous ito^ semimartingales with noise in non-synchronous observation schemes. Journal of Multivariate Analysis 120, 59≠84.

41

Cle¥ment, E., Delattre, S., Gloter, A., 2013. An infinite dimensional convolution theorem with applications to the efficient estimation of the integrated volatility. Stochastic Processes and their Applications 123, 2500≠2521.
Fukasawa, M., 2010. Realized volatility with stochastic sampling. Stochastic Processeses and their Applications 120, 209≠233.
Gloter, A., Jacod, J., 2001. Diffusions with measurement errors 1 and 2. ESAIM Probability and Statistics 5, 225≠242.
Hayashi, T., Yoshida, N., 2011. Nonsynchronous covariation process and limit theorems. Stochastic Processes and their Applications 121, 2416≠2454.
Jacod, J., 1997. On continuous conditional gaussian martingales and stable convergence in law. Se¥minaire de Probabilitie¥s, 232≠246.
Jacod, J., 2012. Statistics and high frequency data. Proceedings of the 7th Se¥minaire Europe¥en de Statistique, La Manga, 2007: Statistical methods for stochastic differential equations, edited by M. Kessler, A. Lindner and M. S¯rensen.
Jacod, J., Li, Y., Mykland, P. A., Podolskij, M., Vetter, M., 2009. Microstructure noise in the continous case: the pre-averaging approach. Stochastic Processes and their Applications 119, 2803≠2831.
Jacod, J., Mykland, P. A., 2013. Microstructure noise in the continuous case: Efficiency and the adaptive pre-averging method. working paper.
Podolskij, M., Vetter, M., 2010. Understanding limit theorems for semimartingales: a short survey. Statistica Neerlandica 64 (3), 329≠351.
Reiﬂ, M., 2011. Asymptotic equivalence for inference on the volatility from noisy observations. Annals of Statistics 39 (2), 772≠802.
Renault, E., Sarisoy, C., Werker, B. J. M., 2013. Efficient estimation of integrated volatility and related processes. SSRN: http://ssrn.com/abstract=2293570.
Tao, T., 2012. Topics in random matrix theory. Vol. 132 of Graduate Studies in Mathematics. American Mathematical Society, Providence, RI.
Xiu, D., 2010. Quasi-maximum likelihood estimation of volatility with high frequency data. Journal of Econometrics 159, 235≠250.
Zhang, L., 2006. Efficient estimation of stochastic volatility using noisy observations: A multi-scale approach. Bernoulli 12 (6), 1019≠1043.
Zhang, L., Mykland, P. A., A®it-Sahalia, Y., 2005. A tale of two time scales: Determining integrated volatility with noisy high-frequency data. Journal of the American Statistical Association 100 (472), 1394≠1411.
42

SFB 649 Discussion Paper Series 2014
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "Principal Component Analysis in an Asymmetric Norm" by Ngoc Mai Tran, Maria Osipenko and Wolfgang Karl H‰rdle, January 2014.
002 "A Simultaneous Confidence Corridor for Varying Coefficient Regression with Sparse Functional Data" by Lijie Gu, Li Wang, Wolfgang Karl H‰rdle and Lijian Yang, January 2014.
003 "An Extended Single Index Model with Missing Response at Random" by Qihua Wang, Tao Zhang, Wolfgang Karl H‰rdle, January 2014.
004 "Structural Vector Autoregressive Analysis in a Data Rich Environment: A Survey" by Helmut L¸tkepohl, January 2014.
005 "Functional stable limit theorems for efficient spectral covolatility estimators" by Randolf Altmeyer and Markus Bibinger, January 2014.
SFB 649, Spandauer Straﬂe 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

