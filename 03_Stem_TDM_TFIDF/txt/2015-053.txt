BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2015-053
Specification Testing in Random Coefficient Models
Christoph Breunig* Stefan Hoderlein*≤
* Humboldt-Universit‰t zu Berlin, Germany *≤ Boston College, United States of America This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universit‰t zu Berlin Spandauer Straﬂe 1, D-10178 Berlin

Specification Testing in Random Coefficient Models

Christoph Breunig  Stefan Hoderlein

Humboldt-Universit®at zu Berlin

Boston College

March 3, 2016

Abstract In this paper, we suggest and analyze a new class of specification tests for random coefficient models. These tests allow to assess the validity of central structural features of the model, in particular linearity in coefficients and generalizations of this notion like a known nonlinear functional relationship. They also allow to test for degeneracy of the distribution of a random coefficient, i.e., whether a coefficient is fixed or random, including whether an associated variable can be omitted altogether. Our tests are nonparametric in nature, and use sieve estimators of the characteristic function. We analyze their power against both global and local alternatives in large samples and through a Monte Carlo simulation study. Finally, we apply our framework to analyze the specification in a heterogeneous random coefficients consumer demand model.
Keywords: Nonparametric specification testing, random coefficients, unobserved heterogeneity, sieve minimum distance, characteristic function, consumer demand.
JEL classification: C12, C14

1 Introduction
Heterogeneity of individual agents is now widely believed to be an important - if not the most important - source of unobserved variation in a typical microeconometric application.
We thank seminar participants at Northwestern and WIAS Berlin. Christoph Breunig's research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 Economic Risk
Christoph Breunig, Humboldt-Universit®at zu Berlin, Spandauer Straﬂe 1, 10178 Berlin, Germany, e-mail: christoph.breunig@hu-berlin.de.
Stefan Hoderlein, Boston College, Department of Economics, 140 Commonwealth Ave, Chestnut Hill, MA 02467, USA, email: stefan hoderlein@yahoo.com.
1

Increasingly, the focus of econometrics shifts towards explicitly modeling this central feature

of the model through random parameters, as opposed to searching for fixed parameters that

summarize only, say, the mean effect. However, as always when additional features are being

introduced, this step increases the risk of model misspecification and therefore introducing

bias. This suggests to use all the information available in the data to assess the validity of the

chosen specification through a test before performing the main analysis. A second important

feature of a specification test is that we may be able to find a restricted model that is easier

to implement than the unrestricted one. This feature is particularly important in models of

complex heterogeneity, which are generically only weakly identified and therefore estimable

only under great difficulties.

This papers proposes a family of nonparametric specification tests in models with complex

heterogeneity. We focus on the important class of random coefficient models, i.e., models in

which there is a finite (db dimensional) vector of continuously distributed and heterogeneous parameters B  Rdb, and a known structural function g which relates these coefficients and a dx

dimensional vector of observable explanatory variables X to a continuous dependent variable

Y , i.e.,

Y = g(X, B).

(1.1)

Throughout this paper, we assume that X is independent of B (however, as we discuss below, this does not preclude extensions where some variables in the system are endogenous). The leading example in this class of models is the linear random coefficient model, where g(X, B) = X B, but we also propose specification tests in models where g is nonlinear. Indeed, in extensions we also consider the case where Y is binary, and/or where Y is a vector.
The simple linear model with independent random coefficients is well suited to illustrate our contribution and to explain the most important features of such a nonparametric specification test. This model is known to be exactly point identified in the sense that there is a one-to-one mapping from the conditional probability density function of the observable variables, fY |X to the density of random coefficients fB such that the true density of random coefficients is associated with exactly one density of observables (see, e.g., Beran et al. [1996] and Hoderlein et al. [2010]). However, despite the one-to-one mapping between population density of the data and density of random coefficients, the model imposes structure that can be used to assess the validity of the model. For instance, in the very same model, the conditional expectation is linear, i.e., E[Y |X] = b0 +b1X1 +...+bkXk, where bj = E[Bj]. This means that a standard linear model specification test for quadratic terms in X, or, somewhat more elaborate, nonparametric specification tests involving a nonparametric regression as alternative could be used to test the specification. Similarly, in this model the conditional skedastic function is at most quadratic in X, so any evidence of higher order terms can be taken as rejection of this linear random

2

coefficients specification, too. However, both of these tests do not use the entire distribution of

the data, and hence do not allow us to discern between the truth and certain alternatives.

In contrast, our test will be based on the characteristic function of the data, i.e., we use

the entire distribution of the data to assess the validity of the specification. In the example

of the linear model, we compare the distance between a series least squares estimator of the

unrestricted characteristic function E[exp(itY )|X], and an estimator of the restricted one, which

is E[exp(it(X B))|X] = exp(it(X b))fB(b)db, where the probability density function fB of the random coefficients B is replaced by a sieve minimum distance estimator under the hypothesis

of linearity. More specifically, using the notation (X, t) = E[exp(itY ) - exp(it(X B))|X], our

test is based on the observation that under the null hypothesis of linearity, (X, t) = 0 holds,

or equivalently,

E |(X, t)|2 (t)dt = 0,

for any strictly positive weighting function . Our test statistic is then given by the sample

counterpart

n
Sn  n-1
j=1

|n(Xj, t)|2 (t)dt,

where n denotes an estimator of  as described above. We reject the null hypothesis of linearity if the statistic Sn becomes too large.
This test uses evidently the entire distribution of the data to assess the validity of the spec-

ification. It therefore implicitly uses all available comparisons between the restricted and the

unrestricted model, not just the ones between, say a linear conditional mean and a nonpara-

metric conditional mean. Moreover, it does not even require that these conditional means (or

higher order moments) exist. To see that our test uses the information contained in the condi-

tional moments, consider again the linear random coefficients model. Using a series expansion

of the exponential function, (X, t) = 0 is equivalent to


(it)l E[Y l|X] - E[(X B)l|X] /(l!) = 0,
l=0

provided all moments exist. This equation holds true, if and only if, for every coefficient l  1 :

E[Y l|X] = E[(X B)l|X],

i.e., there is equality of all of these conditional moments. This implies, in particular, the first and second conditional moment equation E[Y |X] = X E[B] and E[Y 2|X] = X E[BB ]X. As such, our test exploits potential discrepancies in any of the conditional moments, and works even if some or all of them do not exist.

3

Our test is consistent against a misspecification of model (1.1) in the sense that, under the

alternative, there exists no vector of random coefficients B satisfying the model equation (1.1)

for a known function g. Indeed, such a misspecification leads to a deviation of the unrestricted

from the restricted conditional characteristic function. Moreover, our test is also consistent

against certain specific other alternatives, e.g., if the null is the linear random coefficient model

and the alternative is a higher order polynomial with random parameters.

However, we can also use the same testing principle to analyze whether or not a parameter is 
nonrandom, which usually allows for a n consistent estimator for this parameter, and whether

it has in addition mean zero which implies that we may omit the respective variable altogether.

This is important, because from a nonparametric identification perspective random coefficient

models are weakly identified (i.e., stem from the resolution of an ill posed inverse problem), a

feature that substantially complicates nonparametric estimation1. If we think of a parametric

model as an approximation to a more complex nonparametric model, this is likely also going

to affect the finite sample behavior of any parametric estimator. Since this can be tied to

the number of dimensions (see Hoderlein et al. [2010]), it is desirable to reduce the number of

dimensions of random parameters as much as possible. Our test may serve as guidance in this

process.

Finally, it is important to note that our method also applies to other point identified random

coefficient models such as models that are linear in parameters, but where X is replaced by

a element-wise transformation of the covariates (i.e., Xj is replaced by hj(Xj) with unknown hj. See Gautier and Hoderlein [2015] for the formal argument that establishes identification). The reason is that the mean regression in these models is still of an additive structure, i.e.,

in particular it does preclude interaction terms among the variables that feature across all

moments.

Extensions. While setting up the basic framework is a contribution in itself, a key insight

in this paper is that testing is possible even if the density of random coefficients is not point

identified under the null hypothesis. This is important, because many structural models are

not linear in an index. As such, it is either clear that they are not point identified in general

and at best set identified (see Hoderlein et al. [2014], for such an example), or identification

is unknown. To give an example of such a model, consider a stylized version of the workhorse

QUAIDS model of consumer demand (Banks et al. [1997]), where demand for a good Y is

defined through:

Y = B0 + B1X + B2X2,

where Bj denotes parameters, and X log total expenditure. For reasons outlined in Masten
1In a nonparametric sense, there is a stronger curse of dimensionality associated with random coefficient models than with nonparametric density estimation problems (see, e.g., Hoderlein et al. [2010]).

4

[2015], the joint density of random parameters B0, B1, B2 is not point identified in general. Our strategy is now to solve a functional minimization problem that minimizes a similar distance as outlined above between restricted and unrestricted model, and allows us to obtain one element in this set as minimizer. If the distance between the restricted model and the unrestricted model is larger than zero, we conclude that we can reject the null that the model is, in our example, a heterogeneous QUAIDS. However, if the distance is not significantly different from zero, there still may be other non-QUAIDS models which achieve zero distance, and which we therefore cannot distinguish from the heterogeneous QUAIDS model. As such, in the partially identified case we do not have power against all possible alternatives, and our test becomes conservative.
Interestingly, even if our model is not identified under the null hypothesis, such as in the case of the random coefficients QUAIDS model, our test still has power against certain alternatives, e.g., any higher polynomial random coefficient model. Again, since our test compares all conditional moments, (X, t) = 0 for all t implies that the cubic model Y = B0 +XB1 +X2B2 +X3B3 with random coefficients (B0, B1, B2, B3) or any other higher polynomial model is misspecified. In this sense, our test has power even in situations where neither the null nor the alternative model is identified.
The second extension is that our testing principle extends to systems of equations, i.e., situations in which the endogenous variable is not a scalar, but a vector, by replacing the scalar conditional characteristic function with a vector valued one, i.e., E [exp(it Y )|X = x] . For instance, one may reformulate the triangular random coefficients model of Hoderlein et al. [2014], where Y1 = A0 + A1Y2, Y2 = B2 + B3X as
Y1 = B0 + B1X, Y2 = B2 + B3X,
with B = (B0, B1, B2, B3)  X, and then either use the minimum distance principle outlined above, or, under the additional assumptions in Hoderlein et al. [2014], their estimator for the restricted model.
Finally, we may extend the approach outlined in this paper to binary or discrete dependent variables, provided we have a special regressor Z, as in Lewbel [2000]. In this case, we replace the density of the data with the marginal probability with respect to the special regressor; otherwise, most of the above reasoning remains virtually unchanged.
Related Literature. As already mentioned, this paper draws upon several literatures. The first is nonparametric random coefficients models, a recently quite active line of work, including work on the linear model (Beran and Hall [1992], Beran et al. [1996], and Hoderlein et al. [2010]),
5

the binary choice model (Ichimura and Thompson [1998] and Gautier and Kitamura [2013]), and the treatment effects model (Gautier and Hoderlein [2015]). Related is also the wider class of models analyzed in Fox and Gandhi [2009] and Lewbel and Pendakur [2013], who both analyze nonlinear random coefficient models, Masten [2015] and Matzkin [2012], who both discuss identification of random coefficients in a simultaneous equation model, Hoderlein et al. [2014] who analyze a triangular random coefficients model, and Dunker et al. [2013] and Fox and Lazzati [2012] who analyze games.
As far as we know, the general type of specification tests we propose in this paper is new to the literature. In linear semiparametric random coefficient models, Beran [1993] proposes a minimum distance estimator for the unknown distributional parameter of the random coefficient distribution. Within this framework of a parametric joint random coefficients' distribution, Beran also proposes goodness of fit testing procedures. Also, in a parametric setup where the unknown random coefficient distribution follows a parametric model, Swamy [1970] establishes a test for equivalence of random coefficient across individuals, i.e., a test for degeneracy of the random coefficient vector. We emphasize that with our testing methodology, despite less restrictive distributional assumptions, we are able to test degeneracy of a subvector of B while others are kept as random. Another test in linear parametric random coefficient models was proposed by Andrews [2001], namely a test for degeneracy of some random coefficients. In contrast, our nonparametric testing procedure is based on detecting differences in conditional characteristic function representation and, as we illustrate below, we do not obtain boundary problems as in Andrews [2001].
In this paper, we use sieve estimators for the unknown distributional elements. In the econometrics literature, sieve methodology was recently used to construct Wald statistics (see Chen and Pouzo [2015] and Chen and Pouzo [2012] for sieve minimum distance estimation) or nonparametric specification tests (see Breunig [2015b]), and, in nonparametric instrumental regression, tests based on series estimators have been proposed by Horowitz [2012] and Breunig [2015a]. Moreover, in the nonparametric IV model, tests for parametric specification have been proposed by Horowitz [2006] and Horowitz and Lee [2009], while Blundell and Horowitz [2007] proposes a test of exogeneity. Santos [2012] develops hypothesis tests which are robust to a failure of identification. More generally, there is a large literature on model specification tests based on nonparametric regression estimators in L2 distance starting with H®ardle and Mammen [1993]. Specification tests in nonseparable were proposed by Hoderlein et al. [2011] and Lewbel et al. [2015]. None of these tests is applicable to specification testing in random coefficient models.
Finally, our motivation is partly driven by consumer demand, where heterogeneity plays an important role. Other than the large body of work reviewed above we would like to mention
6

the recent work by Hausman and Newey [2013], Blundell et al. [2010], see Lewbel [1999] for a review of earlier work.
Overview of Paper. In the second section, we introduce our test formally, and discuss its large sample properties in the baseline scenario. We distinguish between general specification tests, and subcases where we can separate additively a part of the model which contains only covariates and fixed coefficients from the remainder. In the third section, we focus on the extensions discussed above. The finite sample behavior is investigated through a Monte Carlo study in the fourth section. Finally, we apply all concepts to analyze the validity of a heterogeneous QUAIDS (Banks et al. [1997]) model which is the leading parametric specification in consumer demand.
2 The Test Statistic and its Asymptotic Properties
2.1 Examples of Testable Hypotheses
In the wider class of models encompassed by (1.1), we consider two different types of hypotheses tests. First, we provide a general test for the hypothesis that the structural relation between the covariates, the random coefficients, and the outcome variable coincides with a known function g. We thus consider the hypothesis 2
Hmod : Y = g(X, B) for some random parameters B.
The alternative hypothesis is given by P Y = g(X, B) for all random parameters B > 0. An important example is testing the hypothesis of linearity, i.e., whether with probability one
Hlin : Y = X B,
in which case the distribution of B is point identified. Another example is a quadratic form of the function g in each component of the vector of covariates X, i.e., we want to assess the null hypothesis
Hquad : Y = B0 + X B1 + (X2) B2,
for some B = (B0, B1, B2), where the square of the vector X is understood element-wise. Note that in the latter example the distribution of the random parameters B is only partially identified. As already discussed above, this fact will generally result in a lack of power against certain alternatives.
2Equalities involving random variables are understood as equalities with probability one, even if we do not say so explicitly.
7

The second type of hypotheses our test allows to consider is whether a subvector of B, say, B2, is deterministic (or, equivalently, has a degenerate distribution). More specifically, we want to consider the following hypothesis

Hdeg : B2 = b2 for some B = (B0, B1, B2) satisfying (1.1).
The alternative is given by P B2 = b2 for all B satisfying (1.1) > 0. While the hypothesis Hdeg could be considered in more general models, motivated by the linear (or polynomial) model we will confine ourselves to functions g that are additively separable in the sense that

Hadd : Y = g1(X, B-2) + g2(X, B2),

(2.1)

where g1 and g2 denote two known functions, and we use the notation B-2 = (B0, B1) . The leading example for this type of hypothesis is of course when g1 is a linear function of a subvector X1 of covariates X, in which case we obtain a partially linear structure, i.e.,

Hpart-lin : Y = B0 + X1B1 + g2(X, B2),

(2.2)

where g2 is a known function. This covers the following examples of hypotheses already outlined in the introduction: First, in a linear model, i.e., Y = B0 + X1B1 + X2B2, it allows to test whether the coefficient on X2 is deterministic, i.e., we may test the null

Hdeg-lin : Y = B0 + X1B1 + X2b2,

against the alternative that B2 is random. Obviously, in this case b2 is identified by standard linear mean regression identification conditions. A second example arises if, in the quadratic model, we want to test a specification with deterministic second order terms, i.e.

Hdeg-quad : Y = B0 + X1B1 + (X12) b2,

against the alternative that B2 is random. Note that in the latter two hypotheses, identification of b2 follows as in parametric mean regression, and in equation (2.2), point identification under the null holds for instance if g2(X, b2) = h(X2) b2 for some vector valued function h such that the associated rank condition is satisfied. In the Monte Carlo study and the application, we will only consider the case where b2 is point identified, which we consider to be the leading case. However, we would like to point out that the test applies also more generally to situations where b2 need not to be point identified, as is in the most general case defined by hypothesis Hadd, albeit with a loss of power against some alternatives.

8

2.2 The Test Statistic
Our test statistic is based on the L2 distance between an unrestricted conditional characteristic function and a restricted one. We show below that each null hypothesis is then equivalent to

(X, t) = 0 for all t,

(2.3)

where  : Rdx+1  C is a complex valued, measurable function. Our testing procedure is based on the L2 distance of  to zero. Equation (2.3) is equivalent to

E (X, t) 2 (t)dt = 0,

for some strictly positive weighting function with (t)dt < . In the following examples, we provide explicit forms for the function . The analysis is based on the assumption of independence of covariates X and random coefficients B. See also the discussion after Assumption 1 below.
Example 1 (Testing functional form restrictions). The null hypothesis Hmod is equivalent to the following equation involving conditional characteristic functions

E[exp(itY )|X] = exp(itg(X, b))fB(b)db,

for each t  R, a known function g, and some random parameters B, with probability density function (p.d.f.) fB. Hence, equation (2.3) holds true with

(X, t) = E[exp(itY )|X] - exp(itg(X, b))fB(b)db.

(2.4)

As already mentioned, if the function g is nonlinear the p.d.f. of random coefficients B is not necessarily point identified. On the other side, if g is the inner product of its entries, then (2.3) holds true with
(X, t) = E[exp(itY )|X] - exp(itX b)fB(b)db,
and in this case the distribution of B is point identified (see, e.g., Hoderlein et al. [2010]). While our test, based on the function , is in general consistent against a failure of the null
hypothesis Hmod, it is also consistent against certain alternative models such as higher order polynomials which are not point identified. To illustrate this, consider testing linearity of the random coefficient QUAIDS model which is given by Y = B0 + B1X + B2X2 for random coefficients B0, B1, and B2 (also independent of X). In this case, the conditional first and second moment equation implied by equation (2.3) yield E[B2] = 0 and V ar(B2) = 0, respectively. We

9

thus conclude that B2 = 0 with probability one.
Example 2 (Testing degeneracy under the random coefficients specification). In the case of an additively separable structure Hadd (see equation (2.1)), the null hypothesis Hdeg implies the equality of conditional characteristic functions, i.e.,

E[exp(itY )|X] = exp itg1(X, b-2) fB-2(b-2)db-2 exp itg2(X, b2) , for each t  R. Therefore, equation (2.3) holds with

(2.5)

(X, t) = E[exp(itY )|X] - exp itg1(X, b-2) fB-2(b-2)db-2 exp itg2(X, b2) .
Given a partially linear structure Hpart-lin (see equation (2.2)), the null hypothesis Hdeg implies the equality of conditional characteristic functions, i.e., equation (2.3) holds with

(X, t) = E[exp(itY )|X] - exp(itX1b-2)fB-2(b-2)db-2 exp itg2(X, b2) ,
where the distribution of the random coefficients is identified. Our test, based on the function , has power against any failure of hypothesis Hdeg if the distribution of the random coefficients under the maintained hypothesis Hadd is identified, i.e., if g1 and g2 are linear in X1 and X2, respectively, or element-wise transformations of each component of these vectors (see Gautier and Hoderlein [2015]).
To illustrate that our test of degeneracy has power in the random coefficient QUAIDS model Y = B0 + B1X + B2X2, note that under the null the conditional first and second moment regressions implied by equation (2.3) already yield that E[B2] = b2 and E[B22] = b22, respectively. From this observation we are already in the position to conclude that B2 is degenerate with B2 = b2.
Example 3 (Testing degeneracy under additive separability alone). We also present an alternative test of degeneracy under Hadd (see equation (2.1)) when g1 depends on covariates X1 but not on a subvector X2 of the covariates X = (X1, X2) . In this case, we rely on additive separability alone and base our test on

E[exp(itY )|X] = E exp it(Y - g2(X, b2) X1 exp itg2(X, b2) .

(2.6)

Of course, such a test is only reasonable if the sigma algebra generated by X is not contained in the one generated by X1. This rules out, for instance, testing degeneracy in the random coefficient QUAIDS model where X is scalar and g2 is a quadratic function of X.

10

This test would not require any structure on the first term (despite not depending on X2), i.e., in equation (2.1) we do neither have to know g1, nor would have to assume that B-2 is finite. In contrast to the setting in Example 2, however, we require b2 to be point identified, which in the absence of any structure on g1 may be difficult to establish. There are examples where this structure could be useful. Consider for instance a model which has a complex nonlinear function in X1, but is linear in X2, i.e., Y = g1(X1, B-2) + X2B2, with an unknown function g1. Suppose a researcher wants to test the null that the random coefficients B2 has a degenerate distribution. In this case, b2 is identified by a partially linear mean regression model, since E[Y |X] = µ(X1) + X2b2, where µ(X1) = E[g1(X1, B-2)|X1]. Evidently, this test requires less structure on the way X1 enters, but in return suffers from lower power, e.g., if X1 indeed enters through a random coefficients specification.
As already mentioned, we use the fact that equation (2.3) is equivalent to
E (X, t) 2 (t)dt = 0,

for some strictly positive weighting function . Our test statistic is given by the sample counterpart to this expression, which is

n
Sn  n-1
j=1

n(Xj, t) 2 (t)dt,

where n is a consistent estimator of . Below, we show that the statistic Sn is asymptotically normally distributed after standardization. As the test is one sided, we reject the null hypothesis at level  when the standardized version of Sn is larger than the (1 - )≠quantile of N (0, 1).
We consider a series estimator for the conditional characteristic function of Y given X, i.e., (x, t)  E[exp(itY )|X = x]. To do so, let us introduce a vector of basis functions denoted by pm(∑) = (p1(∑), . . . , pm(∑)) for some integer m  1. Further, let Xm  pm(X1), . . . , pm(Xn) and Yn(t) = exp(itY1), . . . , exp(itYn) . We replace  by the series least squares estimator

n(x, t)  pmn(x) XmnXmn -1XmnYn(t),

where the integer mn increases with sample size n. We compare this unrestricted conditional expectation estimator to a restricted one which depends on the hypothesis under consideration.
Example 4 (Testing functional form restrictions (cont.)). Let us introduce the integral transform (Fgf )(X, t)  exp(itg(X, b))f (b)db, which coincides with the Fourier transform evaluated at tX, if g is linear.3 If g is nonlinear, then the random coefficient's p.d.f. fB does not
3The Fourier transform is given by (F )(t)  exp(itz)(z)dz for a function   L1(Rd) while its inverse is

11

need to be identified through  = Fgf . We estimate the function  by n(Xj, t) = n(Xj, t) - (FgfBn)(Xj, t),

where the estimator fBn is a sieve minimum distance estimator given by

fBn  arg min
f Bn

n j=1

|n(Xj, t) - (Fgf )(Xj, t)|2 (t)dt

(2.7)

and Bn = (∑) =

kn l=1

l

ql

(∑)

is a linear sieve space of dimension kn <  with basis functions

{ql}l1. Here, kn and mn increase with sample size n. As we see below, we require that mn

increases faster than kn. Next, using the notation Fn(t) = (Fgqkn)(X1, t), . . . , (Fgqkn)(Xn, t) ,

the minimum norm estimator of fB given in (2.7) coincides with fBn(∑) = qkn(∑) n where

n =

-

Fn(t) Fn(t) (t)dt

Fn(t) n(t) (t)dt

and n(t) = n(X1, t), . . . , n(Xn, t) .4 The exponent - denotes the Moore≠Penrose generalized inverse. As a byproduct, we thus extent the minimum distance estimation principle of Beran and Millar [1994] to nonlinear random coefficient models and the sieve methodology.
Example 5 (Testing degeneracy under the random coefficients specification (cont.)). We estimate the function  by

n(Xj, t) = n(Xj, t) - (Fg1fB-2,n)(Xj, t) exp itg2(Xj, b2n) ,

where the estimators fB-2,n and b2n are a sieve minimum distance estimators of the p.d.f. fB-2 and the parameter b2, respectively, given by

(fB-2n, b2n)  arg min
(f,b)B-2,n◊B2

n j=1

n(Xj, t) - (Fg1f )(Xj, t) exp itg2(Xj, b) 2 (t)dt (2.8)

and B-2,n = (∑) =

kn l=1

l

ql

(∑)

is a linear sieve space of dimension kn <  with basis

functions {ql}l1 of B-2 and B2 is a compact parameter space. See also Ai and Chen [2003]

for sieve minimum distance estimation for finite dimensional parameters and nonparametric

functions. As in the previous example, kn and mn increase with sample size n, but we require that mn increases faster than kn.

(F -1)(z)  (2)-d exp(-itz)(t)dt. 4The integral transform Fg of a vector of functions is always understood element-wise, i.e., (Fgqkn )(Xj, t) =
(Fgq1)(Xj, t), . . . , (Fgqkn )(Xj, t) .

12

Example 6 (Testing degeneracy under additive separability alone (cont.)). Let b2n denote a consistent estimator of the point identified parameter b2. For instance, under the partially linear structure Hpart-lin (see equation (2.2)), we have the moment restriction E[Y |X] = b0 + X1b1 + g2(X, b2) and thus, b2n would coincide with the nonlinear least squares estimator of b2. We denote pkn(∑) = (p1(∑), . . . , pkn(∑)) and X1n  pkn(X11), . . . , pkn(X1n) which is a n ◊ kn matrix. Consequently, we estimate the function  by
n(Xj, t) = n(Xj, t) - pkn(X1j) X1nX1n -1X1nUn exp itg2(Xj, b2n) ,
where Un = exp(it(Y1 - g2(X1, b2n))), . . . , exp(it(Yn - g2(Xn, b2n))) .
2.3 The Asymptotic Distribution of the Statistic under the Null Hypothesis
As a consequence of the previous considerations, we distinguish between two main hypotheses, i.e., functional form restrictions and degeneracy of some random coefficients. Both types of tests require certain common assumptions, and we start out this section with a subsection where we discuss the assumptions we require in both cases. Thereafter, we analyze each of the two types of tests in a separate subsection, and provide additional assumptions to obtain the test's asymptotic distribution under each null hypothesis.
2.3.1 General Assumptions for Inference
Assumption 1. The random vector X is independent of B.
Assumption 1 is crucial for the construction of our test statistic. Full independence is commonly assumed in the random coefficients literature (see, for instance, Beran [1993], Beran et al. [1996], Hoderlein et al. [2010], or any of the random coefficient references mentioned in the introduction). It is worth noting that this assumption can be relaxed by assuming independence of X and B conditional on additional variables that are available to the econometrician, allowing for instance for a control function solution to endogeneity as in Hoderlein and Sherman [2015], or simply controlling for observables in the spirit of the unconfoundedness assumption in the treatment effects literature. Further, X denotes the support of X.
Assumption 2. (i) We observe a sample ((Y1, X1), . . . , (Yn, Xn)) of independent and identically distributed (i.i.d.) copies of (Y, X). (ii) There exists a strictly positive and nonincreasing sequence (n)n1 such that, uniformly in n, the smallest eigenvalue of n-1E[pmn(X)pmn(X) ] is bounded away from zero. (iii) There exists a constant C  1 and a sequence of positive integers (mn)n1 satisfying supxX pmn(x) 2 Cmn with m2n log n = o(nn).
13

Assumption 2 (ii) - (iii) restricts the magnitude of the approximating functions {pl}l1 and imposes nonsingularity of their second moment matrix. Assumption 2 (iii) holds, for instance, for polynomial splines, Fourier series and wavelet bases. Moreover, this assumption ensures that the smallest eigenvalue of E[pmn(X)pmn(X) ] is not too small relative to the dimension mn. In Assumption 2 (ii), we assume that the eigenvalues of the matrix E[pmn(X)pmn(X) ] may tend to zero at the rate n which was recently also assumed by Chen and Christensen [2015]. On the other hand, the sequence (n)n1 is bounded away from zero if {pl}l forms an orthonormal basis on the compact support of X and the p.d.f. of X is bounded away from zero (cf. Proposition 2.1 of Belloni et al. [2015]). The next result provides sufficient condition for Assumption 2 (ii) to hold even if the sequence of eigenvalues (n)n1 tends to zero.
Proposition 1. Assume that {pl}l1 forms an orthonormal basis on X with respect to a measure . Let (n)n1 be a sequence that tends to zero. Suppose that, for some constant 0 < c < 1, for all n  1 and any vector an  Rmn the inequality

(anpmn(x))2 1 {f (x) < n}(dx)  c (anpmn(x))2(dx)

(2.9)

holds, where f = dFX/d. Then, Assumption 2 (ii) is satisfied.
Condition (2.9) is violated, for instance, if dFX/d vanishes on some subset A of the support of  with (A) > 0. Estimation of conditional expectations with respect to X is more difficult when the marginal p.d.f. fX is close to zero on the support X . In this case, the rate of convergence will slow down relative to n (see Lemma 2.4 in Chen and Christensen [2015] in case of series estimation). As we see from Proposition 2.9, n plays the role of a truncation parameter used in kernel estimation of conditional densities to ensure that the denominator is bounded away from zero.
To derive our test's asymptotic distribution, we standardize Sn by subtracting the mean and dividing through a variance which we introduce in the following. Let V  (Y, X), and denote by  a complex valued function which is the difference of exp(itY ) and the restricted conditional characteristic function, i.e., (V, t) = exp(itY ) - (FgfB)(X, t) in case of Hmod, and (V, t) = exp(itY ) - E[exp(it(B0 + X1B1))|X1] exp(itg2(X, b2)) in case of Hdeg. Moreover, note that E (V, t) X (t)dt = 0 holds.
Definition 1. Denote by Pn = E[pmn(X)pmn(X) ], and define

µmn  mn 

E |(V, t)|2pmn(X) Pn-1pmn(X) (t)dt and
2 1/2
Pn-1/2E (V, s)(V, t)pmn(X) pmn(X) Pn-1/2 (s) (t)dsdt . F

14

Here, we use the notation  for the complex conjugate of a function , and ∑ F to denote the Frobenius norm.

Assumption 3. There exists some constant C > 0 such that E | (V, t) (t)dt|2 X  C.

Assumption 3 ensures that the conditional variance of (V, t) (t)dt is uniformly bounded

away from zero. Assumptions of this type are commonly required to obtain asymptotic nor-

mality of series estimators (see Assumption 4 of Newey [1997] or Theorem 4.2 of Belloni et al.

[2015]).

As

we

show

in

the

appendix,

Assumption

3

implies

mn



 C mn.

2.3.2 Testing functional form restrictions

We now present conditions that are sufficient to provide the test's asymptotic distribution under

the null hypothesis Hmod. To do so, let us introduce the norm  = E|(X, t)|2 (dt) 1/2

and the linear sieve space n   : (∑) =

mn j=1

j

pl

(∑)

.

Moreover,

∑

and

∑ ,

respectively, denote the Euclidean norm and the supremum norm. Let us introduce An =

E[(Fgqkn)(X, t)(Fgqkn)(X, t) ] (t)dt and its empirical analog An = n-1 Fn(t) Fn(t) (t)dt

(see also Example 4).

Assumption 4. (i) For any

that 2

n =

Fg(knfB - o( mn) and

fB) 2 mn

= -

p.d.f. fB 
o( mn).

satisfying  = FgfB there exists knfB

(ii)

There

exists

mn 

 n 

such

that

  = O(1). (iii) It holds kn = o( mn). (iv) It

 Bn such n mn - holds A-n =

O(1) and P rank(An) = rank(An) = 1 + o(1). (v) There exists a constant C > 0 such that l1 Rdb (b)ql(b)db 2  C Rdb 2(b)db for all square integrable functions .

Assumption 4 (i) is a requirement on the sieve approximation error for all functions fB that belong to the identified set Ig  f : f is a p.d.f. with  = Fgf . This condition ensures that the bias for estimating any fB in the identified set Ig is asymptotically negligible. Assumption 4 (ii) determines the sieve approximation error for the function . Consider the linear case and let F (knfB - fB) = O(kn-s/dx) for some constant s > 0, then Assumptions 4 (i) and (iii) are satisfied if mn  n and kn  n where dx(1 - /2)/(2s) <  < /2.5 We thus require  > 2dx/(2s+dx), so s has to increase with dimension dx, which reflects a curse of dimensionality. In this case, Assumption 4 (ii) automatically holds if mn -  = O(mn-s/dx) and we may choose  to balance variance and bias, i.e.,  = dx/(2s + dx).6 For further discussion and examples of sieve bases, we refer to Chen [2007]. Assumption 4 (iv) ensures that the sequence
of generalized inverse matrices is bounded and imposes a rank condition. This condition is

5We use the notation an  bn for cbn  an  Cbn given two constant c, C > 0 and all n  1. 6This choice of kn corresponds indeed to the optimal smoothing parameter choice in nonparametric random coefficient model if s = r + (dx - 1)/2 where r corresponds to the smoothness of fB (see Hoderlein et al. [2010]
in case of kernel density estimation).

15

sufficient and necessary for convergence in probability of generalized inverses of random matrices
with fixed dimension (see Andrews [1987] for generalized Wald tests). Assumption 4 (v) is satisfied if {ql}l1 forms a Riesz basis in L2(Rdb)   : Rdb 2(s)ds <  . The following result establishes asymptotic normality of our standardized test statistic.

Theorem 2.1. Let Assumptions 1≠4 hold with (V, t) = exp(itY ) - (FgfB)(X, t). Then, under

Hmod we obtain

 ( 2mn )-1 n Sn - µmn

d N (0, 1).

Remark 2.1 (Estimation of Critical Values). The asymptotic results of the previous theorem depends on unknown population quantities. As we see in the following, the critical values can be easily estimated. We define n(V, t) = exp(itY ) - (FgfBn)(X, t), and

n(s, t) = n(V1, s)n(V1, t), . . . , n(Vn, s)n(Vn, t)) .

We replace µmn and mn, respectively, by the estimators µmn = tr XnXn -1/2Xn diag(n(t, t)) Xn XnXn -1/2 (t)dt

and mn =

XnXn -1/2Xn diag(n(s, t)) Xn XnXn -1/2 2

1/2
(s) (t)dsdt .

F

Proposition 2. Under the conditions of Theorem 2.1, we obtain

mnm-n1 = 1 + op(1)

and

 µmn = µmn + op( mn).

The asymptotic distribution of our standardized test statistic remains unchanged if we replace µmn and mn by estimators introduced in the last remark. This is summarized in following corollary, which follows immediately from Theorem 2.1 and Proposition 2.

Corollary 2.1. Under the conditions of Theorem 2.1, we obtain

 ( 2 mn )-1 n Sn - µmn

d N (0, 1).

An alternative way to obtain critical values is the bootstrap which, for testing nonlinear functionals in nonparametric instrumental regression, was considered by Chen and Pouzo [2015]. In our situation, the critical values can be easily estimated and the finite sample properties of our testing procedure are promising, thus we do not elaborate bootstrap procedures here. In

16

the following example, we illustrate our sieve minimum distance approach for estimating fB in the case of linearity of g.
Example 7 (Linear Case). Let g be linear and recall that in this case the integral transform Fg coincides with the Fourier transform F. For the sieve space Bn, we consider as basis functions Hermite functions given by

ql(x) =

(-1)l 
2ll! 

exp(x2/2)

dl dxl

exp(-x2).

These functions form an orthonormal basis of L2(R). Hermite functions are also eigenfunctions of the Fourier transform with
 (F ql)(∑) = 2 (-i)-lql(∑).

Let us introduce the notation ql(∑)  (-i)-lql(∑) and Xn(t) = qkn(tX1) , . . . , qkn(tXn) . Thus, the estimator of fB given in (2.7) simplifies to fBn(∑) = qkn(∑) n where

n
n = min Rkn j=1

n(Xj, t) - qkn(tXj)  2 (t)dt.

(2.10)

An explicit solution of (2.10) is given by

n =

-

Xn(t) Xn(t) (t)dt

Xn(t) n(t) (t)dt

where n(t) = n(X1, t), . . . , n(Xn, t) . We emphasize that under the previous assumptions, the matrix Xn(t) Xn(t) (t)dt will be nonsingular with probability approaching one.

2.3.3 Testing degeneracy under the random coefficient specification for the model

For testing degeneracy, Theorem 2.1 is not directly applicable as the required sieve approxi-

mation error in Assumption 4 (i) is here not satisfied in general. In contrast, we will impose

an approximation condition on the function g(x, t, b)  exp(itg2(x, b)) where b belongs to the

parameter space B2.

Let us introduce a (kn ∑ ln)≠dimensional vector valued function n given by n(x, t) =

(Fg1qkn)(x, t)  pln(x, t), where  denotes the Kronecker product and pln is a ln≠dimensional

vector of complex valued basis functions used to approximate g(∑, ∑, b). For instance, if g2(x, b) =

(x)(b) then approximation conditions can be easily verified due to g(x, t, b) = l0 pl(x, t)(b)l where pl(x, t) = it(x) l/l!. Let us introduce An = E[n(X, t)n(X, t) ] (t)dt and its

empirical analog An = n-1

n j=1

n(Xj

,

t)n(Xj

,

t)

(t)dt. Recall that B-2,n =

(b) =

17

kn l=1

lql(b)

for

b



Rdb2

where db2 denotes the dimension of b2 and let G2,n =

(x, t) =

ln l=1

lpl(x,

t)

.

Assumption 5. (i) The hypothesis Hadd holds. (ii) The set of parameters b2 satisfying (2.5)

belongs to a compact parameter space B2

G2,n satisfying n lng(∑, ∑, b) - g(∑, ∑, b) 2

there knln

exists 

kn fB-2



B-2,n

= o( mn). (vi) It holds

such An-

that =O



Rdb2 . 

(iii)

For

any

b



B2

there

exists

lng(∑, ∑, b)



= n

o( mn). (iv) For any Fg1 (kn fB-2 - fB-2 ) 2

p.d.f. fB-2 satisfying = o( mn). (v) It

(2.5) holds

(1) and P rank(An) = rank(An) = 1 + o(1). (vii)

There exists a constant C > 0 such that l,l 1 Fg1ql ∑ pl,  2  C  2 for all functions  with

 < .

Assumption 5 (i) states the maintained hypothesis of an additive structure of g given in
equation (2.1). Assumption 5 (iii) states an asymptotic condition of the sieve approximation error for g(∑, ∑, b) for any b in the parameter space B2. By doing so, we impose regularity conditions on the integral transform Fg2 of the Dirac measure at b but not on the Dirac measure itself. For instance, if again g2(x, b) = (x)(b) and pl(x, t) = it(x) l/l! for l  1 then lng(∑, ∑, b) - g(∑, ∑, b)  C/(ln + 1)! for some constant C > 0, provided that E[ln(X)] ln(b) tln (t)dt is bounded. Assumption 5 (v) restricts the magnitude of kn also relative to the dimension parameter ln, which is not too restrictive as the dimension kn is used to approximate a lower dimensional p.d.f. than in Theorem 2.1. Assumption 5 (iii) requires an
appropriate sieve approximation error only for any nondegenerate p.d.f. fB-2 satisfying (2.5). Assumption 5 (vi) and (vii), respectively, are closely related to Assumption 4 (iv) and (v).

Theorem 2.2. Let Assumptions 1≠3, 4 (ii), and 5 be satisfied with (V, t) = exp(itY ) -

(Fg1fB-2)(X, t) g(X, t, b2). Then, under Hdeg we obtain

 ( 2mn )-1 n Sn - µmn

d N (0, 1).

The critical values can be estimated as in Remark 2.1 but where now n(V, t) = exp(itY ) - (Fg1fB-2n)(X, t) g(X, t, b2n). The following result shows that, by doing so, the asymptotic distribution of our standardized test statistic remains unchanged. This corollary follows directly from Theorem 2.3 and the proof of Proposition 2; hence we omit its proof.

Corollary 2.2. Under the conditions of Theorem 2.3 it holds

 ( 2 mn )-1 n Sn - µmn

d N (0, 1).

Remark 2.2 (Comparison to Andrews [2001]). It is instructive to compare our setup and

18

results to Andrews [2001], who considers the random coefficient model:

Y = B0 + B1X1 + (b2 +  B2)X2,
where E[B0 ∑ B1|X] = 0, B1 is independent of B2, and E[B1|X] = E[B2|X] = 0. In this model, degeneracy of the second random coefficient is equivalent to  = 0 and degeneracy fails if  > 0. So under Hdeg the parameter  is on the boundary of the maintained hypothesis with   [0, ).
In contrast, we rely in this paper on independence of B to X under the maintained hypothesis. In this case, the hypothesis of degeneracy is equivalent to a conditional characteristic function equation as explained in Example 2 and which is not possible given the assumptions of Andrews [2001]. This is why in our framework we automatically avoid the boundary problem that is apparent in Andrews [2001].

2.3.4 Testing degeneracy under additive separability alone

We now establish the asymptotic distribution of our test of degeneracy based on separabil-

ity but not full knowledge of g1 (see Examples 3 and 6). We introduce the function h(∑, t) =

E[exp(it(Y -g2(X, b2))|X1 = ∑] and a linear sieve space Hn   : (x1) =

kn j=1

j pl (x1 )

for

x1



Rdx1 where dx1 denotes the dimension of X1. The series least squares estimator of h is denoted by hn(∑) = pkn(∑) X1nX1n -1X1nUn where Un = exp(it(Y1 - g2(X1, b2n))), . . . , exp(it(Yn -

g2(Xn, b2n))) and b2n denotes an estimator of b2. Recall the notation g(x, t, b)  exp(itg2(x, b))

for b  B2. Below we denote the vector of partial derivatives of g with respect to b by gb.

Assumption 6. (i) The hypothesis Hadd holds, where g1 need not to be known except that it

does not depend on X2.

(ii) There exists knh  Hn such that n

knh - h

2

=o

 mn

.

(iii)

The parameter b2 is point identified and belongs to the interior of a compact parameter space

B2



Rdb2 .

(iv)

There

exists

an

estimator

b2n

such

that

 n(b2n - b2)

=

Op(1)

(v)

The

function

g is partially differentiable with respect to b and 

E supbB2 gb(X, t, b) 2 (t)dt < . (vi) It

holds kn = o( mn).

Assumption 6 (ii) determines the required asymptotic behavior of the sieve approximation
bias for estimating h. This condition ensures that the bias for estimating the function h is
asymptotically negligible but does not require undersmoothing of the estimator hn. To see this, let knh - h = O(kn-s/dx1 ) for some constant s > 0. Assumptions 6 (ii) and (vi) are satisfied if mn  n and kn  n where dx1(1 - /2)/(2s) <  < /2. We thus require  > 2dx1/(2s + dx1) and we may choose  to balance variance and bias, i.e.,  = dx1/(2s + dx1). In this case, Assumption 4 (ii) automatically holds if mn- = O(m-n s/dx) and 2dx1  dx. Under a partially linear structure Hpart-lin, Assumptions 6 (iv) is automatically satisfied if b2n

19

coincides with the nonlinear least squares estimator. If g2 is linear, Assumption 6 (iv) holds true if E X 2 <  and t2 (t)dt < .

Theorem 2.3. Let Assumptions 1≠3, 4 (ii), and 6 hold, with (V, t) = exp(itY )-h(X1, t)g(X, t, b2). Then, under Hdeg we obtain

 ( 2mn )-1 n Sn - µmn

d N (0, 1).

The critical values can be estimated as in Remark 2.1 but where now n(V, t) = exp(itY ) - hn(X1, t) exp(itg2(X, b2n)). The following result shows that, by doing so, the asymptotic distribution of our standardized test statistic remains unchanged. This corollary follows directly from Theorem 2.3 and the proof of Proposition 2; hence we omit its proof.

Corollary 2.3. Under the conditions of Theorem 2.3 it holds

 ( 2 mn )-1 n Sn - µmn

d N (0, 1).

2.4 Consistency against a fixed alternative
In the following, we establish consistency of our test when the difference of restricted and unrestricted conditional characteristic functions does not vanish for all random parameters B. In case of testing functional form restrictions, this is equivalent to a failure of the null hypothesis Hmod, i.e., P Y = g(X, B) for all random parameters B > 0. A deviation of conditional characteristic functions can be also caused by alternative models with a different structural function (see Example 1). We only discuss the global power for testing functional form restrictions here, but the results for testing degeneracy follow analogously (of course, in this case we have to be more restrictive about the shape of g1 and g2 as discussed in Example 2). The next proposition shows that our test of functional form restrictions has the ability to reject a failure of the null hypothesis Hmod with probability one as the sample size grows to infinity.
Proposition 3. Suppose that Hmod is false and let Assumptions 1≠4 be satisfied. Consider a sequence (n)n1 satisfying n = o(nm-n1 ). Then, we have
 P ( 2 mn)-1 n Sn - µmn > n = 1 + o(1).

2.5 Asymptotic distribution under local alternatives
We now study the power of our testing procedure against a sequence of linear local alternatives that tends to zero as the sample size tends to infinity. First, we consider deviations from
20

the hypothesis of known functional form restriction. Under Hmod, the identified set in the nonseparable model (1.1) is given by Ig = f : f is a p.d.f. with  = Fgf . We consider the following sequence of local alternatives

 = Fg fB +  mn/n ,

(2.11)

for some function   L1(Rdb)L2(Rdb) and fB is a p.d.f. satisfying FgfB -  Fgf - for any p.d.f. f . Here, we assume that  is such that fB +  mn/n does not belong to the identified set Ig. The next result establishes asymptotic normality under (2.11) of the standardized test statistic Sn for testing functional form restrictions.

Proposition 4. Let the assumptions of Theorem 2.1 be satisfied. Then, under (2.11) we obtain

 ( 2 mn )-1 n Sn - µmn

d N

2-1/2 Fg 2 , 1 .

As we see from Proposition 4, our test can detect linear alternatives at the rate mn/n. Results for testing degeneracy follow similarly. In the following, we thus study deviations from

the hypothesis of degeneracy only under the maintained hypothesis Hlin : Y = B0 + B1X1 + B2X2. Under the maintained hypothesis of linearity, any deviation between the conditional characteristic functions is equivalent to a failure of a degeneracy of the random coefficients B2. Let us denote Bdeg  (B1, b2) with associated p.d.f. fBdeg . We consider the following sequence of linear local alternatives

fB = fBdeg +  mn /n,

(2.12)

for some density function   L1(Rdb)  L2(Rdb) which is not degenerate at b2. Applying the Fourier transform to equation (2.12) yields

E[exp(itX B)|X] = E[exp(it(B0 + X1B1))|X] exp(itX2b2) + exp(itX s)(s)ds mn/n.

The next result establishes asymptotic normality under (2.12) for the standardized test statistic Sn for testing degeneracy. This corollary follows by similar arguments used to establish Proposition 4 and hence we omit the proof.

Corollary 2.4. Let the assumptions of Theorem 2.3 be satisfied. Then, under (2.12) we obtain

 ( 2 mn )-1 n Sn - µmn

d N

2-1/2 F  2 , 1 .

21

3 Extensions
In this section, we show that our testing procedures can be extended to two different models. First, we consider the class of heterogeneous binary response models. Second, we discuss an extension of linear random coefficient models to system of equations. In both cases, we again discuss testing functional form restrictions and testing degeneracy of some random coefficients separately.

3.1 Binary Response Models
We consider the binary response model

Y = 1{g(X, B) < Z},

(3.1)

where, besides the dependent variable Y and covariates X, a special regressor Z is observed as well. In the following, we assume that (X, Z) is independent of B. In contrast to the previous section, the test in the binary response model is based on the difference of a partial derivative of the conditional success probability P (Y = 1|X, Z) and a restricted transformation of the p.d.f. fB.

Testing functional form restrictions. In the binary response model (3.1), observe that

P [Y = 1|X = x, Z = z] = =

1 {z > g(x, b)} fB(b)db
z
fB (b)d (b)ds,
- Px,s

where  is the Lebesgue measure on the lower dimensional hyperplane Px,s = {b : g(x, b) = s}. Consequently, it holds

(x, z)  zP [Y = 1|X = x, Z = z] = fB(b)d(b).
Px,z
Again by considering conditional characteristic functions, the null hypothesis Hmod is equivalent to E[exp itY |X] = E[exp itg(X, B) |X] for some random coefficient B. By using the above integral representation of  we equivalently obtain F (X, ∑) (t) = (FgfB)(t, X) (recall the definition of the integral transform (Fgf )(X, t)  exp(itg(X, b))f (b)db). Due to technical reason, we invert the Fourier transform and conclude that equation (2.3) holds true with
(X, z) = (X, z) - F -1[(FgfB)(X, ∑)] (z).

22

In the case of a linear g, the random coefficient density fB is thus identified through the Radon transform, see also Gautier and Hoderlein [2015].
To estimate the function , we replace  by a series least squares estimator. Let us introduce the matrix Wn = pmn(X1, Z1), . . . , pmn(Xn, Zn) where the basis function pl, l  1, are assumed to be differentiable with respect to the (dx + 1)≠th entry. We estimate  by
n(x, z) = zpmn(x, z) WnWn -1Yn,

where Yn = (Y1, . . . , Yn) . Consequently, we replace the function  by n(Xj, z) = n(Xj, z) - (F -1[(FgfBn)(Xj, ∑)])(z),

where fBn is the sieve minimum distance estimator given by

fBn  arg min
f Bn

n j=1

|n(Xj, z) - (F -1[(Fgf )(Xj, ∑)])(z)|2 (z)dz

(3.2)

and Bn = (∑) =

kn l=1

l

ql

(∑)

.

Our test statistic is Sn = n-1

n j=1

|n(Xj, z)|2

(z)dz

where, in this section, is an integrable weighting function on the support of Z.

We introduce an mn dimensional linear sieve space n   : (x, z) =

mn j=1

j

pl

(x,

z

)

.

Let pmn(X, Z) be a tensor-product of vectors of basis functions pmn1 (X) and pmn2 (Z) for integers mn1 and mn2 with mn = mn1∑mn2. We assume that zpmn2 (z) = (p0(z), 2p1(z), . . . , mn2pmn2-1(z)) . Further, let l denote the squared integer that is associated with zpl. In Definition 1, pl(X) has

to be replaced by lpl(X, Z). Let Bn = E[(F -1[(Fgqkn)(X, ∑)](z)(F -1[(Fgqkn)(X, ∑)](z) ] (z)dz,

which is denoted by Bn when the expectation is replaced by the sample mean.

Assumption 7. (i) The random vector (X, Z) is independent of B. (ii) For any p.d.f. fB

satisfying F  = FgfB there exists knfB  n such (iii) There exists mn  n such that n mn - 2 P rank(Bn) = rank(Bn) = 1+o(1). (v) It holds kn =

that n  - 
= o( mn).  o( mn) and

F -1Fgkn fB 2

(iv) It holds Bn-

m2n(log n)

mn l=1

 = o( mn). = O(1) and l = o(nn).

Assumption 7 is similar to Assumption 4. Note that due to the partial derivatives of the basis functions we need to be more restrictive about the dimension parameter mn, which is captured in Assumption 7 (iv). The following result establishes the asymptotic distribution of our test statistic under Hmod in the binary response model (3.1).

Proposition 5. Let Assumptions 2, 3, and 7 hold with (Y, X, Z) = Y - 1{Z > X b}fB(b)db. Then, under Hmod we have

 ( 2mn )-1 n Sn - µmn

d N (0, 1).

23

The critical values can be estimated as in Remark 2.1 but where now n(Y, X, Z) = Y - 1{Z  X b}fBn(b)db with the estimator fBn given in (3.2).

Testing degeneracy. To keep the presentation simple, we only consider the linear case in the following. Under Hlin, the binary response model (3.1) simplifies to

Y = 1{X B < Z}.

(3.3)

exp itz (X, z)dz = exp itz (X1, z - X2b2)dz.
By nonsingularity of the Fourier transform, we conclude that Hdeg is equivalent to equation (2.3) where

(X, z) = (X, z) - (X1, z - X2b2).

If  only depends on X1, we consider the estimator 1n(x1, z) = zpkn(x1, z) Wn1Wn1 -1Yn, where Wn1 = pkn(X11, Z1), . . . , pkn(X1n, Zn) . We propose a minimum distance estimator of b2 given by

n
b2n = argminB
j=1

2
n(Xj, t) - 1n(X1j, t -  X2) (t)dt.

(3.4)

Consequently, we estimate the function  by n(Xj, z) = n(Xj, z) - 1n(X1j, z - b2nX2j).

Proposition 6. Let Assumptions 2, 3, 7 (i), (iii), (v) with (Y, X, Z) = Y - P (Y = 1|X1, Z -

X2b2), and Hlin hold true. Assume that n

E|(kn)(X1, z) - (X1, z)|2

 (z)dz = o( mn).

Then, under Hdeg we have

 ( 2mn )-1 n Sn - µmn

d N (0, 1).

The critical values can be estimated as in Remark 2.1 by replacing P (Y = 1|X1, Z - X2b2) by a series least squares estimator.

3.2 Application to Systems of Equations
In this subsection, we apply our testing procedure to systems of equations, i.e., situations in which the endogenous variable is not a scalar, but a vector. For simplicity, we consider in the

24

following only the bivariate case. Formally, we consider the model

Y = g(X, B),

(3.5)

for some function g and Y  R2. Again the vector of random coefficients B = (B0, B1, B2, B3) is assumed to be independent of the covariates X.

Testing functional form restrictions. Null hypothesis Hmod is equivalent to equation (2.3) with
(X, t) = E[exp(it Y ) - exp(it g(X, B))|X]

for some t  R2. Our test of Hmod is now based on Sn  n-1

n j=1

n(Xj, t) 2 (t)dt where

n is the estimator of  introduced in Example 4 but with a multivariate index t and being

a weighting function on R2. Under a slight modification of assumptions required for Theorem

2.1, asymptotic normality of the standardized test statistic Sn follows under Hmod.

Testing degeneracy. In the partially linear case (i.e., Hpart-lin holds), the random coefficient model (3.5) simplifies to

Y1 = B0 + B11X1 + B12X2 Y2 = B2 + B31X1 + g2(X2, B32).
This model is identified if B32 is degenerate (see Hoderlein et al. [2014]). A test for degeneracy of Hdeg : B32 = b, for some non-stochastic vector b, uses only the second equation, i.e.,
E[exp(itY2)|X] = E[exp(it(B2 + B31X1))|X1] exp(itg2(X32, b)).
We can consequently use the testing methodology developed in Section 2.3.4.

4 Monte Carlo Experiments
In this section, we study the finite-sample performance of our test by presenting the results of a Monte Carlo simulation study. The experiments use a sample size of 500 and there are 1000 Monte Carlo replications in each experiment. As throughout the paper, we structure this section again in a part related to testing functional form restrictions, and a part related to testing degeneracy.

25

4.1 Testing Functional Form Restrictions
In each experiment, we generate realizations of regressors X from X  N (0, 2) and random coefficients B = (B1, B2) from B  N (0, A) where
1 1/2 A= .
1/2 1
We simulate a random intercept B0  (B1, B2) according to the standard normal distribution. Realizations of the dependent variable Y are generated either by the linear model

Y = B0 + XB1,

(4.1)

the quadratic model

Y = c1(B0 + XB1 + X2B2),

(4.2)

or the nonlinear model

Y = c2(B0 + XB1 + |X| B2),

(4.3)

 where the constant  is either 0.5 or 1. Here, the normalization constants c1 and c2 ensure that

the dependent variables in models (4.1)≠(4.3) have the same variance.7 Note that the random

coefficient density fB is neither point identified in model (4.2) nor in model (4.3). However, recall that even if the model is not point identified under the maintained hypothesis, our testing

procedure may still be able to detect certain failures of the null hypothesis, in particular if they

arise from differences in conditional moments. Consider, for example, testing linearity in the

heterogeneous QUAIDS model (4.2), where the first two conditional moments yield E[B2] = 0 and V ar(B2) = 0. Consequently, P |(X, t)|2 (t)dt = 0 > 0 if and only if P (B2 = 0) > 0. We also observe in the finite sample experiment that our testing procedure is able to detect

such deviations.

The test is implemented using Hermite functions, and uses the standardization described

in Remark 2.1. When (4.1) is the true model, we estimate the random coefficient density

as described in Example 7, where we make use of the fact that the Hermite functions are

eigenfunctions of the Fourier transform. If (4.2) is the true model, the integral transform Fg is computed using numerical integration. In both cases, the weighting function coincides

with the standard normal p.d.f.. If (4.1) is the correct model, we use kn = 4 (= 3 + 2) Hermite functions to estimate the density of the bivariate random coefficients (B0, B1) and let mn = 9.

7This normalization ensures that large empirical rejection probabilities are not only driven by a large variance of the alternative models (see, for instance, Blundell and Horowitz [2007]).

26

Null Model Alt. Model  Empirical Rejection probabilities at level

Hmod

True DGP

0.010

0.050

0.100

(4.1)

0.5 0.003 0.027

0.076

(4.2)

0.008

0.034

0.072

(4.1)

(4.2)

0.698

0.911

0.958

(4.1)

(4.3)

0.178

0.491

0.683

(4.2)

(4.1)

0.714

0.928

0.980

(4.2)

(4.3)

0.864

0.982

0.994

(4.1)

1

0.007

0.047

0.127

(4.2)

0.007

0.058

0.154

(4.1)

(4.2)

0.491

0.804

0.907

(4.1)

(4.3)

0.102

0.368

0.615

(4.2)

(4.1)

0.557

0.875

0.970

(4.2)

(4.3)

0.558

0.905

0.978

Table 1: Rows 1,2,7,8 depict the empirical rejection probabilities if Hmod holds true, the rows 3≠6 and 9≠12 show the finite sample power of our tests against various alternatives. The first column states the null model while the second shows the alternative model and is left empty if the null model is the correct model. Column 3 specifies the noise level of the data generating process. Columns 4≠6 depict the empirical rejection probabilities for different nominal levels.

If (4.2) is the correct model, we have an additional dimension which accounts for the nonlinear 
part. Here, the choice of Hermite basis functions is kn = 7 (= 3+2∑2) with mn = 12 if  = 0.5 and kn = 9 (= 3 + 2 ∑ 3) with mn = 16 if  = 1. We thus increase the dimension parameters kn and mn as the noise level  becomes larger, i.e., the model becomes more complex. Note that mn could be any integer larger than const. ◊ kn2 that is smaller than n1/2 (up to logs). In practice, we let kn such that it minimizes the value of the test statistic. I.e., if s(kn, mn) denotes the value of the test statistic, a guideline for parameter choice in practice is given by the minimum-maximum principle min1kn<n1/4 maxkn2 <mn<n1/2 {s(kn, mn)}.
The empirical rejection probabilities of our tests are shown in Table 1 at nominal levels 0.010, 0.050, and 0.100. We also note that the models are normalized and hence, the null and alternative have the same variance. The differences between the nominal and empirical rejection probabilities are small under the correct functional form restrictions, as is obvious from rows 1, 2, 7, and 8. Comparing the empirical rejections probabilities in rows 3≠6 and 9≠12, we see that our tests become less powerful as the parameter  increases, as was to be expected. On the other hand, we observe from this table that our tests have power to detect nonlinear alternatives even in cases where the model under the maintained hypothesis is not identified. This is in line with our observation that these alternatives imply deviations between the restricted and unrestricted characteristic functions. Comparing rows 3, 9 with 4, 10 in Table 1, we observe

27

that our test rejects the quadratic model (4.2) more often than the nonlinear model (4.3). From rows 5, 11 and 6, 12 we see that our test rejects the nonlinear model (4.3) slightly more often than the linear model (4.1).
We have also tried different data generating processes, such as a cubic polynomial with random coefficients. In this case, our test of linearity led to empirical rejection probabilities which were close to one for all nominal levels considered and hence these results are not reported here. Regarding consistency, we also conducted experiments with larger sample sizes. In particular, we saw that the slight tendency of our test statistic to under-reject for small , see in Table 1 in rows 1 and 2, diminishes as we increase the sample size to n = 1000. Not surprisingly, when n = 1000 also the empirical rejection probabilities in rows 3≠6 and 9≠12 increase.

4.2 Testing Degeneracy
In each experiment, we generate realizations of X from X  N (0, A) and random coefficients B = (B1, B2) from B  N (0, A), where

1 .5 A=
.5 1

2

and A =

,

2

for some constant  > 0, which varies in the experiments. Further, we generate the dependent variable Y as
Y = B0 + B1X1 + X2,
if the null hypothesis Hdeg holds. For the alternative, we generate the dependent variable Y using
Y = B0 + B1X1 + B2X2,
for some constant  > 0, which varies in the simulations below. The test is implemented as described in Example 6 with B≠splines, and uses the standard-
ization described in Remark 2.1 with n(V, t) = exp(itY ) - hn(X1, t) exp(itg2(X, b2n)). This means that we use the more general test that allows for a nearly arbitrary specification in the remaining model Y - g2(X2, b2). We focus in the simulation on this specification, because it has arguably less power than the more specific one that imposes in addition the linear random coefficients structure. However, as will be evident from the results below, this test already has very good power properties, implying that separating the term involving the fixed coefficient turns out to already be a powerful device in testing. To estimate the restricted conditional characteristic function, we use B≠splines of order 2 with one knot (hence, kn = 4), and for the

28

Alt. Model

Empirical Rejection probabilities at level



0.010

0.050

0.100

0.003

0.049

0.108

0.75 1

0.033

0.177

0.352

1

0.142

0.479

0.837

1.25

0.378

0.738

0.876

0.75 1.5

0.118

0.396

0.643

1

0.367

0.741

0.837

1.25

0.627

0.904

0.967

Table 2: The first row depicts the empirical rejection probabilities under degeneracy of the coefficient of X2, the rows 2≠7 show the finite sample power of our tests against various alternatives. Column 1 depicts the value of  in the correct model and is empty if the null model is correct. Column 2 specifies the covariance of B1 and B2 for the alternative models. Columns 4≠6 depict the empirical rejection probabilities for different nominal levels.

unrestricted one a tensor-product of this B≠spline basis functions and a quadratic polynomial (hence, mn = 12). In practice, we may employ the minimum-maximum principle for parameter choice, as described in the previous subsection.
The empirical rejection probabilities for testing degeneracy are shown in Table 2 at nominal levels 0.010, 0.050, and 0.100. Again we normalize the models to ensure that the null and alternative have the same variance. The differences between the nominal and empirical rejection probabilities are small under a fixed coefficient for X2, as is obvious from the first row. In Table 2, we also see from rows 2≠7 that our test rejects the alternative model more often for a larger variance of B2, as we expect. Moreover, the empirical rejection probabilities increase as the covariance of B1 and B2 becomes larger, as we see by comparing rows 2≠4 with 5≠7.

5 Application
5.1 Motivation: Consumer Demand
Heterogeneity plays an important role in classical consumer demand. The most popular class of parametric demand systems is the almost ideal (AI) class, pioneered by Deaton and Muellbauer [1980]. In the AI model, instead of quantities budget shares are being considered and they are being explained by log prices and log total expenditure8. The model is linear in log prices and a term that involves log total expenditure over a nonlinear price index that depends on
8The use of total expenditure as wealth concept is standard practice in the demand literature and, assuming the existence of preferences, is satisfied under an assumption of separability of the labor supply from the consumer demand decision, see Lewbel [1999].
29

parameters of the utility function. In applications, one frequent shortcut is to replace the price index by an actual price index, another is that homogeneity of degree zero is imposed, which means that all prices and total expenditure are relative to a price index, resulting in an entirely linear model.
A popular extension of this model allows for quadratic terms in total expenditure (QUAIDS, Banks et al. [1997]). Since we focus in this paper on the budget share for food at home (BSF ), which, due at least in parts to satiation effects, is often documented to decline steadily across the total expenditure range, we want to assess whether quadratic terms are really necessary. Note that prices enter the quadratic term in a nonlinear fashion, however, due to the fact that we have very limited price variation, we can treat the nonlinear expression involving prices as fixed. This justifies the use of real total expenditure as regressor, even in the quadratic term. In other words, we thus consider an Engel curve QUAIDS model. However, we want to allow for preference heterogeneity, and hence consider the following model:

BSFi = B0i + B1i log(T otExpi) + B2i log(T otExpi) 2 + b4W1i + b5W2i.

(5.1)

Unobserved heterogeneity is reflected in the three random coefficients B0i, B1i and B2i. To account for observed heterogeneity in preferences, we include in addition household covariates as regressors. Specifically, we use principal components to reduce the vector of remaining household characteristics to a few orthogonal, approximately continuous components. We only use two principal components, denoted W1i and W2i. While including additional controls in this form is arguably ad hoc, we perform some robustness checks like alternating the component or adding several others, and the results do not change appreciably. Moreover, the additive specification can be justified as letting the mean of the random intercept B0i depend on covariates.
We implement the test statistics as described in the Monte Carlo section. For testing degeneracy, we estimate the conditional characteristic functions as described in Example 5. For testing functional form restrictions, our test is implemented as described in Example 4, where in the linear case we employ the estimation procedure in Example 7. In both cases, we choose the dimension parameters kn and mn by the minimum-maximum principle explained in the Monte Carlo section.

5.2 The Data: The British Family Expenditure Survey
The FES reports a yearly cross section of labor income, expenditures, demographic composition, and other characteristics of about 7,000 households. We use years 2008 and 2009. As is standard in the demand system literature, we focus on the subpopulation of two person households where both are adults, at least one is working, and the head of household is a white collar worker.
30

This is to reduce the impact of measurement error; see Lewbel [1999] for a discussion. We thus have a sample of size 543, which is similar to the one considered in the Monte Carlo section.
We form several expenditure categories, but focus on the food at home category. This category contains all food expenditure spent for consumption at home; it is broad since more detailed accounts suffer from infrequent purchases (the recording period is 14 days) and are thus often underreported. Food consumption accounts for roughly 20% of total expenditure. Results actually displayed were generated by considering consumption of food versus nonfood items. We removed outliers by excluding the upper and lower 2.5% of the population in the three groups. We form food budget shares by dividing the expenditures for all food items by total expenditures, as is standard in consumer demand. The following table provides summary statistics of the economically important variables. Since the data are similar to the data used in Hoderlein (2011), for brevity of exposition we refer to this paper for additional descriptive statistics, especially regarding household covariates.
Min. 1st Qu. Median Mean 3rd Qu. Max. St. Dev. Food share 0.008 0.137 0.178 0.188 0.232 0.591 0.075 log(TotExp) 4.207 5.534 5.788 5.782 6.066 6.927 0.448
5.3 Results
For testing degeneracy of the coefficient B2, we estimate the coefficient under Hdeg, i.e., we assume that this coefficient is fixed. The ordinary least squares estimate is -0.009 with standard error 0.008, which means that mean effects are rather insignificant. A potential role of the nonlinear term more generally is, however, picked up by our procedure. Table 3 shows the different values of the test statistics and p-values at nominal level 0.05. As we see from Table 3, our test fails to reject the model (5.1) with degenerate B2i but rejects the linear random coefficient model where B2i = 0. Not surprisingly, we also fail to reject the random coefficient QUAIDS model. The dimension parameters kn and mn are chosen via the proposed minimummaximum principle. It is interesting to note that the procedure selects higher order basis functions to account for the random coefficient of the quadratic term. Since higher order basis functions are required to estimate sharp peaks, this also supports the hypothesis that the marginal p.d.f. B2 is akin to a Dirac measure (i.e., the distribution is degenerate), or very close it.
The analysis thus far assumes that total expenditure is exogenous. However, in consumer demand it is commonly thought that log total expenditure is endogenous and is hence instru-
31

Null Hypothesis
value of test p-values

linear RC
2.1289 0.0166

quadratic RC
1.4200 0.0778

RC with fixed coeff. on quadratic term in TotExp
1.4029 0.0803

Table 3: Values of the tests with p-values when null hypothesis is either a linear random coefficient model (i.e., B2i = 0 in (5.1)), a quadratic random coefficient model (i.e., random B2i in (5.1)), or a random coefficient model with degenerate coefficient on the quadratic term (i.e., B2i = b2 in (5.1) for some fixed b2).

mented for, typically by labor income, say Z, see Lewbel [1999]. One might thus argue that we reject our hypotheses not due to a failure of the functional form assumptions, but because of a violation of exogeneity of total expenditure. Therefore, we follow Imbens and Newey [2009], and model endogeneity through a structural heterogeneous equation that relates total expenditure X to the instrument labor income Z, i.e.,

X = (Z, U ),

where U denotes a scalar unobservable. Following Imbens and Newey [2009], we assume that the instrument Z is exogenous, i.e., we assume Z  (B, U ), implying X  B|U , and we assume that the function  is strictly monotonic in U. Finally, we employ the common normalization that U |Z is uniformly distributed on the unit interval [0, 1]. Then, the disturbance U is identified through the conditional cumulative distribution function of X given Z, i.e.,

U = FX|Z(X|Z).

Since X  B|U , we then simply modify our testing procedure by additionally conditioning on controls U . In the consumer demand literature, this control function approach was also considered by Hoderlein [2011], who propose a life-cycle structural model that yields this specification. Generally, the control function U would have to be estimated in a first stage. Since the theory involving pre-estimation is beyond the scope of this paper, we do not adjust for estimation error in this variable, which may lead to a higher variance (depending on the smoothness assumptions).
The results of this modification are summarized in Table 4. As we see from this table, the

Null Hypothesis
value of test p≠values

linear RC
2.0661 0.0194

quadratic RC
1.3978 0.0810

RC with fixed coeff. on quadratic term in TotExp
1.3747 0.0846

Table 4: Values of the test statistics with p≠values, when additionally corrected for endogeneity.

32

value of the modified test statistics are smaller, once we introduce the instrument Z in a control function approach. This possibly indicates that there is some endogeneity bias in the first case; however, our main conclusions remain unchanged: We soundly reject the linear RC model, and fail to reject Hdeg and Hmod.

6 Conclusion
This paper develops nonparametric specification testing for random coefficient models. We employ a sieve strategy to obtain tests for both the functional form of the structural equation, e.g., for linearity in random parameters, as well as for the important question of whether or not a parameter can be omitted. While the former can be used to distinguish between various models, including such models where the density of random coefficients is not necessarily point identified, the latter types of test reduce the dimensionality of the random coefficients density. From a nonparametric perspective, this is an important task, because random coefficient models are known to suffer from very slow rates of convergence, see Hoderlein et al. [2010]. We establish the large sample behavior of our test statistics, and show that our tests work well in a finite sample experiment, and allow to obtain reasonable results in a consumer demand application.

Mathematical Appendix
Throughout the proofs, we will use C > 0 to denote a generic finite constant that may be different in different uses. We use the notation an bn to denote an  Cbn for all n  1. Further, for ease of notation we write j for jn=1. Recall that ∑ denotes the usual Euclidean norm, while for a matrix A, A is the operator norm. Further,  X  E(2(X)) and ,  X  E[(X)(X)]. For any integer m  1, Im denotes the m ◊ m dimensional identity matrix. Recall the notation Pn = E[pmn(X)pmn(X) ].

Proofs of Section 2.

Proof of Proposition 1. Let us denote f

=

dFX d

.

For some constant 0 < c < 1, for all

n  1, and any an  Rmn we have

an 2 = (an pmn(x))2 1{f (x)  n}(dx) + (an pmn(x))2 1{f (x) < n}(dx)  n-1 (an pmn(x))2f (x)(dx) + c (an pmn(x))2(dx).

Consequently, we obtain nImn Pn.

33

By Assumption 2, the eigenvalues of -n 1Pn are bounded away from zero and hence, it may

be assumed that Pn = nImn. Otherwise, consider a linear transformation of pmn of the form

pmn  (Pn/n)-1/2pmn where supxX pmn(x)

mn using that the smallest eigenvalue of

(Pn/n)-1/2 is bounded away from zero uniformly in n.

 Lemma 6.1. It holds mn mn.

Proof. Without loss of generality it may be assumed that mn we conclude

(t)dt = 1. By the definition of

mn
m2 n  n-2

2
E (V, s)(V, t)pl2(X) (s)

l=1

mn 2

 n-2

E | (V, t) (t)dt|2pl2(X)

l=1

mn

 C-n 2

E[p2l (X)] 2

l=1

(t)dsdt

= Cmn.

(by Jensen's inequality) (by Assumption 3)

In the following, we make use of the notations Pn = n-1 j pmn(Xj)pmn(Xj) and n(t)  (nPn)-1 j exp(itYj)pmn(Xj). Let An = n-1 j (Fgqkn)(Xj, t)(Fgqkn)(Xj, t) (t)dt and An = E (Fgqkn)(X, t)(Fgqkn)(X, t) (t)dt . Recall n = (nAn)- j (Fgqkn)(Xj, t)n(Xj, t) (t)dt and let n = An- E[(Fgqkn)(X, t)(X, t)] (t)dt.
Proof of Theorem 2.1. We make use of the decomposition

nSn =
j
=
j

n(Xj, t) 2 (t)dt pmn(Xj) n(t) - mn(Xj, t) 2 (t)dt

+2
j

pmn(Xj) n(t) - mn(Xj, t) mn(Xj, t) - (FgfBn)(Xj, t)

+
j

mn(Xj, t) - (FgfBn)(Xj, t) 2 (t)dt

=In + 2 IIn + IIIn (say).

(t)dt

34

Consider In. We conclude

In = n n(t) - (∑, t), pmn X Pn n(t) - (∑, t), pmn X (t)dt

= n-1

exp(itYj) - mn(Xj, t) pmn(Xj) Pn-1
j

◊ exp(itYj) - mn(Xj, t) pmn(Xj) (t)dt
j

= -n 1

n-1/2

exp(itYj) - mn(Xj, t) pmn(Xj) 2 (t)dt

j

+ n-1

exp(itYj) - mn(Xj, t) pmn(Xj) Pn-1 - n-1In
j

◊ exp(itYj) - mn(Xj, t) pmn(Xj) (t)dt
j

= B1n + B2n (say).

Since (mn(X, t) - (X, t))pmn(X) is a centered random variable for all t it is easily seen

that B1n = n-1 yields ( 2mn)-1

n-1/2 j B1n - µmn

exp(itYj) - (Xj, t) pmn(Xj) 2 d N (0, 1). To show that B2n =

(t)dt + op(1). Thus, 
op( mn) note that

Lemma

6.2

Pn-1 - -n 1In  -n 1 (Pn/n)-1 In - Pn/n = Op (mn log n)/(n2n)

by Lemma 6.2 of Belloni et al. [2015]. Further, from E[(exp(itY ) - mn(X, t))pl(X)] = 0, 1  l  mn, we deduce

n-1 E

2
exp(itYj) - mn(Xj, t) pmn(Xj) (t)dt

j

mn

(t)dt E pmn(X) 2 + sup pmn(x) 2

xX

l=1

(∑, t), pl

2 X

(t)dt E[p2l (X)]

mnn.

(6.1)

The

result follows 

due

to

condition

m2n log n

=

o(nn).

Thereby,

it

is

sufficient

to

prove

IIn +

IIIn = op( mn). Consider IIIn. We observe

I I In

j

Fg(fBn - knfB)(Xj, t) 2 (t)dt +
j

(FgknfB)(Xj, t) - mn(Xj, t) 2 (t)dt,

35

where

j

(FgknfB)(Xj, t) - mn(Xj, t) 2

 (t)dt = op( mn) and

Fg(fBn - knfB)(Xj, t) 2 (t)dt = (n - n)

(Fgqkn)(Xj, t)(Fgqkn)(Xj, t) (t)dt(n - n)

jj

= n(n - n) An(n - n).

Let us introduce the vector n = (nAn)- j (Fgqkn)(Xj, t)(Xj, t) (t)dt. Using the property of Moore-Penrose inverses that An = AnA-n An, we conclude

n(n - n) An(n - n)
n-1/2
j
+ n-1/2
j
+ n-1/2
j

n(n - n) An(n - n) + n(n - n) An(n - n)
2
(Fgqkn)(Xj, t) n(Xj, t) - (Xj, t) (t)dt A-n
2
(Fgqkn)(Xj, t)(Xj, t) (t)dt A-n - An- 2 An
(Fgqkn)(Xj, t)(Xj, t) - E (Fgqkn)(X, t)(X, t)

(t)dt 2 A-n 2 An .

From Lemma 6.3 we have An- - An- = Op An- = O(1) and thus, An-  An- - A-n
consider

(log n)kn/n . By Assumption 4 (v) it holds + A-n = Op(1). Thereby, it is sufficient to

n-1/2
j

2
(Fgqkn)(Xj, t) n(Xj, t) - (Xj, t) (t)dt

n-1/2
j

2
(Fgqkn)(Xj, t)pmn(Xj) n(t) - (∑, t), pmn X (t)dt

+ n-1/2

2
(Fgqkn)(Xj, t) mn(Xj, t) - (Xj, t) (t)dt

j

2
n E (Fgqkn)(X, t)pmn(X) n(t) - (∑, t), pmn X (t)dt

2
+ n E (Fgqkn)(X, t) mn(X, t) - (X, t) (t)dt + Op(kn)

= Op kn + n mn -  2

which can be seen as follows. Let ∑, ∑ denote the inner product induced by the norm ∑ .

36

We calculate

E (Fgqkn)(X, t) mn(X, t) - (X, t)

2 kn
(t)dt =

Fgql, mn -  2

l=1

kn
=

2
ql(b)E Fg(mn - ) (X, b) db

l=1

2
E Fg(mn - ) (X, b) db

mn -  2

CwinohnpersaeerqtFiucgeunliatslry,t,hIweIeIandhja=ovineotpn(o(pemnr-ant)o.rnC)oofAnFns(igdgenriv-IenInnb.)yF=(rFoOmgpa)k(bnbo)+v=enweEim[nenfxepr-(nitg(nX2 -, b=))no(p2X(=, tm)O]np)(kta)nndd+t., n mn -  2 by employing that An- is stochastically bounded. Thereby, we obtain

|I In |2 + n

2
exp(itYj) - mn(Xj, t) pmn(Xj) (∑, t) - (FgknfB)(∑, t), pmn X (t)dt
j
2
exp(itYj) - mn(Xj, t) pmn(Xj) (Fg(knfB - fBn)(∑, t), pmn X (t)dt + op(mn)
j
E mn(X, t) - (mnFgknfB)(X, t) 2 (t)dt

+ n E exp(itY ) - mn(X, t) (mnFgqkn)(X, t) 2 (t)dt n - n 2 + op(mn)

= Op n Fg(knfB - fB) 2 + kn(kn + n mn -  2 ) + op(mn)

= op(mn)

where we used that mn -   = O(1) and

kn l=1

mn Fgql

2

= O(kn), which completes

the proof.

We require the following notation. Let us introduce the covariance matrix estimator mn(s, t) = n-1 j pmn(Xj)pmn(Xj) n(Vj, s)n(Vj, t) where n(Vj, s) = exp(itY ) - (FgfBn)(X, t). Further, we define n(V, t) = exp(itY ) - (FgknfB)(X, t) and introduce the matrix mn(s, t) = n-1 j pmn(Xj)pmn(Xj) n(Vj, s)n(Vj, t).
Proof of Proposition 2. To keep the presentation of the proof simple, we do not consider

37

estimation of Pn in mn and µmn. We make use of the relationship

n(∑, s)n(∑, t) - n(∑, s)n(∑, t) =n(∑, s) (FgfBn)(∑, t) - (FgknfB)(∑, t) + n(∑, t) (FgfBn)(∑, s) - (FgknfB)(∑, s) .

Observe

mn(s, t) - mn(s, t)

2 F

(s)ds

(t)dt

2

n-1 pmn(Xj)pmn(Xj) n(Vj, s) (FgfBn)(Xj, t) - (FgknfB)(Xj, t)

(s)ds (t)dt

F

j

2

+

n-1 pmn(Xj)pmn(Xj) n(Vj, t) (FgfBn)(Xj, s) - (FgknfB)(Xj, s)

(s)ds (t)dt

F

j

= In + IIn (say).

We conclude

In  

12

n

n(Vj, s)pmn(Xj)pmn(Xj) (Fgpkn)(Xj, t) (n - n) (s)ds (t)dt F

j

2
E[ n(V, s)pmn(X)pmn(X) (Fgqkn)(X, t) ](n - n) (s)ds (t)dt + op(1) F

 n - n 2

◊ Op

mn kn j,l=1 l =1

2
E[((X, s) - (FgknfB)(X, s))(Fgql )(X, t)pj(X)pl(X)] (s)ds (t)dt

 n - n 2

◊ Op

mn kn l=1 l =1

E ((X, s) - (FgknfB)(X, s))(Fgql )(X, t)pl(X) 2 (s)ds (t)dt

= Op mnkn2/n + mnkn mn -  2 = op(1).

Here, we used n - n 2 = Op(kn/n + mn -  2 ) which can be seen as in the proof of

38

Theorem 2.1. Since In = op(1) we conclude

2
IIn (n - n) E[(Fgqkn)(X, s)pmn(X)pmn(X) (Fgqkn)(X, t) ](n - n) (s)ds (t)dt + op(1) F

mn
 n - n 4

E[ (Fgqkn)(X, s) (Fgqkn)(X, t) |pj(X)pl(X)|]2 (s)ds (t)dt + op(1)

j,l=1

 Cm2n n - n 4

2
E (Fgqkn)(X, t) 2 (t)dt + op(1)

= Op m2nkn/n2 + mn2 mn -  4 = op(1).

by using kn

 = o( mn).

Finally, it is easily seen that m2 n -

mn(s, t) 2 (s)ds (t)dt =

op(1), which proves mnm-n1 = 1 + op(1). In particular, convergence of the trace of mn(t, t) to

the trace of mn(t, t) follows by using |µmn - µmn|2  mn

mn(t, t) - mn(t, t)

2 F

(t)dt =

op(mn).

Proof of Theorem 2.2. Let us introduce n = (nAn)- E[n(X, t)(X, t)]

estimator

n = (nAn)-

n(Xj, t)n(Xj, t) (t)dt.

j

(t)dt and the

We prove in the following that

n(Xj, t) - (Fg1fB-2,n)(Xj, t) g(Xj, t, b2n) 2 (t)dt

j

=

n(Xj, t) - n(Xj, t)n 2

 (t)dt + op( mn).

j

By the definition of the estimator b2n in (2.8) we obtain

n(Xj, t) - (Fg1fB-2,n)(Xj, t) g(Xj, t, b2n) 2 (t)dt
j


j

n(Xj, t) - (Fg1fB-2,n)(Xj, t) g(Xj, t, b2) 2 (t)dt (6.2)

for any b2  B2 satisfying (2.5). By the definition of the least squares estimator n and the

39

triangular inequality we obtain

n(Xj, t) - (Fg1fB-2,n)(Xj, t)g(Xj, t, b2n) 2 (t)dt
j


j

n(Xj, t) - (Fg1fB-2,n)(Xj, t)lng(Xj, t, b2n) 2 (t)dt

-

j
=
j

(Fg1fB-2,n)(Xj, t) lng(Xj, t, b2n) - g(Xj, t, b2n) 2 (t)dt

j

n(Xj, t) - n(Xj, t) n 2



(t)dt - Op

n max bB2

lng(∑, ∑, b) - g(∑, ∑, b)

n(Xj, t) - n(Xj, t) n 2 (t)dt - op(mn1/4).

Consequently, applying again the triangular inequality together with inequality (6.2) yields

n(Xj, t) - (Fg1fB-2,n)(Xj, t)g(Xj, t, b2n) 2 (t)dt
j

-
j

n(Xj, t) - n(Xj, t) n 2 (t)dt


j

n(Xj, t) - (Fg1fB-2,n)(Xj, t)g(Xj, t, b2) 2 (t)dt

-
j

n(Xj, t) - n(Xj, t) n 2 (t)dt + op(m1n/4)



lng(Xj, t, b2) - g(Xj, t, b2) 2

 (t)dt + n n - n

j
= n lng(∑, ∑, b2) - g(∑, ∑, b2) 2 + Op

 knln + n mn - 

+ op(mn1/4) + op(mn1/4)

= op(m1n/4),

as in the proof of Theorem 2.1. Now following line by line the proof of Theorem 2.1 and using

mn(Xj, t) - (Fg1knfB-2)(Xj, t)lng(Xj, t, b2) 2 (t)dt

j

n

mn - 

2

+n

Fg1 kn fB-2 - Fg1 fB-2

2

+n

lng(∑, ∑, b2) - g(∑, ∑, b2)

2

 + op( mn)

 = op( mn),

the result follows.

40

Proof of Theorem 2.3. We make use of the decomposition

nSn =
j

pmn(Xj) n(t) - (∑, t)pmn X 2 (t)dt

+2
j

pmn(Xj) n(t) - (∑, t), pmn X

◊ mn(Xj, t) - hn(X1j, t)g(Xj, t, b2n) (t)dt

+
j

mn(Xj, t) - hn(X1j, t)g(Xj, t, b2n) 2 (t)dt

=In + 2 IIn + IIIn (say)

where we used

h(∑, t)g(∑, t, b2), pmn X =

(∑, t), pmn

.
X

Consider In.

As in the proof of

Theorem 2.1 we have

In = n-n 1

n-1/2
j

2 exp(itYj) - h(X1j, t)g(Xj, t, b2) pmn(Xj) (t)dt + op( mn).

 Thus, Lemma 6.2 yields ( 2mn)-1 In - µmn

d N (0, 1). Consider IIIn. Since |g(Xj, t, b)|  1

for all b we evaluate

I I In

j
+
j
+
j

mn(Xj, t) - (Xj, t) 2 (t)dt h(X1j, t) - hn(X1j, t) 2 (t)dt |hn(X1j, t)|2 g(Xj, t, b2) - g(Xj, t, b2n) 2 (t)dt.

It holds

hn(∑, t) - knh(∑, t)

2 X1

(t)dt = Op(kn/n) as we see in the following. We have

n  n

hn(∑, t) - knh(∑, t)

2 X1

(t)dt

pkn (Xj)pkn (Xj) -1
j

knh(X1j, t)-exp it(Yj-g2(Xj, b2n)) pkn(X1j) 2 (t)dt
j

n-1
j
kn
+ b2n - b2 2
l=1

knh(X1j, t) - exp it(Yj - g2(Xj, b2)) pkn(X1j) 2 (t)dt
n-1 exp(itYj)gb(Xj, t, b2n)pl(X1j) 2 (t)dt + op(1),
j

by a Taylor series expansion, where b2n is between b2n and b2. As in relation (6.1), from

41

E[ knh(X, t) - exp(it(Y - g2(X, b2)) pkn(X)] = 0 we deduce

E n-1

knh(X1j, t) - exp(it(Yj - g2(Xj, b2)) pkn(Xj) 2 (t)dt = O(n-1knn).

j

Further, since E supbB2 gb(X, t, b) 2 (t)dt  C we have

kn
E
l=1

n-1

exp(itYj)gb(Xj, t, b2n)pl(Xj) 2

1/2
(t)dt

j

 E pkn(X)

gb(X, t, b2n) 2

1/2
(t)dt

 E pkn (X) 2 1/2

E sup

gb(X, t, b) 2

1/2
(t)dt

bB2

= O nkn .

This from

establishes n b2 - b2n

the rate for the 2 = Op(1) and

estimator hn. 
kn = o( mn)

In light of condition n 

knh - h

2

=o

 mn

,

we infer IIIn = op( mn). It remains to show



IIn = op( mn), which follows by

|I In |

exp(itYj) - mn(Xj, t) pmn(Xj) mn(∑, t) - knh(∑, t)g(∑, t, b2), pmn X (t)dt
j

+ exp(itYj) - mn(Xj, t) pmn(Xj) knh(∑, t)g(∑, t, b2) - hn(∑, t)g(∑, t, b2n), pmn X

j
 + op( mn)
 = Op( n knh - h

 ) + op( mn)

+ Op kn E sup
bB2
 = op( mn),

mn
pl(X) gb(∑, t, b)pkn, pl X 2

1/2
(t)dt

l=1

(t)dt

using that E supbB2 proves the result.

mn l=1

pl

(X

)

gb(∑, t, b)pkn, pl

X

2

(t)dt 

kn l=1

E[p2l (X)]

=

O(kn),

which

In the following, recall the definition of fB satisfying FgfB -   Fgf -  for all p.d.f. f .

Proof of Proposition 3. For the proof it is sufficient to show Sn  C FgfB -  2 + op(1).

42

The proof of Theorem 2.1 together with the basic inequality (a - b)2  a2 - b2 implies that

mn
Sn = n-1

2
n-1 (exp(itYj) - (FgfB )(Xj, t))pl(Xj) (t)dt + op(1)

l=1 j

mn
E[(exp(itY ) - (FgfB )(X, t))pl(X)] 2 (t)dt + op(1)

l=1

FgfB -  2 + op(1),

by using that (n)n1 is a nonincreasing sequence.

Proof of Proposition 4. Following the proof Theorem 2.1, it is easily seen that

mn
nSn =-n 1
l=1
+
j

n-1/2

2
(Yi - (Xj, t))pl(Xj) (t)dt

j

(FgknfB )(Xj, t) - mn(Xj, t) 2

 (t)dt + op( mn).

Further, under the sequence of local alternatives (2.11), we calculate

(FgknfB )(Xj, t) - mn(Xj, t) 2

(t)dt = n

FgfB - 

2

 + op( mn)

j

= m-n1

Fg 

2

 + op( mn),

which proves the result.

Proofs of Section 3.
In the following, we make use of the notation n  (nRn)-1 j Yjpmn(Xj, Zj) where Rn = n-1 j pmn(Xj, Zj)pmn(Xj, Zj) . The Kronecker product for matrices is denoted by .

43

Proof of Proposition 5. We make use of the decomposition

nSn =
j

2
zpmn(Xj, z) n - E[1{Z > g(X, B)}pmn(X, Z)] (z)dz

+2
j

zpmn(Xj, z) n - E[1{Z > g(X, B)}pmn(X, Z)]

◊ zpmn(Xj, z) E[1{Z > g(X, B)}pmn(X, Z)] - F -1[(FgfBn)(Xj, ∑)] (z)

(z)dz

+
j

zpmn(Xj, z) E[1{Z > g(X, B)}pmn(X, Z)] - F -1[(FgfBn)(Xj, ∑)] (z) 2 (z)dz

=In + 2IIn + IIIn (say).

Consider In. For all l  1, the derivative of a basis function pl is given by lpl-1. Since pl forms an orthonormal basis in L2 (R) is holds

n

In

= n

mn - E[1{Z > g(X, B)}pmn(X, Z)]



+ op( mn)

Im1n  Tn mn - E[1{Z > g(X, B)}pmn(X, Z)]

where Tn is a m2n ◊ m2n diagonal matrix with l≠th diagonal element is given by (l - 1)2. It holds

mn

In = -n 1

l n-1/2

l=1

j

Yj -

2
1{Zj > g2(Xj, b)}fB(b)db pl(Xj, Zj) + op(1).

 Thus, Lemma 6.2 yields ( 2mn)-1 In - µmn

d N (0, 1). Consider IIIn. We have

I I In

j

2
(mn)(Xj, z) - (Xj, z) (z)dz +
j

=An1 + An2.

2
F -1[(Fg(fBn - fB))(Xj, ∑)] (z) (z)dz

We have An1 = Op n mn -  2

 = op( mn) and

An2

j

+
j

F -1[(Fg(fBn - knfB))(Xj, ∑)] (z) 2 (z)dz F -1[(Fg(knfB - fB))(Xj, ∑)] (z) 2 (z)dz,

44

 where the second summand on the right hand is of the order op( mn). Further,

F -1[(Fg(fBn - knfB))(Xj, ∑)] (z) 2 (z)dz
j

= (n - n)
j

F -1[(Fgqkn)(Xj, ∑)] (z) F -1[(Fgqkn)(Xj, ∑)] (z) (z)dz(n - n)

 and thus, following the proof of Theorem 2.1 we obtain An2 = op( mn). Similarly as in the
 proof of Theorem 2.1 it can be seen that IIn = op( mn), which completes the proof.

Proof of Proposition 6. We decompose our test statistic as

nSn =
j

2
zpmn(Xj, z) n - E[Y pmn(X, Z)] (z)dz

+2
j
+
j

zpmn(Xj, z) n - (mn)(Xj, z) (mn)(Xj, z) - 1n(X1j, z - X2jb2n)
2
(mn)(Xj, z) - 1n(X1j, z - X2jb2n) (z)dz

=In + 2IIn + IIIn (say).

(z)dz

Consider In. As in the proof of Proposition 5 we obtain

mn

In = n-1

l n-1/2

l=1

j

Yj -

2
1{Zj  X1b1 + X2b2}fB1(b1)db1 pl(Xj, Zj) + op(1),

 and thus, Lemma 6.2 yields ( 2mn)-1 In - µmn

d N (0, 1). Concerning IIIn, we calculate

I I In

j
+
j
+
j

2
(mn)(Xj, z) - (Xj, z) (z)dz
2
(X1j, z - X2jb2) - n(Xj, z) (z)dz
2
n(Xj, z) - 1n(X1j, z - X2jb2n) (z)dz.

45

The definition of the estimator b2 in (3.4) yields
2
n(Xj, z) - 1n(X1j, z - X2jb2n) (z)dz
j 2
 n(Xj, z) - 1n(X1j, z - X2jb2) (z)dz
j 2
n(Xj, z) - (Xj, z) (z)dz
j 2
+ 1n(X1j, z - X2jb2) - (X1j, z - X2jb2) (z)dz
j
 = op( mn).
 It thus follows IIIn = op( mn). Similarly as in the proof of Theorem 2.3 it can be shown that
 IIn = op( mn).

Technical Appendix.

Lemma 6.2. Let Assumptions 1≠3 hold true. Then

 mn ( 2mn )-1 -n 1
l=1

n-1/2

2
(Vj, t)pl(Xj)

(t)dt - µmn

d N (0, 1).

j

Proof. Let us denote the real and imaginary parts of (V, t)pl(X) by lR(V, t) = Re (V, t) pl(X) and lI(V, t) = Im (V, t) pl(X), respectively. We have

mn 2
(nn)-1/2 (Vj, t)pl(Xj) (t)dt

l=1 j

mn
=

(nn)-1/2

2

lR(Vj, t), lI (Vj, t)

(t)dt

l=1 j

mn
=(nn)-1

2

lR(Vj, t), lI (Vj, t)

(t)dt

l=1 j

mn
+ (nn)-1

lR(Vj, t)lR(Vj , t) + lI (Vj, t)lI (Vj , t)

l=1 j=j

=In + IIn (say).

(t)dt

46

We observe

mn
E|In - µmn|2 = V ar (nn)-1

2
(Vj, t)pl(Xj) (t)dt

l=1 j

 n-2n-1E

(V, t) 4

(t)dt

mn 2
pl2 (X )

l=1

mn

sup pmn(x) 2-n 2n-1 E[p2l (X)]

xX

l=1

mn2 n-1-n 1 = o(1)

using that

supv

|

(v,

t)|4 

(t)dt is

difference array Qnj = 2(mnn)-1

bounded. Consider IIn. Let us introduce the Martingale

mn j-1 l=1 j =1

lR(Vj, t)lR(Vj , t) + lI (Vj, t)lI (Vj , t) (t)dt

for j = 2, . . . , n, and zero otherwise. Further,

 ( 2mn)-1IIn = 2(mnn)-1

mn

j<j l=1

lR(Vj, t)lR(Vj , t)+lI (Vj, t)lI (Vj , t) (t)dt = Qnj.
j

It remains to show that j Qnj d N (0, 1), which follows by Lemma A.3 of Breunig [2015b]

by using the following computations. To show

 j=1

E |Qnj |2



1

observe

that

lI (Vj, t)lR(Vj , t) - lR(Vj, t)lI (Vj , t) (t)dt = 0
j=j

and E[X1jX1j ] = 0 for j = j . Thus, for j = 2, . . . , n we have

E |Qnj |2

=

2(j - 1) E
n2m2 n

mn l=1

2(j - 1) mn =
n2m2 n l,l =1

2(j - 1) mn =
n2m2 n l,l =1

2(j - 1) = n2

2
l(V1, t)l(V2, t) (t)dt
E l(V, s)l (V, t) E l(V, s)l (V, t)
2
E l(V, s)l (V, t) (s)ds (t)dt

(s)ds (t)dt

by the definition of mn and thus j E|Qnj|2 = 1 - 1/n. Recall An = n-1 Fn(t) Fn(t) (t)dt and An = E (Fgpkn)(X, t)(Fgpkn)(X, t)

(t)dt.

Lemma 6.3. Under the conditions of Theorem 2.1 it holds

An- = An- + Op (log n)kn/n .

47

Proof. On the set   An- An - An < 1/4, rank(An) = rank(An) , it holds R(An)  R(An) = {0} by Corollary 3.1 of Chen et al. [1996], where R denotes the range of a mapping.
Consequently, by using properties of the Moore-Penrose pseudoinverse it holds on the set :

An- - An- = - An-(An - An)An- + A-n (An-) (An - An) (Ikn - AnA-n ) + (Ikn - AnA-n )(An - An) (An-) A-n ,

see derivation of equation (3.19) in Theorem 3.10 on page 345 of Nashed [2014]. Applying the operator norm and using the fact that Ikn - AnAn- and Ikn - AnA-n as projections have operator norm bounded by one, we obtain

A-n - An- 1 = A-n An - An A-n + A-n 2 An - An + A-n 2 An - An  3 An - An max A-n 2, A-n 2 1 .

1

By Theorem 3.2 of Chen et al. [1996] it holds A-n 1  3 An- = O(1). Consequently, Lemma 6.2 of Belloni et al. [2015] yields A-n - A-n 1 = Op kn(log n)/n . The assertion follows by
1 = 1 with probability approaching one.

References
C. Ai and X. Chen. Efficient estimation of models with conditional moment restrictions containing unknown functions. Econometrica, 71:1795≠1843, 2003.
D. W. Andrews. Asymptotic results for generalized wald tests. Econometric Theory, 3(03): 348≠358, 1987.
D. W. Andrews. Testing when a parameter is on the boundary of the maintained hypothesis. Econometrica, pages 683≠734, 2001.
J. Banks, R. Blundell, and A. Lewbel. Quadratic engel curves and consumer demand. Review of Economics and Statistics, 79(4):527≠539, 1997.
A. Belloni, V. Chernozhukov, D. Chetverikov, and K. Kato. Some new asymptotic theory for least squares series: Pointwise and uniform results. Journal of Econometrics, 186(2):345≠366, 2015.
R. Beran. Semiparametric random coefficient regression models. Annals of the Institute of Statistical Mathematics, 45(4):639≠654, 1993.

48

R. Beran and P. Hall. Estimating coefficient distributions in random coefficient regressions. The Annals of Statistics, pages 1970≠1984, 1992.
R. Beran and P. W. Millar. Minimum distance estimation in random coefficient regression models. The Annals of Statistics, 22(4):1976≠1992, 1994.
R. Beran, A. Feuerverger, P. Hall, et al. On nonparametric estimation of intercept and slope distributions in random coefficient regression. The Annals of Statistics, 24(6):2569≠2592, 1996.
R. Blundell and J. Horowitz. A nonparametric test of exogeneity. Review of Economic Studies, 74(4):1035≠1058, Oct 2007.
R. Blundell, D. Kristensen, and R. Matzkin. Stochastic demand and revealed preference. Technical report, working paper, 2010.
C. Breunig. Goodness-of-fit tests based on series estimators in nonparametric instrumental regression. Journal of Econometrics, 184(2):328≠346, 2015a.
C. Breunig. Specification testing in nonparametric instrumental quantile regression. Technical report, working paper, 2015b.
G. Chen, M. Wei, and Y. Xue. Perturbation analysis of the least squares solution in hilbert spaces. Linear algebra and its applications, 244:69≠80, 1996.
X. Chen. Large sample sieve estimation of semi-nonparametric models. Handbook of Econometrics, 2007.
X. Chen and T. M. Christensen. Optimal uniform convergence rates and asymptotic normality for series estimators under weak dependence and weak conditions. Journal of Econometrics, 2015.
X. Chen and D. Pouzo. Estimation of nonparametric conditional moment models with possibly nonsmooth generalized residuals. Econometrica, 80(1):277≠321, 01 2012.
X. Chen and D. Pouzo. Sieve quasi likelihood ratio inference on semi/nonparametric conditional moment models. Econometrica, 83(3):1013≠1079, 2015.
A. Deaton and J. Muellbauer. An almost ideal demand system. American Economic Review, pages 312≠326, 1980.
49

F. Dunker, S. Hoderlein, and H. Kaido. Random coefficients in static games of complete information. Technical report, cemmap working paper, Centre for Microdata Methods and Practice, 2013.
J. T. Fox and A. Gandhi. Identifying heterogeneity in economic choice and selection models using mixtures. In James Heckman and B. Citeseer, 2009.
J. T. Fox and N. Lazzati. Identification of potential games and demand models for bundles. Technical report, National Bureau of Economic Research, 2012.
E. Gautier and S. Hoderlein. A triangular treatment effect model with random coefficients in the selection equation. Technical report, Toulouse School of Economics, 2015.
E. Gautier and Y. Kitamura. Nonparametric estimation in random coefficients binary choice models. Econometrica, 81(2):581≠607, 2013.
W. Ha®rdle and E. Mammen. Comparing nonparametric versus parametric regression fits. The Annals of Statistics, pages 1926≠1947, 1993.
J. Hausman and W. Newey. Individual heterogeneity and average welfare. Technical report, Centre for Microdata Methods and Practice, 2013.
S. Hoderlein. How many consumers are rational? Journal of Econometrics, 164(2):294≠309, 2011.
S. Hoderlein and R. Sherman. Identification and estimation in a correlated random coefficients binary response model. Journal of Econometrics, 2015.
S. Hoderlein, J. Klemel®a, and E. Mammen. Analyzing the random coefficient model nonparametrically. Econometric Theory, 26(03):804≠837, 2010.
S. Hoderlein, L. Su, and H. White. Specification testing for nonparametric structural models with monotonicity in unobservables. V UCSD Department of Economics Working Paper, 2011.
S. Hoderlein, H. Holzmann, and A. Meister. The triangular model with random coefficients. Technical report, Boston College, 2014.
J. L. Horowitz. Testing a parametric model against a nonparametric alternative with identification through instrumental variables. Econometrica, 74(2):521≠538, 2006.
J. L. Horowitz. Specification testing in nonparametric instrumental variables estimation. Journal of Econometrics, 167:383≠396, 2012.
50

J. L. Horowitz and S. Lee. Testing a parametric quantile-regression model with an endogenous explanatory variable against a nonparametric alternative. Journal of Econometrics, 152(2): 141≠152, 2009.
H. Ichimura and T. S. Thompson. Maximum likelihood estimation of a binary choice model with random coefficients of unknown distribution. Journal of Econometrics, 86(2):269≠295, 1998.
G. W. Imbens and W. K. Newey. Identification and estimation of triangular simultaneous equations models without additivity. Econometrica, 77(5):1481≠1512, 2009.
A. Lewbel. Consumer demand systems and household expenditure. Handbook of Applied Econometrics, Blackwell Handbooks in economics, 1999.
A. Lewbel. Semiparametric qualitative response model estimation with unknown heteroscedasticity or instrumental variables. Journal of Econometrics, 97(1):145≠177, 2000.
A. Lewbel and K. Pendakur. Unobserved preference heterogeneity in demand using generalized random coefficients. Technical report, Boston College Department of Economics, 2013.
A. Lewbel, X. Lu, and L. Su. Specification testing for transformation models with an application to generalized accelerated failure-time models. Journal of Econometrics, 184(1):81≠96, 2015.
M. Masten. Random coefficients on endogenous variables in simultaneous equations models. Technical report, cemmap working paper, Centre for Microdata Methods and Practice, 2015.
R. L. Matzkin. Identification in nonparametric limited dependent variable models with simultaneity and unobserved heterogeneity. Journal of Econometrics, 166(1):106≠115, 2012.
M. Z. Nashed. Generalized Inverses and Applications: Proceedings of an Advanced Seminar Sponsored by the Mathematics Research Center, the University of WisconsinMadison, October 8-10, 1973. Number 32. Elsevier, 2014.
W. K. Newey. Convergence rates and asymptotic normality for series estimators. Journal of Econometrics, 79(1):147≠168, 1997.
A. Santos. Inference in nonparametric instrumental variables with partial identification. Econometrica, 80(1):213≠275, 2012.
P. A. Swamy. Efficient inference in a random coefficient regression model. Econometrica, pages 311≠323, 1970.
51

SFB 649 Discussion Paper Series 2015
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "Pricing Kernel Modeling" by Denis Belomestny, Shujie Ma and Wolfgang Karl H‰rdle, January 2015.
002 "Estimating the Value of Urban Green Space: A hedonic Pricing Analysis of the Housing Market in Cologne, Germany" by Jens Kolbe and Henry W¸stemann, January 2015.
003 "Identifying Berlin's land value map using Adaptive Weights Smoothing" by Jens Kolbe, Rainer Schulz, Martin Wersing and Axel Werwatz, January 2015.
004 "Efficiency of Wind Power Production and its Determinants" by Simone Pieralli, Matthias Ritter and Martin Odening, January 2015.
005 "Distillation of News Flow into Analysis of Stock Reactions" by Junni L. Zhang, Wolfgang K. H‰rdle, Cathy Y. Chen and Elisabeth Bommes, January 2015.
006 "Cognitive Bubbles" by Ciril Bosch-Rosay, Thomas Meissnerz and Antoni Bosch-DomËnech, February 2015.
007 "Stochastic Population Analysis: A Functional Data Approach" by Lei Fang and Wolfgang K. H‰rdle, February 2015.
008 "Nonparametric change-point analysis of volatility" by Markus Bibinger, Moritz Jirak and Mathias Vetter, February 2015.
009 "From Galloping Inflation to Price Stability in Steps: Israel 1985≠2013" by Rafi Melnick and till Strohsal, February 2015.
010 "Estimation of NAIRU with Inflation Expectation Data" by Wei Cui, Wolfgang K. H‰rdle and Weining Wang, February 2015.
011 "Competitors In Merger Control: Shall They Be Merely Heard Or Also Listened To?" by Thomas Giebe and Miyu Lee, February 2015.
012 "The Impact of Credit Default Swap Trading on Loan Syndication" by Daniel Streitz, March 2015.
013 "Pitfalls and Perils of Financial Innovation: The Use of CDS by Corporate Bond Funds" by Tim Adam and Andre Guettler, March 2015.
014 "Generalized Exogenous Processes in DSGE: A Bayesian Approach" by Alexander Meyer-Gohde and Daniel Neuhoff, March 2015.
015 "Structural Vector Autoregressions with Heteroskedasticy" by Helmut L¸tkepohl and Aleksei Netsunajev, March 2015.
016 "Testing Missing at Random using Instrumental Variables" by Christoph Breunig, March 2015.
017 "Loss Potential and Disclosures Related to Credit Derivatives ≠ A CrossCountry Comparison of Corporate Bond Funds under U.S. and German Regulation" by Dominika Paula Galkiewicz, March 2015.
018 "Manager Characteristics and Credit Derivative Use by U.S. Corporate Bond Funds" by Dominika Paula Galkiewicz, March 2015.
019 "Measuring Connectedness of Euro Area Sovereign Risk" by Rebekka G‰tjen Melanie Schienle, April 2015.
020 "Is There an Asymmetric Impact of Housing on Output?" by Tsung-Hsien Michael Lee and Wenjuan Chen, April 2015.
021 "Characterizing the Financial Cycle: Evidence from a Frequency Domain Analysis" by Till Strohsal, Christian R. ProaÒo and J¸rgen Wolters, April 2015.
SFB 649, Spandauer Straﬂe 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

SFB 649 Discussion Paper Series 2015
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
022 "Risk Related Brain Regions Detected with 3D Image FPCA" by Ying Chen, Wolfgang K. H‰rdle, He Qiang and Piotr Majer, April 2015.
023 "An Adaptive Approach to Forecasting Three Key Macroeconomic Variables for Transitional China" by Linlin Niu, Xiu Xu and Ying Chen, April 2015.
024 "How Do Financial Cycles Interact? Evidence from the US and the UK" by Till Strohsal, Christian R. ProaÒo, J¸rgen Wolters, April 2015.
025 "Employment Polarization and Immigrant Employment Opportunities" by Hanna Wielandt, April 2015.
026 "Forecasting volatility of wind power production" by Zhiwei Shen and Matthias Ritter, May 2015.
027 "The Information Content of Monetary Statistics for the Great Recession: Evidence from Germany" by Wenjuan Chen and Dieter Nautz, May 2015.
028 "The Time-Varying Degree of Inflation Expectations Anchoring" by Till Strohsal, Rafi Melnick and Dieter Nautz, May 2015.
029 "Change point and trend analyses of annual expectile curves of tropical storms" by P.Burdejova, W.K.H‰rdle, P.Kokoszka and Q.Xiong, May 2015.
030 "Testing for Identification in SVAR-GARCH Models" by Helmut Luetkepohl and George Milunovich, June 2015.
031 "Simultaneous likelihood-based bootstrap confidence sets for a large number of models" by Mayya Zhilova, June 2015.
032 "Government Bond Liquidity and Sovereign-Bank Interlinkages" by Sˆren Radde, Cristina Checherita-Westphal and Wei Cui, July 2015.
033 "Not Working at Work: Loafing, Unemployment and Labor Productivity" by Michael C. Burda, Katie Genadek and Daniel S. Hamermesh, July 2015.
034 "Factorisable Sparse Tail Event Curves" by Shih-Kang Chao, Wolfgang K. H‰rdle and Ming Yuan, July 2015.
035 "Price discovery in the markets for credit risk: A Markov switching approach" by Thomas Dimpfl and Franziska J. Peter, July 2015.
036 "Crowdfunding, demand uncertainty, and moral hazard - a mechanism design approach" by Roland Strausz, July 2015.
037 ""Buy-It-Now" or "Sell-It-Now" auctions : Effects of changing bargaining power in sequential trading mechanism" by Tim Grebe, Radosveta Ivanova-Stenzel and Sabine Krˆger, August 2015.
038 "Conditional Systemic Risk with Penalized Copula" by Ostap Okhrin, Alexander Ristig, Jeffrey Sheen and Stefan Tr¸ck, August 2015.
039 "Dynamics of Real Per Capita GDP" by Daniel Neuhoff, August 2015. 040 "The Role of Shadow Banking in the Monetary Transmission Mechanism
and the Business Cycle" by Falk Mazelis, August 2015. 041 "Forecasting the oil price using house prices" by Rainer Schulz and Mar-
tin Wersing, August 2015. 042 "Copula-Based Factor Model for Credit Risk Analysis" by Meng-Jou Lu,
Cathy Yi-Hsuan Chen and Karl Wolfgang H‰rdle, August 2015. 043 "On the Long-run Neutrality of Demand Shocks" by Wenjuan Chen and
Aleksei Netsunajev, August 2015.
SFB 649, Spandauer Straﬂe 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

SFB 649 Discussion Paper Series 2015
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
044 "The (De-)Anchoring of Inflation Expectations: New Evidence from the Euro Area" by Laura Pagenhardt, Dieter Nautz and Till Strohsal, September 2015.
045 "Tail Event Driven ASset allocation: evidence from equity and mutual funds' markets" by Wolfgang Karl H‰rdle, David Lee Kuo Chuen, Sergey Nasekin, Xinwen Ni and Alla Petukhina, September 2015.
046 "Site assessment, turbine selection, and local feed-in tariffs through the wind energy index" by Matthias Ritter and Lars Deckert, September 2015.
047 "TERES - Tail Event Risk Expectile based Shortfall" by Philipp Gschˆpf, Wolfgang Karl H‰rdle and Andrija Mihoci, September 2015.
048 "CRIX or evaluating Blockchain based currencies" by Wolfgang Karl H‰rdle and Simon Trimborn, October 2015.
049 "Inflation Co-movement across Countries in Multi-maturity Term Structure: An Arbitrage-Free Approach" by Shi Chen, Wolfgang Karl H‰rdle, Weining Wang, November 2015.
050 "Nonparametric Estimation in case of Endogenous Selection" by Christoph Breunig, Enno Mammen and Anna Simoni, November 2015.
051 "Frictions or deadlocks? Job polarization with search and matching frictions" by Julien Albertini, Jean Olivier Hairault, FranÁois Langotz and Thepthida Sopraseuthx, November 2015.
052 "lCARE - localizing Conditional AutoRegressive Expectiles" by Xiu Xu, Andrija Mihoci, Wolfgang Karl H‰rdle, December 2015.
053 "Specification Testing in Random Coefficient Models" by Christoph Breunig and Stefan Hoderlein, December 2015.
SFB 649, Spandauer Straﬂe 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

