BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2010-035
Efficiency and Equilibria in Games of Optimal Derivative Design
Ulrich Horst* Santiago Moreno-Bromberg*
* Humboldt-Universit‰t zu Berlin This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universit‰t zu Berlin Spandauer Straﬂe 1, D-10178 Berlin

Efficiency and Equilibria in Games of Optimal Derivative Design

Ulrich Horst

Santiago Moreno≠Bromberg

Institut fu®r Mathematik Humboldt-Universita®t zu Berlin
Unter den Linden 6 10099 Berlin
horst@math.hu-berlin.de

Institut fu®r Mathematik Humboldt-Universita®t zu Berlin
Unter den Linden 6 10099 Berlin
smoreno@math.hu-berlin.de

June 29, 2010
Abstract
In this paper the problem of optimal derivative design, profit maximization and risk minimization under adverse selection when multiple agencies compete for the business of a continuum of heterogenous agents is studied. In contrast with the principal≠agent models that are extended within, here the presence of ties in the agents' best≠response correspondences yields discontinuous payoff functions for the agencies. These discontinuities are dealt with via efficient tie≠breaking rules. The main results of this paper are a proof of existence of (mixed≠strategies) Nash equilibria in the case of profit≠maximizing agencies, and of socially efficient allocations when the firms are risk minimizers. It is also shown that in the particular case of the entropic risk measure, there exists an efficient "fix≠mix" tie≠breaking rule, in which case firms share the whole market over given proportions.

Preliminary - Comments Welcome
JEL classification: C62, C72, D43, D82, G14. Keywords: Adverse selection, Nash equilibria, Pareto optimality, risk transfer, socially efficient allocations, tie≠breaking rules.

We thank Guillaume Carlier, Ivar Ekeland, and seminar participants at various institutions for valuable comments and suggestions. We are grateful to Alexander Fromm for his help in developing Section 5 of this work. This paper was finalized while the authors were visiting the Institute for Mathematical Sciences at the National University of Singapore. Financial support from the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk" and from the Alexander von Humbold Foundation via a research fellowship is gratefully acknowledged.
1

1 Introduction
This work lies in the intersection of two fields that have produced a significant number of contributions in the last decade: Principal≠Agent models under adverse selection and optimal risk sharing and the optimal design of financial products under translation invariant preferences.
In a Principal≠Agent model of non≠linear pricing of hedonic goods, a monopolist (the principal) has the capacity to deliver quality≠differentiated products, which are assumed to lie on some compact and convex set C  Rn. Such products are the technologically feasible goods from the point of view of the principal. These vectors are usually called consumption bundles, and each of its coordinates indicates how much a certain product possesses of a given attribute. In other words, goods are assumed to be fully described by a list of qualities that are relevant to the consumers. The buyers (or agents) whom the principal engages with the intent to trade have heterogenous preferences. This is captured by indexing the different characteristics or agent types with vectors in some set   Rm, and including the types in the arguments of the buyers' utility functions. The types are private information, i.e. the principal is aware of their statistical distribution µ, but she cannot distinguish an agent's type prior to engaging him. The ill≠informed principal designs incentive compatible catalogues with the intention of (at least partially) screening the market. The trading is done on a take≠it≠or≠leave≠it basis and it is assumed there is no second≠hand market. The characterization of the solutions to problems of this kind can be found, among others, in the works of Armstrong [2], Mussa & Rosen [23] and Rochet & Chon¥e [33].
The standard Principal≠Agent model was extended by Carlier, Ekeland & Touzi in [9] to model a problem of optimal (over≠the≠counter) derivative design. They assume there is a direct cost to the principal when she delivers a derivative contract or financial product (a typical example are mutual funds) and that the agents' utilities are of mean≠variance type 1. This allows them to phrase the principal's profit maximization problem as a problem in the Calculus of Variations subject to convexity constraints, the latter capturing the incentive compatibility constraints on the set of admissible catalogues. This approach was further modified by Horst & Moreno≠Bromberg in [20]. Here the authors assume the principal is exposed to some non≠headgeable risky position, which she evaluates using a convex risk measure. This could be, for example, an insurer who has issued claims that are correlated to weather phenomena. The principal's aim is to minimize her exposure by laying off part of her risk with heterogenous agents. To do so she proceeds as in [9] and designs a catalogue of derivatives written on her income, as well as a non≠linear pricing schedule. In contrast with Carlier, Ekeland & Touzi, in this case the impact of each individual trade on the principal's evaluation of her risk is non≠linear, and an individual trade does not necessarily reduce the principal's exposure. The main results of both papers are existence and characterization of direct revelation mechanisms that maximize the principal's income ([9]) or minimize the principal's risk assessment ([20]).
A more complex scenario, in which our current model is embedded, contemplates an oligopoly. The firms composing the latter have to take into account both the adverse selection problem and the competition among them. The first challenge that needs to be addressed when one studies existence of equilibria and/or Pareto optimal allocations is the fact that the Revelation Principle, an important simplifying ingredient in the Principal≠Agent literature, may no longer be applied without loss of generality. In other words, some equilibrium allocations may not be implementable via direct revelation mechanisms. There are two ways to overcome this. The first one, introduced by Epstein & Peters [13], consists in enlarging the message space to include not only the agent types, but also a description of the market situations. Despite the theoretical value of this result, it is in general not practical for applications. Alternatively, Martimort &
1These are type-dependent utility functions of the form U (, X) = G(X) +  ∑ F (X), where the asset≠space is X , G : X  R is linear and F : X  .
2

Stole [24] and Page Jr. & Monteiro [27] developed a multi≠agency analogue of the Revelation Principle, the Delegation Principle, which allows enough simplification of the general non≠linear pricing game to have a workable setting. A second challenge is the emergence of ties in the agents' best≠response mappings. When agents are indifferent between contracting with different firms, then these firms' payoff functions may have discontinuities. This precludes the use of the classical results of Debreu, Glicksberg and Fan (see for example [18]) to guarantee the existence of Nash equilibria. Instead, much of the current literature on the existence of Nash equilibria in multi≠firm≠agent games relies on Reny's seminal paper [31], and the necessary conditions he presents for the existence of Nash equilibria in discontinuous games. The results of Bagh & Jofr¥e in [4], and of Page Jr. & Monteiro in [28] and [29] provide testable conditions that allow for Reny's results to be used in multi≠firm≠agent games.
The second field that influenced this work could be broadly labeled "risk minimization and sharing" with coherent or, more generally, convex risk measures. The notion of coherent risk measures was axiomatized by Artzner, Delbaen, Ebert & Heath in [3] as an "acceptable" way to assess the riskiness of a financial position. It was then extended to convex risk measures by, among others, F®ollmer & Schied [16] and Frittelli & Rosazza Gianin [17]. This theory has experienced an accelerated development, as evidenced by a large number of publications. Some quite natural questions to address, in a multitude of settings, are the existence and structure of risk≠minimizing positions or of risk≠sharing allocations that are either Pareto optimal or that constitute an equilibrium of some sort. The problem of optimal risk sharing for convex risk measures was first studied by Barrieu & El Karoui in [6]. They gave sufficient conditions for the risk≠sharing problem with general state spaces to have a solution. Their conditions can be verified for the special case where the initial endowments are deterministic and the agents use modifications of the same risk measure; Jouini, Schachermayer & Touzi proved in [21] the existence of optimal risk≠sharing allocations when the economic agents assess risk using convex risk measures which are law≠invariant. The optimal allocations are Pareto optimal but not necessarily individually rational. That is, a cash transfer, also called the rent of risk exchange, could be necessary to guarantee that the outcome leaves all parties better off than they originally were. It should also be mentioned that the setting in in [21] is over≠the≠ counter (OTC) in nature, hence the question of efficiency and implementability cannot be left to the market. Implementability could depend on the presence of a social planer who enforces cash≠transfer schemes or other policies that generate individually rational or socially optimal outcomes. In contrast, equilibrium models do not require the presence of a regulator to guarantee the implementability of efficient allocations. Implementability and efficiency is left up to the (financial) market. Equilibrium models of incomplete markets where agents use convex risk measures to evaluate their risk exposures were studied by, e.g., Filipovi¥c & Kupper in [14] in the static case and Cheridito et al. [8] in the dynamic one.
In this paper we study the problem of optimal derivative design, profit maximization and risk minimization under adverse selection when multiple agencies compete for the business of a continuum of heterogenous agents. We first extend the model of profit maximization presented in [9] to a multi≠firm one. Here is where the theory of games played under adverse selection comes into play. In order to use recent results from the theory of catalogue games, we assume that each firm's strategy set consists of the closed, convex hull of a finite number of basic products. We believe this is consistent with the idea that each firm is exposed to a direct cost when delivering financial products or derivative securities, since it must purchase the underlying assets that shall be structured into its' product line. In mathematical terms, such assumption renders the strategy sets compact with respect to the same topology for which the players' preferences are continuous (a necessary assumption), and therefore makes the game in hand compact. We show that when the game is played under a particular kind of tie≠breaking rules, then it is uniformly payoff secure and reciprocally upper semicontinuous and hence has a mixed≠strategies Nash equilibrium. Such rules, which paraphrasing [29] we call efficient, might not be implemented if not for the
3

presence of a social planer. The regulator also plays a key role in our multi≠agency extension of the risk minimization model studied in [20]. In both cases the impact of a single trade on the firm's risk evaluation is highly non≠linear and depends strongly on the firm's overall position.2 This results in two considerable technical difficulties. First, there is no reason to expect (and in general it will not be the case) that the firms' payoff functions will be uniformly payoff secure.3 Second, most of the current results ([4], [5], [18], [27], [25],...) on existence of Nash equilibria require some form of (quasi-) concavity (except [34] where a complete, yet very challenging to verify, characterization of Nash equilibria is presented). In our model these conditions are only satisfied by the mixed extension of the game. Even if the game were uniformly payoff secure and (weakly) reciprocally upper semicontinuous (by no means a given),4 considering a mixed extension of the game would mean the following: firms view linear aggregation of possible risk evaluations as the way to assess the influence of others' in their own risk. Whether this approach is consistent with the ideas behind the theory of convex risk measure is in our opinion debatable. Taking the previous arguments into account, we do not seek the existence of (mixed≠strategies) Nash equilibria. Our focus is instead on an existence proof for socially efficient allocations of risk exposures. Such risk allocations minimize the firms' aggregate risk and can hence be thought of as the multi≠firm≠agent game analogous of the Pareto optimal allocations described in [21]. The proof of existence of efficient tie≠breaking rules relies heavily on the fact that for fixed price schedules and tie≠breaking rule, the contracts that minimize the aggregate risk can be expressed as the product of a type≠independent random variable and a coefficient that depends exclusively on types. This separation result was already observed in [20], but it is in this paper where it is truly exploited. It is important to mention that efficient tie≠breaking rules are generated endogenously. This implies that in our OTC model efficiency and regulation go hand≠in≠hand, even in the absence of a cash≠transfer scheme. When it comes to implementability, we have obtained for the case of the entropic risk measure that among all efficient tie≠breaking≠rules, there is a constant ratio of market shares. In other words, there is a "fix≠mix" ratio under which firms share the whole market, rather than segmenting it by agent types. The latter implies that all the firms offer the same indirect utility to each of the consumers. A real≠world example where firms offer consumers essentially the same utility (using different products), and where the assumption of mean≠variance optimizing consumers is appropriate, is retail banking. In such case "fix≠mix" is also a reasonable assumption: retail banks differentiate customers according to their risk aversion when designing portfolio strategies, but do not necessarily try to appeal differently to customers with different attitudes towards risk. The methodology we used to obtain the "fix≠mix" result suggests that it carries over to more general risk measures. A full analysis would be quite technical though, and certainly beyond the scope of this paper. We illustrate this result with a numerical example, in which we also find that (as expected) firms are worse off in the presence of competition, whereas the contrary is the case for the buyers. Moreover, the aggregate risk in the economy is better dealt with in the competitive, yet regulated, case. The numerical algorithm that we use for this example, a hybrid descent method, is also used to analyze an example where the firms are AV@R≠minimizers. We find quite a sharp contrast in the firms' risk profiles before and after trading when comparing the entropic and AV@R cases, which obeys the fact that when minimizing the latter, one should focus in the worst state of the world (our examples use, unavoidably, a finite probability space) in as much as the problem's constraint allow, then move to the second worse and so on.
The remainder of this paper is organized as follows: Section 2 contains the description of our general framework. We leave the setting as general as possible while still describing the asymmetry of information
2In a model of profit maximization a firm contracts with some agent type independently of other types as long as that particular type contributes positively to the firm's revenues.
3The "worst≠case" tie≠breaking rule, where each firm assumes ties will be broken in the most disadvantageous way for itself, does yield payoff security, but at the cost of reciprocally upper semicontinuity.
4This would imply the existence of Nash equilibria in mixed strategies
4

in the model, the best≠response sets of the agents that give rise to ties, tie≠breaking rules and the influence of the social planer. In Section 3 we study the game played among profit≠maximizing firms, where the main result is the existence of mixed≠strategies Nash equilibria. Section 4 is devoted to the risk≠minimization game, where we prove the existence of socially efficient allocations. Finally, we present in Section 5 numerical algorithms to estimate equilibrium points and socially efficient allocations in some particular examples, as well as the "fix≠mix" result mentioned above.

2 General Framework
We consider an economy that consists of two firms and a continuum of agents. We study both the case when the firms are profit maximizers, and the one where their objective is to minimize the risk assessments of some initial uncertain payoffs. The analysis of the two scenarios require different mathematical techniques and distinct notions of efficient allocations, so we study the two models separately.5

2.1 The financially feasible sets

The firms compete for the agents' business by offering derivatives contracts. The set from which firm i = 1, 2 may choose products, i.e. its financially feasible set, is

Xi  L2 (, F , P) ,

where (, F, P) is a standard probability space. We assume these sets are closed, convex and bounded,

and that 0  Xi. The boundedness of Xi implies there is M > 0 such that Xi 2  M for all Xi  Xi.

Any additional requirements on the sets Xi shall be introduced when necessary.6 Throughout this paper

we use the notation

Xn --∑ 2 X, Xn -a-.s. X and Xn -w. X

to indicate that the sequence {Xn} converges strongly, almost surely and weakly to X. We also use 11A to denote the indicator function of a set A.
In the literature on multi≠firm, non≠linear pricing games, it is generally assumed that each firm chooses a compact subset Yi from its financially feasible set, and it devises a (non-linear) pricing schedule

pi : Yi  R.

Each pair (X, pi(X)) (where X  Xi) is called a contract. Then the Delegation and Competitive Taxation Principles (see for example [27]) allow for a without≠loss≠of≠generality analysis of the existence of Nash equilibria by studying the (simpler) catalogue game played over compact subsets of the product≠price space Xi ◊ R. In fact, the boundedness assumption on Xi implies that prices belong to some compact set P  R. We also study games played over catalogues, but their structure will be case≠dependent. We write Ci to denote a catalogue offered by firm i, and (C1, C2) for a catalogue profile (also called a market situation). We postpone the specification of the criterions that the firms aim to optimize until Sections 3 and 4.

2.2 The agents' preferences
The agents are heterogenous, mean≠variance maximizers whose set of types (or characteristics) is
 = [a, 1] for some a > 0.
5Our arguments can be extended to an economy with m firms. We chose to work on the case m = 2 for simplicity. 6We omit writing i = 1, 2 when we refer to properties shared by both firms.

5

The right endpoint of  has been normalized to 1, but it could be any finite value. What is required is for the set of types to be a compact subset of the strictly positive real numbers. An agent's type represents her risk aversion (hence the assumption a > 0 means there are no risk≠neutral agents). In other words, given a contingent claim Y an agent of type  assesses its worthiness via the (type≠dependent) utility function
U (, Y ) = E[Y ] -  Var[Y ].

The types are private information and not transparent to the firms. They are distributed according to a measure µ, which we assume is absolutely continuous with respect to Lebesgue measure. The measure µ is known to all firms. In other words, firms cannot distinguish an agent's type when engaging in trading with her (or they are legally prevented from doing so) but they know the overall distribution of types. This asymmetry of information, also known as adverse selection, prevents the firms from extracting all the above≠reservation≠utility wealth form each agent. The knowledge of µ is therefore essential for the agencies.7 In the upcoming sections we require the following auxiliary lemma:
Lemma 2.1 The family of functions U = {U (, ∑) |   } is uniformly equicontinuous.
Proof. Let > 0 and consider X, X  X , and   , then
|U (, X) - U (, X )| = |E[X] -  Var[X] - E[X ] +  Var[X ]|.
From the triangle inequality and the fact that 0 <   1 we get
|U (, X) - U (, X )|  |E[X] - E[X ]| + |Var[X] - Var[X ]|.
It follows from the Cauchy-Schwartz inequality that

|E[X] - E[X ]|  dP(X, X ) and |Var[X] - Var[X ]|  dP(X, X ) |X + X |dP + |E[X] + E[X ]| ,

where dP(X, X ) is the L1≠distance with respect to P. Since -M  X, X  M, we obtain
|U (, X) - U (, X )|  dP(X, X ) (1 + 4 M )  (1 + 4 M ) X - X 2. Setting  = (1 + 4 M )-1 yields the desired result.

2

2.3 Indirect utilities and best≠response sets
When an agent faces a catalogue profile (C1, C2), she chooses a single contract from some Ci on a take≠ it≠or≠leave≠it basis. Agents may choose any (available) contract they wish, but no bargaining regarding prices or products takes place. Given (C1, C2), the indirect utility of an agent of type  is:
v(, C1, C2) sup U (, X) - p | (X, p)  Ci for some i .
We assume that the agents have an outside option that yields their reservation utility, which we normalize to zero for all agents. For a fixed market situation, the function v(∑, C1, C2) :   R is convex, since it is defined as the pointwise supremum of affine functions of . The presence the outside option guarantees v  0. The best≠response set of the agents of type  to a certain catalogue profile is defined as:
L(, C1, C2) argsup U (, X) - p | (X, p)  Ci for some i .
7We could make additional assumptions on µ and allow for a = 0.
6

In Sections 3 and 4 we make necessary assumptions on Ci as to guarantee L(, C1, C2) =  for all   . Agents of type  are indifferent among the elements of L(, C1, C2), which they strictly prefer over any other contract that can be chosen from (C1, C2). The Envelope Theorem (see for example [22]) implies that for any (X(), p())  L(, C1, C2)

v (, C1, C2) = -Var[X()] µ - a.s..

(1)

In particular v (∑, C1, C2)  0 µ-a.s.. Equation (1) provides a valuable link between optimal contracts (from the point of view of the agents) and the indirect utility functions.
In order to exploit the information contained in µ, firms must choose catalogues that do not offer the agents incentives to lie about their types. If firm i intends to (partially) screen the market, the subset Ci()  Ci of products from which it expects agents of type  to make their choices must satisfy

E[X()] - Var[X()] - p()  E[Y ] - Var[Y ] - q,  (X(), p())  Ci(), (Y, q)  Ci.

Catalogues that satisfy this property are called incentive compatible. Let

L(, Ci) argsup U (, X) - p | (X, p)  Ci ,
then Ci is incentive compatible if and only if Ci() = L(, Ci).8 A catalogue where the products intended for agents of type  yield at least their reservation utility is said to be individually rational. Since all reservation utilities are zero, an individually rational catalogue satisfies

E[X()] - Var[X()] - p()  0  (X(), p())  L(, Ci).

In the presence of the outside option, participation in the market is endogenously determined.

2.4 Tie≠breaking rules & market segmentation
A crucial element of multi≠firm games is the presence of ties. There is no reason to assume that for a given catalogue profile (C1, C2) the sets L(, C1, C2) (  ) will be singletons. This fact renders the analysis considerably harder than it is for principal≠agent games, where the Revelation Principle allows for such assumption. There can be both inter≠ and intra≠firms ties, i.e. an agent may be indifferent between two products that are offered by distinct firms, or maybe between two contracts that are offered by the same agency. In what follows we study mechanisms via which ties are broken, as well as the partitions of  that are generated by tie≠breaking. In order to study the ties that originate from a catalogue profile (C1, C2), we define
v(, Ci) = vi() sup U (, X) - p | (X, p)  Ci ,
which are the one≠catalogue analogues to v(, C1, C2). The vi's are related to v(, C1, C2) via
v(, C1, C2) = max v(, C1), v(, C2) .
Some important properties of the functions v(, Ci) are summarized in Lemma 2.2 below. In a nutshell it states that the indirect utility functions generated by incentive compatible catalogues are convex, and that there is a crucial link between the derivatives of such functions at a given type and the variance of the contracts that such type may choose.
8It has been shown in [33] that in general principal≠agent models it is not possible to perfectly screen the market. In most instances there is a non≠negligible set of agents who are pushed down to their reservation utilities (bunching of the first type), and another one where agents stay above their reservation levels, but they choose the same product despite the fact of their different preferences (bunching of the second type). In all likelihood, this behavior is inherited by multi≠firm models.

7

Lemma 2.2 Let (C1, C2) be a catalogue profile and assume L(, Ci) =  for all   , then:
1. The functions v(∑, Ci) :   R are convex.
2. If Ci is incentive compatible then -Var[Xi()]  v(, Ci) for all (Xi(), pi())  Ci(). In particular, the equation -Var[Xi()] = v (, Ci) holds µ-a.s..
Proof. The mapping   U (, X) - p is affine on the -th coordinate, so v(, Ci) is defined as the pointwise supremum of affine mappings and it is therefore convex (see for example Proposition 3.1 in [12]). By assumption L(, Ci) = , an applying the Envelope Theorem as above we have that for any (Xi(), pi())  L(, Ci), -Var[Xi()] = v(, Ci). The assumption of incentive compatibility implies that if (Xi(), pi())  Ci(), then -Var[Xi()] = v (, Ci) µ-a.s..
2 If for 0   we have vi(0) > v-i(0), then the agents of type 0 will contract with firm i. The set of types that are indifferent between the firms' offers is
0    | v(, C1) = v(, C2) .
To avoid ambiguities we assume that if vi() = v-i() = 0 then the corresponding agents opt for the outside option. The market is then segmented in the sets
1 {v1 > v2}, 2 {v2 > v1} and 0.
In order to deal with types in 0 whose indirect utility is not zero, we define the set of tie≠breaking rules as
F f  L0[a, 1] | 0  f  1 . From this point on, given a TBR f we write f1 = f and f2 = 1 - f. Then fi  1 on i, fi  0 on -i, and for 0  0 the proportion fi(0) contracts with firm i.
In the sections below, we rephrase in as much as possible the interaction of the firms in terms of the indirect utilities generated by the catalogues they offer. This provides a clearer understanding of the market's segmentation, and in mathematical terms it allows us to use well established convex analysis machinery. To this end we define
Ci v :   R+ | v  0, {X()}  Xi s.t. v () = -Var[X()] .
These are the sets of all possible (single≠firm) indirect utilities that can be generated from incentive compatible catalogues contained in Xi. The incentive compatibility is reflected in the requirement v () = -Var[X()], as in Lemma 2.2. We show below that these sets exhibit convenient compactness properties.
Proposition 2.3 The sets Ci are compact for the topology of uniform convergence.
Proof. When firm i designs a product line, it takes into account that
-M 2  E[X] - Var[X]  M.
This implies that all prices p  P must be below M to satisfy the individual rationality constraint. In counterpart -M 2  p, otherwise all agents would be guaranteed an indirect utility above their reservation utility. Since X 2  M for all X  Xi, then |vi|  M for all vi  Ci, thus
0  vi  3 ∑ max M, M 2 .
8

The convexity of the elements of the (closed) set Ci implies they are locally Lipschitz (see for example [30]); moreover, the L2≠boundedness of Xi together with Equation (1) imply the Lipschitz coefficients are uniformly bounded. This in turn means that Ci is a bounded, closed and uniformly equicontinuous family, which by the Arzela`≠Ascoli is then compact for the topology of uniform convergence.
2
2.5 The social planer
The fundamental theorems of welfare economics establish the equivalence between competitive equilibria (in complete markets) and efficiency, in the sense that frictionless competition leads to Pareto optimal allocations of resources and viceversa. In contrast, in OTC markets participants do not respond to given prices and therefore optimality is an inadequate notion to study. Instead, in the sections below we deal with the existence of Nash equilibria and socially efficient allocations.
Whereas in perfectly competitive settings market forces interact as to eventually reach efficient outcomes, OTC markets may require the influence of a social planer (a regulator) in order to achieve efficiency. This indirect market participant plays two important roles: First, he may choose to enforce certain kinds of TBRs in order to guarantee Nash and/or socially efficient outcomes. Second, he must make sure that individual rationality at the level of firms is preserved. This crucial implementability condition is a non≠ issue in competitive markets, where equilibrium allocations are also individually rational. Alternatively, given that socially efficient allocations are aggregately individually rational, the regulator could focus on efficiency and then establish a payment scheme among firms. These payment scheme would play the role that equilibrium prices do in competitive markets.
In what follows we assume that we work on regulated OTC markets, where the roles of the social planner are to seek that the market settles for socially (aggregate) optimal allocations, and that the latter are individually rational for the agencies.
3 Profit Maximization
In this section we analyze a non≠cooperative game played among profit≠maximizing firms under adverse selection. Our model is an extension into a multi≠firm setting to the one studied in [9]. We show that if efficient tie≠breaking rules are implemented (possibly through the influence of a regulator), then the game possesses a Nash equilibrium in mixed strategies.
3.1 The firms' strategy sets & payoff functions
The theory of equilibria in multi≠firm games developed (among others) in [24], [26] and [27] requires the strategy sets to be compact metric spaces. Moreover, the agents' preferences must be continuous with respect to a topology that makes the strategy sets compact. In our view this implies that in general the strategy sets are actually closed and bounded sets of a finite≠dimensional vector space. Following along the same lines, and with the aim of describing a profit≠maximization model of OTC trading of derivatives contracts, we suppose that firms structure the latter from a set of "basic" products. These products are available in markets to which agents do not have access, and could be, for instance, OTC markets between "high≠rollers". The firms are then exposed to a cost when delivering each of these products.
We assume Xi is the closed convex hull of a finite number of basic products {Xi1, . . . , Ximi }, and that the cost to firm i of delivering Xi  Xi is given by a lower semicontinuous function
Ki : Xi  R.
9

The per≠contract profit of firm i when it sells claim Xi given the price schedule pi : Xi  R is pi(Xi) - Ki(Xi).

Analyzing a multi≠firm game played over non≠linear price schedules would be daunting at best. Here the Revelation Principle (see for example [27]) comes to our rescue. In a nutshell, it states that the game played over product≠price catalogues, i.e. elements of

Pi Ci  Xi ◊ P | Ci closed ,
is as general as the one played over closed subsets of Xi and non≠linear price schedules. We recall that P  R is the compact set where feasible prices lie. We assume that firms compete for the agents' business by offering product≠price catalogues. In other words, the strategy sets Pi are the sets of all compact subsets of Xi ◊ P. We endow Pi with the Hausdorff metric h. Since Xi ◊ P is a compact metric space, so is (Pi, h) (see, for example [1], Section 3.17); furthermore, Tychonoff's theorem guarantees that P P1 ◊ P2 with the corresponding product metric hp is also compact and metric. We write B(P) for the Borel -algebra in P. The following proposition allows us to substitute, without loss of generality, a catalogue profile (C1, C2) for the agents' optimal choices associated with the market situation (C1, C2), i.e., for

L(, C1), L(, C2)

as these sets are closed and hence compact.

Proposition 3.1 For any catalogue Ci  Pi, the set  L(, Ci) is closed.

Proof. Consider (XØ , pØ)  cl(  L(, Ci)), then there exists a sequence {(Xn, pn)}  that
(Xn, pn) --∑-2-◊-|∑| (XØ , pØ).

 L(, Ci) such

By construction (Xn, pn)  L(, Ci) for some   , call it n. Passing to a subsequence if necessary we may assume there is Ø   such that n  Ø and (Xn, pn)  (XØ , pØ) pointwise. If (XØ , pØ)   L(, Ci) we
are done, so let us assume the contrary, thus

E[XØ ] - ØVar[XØ ] - pØ < E[X] - ØVar[X] - p  (X, p)  L(Ø, Ci).

(2)

By definition

E[Xn] - nVar[Xn] - pn  E[X] - nVar[X] - p  (X, p)  Ci.

However, the (a.s.) convergence of the sequence {(Xn, pn)} implies

E[XØ ] - ØVar[XØ ] - pØ  E[X] - ØVar[X] - p  (X, p)  Ci,

which would imply (X, p)  L(Ø, Ci), contradicting Equation (2).

2

The maximal attainable profit for firm i from type  given the (incentive compatible) catalogue profile

(C1, C2) is

i(, C1, C2) max (p - K(X))11{viv-i}() | (X, p)  Ci .

Here the functions vi are as defined in Section 2.4. The functions i are the building blocks of the firms' payoff functions and enjoy the following important continuity property:

10

Proposition 3.2 (Page Jr. [26]) The maps i :  ◊ P  R are upper semicontinuous on P and B() ◊ B(P )-measurable.
For a given TBR f, the payoff function of firm i is given by

i(C1, C2)

i(, C1, C2)fi()µ(d).



These payoff functions exhibit a highly discontinuous behavior, due to the presence of ties. However, the effect of each type≠wise trade on the overall income of the firm is linear and easily quantifiable. Moreover, only agents who make a positive contribution to a firm's revenues contract with it. This last fact plays a role in the analysis of payoff security contained in Section 3.3.2.

3.2 Efficient tie≠breaking rules & reciprocal upper semicontinuity
Roughly speaking, a TBR is said to be efficient if an agent contracts with a firm if and only if the latter values her as a customer at least as much as the competition. As we show below, this is equivalent to saying that an efficient TBR maximizes the aggregate profit for a given market situation (C1, C2).
Definition 3.3 Given a catalogue profile (C1, C2), a tie≠breaking rule f  F is called efficient if
∑ i(, C1, C2)  -i(, C1, C2) implies fi() > 0,
∑ i(, C1, C2) < -i(, C1, C2) implies fi() = 0.
The definition above is equivalent to saying that f  is efficient given the catalogue profile (C1, C2) if and only if
i(f , C1, C2) = sup i(f, C1, C2),
i f F i
which shows that in general efficient TBRs are endogenously determined. In mathematical terms, efficient TBRs yield certain upper semicontinuity properties to the payoff functions of the firms, which are necessary to guarantee the existence of Nash equilibria.

Definition 3.4 A game TBR f if the mapping
is upper semicontinuous.

(i, Pi)

is said to be reciprocal upper semicontinuous (RUSC) for a given
(C1, C2)  i(f, C1, C2)
i

The notion of RUSC games was introduced by Dasgupta and Maskin in [10] (labeled as complementary discontinuous or u.s.c≠sum games) and later generalized by Reny in [31] in order to prove the existence of Nash equilibria in certain discontinuous games. Intuitively, in a RUSC game firm i can only approximate the payoff corresponding to a market situation (C1, C2) by actually playing Ci. We should note that Reny's definition is slightly stronger, but the one above (from [10]) is sufficient for our needs. Furthermore, Proposition 5.1 in [31] tells us that RUSC is inherited by the mixed extension of a game.

Lemma 3.5 (Page Jr. & Monteiro [28]) If the game (Pi, i) is played using efficient TBRs, then it is RUSC.

11

Proof. Consider the mapping (C1, C2)  i i(f , C1, C2). If f  is efficient then we have

i(f , C1, C2) = sup i(f, C1, C2)
i f F i

= sup

i(, C1, C2)fi()µ(d)

f F i 

= max i(, C1, C2) fi()µ(d) for any f  F

i

i

= max i(, C1, C2)µ(d).
i

It follows from Proposition 3.2, that (C1, C2)  maxi i(, C1, C2) is upper semicontinuous, hence so is i i(f , C1, C2). 2
Notice that the definition of efficient TBR, together with the linear aggregation of type-wise profits, implies that the mapping (C1, C2)  i i(f, C1, C2) is independent of the TBR played if the latter it is efficient.
3.3 Existence of Nash equilibria
In this section we study necessary conditions for the existence of Nash equilibria in the agencies' game. We cannot employ the canonical results of Debreu, Glicksberg and Fan, given the discontinuities introduced by the TBRs. Instead we rely on the results of Page Jr. & Monteiro [27] and Reny [31]. Since the payoff functions i are not quasiconcave, one cannot prove the existence of pure≠strategies equilibria using the state≠of≠the≠art results available in the literature. Instead we analyze the existence of mixed≠strategies equilibria. In order to do so we show uniform payoff security of the game. This notion allows one to conveniently test the payoff security of a game's mixed extension.

3.3.1 Defining the mixed≠strategies game
To define a mixed catalogue game, we let M(Pj) be the set of probability measures on (Pi, B(Pi)). We endow the mixed catalogue strategy sets M(Pi) with the (X, X)-topology generated by the dual pair L0(Pi, B(Pi)), M(Pi) . The game is played as follows: Each agency chooses an element i  M(Pi), and its profit under the profile  = (1, 2) is given by

i()

i(C1, C2)(dC),

P

(3)

where (dC) = 1(dC1)2(dC2) is the corresponding product measure. By Proposition 3.2 the integrand is measurable, thus expression (3) is well defined. The game (M(Pi), i) is the mixed catalogue game that extends (Pi, i) .

Definition 3.6 A mixed profile  is a Nash equilibrium for the game (M(Pi), i) if

i(i, -i)  i(i, -i) for all i  M(Pi).

A Nash equilibrium in mixed strategies for (M(Pj), i) can be viewed as an equilibrium in pure strategies for its mixed extension.

12

3.3.2 Uniform payoff security
A game in which the players' strategy sets are compact subsets of a topological space and their payoff functions are bounded is called compact. The mixed extension of the game in hand is a compact game. This is due to the fact that the sets M(Pi) are closed, convex and bounded subsets of (L0(Pi, B(Pi))), thus by the Banach≠Alaoglu theorem they are (X, X)-compact. Reny provides sufficient conditions for existence of a Nash equilibrium in a compact game in the presence of discontinuous payoff functions. A key requirement is that the game is payoff secure. Intuitively this means that small deviations on the part of firm i's competitors can be answered to with a deviation that leaves firm i within a small interval of its profit prior to deviations.

Definition 3.7 Given the payoffs i : Pi  R, the catalogue game (Pi, i) is payoff secure if for all (C1, C2)  P, and > 0 there exist Ci  Pi and  > 0 such that
i(Ci, C-i)  i(Ci, C-i) -
for all C-i  D  P-i | hp(D, C-i) <  .
Payoff security of a game does not imply the same property for its mixed extension; however, such is the case with uniform payoff security (see Theorem 1 in [28]). Proving uniform payoff security of a game is simpler than dealing with the weak-topology to show payoff security of its mixed extension.

Definition 3.8 The catalogue game (Pi, i) is uniformly payoff secure if for all i = 1, 2, Ci  Pi and > 0 there exist Ci such that for all C-i  P-i there exists  > 0 that satisfies
i(Ci, C-i)  i(Ci, C-i) -
for all C-i  D  P-i | hp(D, C-i) <  .
Proposition 3.9 The game (Pi, i) is uniformly payoff secure (hence the game (M(Pj), i) is payoff secure).

Proof. Let Ci  Pi and > 0 and define

Ci (X, p - ) | (X, p)  Ci and p -  Ki(X)  (0, 0) ,

i.e. Ci is obtained from Ci by keeping all contracts that allow for an ≠decrease in prices without this rendering a negative price≠cost benefit. All other contracts are replaced by (0, 0) . Lemma 2.1 implies

there is  > 0 such that if d (X, p), (X , p ) <  (where d(∑, ∑) is the distance generated by ∑ 2 ◊ | ∑ |) then for all   

|U (, X) - p - U (, X ) + p | < .

(4)

Assume first that i(, Ci, C-i) > and let (X, p)  Ci be such that U (, X) - p = i(, Ci, C-i). Then
(X, p - )  Ci . Now consider C-i such that hp(C-i, C-i) < , and let (X , p )  C-i. By definition there exist (Y, q)  C-i such that d (Y, q), (X , p ) < , and by Equation (4)

U (, X) - (p - )  U (, Y ) - (q - ) > U (, X ) - p .

The latter implies that (X , p ) / L(, Ci , C-i) and in turn that an efficient TBR f for (Ci , C-i) satisfies fi() = 1. Thus
i(, Ci , C-i)fi(t)  i(, Ci , C-i).

13

The inequality above is trivially fulfilled if i(, Ci, C-i)  . We have that for any deviation C-i such that hp(C-i, C-i) <  and for any efficient TBR f

i(Ci , C-i) 

i(, Ci , C-i)fi()µ(d) -



= i(Ci, C-i) - .

2 The proof of Proposition 3.9 is a particular case of the proof of Theorem 1 in [29]. We have included it here because it showcases how the linear aggregation of type≠wise profits is key to the existence of Nash equilibria. The simple yet far reaching construction of Ci is only possible in such case. Our result on existence of Nash equilibria relies on the following
Theorem 3.10 (Reny [31]) Suppose that G = {(Xi, ui)}mi=1 is a compact game which is also quasiconcave, reciprocally upper semicontinuous and payoff secure, then it possesses a pure≠strategies Nash equilibrium.
It follows from Lemma 3.5 that the (compact) game (M(Pi), i) is RUSC. The payoff functions are linear in each firm's strategy, hence quasiconcave. Proposition 3.9 then allows us to apply Theorem 3.10 to the mixed extension of the game (Pi, i) to obtain the following
Theorem 3.11 The game (Pi, i) possesses a mixed≠strategies Nash equilibrium.
4 Risk Minimization
In this section we analyze the risk minimization problem faced by firms that have some initial risky endowments. The goal of the firms is to lay off parts of their risk on individual agents. This is done via OTC trading of derivatives contracts. The model presented here is the multi≠firm version of the one introduced in [20]. In contrast with the previous section, we do not seek to prove the existence of Nash equilibria, but rather of socially efficient allocations. The main difficulty towards guaranteeing Nash equilibria stems from the non≠linear, per≠type impact on the firms' risk assessments. In the previous sections, the fact that any agent contracting with an agency had a positive impact on its revenues was essential to show uniform payoff security and RUSC. This is no longer the case for risk≠minimizing firms. Here the risk associated to the aggregate of a firm's initial position plus a contract could be lower than the firm's initial risk assessment, but once all positions are taken into account, the firm might be better off not engaging the agents who would have chosen such contract.
4.1 The firms' strategy sets & risk assessments
The initial risky endowment of each firm is represented by a random variable Wi  L2 (, F , P). Firm i assesses its risk exposure using a convex and law invariant risk measure
i : L2 (, F , P)  R  {+},
which has the Fatou property. We refer the reader to Appendix C for a discussion on these maps, as well as related references. We restrict the firms' choices to catalogues of the form
Ci = (Xi(), pi()) .
14

These are not direct revelation mechanisms: even if firm 1 were to offer the individually rational and incentive compatible catalogue C1, the presence of firm 2 might dissuade agents of type 0 from choosing (X1(0), p1(0)). For a given catalogue profile (C1, C2) and a given TBR f, the position of firm i after trading is
Wi - (pi() - Xi())µ(d) - (pi() - Xi())fi()µ(d),
i 0
where i and 0 are as defined in Section 2.4. If we write pi() = vi(, C1, C2) - vi(, C1, C2), and we rename X() = X() - E[X()],9 then firm i's risk assessment after trading is

Ai(C1, C2, f ) Ri(C1, C2, f ) - Ii((C1, C2, f ),

where

Ri(C1, C2, f )

i Wi - Xi()µ(d) - Xi()fi()µ(d) ,
i 0

denotes firm i's risk and the associated income is given by

Ii((C1, C2, f )

(vi() - vi()µ(d) + (vi() - vi())fi()µ(d).

i 0

As we have seen before, when a catalogue profile (C1, C2) is presented to the agents, the corresponding indirect utility functions (v1, v2) show how the market is segmented. The more interesting set is 0, i.e. the set of indifferent agents. Within this set, there are two intrinsically different situations. First, v1 and v2 may be identical over a non≠negligible subset. These could be regarded as "true" ties, in the sense that they will have different impacts on the firms' risk assessments under different TBRs. Second, there could be types for which v1 and v2 are secant. We show below that given our assumptions on µ, these types do not have a direct impact on the aggregate incomes (in fact they do not impact the Ai's, but we do not require this for our arguments). However, they do indicate the points where agents switch from contracting with one firm to the other one, in other words they show where the customers' preferences shift.

Definition 4.1 Given a pricing schedule (v1, v2)  C1 ◊C2, we say that there is a shift in the customers' preferences at   int() if

(v1(-) - v2(-)) ∑ (v1(+) - v2(+)) < 0.
Proposition 4.2 For any pricing schedule (v1, v2)  C1 ◊ C2 the set s of shifts in the customers' preferences satisfies:

1. s has at most countably many elements. 2. The derived set of s has measure zero.

Proof. The set s(v1, v2) is the union of the closures of the sets 1s {   | v1(x) = v2(x), v1(x) = v2(x)}
and

s {   | v1(x) = v2(x), v1(x) = v2(x), |v1(x~) - v2(x~)| > 0  x~  B( , x) \ {x}, > 0} .
9This is possible due to the translation invariance of i, and fully characterizes pi in terms of vi.

15

The set 1s is denumerable and nowhere dense. This follows directly from the convexity of v1 and v2 and the fact that the corresponding supporting planes to graph{v1} and graph{v2} at (, v1()) are secant. By definition 2 is denumerable and nowhere dense, since any two of its elements can be separated. Therefore cl{1s} and cl{s} are themselves denumerable and nowhere dense.
2
As a result of the preceding proposition we see that the set of pre≠images of the crossings of the graphs of two functions v1  Ci and v2  C2 has µ≠measure zero, which yields the following
Corollary 4.3 Let v1  C1 and v2  C2, then the set {v1 = v2}  {v1 = v2} is of µ≠measure zero.
As a consequence of Corollary 4.3, we have that the aggregate income of the firms is independent of the TBR, namely

Ii(C1, C2, f ) = (v() - v ())µ(d) +

(vi() - vi()µ(d).

i 0

i i

Finally we define

A(C1, C2, f )

Ai(C1, C2, f ).
i

4.2 Socially efficient allocations
A market situation (C1, C2), together with a TBR f  is said to be a socially efficient allocation10 if it minimizes the aggregate risk in the economy and if it is individually rational at the agencies' level; in other words if A(C1, C2, f ) solves the problem



inf inf inf
v fX

A(C1, C2, f ) | -Var[Xi()] = vi(), Ai(C1, C2, f ) 

i(Wi) .

As it was the case in Lemma 2.2, the variance constraints -Var[Xi()] = vi() capture the incentive compatibility of the catalogues Ci, while Ai(C1, C2, f )  i(Wi) is firm i's individual rationality constraint. As we mentioned in Section 2.5, in absence of a competitive market one cannot rely on equilibrium pricing to take care of the issue of individual rationality. It is therefore necessary to work under the constraints Ai(C1, C2, f )  i(Wi), for otherwise one could end up with allocations that are optimal on the aggregate level, yet unenforceable. An alternative would be to establish a cash≠transfer system, which should be supervised by the regulator. We comment further on the latter in Section 4.2.4. In the remainder of this section we study the existence of SEAs, and we show that the presence a regulator is required in order for such allocations to be attainable and/or implementable. Our existence result depends heavily on the implementation of efficient TBRs.

Definition 4.4 Let C = (C1, C2) be a catalogue profile. A tie≠breaking rule fØ  F is efficient for C if

A(C1,

C2,

fØ)

=

inf
f F

A(C1, C2, f ) .

From the definition above one observes that efficient TBRs are endogenously determined. Here we encounter the first need for the social planner in our risk≠minimization setting, as it could be the case that unless regulated, efficient TBRs would not be implemented.
10From this point on we use the shorthand SEA to refer to a socially efficient allocation.

16

4.2.1 Minimizing the risk for fixed incomes and tie≠breaking rule
In a first step, we fix (v1, v2)  C1 ◊ C2 (hence the firms' incomes), as well as f  F. We shall abuse notation slightly and write Ri(v1, v2, Xi, f ) for Ri(C1, C2, f ). We then analyze the problem

1 inf

Ri(v1, v2, Xi, f ) - Var[Xi()] = vi() and Ai(v1, v2, Xi, f )  i(Wi) .

(X1 ,X2 )

i

This problem can be decoupled into the sum of the infima, since the choice of Xi bears no weight on the evaluation of R-i. Hence we must study the solution(s) to the following single≠firm problems:

inf
Xi

Ri(vi, v-i, Xi, f )

- Var[Xi()] = vi() and Ai(v1, v2, Xi, f ) 

i(Wi)

.

To deal with the individual rationality constraints, we define

Xiv,f

Xi  Xi | Ai(v1, v2, Xi, f )  i(Wi) ,

which is the set of individually rational products for the given price schedule (v1, v2), and

Xikiv

X  Xi |

Xi

2 2



kiv

where kiv vi(a) - vi(0). The set Xikiv contains all the products that can be structured as to construct incentive compatible catalogues given (v1, v2), with kiv providing a bound to the L2≠norm of the products via the constraint -Var[Xi()] = vi(). We elaborate further into the kiv's in Appendix A, where we also
provide an outline of the proof of existence of solutions to 1 stated in Lemma 4.5. The proof is analogous
to that of Theorem 2.3 in [20], and we include it for completeness.

Lemma 4.5 For v  C1 ◊ C2 and f  F given, if Xikiv  Xiv,f =  then there exist Xiv,f  Xi such that

1 = R1(v1, v2, X1v,f , f ) + R2(v1, v2, X2v,f , f ).

Remark 4.6 It should be mentioned that individual rationality may be verified ex≠post. If a solution Xiv,f to the minimization problem

inf
Xi

Ri(vi, v-i, Xi, f )

- Var[Xi()] = vi()

satisfies Ai(v1, v2, Xiv,f , f )  i(Wi), then Xikiv  Xiv,f = . If on the contrary, Ai(v1, v2, Xiv,f f ) > i(Wi), then the solution set of 1 is empty.

In order to establish the existence of an efficient TBR it is important to characterize the optimal contracts Xiv,f . Specifically, we show below that Xiv,f can be multiplicatively decomposed into a ≠ dependent function and an ≠dependent random variable. To this end, we construct the Lagrangian
associated to minimizing Ri(vi, v-i, Xi, f ) subject to the moment conditions E[Xi()] = 0 and Var[Xi()]+ vi() = 0, and we compute the Frech¥et differential of Ri at Xi in the direction of h  Xi :

Ri(Xi)h = i Wi - Xi()µ(d) - Xi()fi()µ(d) - h()d - h()fi()µ(d) .

i 0

i 0

Since, for all H  L2(, P), the map K  i(H)K is linear, it follows from the Riesz representation theorem that there is a random variable ZXiv,f  L2(, P) such that

Ri(Xi)h =

Z Xiv,f

-

h()d - h()fi()µ(d) dP.
i 0

17

Let g : F  L0(, µ) be given by

g(f ) =11i +110 f.

The operator Ri has an extremum at Xi under our moment constraints if there exist Lagrange multipliers i, i  L2(, µ) such that



h()


-ZXiv,f g(fi)() + i() + 2i()Xi()

µ(d)dP = 0.

for all h  Xi. Since (, )  -ZXiv,f g(fi)() + i() + 2i()Xi() is an integrable function, the DuBois≠ Reymond lemma implies

-ZXiv,f g(fi)() + i() + 2i()Xi() = 0.

(5)

Using the moment conditions EP[Xiv,f ()] = 0 and Var[Xiv,f ()] = -vi() we obtain

i() = EP ZXiv,f g(fi)()

and

g(fi)()

i() =

2

Var ZXiv,f -vi()

.

Inserting the expressions for the Lagrange multipliers into Equation (5) yields

Xiv,f () = -vi()ZØiv,f ,

(6)

where

ZØiv,f

ZXiv,f - E ZXiv,f

Var ZXiv,f .

Equation (6) shows that the minimizers of problem 1 form collinear families in X . Moreover, the randomness stemming from (, P) and and the one induced by (, µ) are decoupled. This property will prove

to be key in Section 4.2.2, where we show the existence of efficient TBRs. The previous discussion yields

the following characterization result:

Proposition 4.7 Let (X1v,f , X2v,f ) be a solution to 1. Then Xiv,f takes the form

Xiv,f (, ) = -vi()ZØiv,f ()

for some normalized random variable ZØiv,f on (, F , P).
If either X1v,f or X2v,f do not satisfy Ai(v1, v2, Xiv,f , f )  i(Wi), then using the standard convention inf{} =  we would have 1 = . In terms of the program , this guarantees that only pricing schedules and TBRs that offer the possibility of constructing individually rational catalogues stand a chance to be chosen.

4.2.2 Existence of efficient tie≠breaking rules
In this section we show that for a given price schedule (v1, v2) there is a TBR f v such that the corresponding optimal product lines (X1v,fv , X2v,fv ) minimize the aggregate risk evaluation of the firms. For v = (v1, v2)  C1 ◊ C2 we define

R~i(v1, v2, f )

i Wi - Ziv,f ()

-vi()d + fi() -vi()µ(d)

i 0

and Fv f  F | R~i(v1, v2, f ) <  .
i

18

We then have to solve the problem

2 inf R~i(v1, v2, f ).
Fv i

If Fv = , then as above 2 = . Otherwise we must verify the lower semicontinuity of the mapping

f  R~1(v1, v2, f ) + R~2(v1, v2, f ), f  Fv.

To this end consider a minimizing sequence {f n}  Fv. The Banach≠Alaoglu theorem guarantees that

{f n} is weakly convergent11 to some f v  Fv. Since Vi()

-vi() belongs to L2(, µ) for all vi  Ci,

then

fin()Vi()d  fiv()Vi()µ(d).
0 0

(7)

Let

aiv,n Vi()d + fin()Vi()µ(d).
i 0

For f v we define aiv analogously. From (7) we have that aiv,n  avi . Since Ziv,fn 2  1 for all n, there exists Ziv  L2(, P) such that Ziv 2  1 and

Ziv,fn -w. Ziv.

Therefore Yiv,n that

aiv,n ∑ Ziv,fn converges weakly to Ynv avi ∑ Ziv. It follows from the Fatou property of i

i(Wi

-

avi

∑

Ziv )



lim inf
n

i(Wi - avi ,n ∑ Ziv,fn ).

From the lower semicontinuity of the norm in terms of weak convergence we have

Var [ZivVi()]  -vi(). Proceeding as in Section 4.2.1, we have that

R~i(v1, v2, f v)  i(Wi - aiv ∑ Ziv).

Therefore

2
R~i(v1, v2, f v) - Ii(v1, v2, f v) = inf
f F i=1

2
R~i(v1, v2, f ) - Ii(v1, v2, f )
i=1

.

We denote by (X1v, X2v) any optimal list of claims associated to the pricing schedules (v1, v2) and the TBR f v. For notational convenience we define

A(v1, v2)

2
R~i(v1, v2, f v) - Ii(v1, v2, f v) .
i=1

4.2.3 Minimizing with respect to the firms' incomes
To finalize the proof of existence of a SEA, we let {(v1n, v2n)} be a minimizing sequence of
2
R~i(v1, v2, f v) - Ii(v1, v2, f v) .
i=1
11We omit writing "up to a subsequence" when exploiting the compactness of sets, but it should of course be kept in mind.

19

We get from Proposition 2.3 that there exist (vØ1, vØ2)  C1 ◊ C2 such that vin  vØi uniformly. This implies that Vin  VØi almost surely (see for example Proposition A.4 in [11]). Moreover, for any    where convergence holds, it is uniform. We have from Fatou's lemma and the fact that 0  -Ii(v1, v2, f ) for any
(v1, v2)  C1 ◊ C2 and any f  F that

22

-Ii(vØ1,

vØ2,

f

vØ)



lim inf
n

-Ii(v1n, v2n, f vn ).

i=1 i=1

In order to deal with the risky part of the firms' problems we require the following

Lemma 4.8 Let {n}, {n}  L2(, P) and ,   L2(, P) be such that

n --∑ 2  and n -w. , then n, n  ,  ,

where ∑, ∑ is the canonical inner product in L2(, P).

Proof. Adding and subtracting , n from | n, n - ,  | we obtain

n, n - ,   n - , n + , n -  .
Since {n} is a weakly convergent sequence, it is bounded. Let KØ be such bound, then using the Cauchy≠ Schwarz inequality we have

n, n - ,   KØ n -  2 + , n -  .

As n  , the first summand on the righthand side of the inequality converges to zero due to the strong

convergence of the n's to ; the second summand converges to zero due to the weak convergence of the

n's to , which concludes the proof.

2

We show in Proposition 4.9 that if it were the case that the market segments exhibited no jumps in their limiting behavior then then there would exist SEAs. By absence of jumps we mean that

11n0 -a-.s. 11Ø 0 and 11in -a-.s. 11Ø i ,
where Ø 0 = {vØ1 = vØ2} and Ø i = {vØi > vØ-i}. This "nice" convergence of the ni 's is by no means the general scenario. As an example let v1n  v1 and v2n = v1 + 1/n. Here n1  , 2  , but in the limit only Ø 0 = . Nonetheless, the existence result of SEAs under the assumption of convergence of the indicator functions is relevant for the general case, and we present it below.

Proposition 4.9 Let {(v1n, v2n)}, (vØ1, vØ2)  C1 ◊ C2 such that vin  vØi uniformly. Assume that 11jn 11Ø j , and let XØ1, XØ2 and fØ be the (weak) limits of X1vn , X2vn and f vn . Then

22

lim inf
n

R~i(v1n, v2n, f vn )

i=1



i i=1

Wi - XØiµ(d) - fØi XØiµ(d)
Ø i Ø 0

2

 i Wi - XivØµ(d) - fivØXivØµ(d) ,

i=1 Ø i

Ø 0

where (X1vØ, X2vØ, f vØ) solves the social planer's problem for (vØ1, vØ2).

20

Proof. The second inequality follows from the definition of (XØ1, XØ2, fØ). To show that the first one holds, we first use Proposition 4.7 and write

Xivn,fvn µ(d) -
in

fin

X vn,f vn
i

µ(d)

=

Z vn,f vn
i

n0

11ni () - fivn110n Vin() µ(d)


avi n ∑ Zivn,f vn .

The assumption on the convergence of the indicator functions 11nj implies that

Vin11n0 -a-.s. VØi11Ø 0 . Since |Vin110n |, |VØi11Ø 0 |  M and µ() < , by Lebesgue Dominated Convergence we get

Vin11n0 --∑ 2 VØi11Ø 0 . Hence, by Lemma 4.8 we have that aivn  aØi, where

aØi 11Ø 1 () - fØ11Ø 0 VØi() µ(d).


Therefore

avi n ∑ Zivn -w. aØi ∑ ZØi,

and the Fatou property of the risk measure yields

22

Ri(vØ1,

vØ2,

Xi,

f

)



lim inf
n

R~i(v1n, v2n, f vn ).

i=1 i=1

2

We now deal with the possibility of non≠convergence of the indicator functions. We first observe that the 0n's are closed subsets of , which is compact. The set
2Ø := {A   | A =  and A is closed}

endowed with the Hausdorff metric h : Ø2  R+ is a compact metric space (see for example [1], Chapter 3). If n0 =  infinitely often, then there exists ^ 0  Ø2 such that, up to a subsequence if necessary
0n -h ^ 0.
Moreover, ^ 0 is contained in Ø 0. If, on the contrary, 0n =  for all but a finite number of n's, then we define the Hausdorff limit of {0n} as the empty set, which is again contained in Ø 0. In both instances we observe that there can only be more ties in the limit, and hence more ways of breaking them. This suggests that the aggregate risk in the limit is indeed no greater than the aggregate risk in the pre≠limit.
As for the sets in, if  is not eventually in either of them, then either   ^ 0 or it is a type whose preferences alternate. However, the limiting behavior of the latter is that of indifference, due to the convergence of the functions vin. In other words, an agent type  eventually always contracts with the same firm i, alternates between firms or is always indifferent. Thus,

  0n for all sufficiently large n or   Ø 0.

We now decompose the type space into subsets for which the associated indicator functions converge. To

this end, we define

~ 0n Ø 0 \ 0n, and ~ ni ni \ ~ n0 .

21

The sets ~ in contain the "surviving customers", in the sense that there will be no jumps towards indifference from types in ~ in at the limit; ~ n0 is the set of "alternating customers". By construction
 = ~ n0  0n  ~ 1n  ~ 2n = Ø 0  ~ 1n  ~ n2 .
The following lemma shows that the sets ~ in of "surviving customers" converge to the sets of agent types that contract with firm i when (vØ1, vØ2) is offered.
Lemma 4.10 For i = 1, 2 we have 11~ in 11Ø i .
Proof. Let    be given. There are two possible cases. Either there exists N  N such that if n > N, then   ~ in or there exists a subsequence {v1nk , v2nk } such that  / ~ ni k for all nk. In the former case the (uniform) convergence of the vin's implies vØi() > vØ-i(). In the latter case, either  eventually belongs to ~ n-i, in which case convergence of the indicator functions follows or   ~ n1  ~ 2n infinitely often. In this case   ~ n0 and we again have convergence of the indicators.
2

Let us now assume that the social planer's problem were such that at every stage n all agent types that belong to the set of "alternating customers" are deemed indifferent. This results in more tie≠breaking possibilities. Specifically we consider the social planer's problem

A(v1n,

v2n)

=

inf
f nF

inf
X

2

i Wi -

Xinµ(d) -

finXinµ(d) Var[Xin()] = -(vin) () .

i=1

~ in

~ 0nn0

A subset of the possible choices of the fin's is F0n, which is defined as the set of f~  F such that

 0,

f~() =

 1,

vin() < v-n i() vin() > v-n i()

 f (), otherwise,

for some TBR f  F. We then have that

A(v1n, v2n)|F0 = A(v1n, v2n).

Thus,

A(v1n, v2n)  A(v1n, v2n).

Consider a minimizing sequence {(v1n, v2n)} with (uniform) limit (vØ1, vØ2). Lemma 4.10 guarantees that11~ ni 

11Ø i ; moreover ~ n0  n0  Ø 0 to A(v1n, v2n), which yields

so

patently 11~ 0nn0

11Ø 0 .

These

two

facts

allow

us

to

apply

Proposition

4.9

lim inf
n

A(v1n

,

v2n

)



lim inf
n

A(v1n,

v2n

)

2

 i Wi - Xiµ(d) - fiXiµ(d) ,

i=1 Ø i

Ø 0

where (X1, X2, f ) solves the social planer's problem for (vØ1, vØ2). This shows that (X1, X2, f ) is indeed optimal because {(v1n, v2n)} was required to be a minimizing sequence. We have proved the following

Theorem 4.11 If firm i assesses risk using a law invariant risk measure

i : X  R  {+},

which has the Fatou property, and if it offers catalogues of the form

Ci = (Xi(), pi()) , then there exists a socially efficient market situation.

22

4.2.4 Individual rationality revisited
We can also deal with a slightly different setting, in which the regulator's presence would be necessary for the enforcement of a cash transfer. Namely, assume that (C1, C2, f ) is a solution to the problem  without the individual rationality constraints R^i(C1, C2, f )  i(Wi). Since both firms could simply offer (0, 0), a minimization of A(∑, ∑, ∑) would be IR on the aggregate level. Then there would exist r  0 (the rent of risk exchange) such that
A(C1, C2, f ) = 1(W1) + 2(W2) - r We define a transfer SEA to be a quadruple (C1, C2, f , T ) such that
1.  = A(C1, C2, f ), 2. R^1(C1, C2, f ) - T   1(W1), 3. R^2(C1, C2, f ) + T   2(W2), and T   [r1, r2] for some r1, r2  R such that r2 - r1 = r. The arguments contained in Sections 4.2.1, 4.2.2 and 4.2.3 can be immediately applied to prove the following
Corollary 4.12 If firm i assesses risk using a law invariant risk measure
i : X  R  {+},
which has the Fatou property, and if it offers catalogues of the form
Ci = (Xi(), pi()) ,
then there exists a transfer socially efficient market situation.

5 Examples: Risk Minimization
In this section we focus our attention on two well≠known risk measures: entropic and average value at risk. When it comes to the latter, we mostly present in Section 5.3 the results of applying the numerical algorithm that is described in Appendix B to some specific examples12. As for the entropic risk measure, before proceeding with the numerical simulations, we present in Section 5.1 a structural result that exploits the risk measure's particular structure. Moreover, we show that in this case there is a SEA where both firms service all of the agents, and for which the optimal TBR is a constant proportion over the whole market. We refer to such efficient TBRs as "fix≠mix" rules.

5.1 Entropic≠risk≠minimizing firms

In what follows we concentrate on a situation where the firms use the entropic risk measure as a means to

assess their risk exposure, i.e.

i (X )

=

1 i

ln EP

[exp(-iX)] .

The coefficient i represents firm i's risk aversion. This particular choice of risk measures, which is closely related to exponential utility, allows us to further the analysis into the structure of SEAs. Moreover, given

12All of our codes are available upon request

23

that it is strictly convex and that it has a closed≠form representation it lends itself very well to numerical exercises. For vi and f given, Proposition 4.7 allows us to write program 1 (the minimization with respect to the firms' claims for fixed incomes and TBR in Section 4.2.1) as

2
inf
(Z1,Z2)i◊2 i=1

W - Zi

-vi()µ(d) +

-vi()fi()µ(d)

i 0

,

where

i := {Z  Xi | E[Z] = 0,

Z

2 2

=

1}.

The structure above allows us to write (See Section 3.4.2 in [20]) the minimization problem of firm i as that of finding a stationary point to the Lagrangian

L(Z, , ) = ln

e-i(W +Za(vi,fi))dP +  ZdP +  Z2dP,

 

where  and  are the Lagrange multipliers associated to the moment constraints, and

a(vi, fi) =

-vi()µ(d) +

-vi()fi()µ(d).

i 0

This in turn results in the following implicit representation for the optimal claims given vi and f, which has a unique solution for each realization ziv,f of Ziv,f and wi of Wi :

e - E e-i(Wi+Ziv,f a(vi,fi))

-i(Wi+Ziv,f a(vi,fi))

Ziv,f = -

Var e-i(Wi+Ziv,f a(vi,fi))

.

(8)

Remark 5.1 The indirect utility functions vi and the TBR fi only affect the optimal claims Ziv,f via the "aggregator" a(vi, fi).

The previous remark has interesting repercussions for the socially efficient TBRs. Indeed, assume the

firms have initial endowments Wi and they are characterized by risk aversion coefficients i. Theorem 4.11

guarantees the existence of a SEA (v1, v2, f , Z1, Z2), which yields the following aggregate risk in the

economy:

1 W1 - a(v1, f1) Z1 + 2 W2 - a(v2, f2) Z2 + I[v1, v2],

(9)

where I[v1, v2] represents the firms' aggregate income (which is independent of f ). We know from Remark 5.1 that any modification on f  that leaves a(vi, fi) unchanged bears no weight on the value of
expression (9). We can redefine

 0,



f () =

1,

v1() < v2() v1() > v2()

 f (), otherwise,

and define which then allows us to write

v() max v1(), v2() ,

a(vi, fi) =

-(v) ()fi()µ(d).



24

Once we have defined the TBR over the whole , we may go one step further and write

K



-(v) ()f ()µ(d) ,

 -(v) ()µ(d)

then

a(v1, f1) = K

-(v) ()µ(d) and a(v2, f2) = (1 - K)

-(v) ()µ(d).



An interesting economical conclusion from the computations above is that there exists a SEA that consists

of both firms servicing the whole market, and splitting the customers in a K to 1 - K proportion. This follows from the fact that only v (the upper envelope of the original vi) appears in each firm's program. In markets such as regulated health≠insurance, where firms are legally prevented from abstaining from

contracting with any agent, the regulator may oversee that a socially optimal proportion of the market is

serviced by each firm.

5.2 Simulations (Entropic≠risk minimizing firms)
In this section we provide the numerical analysis of a particular example of the entropic≠risk minimizing firms analyzed above. To this end we set
∑ Dimension of the space defining v: 6, dimension of : 14, ∑ W1 = 0.5  (-1, -3, -9, -3, -1, -0.2, -0.1, -0.1, -0.2, 1, -3, -9, -3, -1)T , ∑ W2 = 0.5  (-0.03, -0.1, -0.18, -0.2, -1, -3, -9, -10, -3, -1, -0.2, -0.18, -0.1, -0.03)T , ∑ risk aversion coefficient  = 2.

5.2.1 Risk assessments
Let us benchmark the aggregate risk in the competitive economy against the risk in a monopolistic setting. To this end, we first fix f  1. This corresponds to a model in which firm 1 acts as a monopolist and firm 2 has no access to the market. The a-priori aggregate risk in the economy is 7.36. The risk assessment of firm 1 is reduced from 3.53 to 2.16 after the it has traded with the agents while the risk of firm 2 stays the same. Below we plot the numerical result for Z, as well as the theoretical one from Equation (8) in Figure 1(a) and the corresponding minimizing v (the agents' indirect utility) in Figure 1(b). Likewise, if we fix f  0, which again yields a principal≠agent setting (competition≠wise) for firm 2, we obtain that this firm's initial risk is 3.84, which is reduced to 2.16 after trading. Finally, once we let f vary, the aggregate risk decreases from 7.36 to 5.39, and the corresponding final risk assessments for the firms are 2.17 and 2.67 respectively. While each individual firm is worse off in the presence of competition, it should be noted that the decrement in the aggregate risk in the economy is lower in either case where only one firm has access to the market. Risk decreases from 7.36 to 5.99 when only firm 1 is active, and from 7.36 to 5.72 if it is firm 2 who trades with the agents.

5.2.2 Risk profiles
With respect to the ex≠ante and ex≠post risk profiles, we observe that trading has a smoothing effect, flattening spikes that correspond to the bad states of the World. However the basic shape of the risk profile remains, which is in contrast to what we find in Figure 4 of our AV@R example. This is presented in Figure 2, where the 14 elementary events have been connected by lines for illustration purposes. Figure 3

25

(a) Numerical v.s. theoretical values for Z

(b) The minimizing v

Figure 1: Comparison results for the f  1 case.

(a) Comparison of W1 and W1 - a(v1, f1)Z1

(b) Comparison of W2 and W2 - a(v2, f2)Z2

Figure 2: Positions before and after trading.

shows the agents' indirect utilities associated to each firm's offer, and compares it to the indirect utility for the agents who face a monopolist (in this case firm 1). The market is shared at a 0.42 to 0.58 ratio between the firms. We observe that the upper envelope u() = max{v1(), v2()} dominates the monopolistic situation for all agents. In conclusion, this particular example is in line with the intuition that competition among sellers benefits the buyers. Moreover, the competitive setting also provides a lower aggregate risk exposure. A point could be made that the regulator should make sure that enough incentives exist for all firms to engage in risk≠minimizing trading, as it is socially desirable.
Remark 5.2 Arguably, the implementation of an efficient TBR in full generality could prove to be a daunting task. However, the structure of Ziv,f presented in Equation (8) suggests that in general these variables depend on v and f only via the integral expression a(v, f ). If such were the case, one could achieve an optimum by choosing an efficient "fix-mix" TBR, where each firm caters to a constant proportion of
26

Figure 3: Indirect utilities under monopoly and oligopoly.

the whole market. The latter clearly makes the implementation considerably simpler. For the special case of the entropic measure this can indeed be achieved, as shown above.

5.3 Simulations (AV@R≠minimizing firms)

In this section we study an example where the firms are average value≠at≠risk minimizers. Recall that for   (0, 1], and X  L(, F, P ), one defines

1 AV @R(X)  0 V @R(X)d,

where

V @R(X) inf m | P {X + m < 0}   .

We use the following initial parameters:

∑ Dimension of the space defining v: 6, dimension of (): 14,

∑ W1 = 0.02  (-1, -2, -4, -10, -4, -2, -1, -0.8, -0.5, -0.3, 0, 0, 0, 0)T , ∑ W2 = 0.05  (-0.03, -0.1, -0.18, -0.2, -1, -3, -9, -10, -3, -1, -0.2, -0.18, -0.1, -0.03)T , ∑ levels for the AV@R: 1: 0.05 and 2: 0.1

The initial aggregate initial risk assessment is 0.68, which decreases to 0.21 after trading. In Figure 4 we compare the firms' positions before and after trading. We observe that in contrast with the entropic≠risk≠ measure case (see Figure 2), the ex≠post shapes of the risk profiles have been significantly altered. This is due to the fact that the risk measure in hand places a heavier weight on the bad states of nature, even at the cost of the originally good ones Figure 5(a) shows the indirect utility functions corresponding to the catalogue that each firm offers, and in Figure 5(b) we have plotted an efficient TBR.

27

(a) Comparison of W1 and W1 - a(v1, f1)Z1

(b) Comparison of W2 and W2 - a(v2, f2)Z2

Figure 4: Positions before and after trading.

(a) The indirect utility functions

(b) A possible socially efficient TBR

Figure 5: Indirect utilities and a possible efficient TBR.

Remark 5.3 It should be noted that in neither of the examples presented above were the individual rationality constraints for the firms binding. This is essential to implement the "fix≠mix" TBR without the need of a cash transfer. Although f plays no role in the aggregate income I[v1, v2], it does enter the IR constraints of each firm. If one wanted to implement a "fix≠mix" TBR without a cash transfer scheme, they would in general run into a two≠equations≠one≠unknown issue as soon as an IR constraint bound.
6 Conclusions
In this paper we have extended the principal≠agent models of profit maximization found in [9] and risk minimization found in [20] to a multi≠agency setting. Both of these works deal with OTC trading of derivatives under adverse selection. It should be mentioned that in order to deal with the increased
28

complexity introduced by the enlargement of the set of sellers, additional restrictions had to be imposed on the set of financially feasible products. On the profit maximization side we made use of results of Reny and, more recently, Page Jr. & Monteiro to show the existence of (mixed≠strategies) Nash equilibria. We were unable, however, to obtain a similar result in the case of risk minimization. The non≠linear impact of individual contracts on the firms' risk evaluations is incompatible with the machinery developed by the authors previously mentioned. Moreover, even if the game were uniformly payoff secure and (weakly) reciprocal upper semicontinuous, the lack of quasi≠convexity would require considering the mixed extension of the game. This brings us to the following conceptual issue: what is expected risk? Convex risk measures can be (robustly) represented as a worst≠case analysis over a family of probability measures that are absolutely continuous with respect to the reference one. However, not all of these measures (which can be interpreted as possible distributions of the future states of the World) are given the same weight. Indeed, they are penalized according to a function that maps the space of probability measures into the extended Reals. By considering a mixed extension of our risk≠minimization game, we implicitly assume that "Nature" and the firms behave in qualitatively different ways. In our view this would be inconsistent. Instead, we introduce the notion of socially efficient allocations and prove the existence of such. We believe that an important contribution of this paper is to show that, within our stylized setting, non≠regulated, OTC markets cannot be guaranteed to be efficient (in the sense of the welfare theorems). The extension of our general setting to one where agents have heterogenous initial endowments (multi≠dimensional agent types) and (we believe more interestingly) to a dynamic framework are left for future research.

A Existence of minimizers to 1

In this appendix we give an overview of the proof of existence of minimizers to problem 1 in Section 4.2.1, which is analogous to the proof of Theorem 2.3 in [20]. The main ideas behind the proof are to relax the variance constraint to have a convex minimization problem, and then to show that based on a solution to the latter we can construct a solution to 1. The steps to be taken are the following:

1. We fix (v1, v2)  C1 ◊ C2 and relax the variance constraint to -Var[Xi()]  vi(). We observe that

Xi

2 2

=

vi(a)

-

vi(0)

kiv .

Let Ki be the uniform bound on the elements of Ci (see Prop. 2.3), then

Xi

2 2



kiv



Ki.

2. The convexity of i implies that the set

Xiv,f

Xi  Xi | Ai(v1, v2, Xi, f )  i(Wi)

is convex. The fact that i has the Fatou property implies that Xiv,f is closed.

3. Since the mapping

Xi  Xi()d - Xi()fi()d,
i 0
is a linear, then Xi  Ai(v1, v2, Xi, f ) is a convex mapping. The set

Xikiv

X  Xi |

Xi

2 2



kiv

is a closed, convex and bounded set, hence the relaxed optimization problem has a solution X~iv,f , as long as XiK  Xiv,f = .

4. The variance constraint can be made binding by structuring the products X~iv into Xiv,f = X~iv,f + Y. Here Y is independent of  and  :   R integrates to zero.

29

B Description of the algorithm used in Sections 5.2 and 5.3

In this appendix we provide a brief description of our numerical algorithm, whose aim is to estimate solutions to the problem

subject to:

2
inf
(Z,f,v) i=1

1
i Wi - Zi
a

1
-v ()fi()d + (v() -  v ())fi()d
a

∑ fi  0, f1 + f2 = 1; ∑ v convex, v  0, v  0, v(1) = 0;

∑ E[Zi] = 0, Var[Zi] = 1.

∑

i Wi - Zi

1 a

-v ()fi()d + a1(v() -  v ())fi()d  i Wi . It should be noted that in the

examples presented in Section 5, this constraint was not binding.

In order to do so, we set a discretization level n, and we work with the following structures:

∑ f1()

n-1 k=0

k11[a+k

1-a n

,a+(k+1)

1-a n

]

,

f2

=

1

-

f1,

0



i



1.

∑ v (∑)

1 ∑

-

d d

-v ()d +

2
-v (1) , we shall denote v~

-

d d

-v (), and 

-v (1)  0.

There is a one≠to≠one correspondence between v~  0,   0 and functions v that satisfy the re-

quirements of being convex, non≠increasing and non≠negative. This allows for an easier≠to≠handle

description of such functions, instead of having to impose more burdensome, global convexity con-

straints, which would be necessary in higher dimensions.

∑ We go one step further and define v~()

n-1 k=0

k11[a+k

1-a n

,a+(k+1)

1-a n

]

,

i



0.

∑ Zi

(0i , . . . , di-1)



Rd,

1 d

d-1 k=0

ki

=

0,

1 d

dk-=10(ki )2  1. Following the results presented in

Appendix A, we have relaxed Var[Zi] = 1 to Var[Zi]  1.

In this setting we have that

1

i Wi - Zi

-v ()fi()d = ri(, , , ).

a

and the problem amounts to minimizing the aggregate risk

2 i=1

ri(,



,



,

)

subject

to

ri(, , , )



ri(0, 0, 0, 0) and subject to constraints on , ,  and  specified earlier. The latter are convex (in fact most

of them are linear)in the corresponding variables. A crucial property of the functions ri : Rn+2d+1+n  R

is that for any three fixed entries, they are convex on the remaining variable. Exploiting the latter we use

an iterative algorithm that performs a one≠step, first≠order descent in each direction alternately, such that

the aggregate risk decreases in each step. The algorithm repeats this process until a maximal number of

iterations has been performed or until there is no significant change in the aggregate risk. At each of the

steps we encounter the problem of minimizing a convex function with respect to convex constraints.

Our coding has been done in Java, and we have used the NetBeans IDE 6.8 environment. In the case

of AV @R, we have used the or124.jar package (OR-Objects 1.2.4) to calculate the required gradients.

The descent procedures are all based on a local linearization of the function to be minimized, as well

as of the constraints. Since all of these objects are convex, they can be locally, well approximated by

30

The linearlized boundary

Neighborhood of a point near the boundary

A non-feasible iteration

Projection into the feasible region.

Figure 6: Dealing with non≠feasible points
the corresponding subgradients (which are calculated using the chain rule). The linearized function is minimized, subject to the linearized constraints, on a cubic neighborhood of the current point. This reduces to a linear optimization problem. Again the linear optimization package included in or124.jar is used to obtain a minimizer. If this point does not satisfy the constraints (we carry the linearization error), a correction procedure is performed to obtain a feasible point close to the prior one. This procedure essentially performs a line search in the direction opposite to the direction of the subgradient of the constraint function at the point in hand (See Figure 6). Finally, it is verified whether at this feasible point the value of the objective function has decreased. Otherwise, the procedure is repeated starting with a cube whose size length is half of the original one.
C Convex risk measures on L2.
In this appendix we recall some properties and representation results for risk measures on L2(, P). We refer the reader to [7] and to section 4.3 in [15] for detailed discussions on this topic.
Definition C.1 (i) A monetary measure of risk on L2 is a function : L2(, P)  R  {+} such that for all X, Y  L2 the following conditions are satisfied: ∑ Monotonicity: if X  Y then (X)  (Y ). ∑ Cash Invariance: if m  R then (X + m) = (X) - m.
(ii) A risk measure is called coherent if it is convex and homogeneous of degree 1, i.e., if the following two conditions hold:
31

∑ Convexity: for all   [0, 1] and all positions X, Y  L2: (X + (1 - )Y )   (X) + (1 - ) (Y )

∑ Positive Homogeneity: For all   1

(X) =  (X).

(iii) The risk measure is called law invariant, if

(X) = (Y )

for any two random variables X and Y which have the same law.
(iv) The risk measure on L2 has the Fatou property if for any sequence of random variables X1, X2, . . . that converges in norm to a random variable X we have

(X)  lim inf
n

(Xn).

Since a risk measure that has the Fatou property is a l.s.c. and proper convex mapping from L2(, P) into R  {+}, we may represent it via a Legendre-Fenchel transform. Namely, if we define M1(P) to be the set of probability measures on  that are absolutely continuous (w.r.t P) and

then given

M21(P)

Q  M1(P)

dQ dP



L2

,

there exists a penalty function  : L2(, P)  R  {+} such that

(X) = sup EP[-X] - (Q) .
QM12 (P)
Moreover, if for Q  M21(P) we write Y = dQ/dP, then the above expression can be written as
(X) = sup - X, Y - (Y ) ,
Y 2=1
where ∑, ∑ is the canonical inner product in L2(, P), and (Y ) = (Q).

References
[1] C. Aliprantis & K. Border: Infinite Dimensional Analysis, a Hitchhiker's guide (3rd. edition), Springer Verlag, 2006.
[2] M. Armstrong: Multiproduct Nonlinear Pricing, Econometrica, 64, 51-75, 1996.
[3] P. Artzner, F. Delbaen, J-M Ebert & D. Heath: Coherent Measures of Risk, Mathematical Finance, vol. 9, no. 3, 203228, 1999.
[4] A. Bagh & A. Jofre¥: Reciprocal Upper Semicontinuity and Better Reply Secure Games, a Comment, Econometrica vol. 74, no. 6, pp. 1715-1721, 2006.
[5] P. Barelli & I. Soza: On the Existence of Nash Equilibria in Discontinuous and Qualitative Games, mimeo.

32

[6] P. Barrieu & N. El Karoui: Optimal risk transfer, Finance, 25, pp. 31-47, 2004.
[7] P. Cheridito & T. Li: Dual Characterization of Properties of Risk Measures in Orlicz Hearts, Mathematics and Financial Economics, vol. 2, no. 1, pp. 29-55, 2008.
[8] P. Cheridito, U. Horst, M. Kupper & T.A. Pirvu: Equilibrium Pricing in Incomplete Markets under Translation Invariant Preferences, Working Paper.
[9] G. Carlier, I. Ekeland & N. Touzi: Optimal Derivatives Design for Mean≠Variance Agents under Adverse Selection, Mathematics and Financial Economics, vol. 1, no. 1, pp. 57-80, 2007.
[10] P. Dasgupta & E. Maskin: The Existence of Equilibrium in Discontinuous Economic Games, I: Theory, Review of Economic Studies, vol. 53, no. 1, pp. 1-26, 1986.
[11] I. Ekeland & S. Moreno-Bromberg: An Algorithm for Computing Solutions of Variational Problems with Global Convexity Constraints, Numerische Mathematik, 2009.
[12] I. Ekeland & R. Te¥mam: Convex Analysis and Variational Problems, Classics in Applied Mathematics, 28, SIAM, 1976.
[13] L. Epstein & M. Peters: A Revelation Principle for Competing Mechanisms, Journal of Economic Theory, 88, pp. 119-160, 1999.
[14] D. Filipovic¥ & M. Kupper: Equilibrium Prices for Monetary Utility Functions, International Journal of Theoretical and Applied Finance, 11, pp. 325 - 343, 2008.
[15] H. Fo®llmer & A. Schied: Stochastic Finance. An Introduction in Discrete Time, de Gruyter Studies in Mathematics, 27, 2004.
[16] H. Fo®llmer & A. Schied: Convex Measures of Risk and Trading Constraints, Finance and Stochastics, vol. 6, no. 4, pp. 429-447, 2002.
[17] M. Frittelli & E. Rosazza Gianin: Putting Order in Risk Measures, Journal of Banking & Finance, 26, pp. 1473-1486, 2002.
[18] D. Fudenberg & J. Tirole: Game Theory, MIT Press, 1991.
[19] R. Guesnerie: A contribution to the Pure Theory of Taxation, Econometrica, 49, pp. 33-64, 1995.
[20] U. Horst & S. Moreno-Bromberg: Risk Minimization and Optimal Derivative Design in a Principal Agent Game, Mathematics and Financial Economics, vol. 2, no. 1, pp. 1-27, 2008.
[21] E. Jouini, W. Schachermeyer & N. Touzi: Optimal Risk Sharing for Law Invariant Monetary Utility Functions, Mathematical Finance, vol. 18, no. 2, pp. 269-292, 2008.
[22] P. Milgrom & I. Segal: Envelope Theorems for Arbitrary Choice Sets, Econometrica, vol. 70, no. 2 , pp. 583-601, 2002.
[23] M. Mussa & S. Rosen: Monopoly and Product Quality, Journal of Economic Theory, 18, pp. 301-317, 1978.
[24] D. Martimort & L. Stole: The Revelation and Delegation Principles in Common Agency Games, Econometrica, vol. 70, no. 4, pp. 1659-1673, 2002.
33

[25] R. Nessah & G. Tian: The Existence of Equilibria in Discontinuous and Nonconvex Games, working paper.
[26] F. Page Jr.: Catalogue Competition and Stable Nonlinear Prices, Journal of Mathematical Economics, 44, pp. 822-835, 2008.
[27] F. Page Jr. & P. Monteiro: Three Principles of Competitive Nonlinear Pricing, Journal of Mathematical Economics, 39, Issues 1-2, pp. 63-109, 2003.
[28] F. Page Jr. & P. Monteiro: Uniform Payoff Security and Nash Equilibrium in Compact Games, Journal of Economic Theory, (to appear)
[29] F. Page Jr. & P. Monteiro: Catalogue Competition and Nash Equilibrium in Monlinear Pricing Games, Economic Theory, 34, pp. 503-524, 2008.
[30] R. Phelps: Convex Functions, Monotone Operators and Differentiability:, Lecture Notes in Mathematics, 1364, Springer-Verlag, 1989.
[31] P. Reny: On the Existence of Pure and Mixed Strategy Equilibria in Discontinuous Games, Econometrica, 67, pp. 1029-1056, 1999.
[32] J.-C. Rochet: A Necessary and Sufficient Condition for Rationalizability in a Quasi-linear Context, Jornal of Mathematical Economics, 16, pp. 191-200, 1987.
[33] J.-C. Rochet & P. Chone¥: Ironing, Sweeping and Multidimensional Screening, Econometrica, 66, pp. 783-826, 1988.
[34] G. Tian: The Existence of Equilibria in Games with Arbitrary Strategy Spaces and Payoffs: A Full Characterization, working paper.
34

SFB 649 Discussion Paper Series 2010
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "Volatility Investing with Variance Swaps" by Wolfgang Karl H‰rdle and Elena Silyakova, January 2010.
002 "Partial Linear Quantile Regression and Bootstrap Confidence Bands" by Wolfgang Karl H‰rdle, Ya'acov Ritov and Song Song, January 2010.
003 "Uniform confidence bands for pricing kernels" by Wolfgang Karl H‰rdle, Yarema Okhrin and Weining Wang, January 2010.
004 "Bayesian Inference in a Stochastic Volatility Nelson-Siegel Model" by Nikolaus Hautsch and Fuyu Yang, January 2010.
005 "The Impact of Macroeconomic News on Quote Adjustments, Noise, and Informational Volatility" by Nikolaus Hautsch, Dieter Hess and David Veredas, January 2010.
006 "Bayesian Estimation and Model Selection in the Generalised Stochastic Unit Root Model" by Fuyu Yang and Roberto Leon-Gonzalez, January 2010.
007 "Two-sided Certification: The market for Rating Agencies" by Erik R. Fasten and Dirk Hofmann, January 2010.
008 "Characterising Equilibrium Selection in Global Games with Strategic Complementarities" by Christian Basteck, Tijmen R. Daniels and Frank Heinemann, January 2010.
009 "Predicting extreme VaR: Nonparametric quantile regression with refinements from extreme value theory" by Julia Schaumburg, February 2010.
010 "On Securitization, Market Completion and Equilibrium Risk Transfer" by Ulrich Horst, Traian A. Pirvu and GonÁalo Dos Reis, February 2010.
011 "Illiquidity and Derivative Valuation" by Ulrich Horst and Felix Naujokat, February 2010.
012 "Dynamic Systems of Social Interactions" by Ulrich Horst, February 2010.
013 "The dynamics of hourly electricity prices" by Wolfgang Karl H‰rdle and Stefan Tr¸ck, February 2010.
014 "Crisis? What Crisis? Currency vs. Banking in the Financial Crisis of 1931" by Albrecht Ritschl and Samad Sarferaz, February 2010.
015 "Estimation of the characteristics of a LÈvy process observed at arbitrary frequency" by Johanna Kappusl and Markus Reiﬂ, February 2010.
016 "Honey, I'll Be Working Late Tonight. The Effect of Individual Work Routines on Leisure Time Synchronization of Couples" by Juliane Scheffel, February 2010.
017 "The Impact of ICT Investments on the Relative Demand for HighMedium-, and Low-Skilled Workers: Industry versus Country Analysis" by Dorothee Schneider, February 2010.
018 "Time varying Hierarchical Archimedean Copulae" by Wolfgang Karl H‰rdle, Ostap Okhrin and Yarema Okhrin, February 2010.
019 "Monetary Transmission Right from the Start: The (Dis)Connection Between the Money Market and the ECB's Main Refinancing Rates" by Puriya Abbassi and Dieter Nautz, March 2010.
020 "Aggregate Hazard Function in Price-Setting: A Bayesian Analysis Using Macro Data" by Fang Yao, March 2010.
021 "Nonparametric Estimation of Risk-Neutral Densities" by Maria Grith, Wolfgang Karl H‰rdle and Melanie Schienle, March 2010.

SFB 649 Discussion Paper Series 2010
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
022 "Fitting high-dimensional Copulae to Data" by Ostap Okhrin, April 2010. 023 "The (In)stability of Money Demand in the Euro Area: Lessons from a
Cross-Country Analysis" by Dieter Nautz and Ulrike Rondorf, April 2010. 024 "The optimal industry structure in a vertically related market" by
Raffaele Fiocco, April 2010. 025 "Herding of Institutional Traders" by Stephanie Kremer, April 2010. 026 "Non-Gaussian Component Analysis: New Ideas, New Proofs, New
Applications" by Vladimir Panov, May 2010. 027 "Liquidity and Capital Requirements and the Probability of Bank Failure"
by Philipp Johann Kˆnig, May 2010. 028 "Social Relationships and Trust" by Christine Binzel and Dietmar Fehr,
May 2010. 029 "Adaptive Interest Rate Modelling" by Mengmeng Guo and Wolfgang Karl
H‰rdle, May 2010. 030 "Can the New Keynesian Phillips Curve Explain Inflation Gap
Persistence?" by Fang Yao, June 2010. 031 "Modeling Asset Prices" by James E. Gentle and Wolfgang Karl H‰rdle,
June 2010. 032 "Learning Machines Supporting Bankruptcy Prediction" by Wolfgang Karl
H‰rdle, Rouslan Moro and Linda Hoffmann, June 2010. 033 "Sensitivity of risk measures with respect to the normal approximation
of total claim distributions" by Volker Kr‰tschmer and Henryk Z‰hle, June 2010. 034 "Sociodemographic, Economic, and Psychological Drivers of the Demand for Life Insurance: Evidence from the German Retirement Income Act" by Carolin Hecht and Katja Hanewald, July 2010. 035 "Efficiency and Equilibria in Games of Optimal Derivative Design" by Ulrich Horst and Santiago Moreno-Bromberg, July 2010.

