BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2014-037
Common price and volatility jumps in noisy
high-frequency data
Markus Bibinger* Lars Winkelmann**
* Humboldt-Universität zu Berlin, Germany ** Freie Universität Berlin, Germany
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universität zu Berlin Spandauer Straße 1, D-10178 Berlin

Common price and volatility jumps in noisy high-frequency data
Markus Bibingera Lars Winkelmannb
aDepartment of Mathematics, Humbold-Universita¨t Berlin bDepartment of Statistics and Econometrics, Freie Universita¨t Berlin
16.07.2014
Abstract
We introduce a statistical test for simultaneous jumps in the price of a financial asset and its volatility process. The proposed test is based on high-frequency tick-data and is robust to market microstructure frictions. To localize volatility jumps, we design and analyze a nonparametric spectral estimator of the spot volatility process. A simulation study and an empirical example with NASDAQ order book data demonstrate the practicability of the proposed methods and highlight the important role played by price volatility co-jumps.
Keywords: high-frequency data; microstructure noise; nonparametric volatility estimation; volatility jumps. JEL classification: E58, C14
1 Introduction
In recent years the broad availability of high-frequency intraday financial data has spurred a considerable collection of works dedicated to statistical modeling and inference for such data. Ito^ semimartingales constitute a prominent class of stochastic processes to describe dynamics of intraday log-prices. They comply with fundamental economic hypotheses as exclusion of arbitrage and provide a general and flexible class of processes allowing for stochastic volatility, jumps and leverage. Due to the market microstructure of most high-frequency financial data, as effects of transaction costs and bid-ask bounce, log-prices are not directly well fitted by semimartingales, but should be considered within a noisy observation setup as a suitable model. Taking microstructure frictions into account radically changes statistical properties and involved mathematical concepts of estimators. One core research topic in statistics, finance and econometrics of high-frequency data is inference on the (integrated) volatility, bringing forth the seminal contributions by Andersen and Bollerslev (1998),
Financial support from the Deutsche Forschungsgemeinschaft via SFB 649 `O¨ konomisches Risiko', HumboldtUniversita¨t zu Berlin, is gratefully acknowledged.
1

Andersen et al. (2001), Barndorff-Nielsen and Shephard (2002), A¨it-Sahalia et al. (2005) and much more literature devoted to this aspect. Reliable estimates of volatility are of key importance in the decision making process of portfolio and risk managers, see e.g. Andersen et al. (2007), as well as policy makers, see Dewachter et al. (2014). As the volatility takes a key role in the model, a prosperous research field strives to set up accurate stochastic volatility models, see Eraker et al. (2003) among others. Uncertainty and risk in the evolution of intraday prices is usually ascribed to two distinct sources: First, the volatility process of the continuous semimartingale part that permanently influences observed returns and, second, occasional jumps in prices. The latter reflect updates of markets' expectations in response to firm specific news, macro or monetary policy events. An important question, often left unaddressed in the literature, is if one should incorporate jumps also in the volatility process. First studies by Eraker (2004) and Tauchen and Todorov (2011) suggest to do so and highlight the important implications especially for asset pricing. A natural question arises, if prices and their volatilities jump at common times concertedly stimulated by the same events, or not.
This article offers a statistical test to decide whether intraday log-prices exhibit common price and volatility jumps. The main contribution is to complement the pioneering works by Jacod and Todorov (2010) and Bandi and Reno` (2013) and to provide an approach for an observation model that accounts for market microstructure in order to efficiently exploit information from high-frequency data. The methods particularly build upon the theory by Jacod and Todorov (2010), but smoothing out noise perturbations leads to materially different concepts and asymptotic results. The development of a test that can cope with noise is of high relevance and importance as Jacod and Todorov (2010) already remark in their empirical application that "presence of microstructure noise in the prices is nonnegligible" and "an extension of our tests, while building on the theoretical results here, asks for a significantly more involved mathematical approach which goes beyond the scope of the current paper and is thus left for future work". Jumps in prices and the volatility are of very different nature. Large price jumps are apparent and become visible through large returns. More precisely, in a high-frequency context truncation techniques as suggested by Mancini (2009), Lee and Mykland (2008) and Jacod (2008) can be used to identify returns that involve jumps. Up to some subtle changes due to dilution by microstructure, this remains valid also in the noisy setup, see A¨it-Sahalia et al. (2012) , Li (2013) and Bibinger and Winkelmann (2013) for an extended theory. Contrarily, volatility jumps are latent and not as obvious as price jumps due to the fact that we can not observe the volatility path. We thus infer on the latent volatility of an efficient log-price process from indirect observations of these efficient log-prices diluted by microstructure noise. Our key element to determine volatility jumps even so, will be reliable estimates of the instantaneous volatility from observed prices. Our approach relies on a spectral Fourier method stimulated by Reiß (2011) and Bibinger et al. (2014a) for estimating quadratic (co-)variation. These methods attain lower variance bounds for integrated volatility estimation from noisy observations and are, compared to simple smoothing methods and especially sparse sampling at lower frequency, much more efficient. Price jumps are recovered using
2

a truncation procedure which can be adapted to the local magnitude and intraday shape of volatility. With this estimation approach at hand, we construct a test, comparing estimated local volatilities and their left limits at the estimated jump times of the price. An asymptotic distribution free test with a fast convergence rate based on second order asymptotics of the estimator is suggested. While the overarching strategy follows Jacod and Todorov (2010), the specific test function and construction in the noisy observation case are crucially different. The test statistic is self-scaling in the local volatility which is possible by the simple variance structure of the spectral volatility estimates. Using different estimation techniques to smooth noise as realized kernels motivated by Barndorff-Nielsen et al. (2008), or pre-averaging by Jacod et al. (2009), such a construction, if possible at all, will be more cumbersome. The Monte Carlo study demonstrates the high precision of the methods in finite samples. Our data study shows that price volatility co-jumps occur and are practically relevant.
The rest of this paper is organized as follows. The upcoming Section 2 introduces the notation and technical setup and gives the assumptions imposed on the model. We also review the elements of spectral volatility estimation within Section 2. The main part is Section 3 where we first construct the local spot volatility estimators which then serve as one main ingredient for our tests derived hereafter. Practical guidance and a Monte Carlo analysis are pursued in Section 4. In Section 5 the methods are used to analyze price and volatility jumps in NASDAQ high-frequency intraday trading data, reconstructed from the order book. Section 6 concludes. Proofs are delegated to the Appendix.

2 Model, assumptions and background on spectral volatility estimation

2.1 Statistical model and assumptions

We suppose an underlying latent log-price process X follows an Ito^ semimartingale which is defined on a filtered probability space (, F, (Ft), P). Then, X is of the form

t t

t

Xt = X0 + bs ds +

cs dWs +

(s, x)1{|(s,x)|1}(µ - )(ds, dx)

00

0R

t

+ (s, x)1{|(s,x)|>1}µ(ds, dx) ,

0R

(1)

with W an (Ft)-adapted standard Brownian motion, µ a Poisson random measure on R+ × R with R+ = [0, ) and an intensity measure (predictable compensator of µ) of the form (ds, dx) = (dx)  ds for a given -finite measure . Regularity assumptions on the drift process bs, the squared volatility process cs, and the predictable function  are gathered in Assumption (H-r) below. We consider discrete observation times i/n, i = 0, . . . , n, on the time span [0, 1]. For financial data this corresponds to a tick-time clock. A transfer between tick and non-equispaced calendar-time sampling in case that the latter obeys some mild regularity restrictions is routine and discussed in Bibinger et al. (2014a). As shown there, locally different observation frequencies may be treated as locally varying noise variance, where having locally less frequent observations corresponds to

3

a locally increased noise variance. Since the mapping between both schemes does not affect our methods and only leads to a slight modification of the variances of non-normalized statistics, we stick to the first setting. The prevalent model capturing market microstructure effects which interfere the evolution of an underlying semimartingale log-price process at high frequencies is an indirect observation model with observational errors:

Yi = Xi/n + i , i = 0, . . . , n .

(2)

Regularity conditions on the price and volatility process are stated in the following structural hypothesis.

Assumption (H-r). We assume that sup,x |(t, x)|/(x) is locally bounded for a non-negative de-

terministic function  satisfying R(r(x)  1)(dx) < . The drift bt is locally bounded and almost

surely t, s 

Ho¨lder continuous with some [0, 1]. The volatility process

order t =

> 
ct

0, is

i.e. |bt - bs|  L|t - s| for some L < ca`dla`g and neither t nor t- vanish.

 and all The noise

( i)1in is a discrete-time process, independent of X, and has finite eighth moments and a constant

noise level

m

 = Cov( i, i+l) , i  {m, . . . , n - m},

l=-m

with Cov( i, i+l) = 0, for all l > 2m, m  N finite and fixed. When Cov( i, i+l) = 0 for all l = 0 we set  = Var( i). Necessarily  is non-negative and we impose  > 0. This includes, but is not limited to, the classical i.i.d. modeling.

For the volatility process, our target of inference, we consider the following very general and

flexible smoothness condition with smoothness parameter   (0, 1].

 Assumption (-). The process t = ct satisfies t = f

Zt(1), Zt(2)

with some function f : R2 

R, continuously differentiable in both coordinates, and two (Ft)-adapted processes Z(1), Z(2), where

· Z(1) is an Ito^ semimartingale:

tt

t

Zt(1) = 0 + ~bs ds +

c~1s dWs +

c~2s dWs

00

0

(3)

tt

+ ~(s, x)1{|~(s,x)|1}(µ~ - ~)(ds, dx) + ~(s, x)1{|~(s,x)|>1}µ~(ds, dx) ,

0R

0R

with an (Ft)-Brownian motion W independent of W and a random variable 0, satisfying (H2) for   1/2. For  > 1/2 the continuous martingale part of Z(1) vanishes and Z(1) satisfies (H--1).

· Z(2) lies in a Ho¨lder ball of order  almost surely, i.e. Zt(2) - Zs(2)  L|t - s|, for all t, s  [0, 1] and a random variable L for which at least fourth moments exist.

4

The smaller  the less restrictive is Assumption (-). It is natural to develop results for general   (0, 1] to cover a broad framework and preserve some freedom in the model. This is particularly important, since the precision of nonparametrically estimating a process (or function) foremost hinges on its smoothness. The composition of the volatility as proposed by Assumption (-) allows to incorporate recent volatility models and to realistically describe spot volatility dynamics. For instance, Z(2) can portray a non-random volatility seasonality function while Z(1) models a random fluctuation around Z(2).

2.2 Spectral volatility estimation in a nutshell

Consider the sine basis

jk(t) =

j 2hnn sin 2nhn

-1
sin jh-n 1 (t - khn) 1[khn,(k+1)hn](t) ,

(4)

of L2-orthogonal functions (jk)1jJn for spectral frequencies 1  j  Jn in the Fourier domain up to a spectral cut-off Jn  nhn. The indicator functions localize the sine functions to bins k = 0, . . . , h-n 1 - 1 of a sequence of equispaced partitions of the considered time span [0, 1]. One key idea of spectral volatility estimation is to perform optimal parametric estimation procedures localized on the bins. These localized estimates provide the fundament to build estimators for the instantaneous and the integrated squared volatility. For this purpose, as has been introduced in Reiß (2011), local linear combinations of the noisy data are used with local weights obtained by evaluating the functions (4) on the discrete grid of observation times i/n, i = 0, . . . , n. This strategy corresponds to performing a discrete sine transformation on the observed returns, similarly as proposed in Curci and Corsi (2012), but localized over all bins. We use the notion of empirical scalar products and norms for functions f, g as follows:

1n f, g n := n f

l g
n

l n

and

f

2 n

:=

1 n

n

f2

l n

= f, f n .

l=1 l=1

The empirical norms of the sine functions above give for all bins k = 0, . . . , h-n 1 - 1:

jk

2 n

=

4n2 sin2 (j/(2nhn)) -1 ,

(5) (6)

and we have the discrete orthogonality relations

jk, rk n =

jk

2 n

jr

,

j, r  {1, . . . , nhn} , k = 0, . . . , h-n 1 - 1 ,

(7)

5

where jr = 1{j=r} is Kronecker's delta.
The central building blocks of spectral volatility estimation are the spectral statistics

Sjk =

jk

-1 n

n

inY jk

i n

j = 1, . . . , Jn, k = 0, . . . , h-n 1 - 1 ,

i=1

(8)

in which observed returns ni Y = Yi/n - Y(i-1)/n, i = 1, . . . , n, are smoothed by bin-wise linear combinations with weights from the local discrete sine transformations. In absence of price jumps, bin-wise estimates for the squared volatility ckhn, k = 0, . . . , hn-1 - 1, are provided by weighted sums of bias-corrected squared spectral statistics:

Jn

kad(Y ) =

w^jk

Sj2k -

jk

-2 ^ nn

.

j=1

(9)

The integrated volatility estimator of Bibinger et al. (2014a) is simply the average

h-n 1-1 k=0

hn

kad(Y

).

Our notation allows to distinguish the fully adaptive estimates from the ones with the oracle optimal

weights by writing kad(Y ) and k(Y ), respectively. The oracle optimal weights

wjk = Ik-1Ijk =

ckhn +

jk

-2  nn

-2

Jn m=1

ckhn +

mk

-2  nn

-2 ,

(10)

with Ik =

Jn j=1

Ijk

,

Ij

k

=

1 2

(ckhn

+

jk|-2/n)-2, follow from minimization of the variance

under the constraint of unbiasedness. For a fully adaptive approach we apply a two-stage method

as presented in Section 3.1 below. We will, furthermore, use the notation kad(Z) and k(Z), for

different processes Z, meaning that we insert in (9) spectral statistics (8) computed from the sequence

Zi/n, i = 0, . . . , n, especially kad(X) for the statistics based on the unobserved signal.

The noise level is estimated from the observations. If the noise is i.i.d., we may use

1n ^ =
2n

inY 2 =  + OP n-1/2 ,

i=1

as suggested and analyzed in Zhang et al. (2005). In case of non-zero autocorrelations in the noise,
the estimation based on the empirical autocovariances of the returns is more elaborate. As described in Bibinger et al. (2014b) we still have ^ =  + OP n-1/2 in this case.

Remark 1. Note that spectral statistics have a close relation to pre-averages as used by Jacod et al. (2009). A main difference is that bins are fixed here as for histograms and bin-wise we smooth noisy observations in the Fourier domain by taking linear combinations on each bin along different spectral frequencies 1  j  Jn. It is of pivotal importance that the statistics (8) de-correlate the data
available soon

6

for different frequencies and form their local principal components. This is key to the asymptotic efficiency attained by the spectral estimators as shown in Reiß (2011) and Bibinger et al. (2014a). The latter means that the estimator's asymptotic variance coincides with the minimum asymptotic variance among all asymptotically unbiased estimators. The efficiency theory is so far restricted to models with deterministic volatility, without drift and Gaussian noise and it is conjectured that the analogous asymptotic variance, which is determined in Altmeyer and Bibinger (2014) for the general model, constitutes the general lower bound.

3 Testing for price and volatility co-jumps

3.1 Spot squared volatility estimators

In this subsection we show that the methods considered in Section 2 are eligible to estimate the in-
stantaneous squared volatility ct, t  [0, 1], and its left limit ct- = lims0 ct-s.
The spectral volatility estimation methodology intrinsically provides local estimates (9) for the squared
volatility ckhn, k = 0, . . . , hn-1 - 1. However, we should not rely on kad(Y 1) [khn,(k+1)hn](t) on [0, 1]
directly as an estimator for (ct)t[0,1] because it will not be consistent as the variance does not decrease when n gets large. Instead, we employ a smoothing method, as typical for function estimation
in nonparametric statistics. For this reason, to estimate cs at some fix time s, consider a local window around s of length (rn-1hn)  0 as n  , slowly enough to ensure rn-1  . In the presence of jumps in (1), truncation disentangles bin-wise statistics (9) which involve jumps from all others. In particular if hn|kad(Y )| > un for a threshold sequence un = c hn ,   (0, 1) with some constant c, the quadratic variation increment is of a magnitude that can not come from the continuous part and is evoked by a jump. In order to estimate the volatility, we truncate kad(Y ) for these k. For a simple notation suppose nhn  N and rn-1  N, such that on each bin we enclose nhn noisy observations and on each window we enclose rn-1 bins. In order to estimate the squared volatility and its left limit at a certain time s, we choose two disjoint windows located to the right and to the left of s, respectively.
In particular the window is not centered around s. Since the optimal weights (10) per se hinge on the
unknown squared volatility, we proceed with a two-step estimation approach. First, select a pilot spectral cut-off Jnpi nhn, and build pilot estimators for the squared volatility

sh-n 1 +rn-1

Jnpi

right-hand side: c^rsn,pilot(Y ) =

rn

(Jnpi)-1 Sj2k -

jk

-2 ^ nn

k= sh-n 1 +1 j=1

(11a)

×1 hn

Jnpi j=1

(Jnpi

)-1

Sj2k -

jk

-2 ^ nn

un

,

left-hand side:

c^rsn-,pilot(Y ) =

sh-n 1 -1

Jnpi
rn (Jnpi)-1 Sj2k -

k= shn-1 -rn-1 j=1

jk

-2 ^ nn

7

(11b)

×1 hn

Jnpi j=1

(Jnpi

)-1

Sj2k -

jk

-2 ^ nn

un

,

for s  [rn-1hn, 1 - rn-1hn). At the borders we shrink one window length accordingly. The pilot estimators are hence averages over rn-1 bins and Jnpi spectral frequencies. In the second step, these pilot estimators are plugged in (10) to determine the adaptive weights for the final estimators. With
those at hand, we can evaluate the spectral estimators of the squared instantaneous volatility at time s
and its left limit:

right-hand side:

shn-1 +rn-1

Jn

c^srn (Y ) =

rn w^jk Sj2k -

k= shn-1 +1 j=1

1jk

-2 ^ nn

{hn|kad(Y )|un} ,

(12a)

left-hand side:

c^srn-(Y ) =

sh-n 1 -1

Jn
rn w^jk Sj2k -

k= sh-n 1 -rn-1 j=1

1jk

-2 ^ nn

{hn|kad(Y )|un} ,

(12b)

for s  [rn-1hn, 1-rn-1hn). Estimates (12a) and (12b) are thus local averages of the truncated bin-wise statistics (9). This nonparametric spot volatility estimation is closely related to a usual kernel density estimator when the statistics (9) take the role of de-noised observations which are smoothed over local windows. The approach entails several tuning parameters whose practical choice is discussed below in Section 4. If the aim is to obtain a nonparametric spot squared volatility estimator, one can take ((c^rsn(Y ) + c^rsn-(Y ))/2)s[0,1] as an estimator. This estimator is a hybrid approach combining the spectral volatility estimation with truncation as considered in Bibinger and Winkelmann (2013) for integrated covariances.
For our test derived in the next subsection, starting from times where jumps of X are identified via thresholding we will estimate the volatility before and after these jump times. Moreover, inference for any model incorporating joint price-volatility jumps relies on this estimation technique. At this stage, let us state our first main result on the spot squared volatility estimators and their asymptotic distribution.

Theorem 1. Suppose the structural hypothesis (H-r) with some r < 2 and smoothness Assumption
(-),   (0, 1]. Fix a time s  (0, 1), at which we want to estimate cs and cs- via (12a) and (12b), respectively. Set hn = 1n-1/2 log(n) and rn = 2n- log(n) with constants 1, 2 and Jn   as n  . Then, as n   and if

0< <    1- r ,

2 + 1

2

(13)

with  the truncation exponent in the sequence un in (11a), (11b), (12a) and (12b), the estimators

8

satisfy the stable central limit theorems: n/2 c^srn - cs -(st) M N 0, 8cs3/21/2 ,

(14a)

n/2 c^srn- - cs- -(st) M N 0, 8cs3/-21/2 .

(14b)

Most interesting is the case when   1/2. In this case, for r < 3/2 in Assumption (H-r), we can choose  = 1/4 -  for any  > 0. In fact, we can almost grasp the optimal rate for estimation which is n1/8 in this case. Balancing bias and variance for  = 1/4 guarantees that the estimators (12a) and (12b) attain this rate. For a central limit theorem we avoid an asymptotic bias by slightly undersmoothing. In case that  > 1/2 we obtain faster convergence rates. We point out that the restriction r < 3/2 on the jump activity, to come close to the optimal convergence rate, is less restrictive than the one obtained for integrated squared volatility estimation, r < 1, see Bibinger and Winkelmann (2013). The limit variables in (14a) and (14b) are mixed normal which we denote by M N and defined on a product space of the original probability space (on which X is defined) and an orthogonal space independent of F and the noise. The convergence is stable in law, marked (st), a stronger mode of weak convergence which is equivalent to joint weak convergence with every F-measurable bounded random variable. We refer to Jacod (2012) for background information on this typical kind of limit theorems arising in volatility estimation. Stability of weak convergence then allows for a so-called feasible version of the limit theorem (14a):

rn-1/2I^1/s2h-n 1 +1 c^srn - cs -d N (0, 1) ,

(15)

with I^ shn-1 +1 the estimate of I sh-n 1 +1, as defined in the weights (10), obtained by inserting the pilot estimator and ^ under the conditions of Theorem 1, but also for any Jn fixed as n  . This works analogously for (14b) for which we self-normalize with I^1/s2h-n 1 -1 instead. This feasible limit theorem directly allows for confidence sets of estimates in practice. The estimators developed in this section
provide a main building block for our test constructed below, but are moreover of interest of their own
as efficient spot squared volatility estimators in presence of (possible) volatility-price co-jumps.

3.2 The test for common price and volatility jumps
Let (Sp)p1 be a sequence of stopping times exhausting the jumps of X. We concentrate on the following hypothesis: No common jump of volatility and price on [0, 1]:

H[0,1] :

(cSp - cSp-) = 0 ,

Sp1

(16)

9

against the alternative that there is at least one jump in the volatility at a jump-time of X. The test
(16) investigates if price and volatility co-jumps occur. We specify the test hypothesis more precisely by focusing on jumps of X with absolute values |XSp| > a for a  0 and call this H(a)[0,1]. The reason for this is that a suitable test statistic and associated limit theory for H(a)[0,1] with a > 0 works under a much more general setup with jumps of infinite variation while testing H(0)[0,1] requires Assumption (H-0) to hold. In both cases, we concentrate only on a finite number of jumps of X on
[0, 1] in the hypothesis. This specification is also reasonable from an applied point of view, since we
are interested in testing for volatility movements at finitely many price jumps associated with news
that initiate updates of market participants' expectations. Note that Jacod and Todorov (2010) restrict
hypotheses in the same fashion for the theory without noise. In the sequel consider 1, . . . , Nt, a finite collection of jump times of X on [0, t], t  [0, 1], with |Xi| > a for all i. Denote by g : R2+  R a test function with g(x, x) = 0 for all x. Let us now state the general form of our test statistics:

hn-1 -rn-1 -1

T0(hn, rn, g) =

k=rn-1

1g c^rknhn , c^krnhn-

hn|kad(Y )|> (una2)

.

(17)

Under some mild regularity assumptions on g in terms of differentiability in both coordinates limit theorems for (17) can be proved. We mainly concentrate on testing H(a)[0,1] and consider two specific test functions in the following. Adjustments of the test (16) for sub-intervals of [0, 1] are readily obtained by ignoring all jumps elsewhere.

Theorem 2. Assume (H-r), r < 2, and insert estimates from (12a) and (12b) with hn = 1n-1/2 log n, rn = 2n- log n, where 0 <  < (2 + 1)-1   (1 - r/2) , Jn  , in (17) with the test
function

g(x1, x2) = 2

x1

+ 2

x2

-

 x1

-

 x2

.

(18)

Under H(a)[0,1], if either a > 0 and we impose the condition that the Le´vy measure of X does not have an atom in {a}, or r = 0, the following asymptotic distribution of the test statistics applies:

n^-1/2 T0(hn, rn, g) -d N2 1 .

(19)

Therefore, we obtain an asymptotic distribution free test by the asymptotic 2-distribution with N1

degrees of freedom. On the alternative  \ H(a)[0,1] , T0(hn, rn, g) -P

N1 i=1

g(ci

,

ci-),

and

the

left-hand side in (19) is hence of order n. The test with critical regions

Cn = n^-1/2 T0(hn, rn, g) > q(2N1 )} ,

(20)

where q(2N1) denotes the -quantile of the 2N1-distribution, has asymptotic level  and asymptotic power 1.

10

The result is valid when we instead of the unobserved number of jumps with absolute value larger than a insert the estimated number of jumps via thresholding. A naive approach based on the asymptotic normality results (14a) and (14b) with test function g~(x1, x2) = (x1 - x2) yields as well an asymptotic distribution free test:

rn-1/2

N1
2 I^-h1n-1i +1
i=1

-1/2
T0(hn, rn, g~) -d N (0, 1) ,

(21)

on the hypothesis H(a)[0,1]. Apparently, by the slower rate n/2, close to n1/8 for   1/2, compared to (19) the above test in Theorem 2 is preferable. Here it is particularly beneficial that the convergence rate in (19) is much faster than in (14a) based on second-order asymptotics. For instance, if   1/2, we come close to a n1/4 rate. We can also consider the following kind of hypotheses with the same methods in a multiple testing framework. Not all jumps of the price are accompanied by volatility jumps:

HSp with HSp : (cSp - cSp-) = 0 ,
p1

(22)

against alternative that there is each time a jump in the volatility for any jump-time of X. The test
(22) helps to discriminate events that induce simultaneous jumps in price and volatility from events
that only lead to price jumps and have no influence on the volatility. For the construction of a test procedure we consider a finite set of N^1 statistics by g(c^i, c^i-) i = {g(c^rknhn, c^rknhn-); k  {0, . . . , h-n 1 - 1} with hn|kad(Y )| > un  a2}, namely with i, i = 1, . . . , N^1, exhausting the estimated jumps in X.

Corollary 3.1. On the assumptions of Theorem 2, we obtain with the test function (18) for all i = 1, . . . , N^1:

n^-1/2 g(c^i , c^i-) -d 12 ,

(23)

i.e. an asymptotic 2-distribution with one degree of freedom. The multiple test with critical regions

Cn,i = n ^-1/2 g(c^i , c^i-) > q1-(1-)1/N^1 (21)} ,

(24)

for all i = 1, . . . , N^1, where q(12) denotes the -quantile of the 21-distribution, controls the asymptotic level  for the familywise error rate.

We use the S ida´k correction for the critical regions, since the single tests are almost surely asymp-
totically independent. Other concepts of multiple testing theory can be used, but note that contrarily to usual multiple comparisons in our setup N^1 will be typically rather small.

11

4 Implementation and numerical study
4.1 Practical guidance
In the sequel, we provide some information and advice on practical aspects for applying the methods from Section 3. In the two-step squared volatility estimation procedure some tuning parameters are involved which have to be specified in practice. In the upcoming discussion we point out that only few crucially effect the overall performance and give instructions how to fix parameters. We address the parameters in order of appearance when implementing the method. The bin-width hn n-1/2 log n balances the number of observations on bins nhn, which should be large enough to smooth out noise, and the discretization error of the local parametric model. Consequently, the smoother the underlying volatility process the smaller the discretization error which allows to involve larger bins. On the other hand, the lower the noise level the smaller the bins can be chosen. The bin-width also influences the frontiers in disentangling small jumps from continuous motion. Smaller bins allow to detect smaller jumps. For this reason we do not give a universal rule to fix the proportionality constant for hn, as the scope of the study and stylized facts of the data should be taken into account. Also, it is possible to employ locally different bin widths, for instance, if the volatility is supposed to be higher at opening we may take smaller bins for a first time period and larger ones for a later period. Within a reasonable range the estimator is quite robust to modifications of hn. We advise to select hn such that the number of observations on bins is ca. 100 for typical signalto-noise ratios and at most 1000 when high noise pollution is indicated. This results in ca. 30-100 bins per trading day. It is important that different choices of hn do not cause any finite-sample bias. Note that the local adaptivity of the method is driven by the adapted weights in the spectral domain and not the bin-width. For the local parametric squared volatility estimation with (12a) and (12b) and the pre-estimation step with (11a) and (11b), we choose spectral cut-offs Jn and Jnpi, respectively. For the oracle spectral estimator, the highest possible cut-off Jn = nhn - 1 provides maximal information. Since the weights (10) decay exponentially for j nhn log n, the addends with j large become negligible. Taking also computational efficiency into account, it suffices to choose Jn log n. The proportionality constant should be larger than 1, we take values between 3 and 12, a larger factor for large sample sizes, but as long as Jn log n, higher cut-offs can only slightly increase the performance. The pilot estimator relies on an average over frequencies j = 1, . . . , Jnpi. Constant weights are a good proxy for the oracle weights up to a moderately small Jnpi (not larger than logarithmic in n). We thus use here Jnpi log n with proportionality factor smaller than for Jn. The crucial difference in the choice of Jnpi compared to Jn is that if Jnpi will be chosen much larger the efficiency of the pilot estimator does not increase, contrarily it becomes less accurate. The threshold un on local quadratic variation estimates kad(Y ), k = 1, . . . , h-n 1 from (9) disentangles the ones which are ascribed to jumps from all others. For the asymptotic theory un hn works with any   (0, 1). Since in absence of jumps local estimates kad(Y ) are of order hn and the maximum
12

over all bins of order 2 log (hn-1)hn, a simple global truncation rule is to set un = hn2 log (hn-1). This threshold is used below for the pre-estimation step of our two-stage method. We incorporate in the finite-sample setup also the magnitude and intraday shape of volatilities. The mean of kad(Y ) is ckhnhn in absence of jumps and based on the pre-estimation step we employ in the second step a time-varying adaptive truncation methodology, see Bibinger and Winkelmann (2013) for a thorough
introduction. Since this truncation principle detects a finite collection of estimated jump times we do
not consider some additional a > 0 in (17). When one is interested in jumps above a certain level
only, this can be done by setting a > 0 in the test statistic.
The most influential tuning parameter for the estimators (12a) and (12b) is the smoothing window rn n- log n. If we choose rn larger, the final estimates become smoother. To cope with edge effects, we take for the first and last rn-1 bins estimates at time t which rely only on the bins on [0, t] and [t, 1], respectively. In simulations below, we first use a large rn-1 in a constant volatility setting. In the complex simulation study and the empirical example, we take rn-1 rather small instead. Note that we conduct local averaging of the parametric bin-wise estimates and one could as well use a kernel
filter ­ however the effects are rather small.

4.2 Monte Carlo study

This Monte Carlo study examines the finite-sample performance of the proposed methods in two implemented models:

ii

· Yi/n =

n
dBt +

n

xµ(dt, dx) + i ,

0 0R

with compensator (dt, dx) = dt (dx) and  the measure of a normal distribution  

N (H, H/100), such that H acts as parameter to trigger the average size of jumps, i iid

N (0, 2) and B a standard Brownian motion. Here we examine the test statistic under the

hypothesis of no common jumps and for a constant volatility, in particular without any volatil-

ity jumps.

ii

· Yi/n =

n t ct dBt +

n

xµ(dt, dx, dy) + i ,

0 0R

with (dt, dx, dy) =  dt (dx)(dy) where again   N (H, H/100), i iid

N (0, 2

1 0

t4

ct2)1/4

.

The jump measure has a second real argument to incorporate instanta-

neous arrivals of volatility jumps. t is a model for a deterministic volatility seasonality motion:

t

=

1

-

3 5

t1/2

+

1 10

t2,

and

ct

a

random

stochastic

volatility

fluctuation

including

leverage:

dct = 6(1 - ct) dt + ctdB~t + dJt .

B and B~ are two standard Brownian motions with d[B, B~]t =  dt and we fix  = 0.2. The

13

Table 1: Parameter specification for Monte Carlo.

Scenario n  H  hn-1 J J pi rn-1 in (12a) rn-1 in (11a)

I 300000 1 0.25 0.001 300 50 25

100

10

II 30000 2 0.25 0.005 60 40 25

3

5

III 30000 2 0.25 0.05 60 40 25

3

5

IV 30000 2 0.05 0.005 60 40 25

3

5

V 5000 2 0.25 0.005 10 30 20

3

3

VI 5000 2 0.25 0.05 10 30 20

3

3

VII 5000 2 0.05 0.005 10 30 20

3

3

VIII 30000 2 0.25 0.005 60 40 25

3

5

IX 5000 2 0.25 0.005 10 30 20

3

3

volatility jump component is of the form

tt

Jt = 

yµ(dt, dx, dy) +

zµ~(dt, dz)

0R

0R

with a  R and ~(dt, dz) = dt (dz) again.

We consider the first constant volatility model with n = 300000 observations as idealized setup in scenario I to investigate the accuracy of our asymptotic results. The second model serves as more realistic setting to mimic dynamics of typical financial high-frequency data. We consider scenarios II-VII setting  = 0 above, which means the hypothesis is valid. Two scenarios VIII and IX are simulated under the alternative with  = 1. In scenario IX we modify the jump measure of the volatility slightly by having with probability 1/2 no jump and with 1/2 normally distributed jumps as above. The parameter configurations used in the Monte Carlo study for different scenarios are summarized in Table 1. The window lengths rn-1 for (12b) and (11b) are set equal to the ones for (12a) and (11a). We take smoothing window widths in (12a) rather large for the constant volatility case and use quite small windows in the stochastic volatility setup.

The results of the Monte Carlo study of scenario I are illustrated in Figures 1 and 2 by comparisons of the empirical Monte Carlo distribution of test statistics under H[0,1] and the theoretical asymptotic distribution. For these illustrations, we have selected 1000 runs with each of them having realized N1 = 1 jumps in X and compare to a 12 distribution. Left-hand the plots for the test from Theorem 2 and an asymptotic 12-distribution are depicted, right-hand for the test from (21) and an asymptotic normal distribution. The density estimates and the QQ-plots for the test from Theorem 2 demonstrate that the empirical statistics are well-predicted by our asymptotic distribution theory. Most importantly the large percentiles very closely track their theoretical counterparts what guarantees the accuracy of the decision method. For the naive decision rule relying on the asymptotics of the spot estimators in (21), the empirical quantities also fit the asymptotic distribution remarkably well even though the rate of convergence is very slow. Only the tails are a bit heavier than Gaussian in our realizations.

14

Figure 1: Empirical distributions of normalized test statistics of 1000 runs in scenario I for the test from Theorem 2 (left-hand) and the test from (21) (right-hand). The plots display histograms and kernel density estimates (solid lines), based on the standard R setup with Silverman's bandwidth selection rule of thumb, and the theoretical asymptotic 12 and standard Gaussian densities (dashed lines).
Figure 2: QQ-plots of MC results in scenario I for Theorem 2 (left-hand) and the test from (21) (right-hand). Let us proceed with the more relevant setup of the stochastic volatility model and scenarios II-VII under the hypothesis and scenarios VIII and IX when the alternative is true. Although we may report
15

Scenario II

Scenario III

Scenario IV

Scenario VIII

Scenario V

Scenario VI

Scenario VII

Scenario IX

Figure 3: Empirical size and power of test in Monte Carlo for iterations with one jump in realized path. Nominal level on x-axis (shows percentiles of theoretical asymptotic distribution) against empirical amount of realizations smaller or equal those percentiles (y-axis). Number of observations is n = 30000 for scenarios II-IV, VIII, upper line, n = 5000 for scenarios V-VII, IX, bottom line. Right column, scenarios VIII and IX under alternative, others under hypothesis.
from our simulations that the naive test from (21) still gives reasonable results, we shall concentrate now on our proposed test from Theorem 2. In scenario II we consider a setup which mimics a realistic situation. The volatility process inherits a very wiggly continuous semimartingale random component and the sample size n = 30000 is ca. the number of trades over one single day for typical highfrequency traded assets (testing intervals we have in mind are one day or longer periods). The signalto-noise ratio is relatively large. The jump sizes are rather large compared to continuous increments which makes the detection via truncation quite precise, also in the presence of high noise dilution. This also reflects a typical real data situation where we focus on relevant price adjustments.
Scenarios III-VII aggravate different difficulties of the setting to analyze the method's reaction. In scenarios V-VII we reduce the sample size to n = 5000, while in scenarios IV and VII we have smaller average jump sizes and in scenarios III and VI a tremendously high noise variance. Scenarios VIII and IX are counterparts to scenarios II and V when the alternative holds true. Results from 2000 Monte Carlo iterations for the ones with one realized jump in X which is recovered by truncation are shown in Figures 3 and 4. Figure 3 visualizes the empirical size and power of the test by plotting percentiles against theoretical asymptotical ones for all considered scenarios. Figure 4 gives density estimates of rescaled test statistics. Results for a different number of realized jumps look very similarly for those with enough realizations. Altogether, the test in Theorem 2 performs
16

Scenario II

Scenario III

Scenario IV

Scenario VIII

Scenario V

Scenario VI

Scenario VII

Scenario IX

Figure 4: Kernel density estimates of empirical distributions from Monte Carlo of standardized test statistics from Theorem 2 rescaled with realized number of jumps N1-1.
very satisfactorily in practice. For the realistic scenario 2 the theoretical asymptotic distribution still explains very well the empirical outcomes. In case of very noisy data the plots for scenarios III and VI reveal a slight under-rejection of the test. For scenarios IV and VII the depicted graph looks a bit wobbly what is explained by the fact that the number of detected jumps by truncation decreases here such that the fit by the realizations gets less accurate. The power realized in scenario VIII is very good, in scenario IX we can not achieve a power close to one, but still reasonable power is attained.
5 Data study
To provide evidence about the practical relevance of price-volatility co-jumps and to study the performance of our estimators and test in a real-world data environment, we apply our methodology to stocks traded at the exchange platform NASDAQ. The data study is based on limit order book data taken from the online data tool LOBSTER. The example refers to stocks of the online and technology companies Amazon.com Inc. (AMZN), Apple Inc. (AAPL), Facebook Inc. (FB), Intel Corp. (INTC) and Microsoft Corp. (MSFT). We focus on transaction prices of 252 trading days in the year 2013. A trading day spans from 9:30 to 16:00 EDT and includes for a single stock a minimum of 4,267 (AMZN 2013-07-03) up to a maximum of 210,812 (FB 2013-10-31) transactions. One benefit of our estimator and test is that we can directly plug-in traded log-prices, reconstructed from the order
LOBSTER academic data- LOBSTER.wiwi.hu-berlin.de, powered by NASDAQ OMX
17

Table 2: Testing for disjoint price and volatility jumps in NASDAQ order book data.

Stocks
Amazon.com Inc. Apple Inc. Facebook Inc. Intel Corp. Microsoft Corp.

% days with price jumps

Rejection rate (common jumps)

 = 5%  = 10%

9.13% 7.94% 11.5% 46.8% 23.8%

60.87% 75.0% 51.7% 36.4% 40.0%

60.87% 80.0% 58.6% 47.8% 53.3%

Sample Averages
(whole year) n I^V

10,924 36,947 41,354 18,535 28,052

1.33 × 10-4 1.19 × 10-4 2.55 × 10-4 6.52 × 10-5 9.89 × 10-5

Notes: Estimation and Test executed for each day separately. n indicates the number of observed trades per trading day, I^V the spectral estimate of the integrated squared volatility. Sample period from 2nd Jan. 2013
until 31st Dec. 2013 (252 days).

book, without considering any skip-sampling or synchronization procedures. Since the method is robust against market microstructure noise and non-regular spaced observations, we efficiently take into account all information stored in the data.
To highlight characteristics of the price processes across the five stocks, we fix the bin-width h of our estimators for all stocks at the same values. Estimates and tests refer to spectral statistics calculated for h-1 = 39 bins, i.e. one trading day is partitioned into 10 minutes intervals. On each 10 minute interval de-noised variation estimates are determined from all available information on the interval using the spectral smoothing methodology. This allows for high efficiency gains compared to simple smoothing techniques as using returns sampled at lower frequency. For the present examples, results are found to be very robust when further shrinking bin-width towards 5 minutes. Therefore, and to keep the example tractable, we do not adjust the bind-width based on the number of particular observations n for each asset and day. We include J = 30, Jpi = 15 spectral frequencies in (11a), (11b), (12a) and (12b). Jumps in prices are detected by the locally adaptive threshold u^k = 2 log(h-1)h^k2, with ^k2 the pilot estimator of the spot squared volatility. We fix the window lengths to r-1 = 6 neighbored bins. The test of jumps in volatility then refers to a two hour interval around a detected jump in prices. Thus, we evaluate the squared spot volatility and its left limit by comparing the volatility one hour before the occurrence of the price jump with the volatility one hour after the price jump. Surely r-1 determines a crucial parameter which can be studied to learn about the persistence or live-time of a break in spot volatility. We apply the test to each day separately. Thereby, we do not focus on overnight price and volatility movements which are systematically present. Price and volatility co-jumps are detected in a 10:30 to 15:00 EDT interval as the considered trading period is 9:30 to 16:00 EDT. This includes in particular arrivals of important news announcements, for instance unemployment rates and news reports by the companies which can evoke jumps. Open and closing period with systematically elevated volatilities at the beginning and end of a trading day are excluded in our
18

Apple Inc. 2013-08-13 495
Transaction price (USD)
490
485
480

Apple Inc. 2013-05-14 456
454
452
450
448

446 475

470 9:30 10:00 10:30 11:00 11:30 12:00 12:30 13:00 13:30 14:00 14:30 15:00 15:30 16:00

444 442
9:30 10:00 10:30 11:00 11:30 12:00 12:30 13:00 13:30 14:00 14:30 15:00 15:30 16:00

10-2
Incrementfinfquadraticfvariantion Thresholdf(un)ftofdetectfpricefjump Leftfandfrightfspotfsquaredfvolatilityfatfpricefjump

10-2

10-3

10-3

10-4

10-4

10-5 0

10-5

5 10 15 20 25 30 35 40

0

5 10 15 20 25 30 35 40

Figure 5: Examples of common price and volatility jumps. Upper figures indicate price processes
as functions of trading hours. Lower figures display the related spectral statistics on 39 10 minute partitions of the trading day. 2013-08-13: n = 87445, estimated quadratic variation Q^V = 3.5×10-4, estimated integrated volatility I^V = 6.05 × 10-5. 2013-05-14: n = 40707, Q^V = 2.29 × 10-4, I^V = 5.86 × 10-5.

analysis. We also need a strategy to deal with situations when price jumps occur with less than two hours in between. However, for the current example this turned out to be of minor relevance as we do not find many days where this is the case. We propose to group several succeeding jumps together and analyze if one volatility jump has occurred by looking at windows left and right of the series of jumps.
Table 2 reports the rejection rates for the 5% and 10% significance levels. Results indicate that on a 5% significance level 36% (INTC) up to 75% (AAPL) of jumps in prices are accompanied by jumps in volatility. For Amazon we find 14 price-volatility jumps with respect to the 5% and identically with respect to the 10% significance level. In comparison with detected price jumps, it appears that the rejection rate decreases in the percentage of price jumps. This leads to relatively stable frequencies of price volatility co-jumps over time across the considered stocks. Referring again to the 5% significance level, the Apple stock price displays with around 6% of the trading days the
19

lowest frequency of common price and volatility jumps. With around 17% of trading days Intel has the largest number of common jumps.
Figure 5 illustrates the mechanisms behind the test for common price and volatility jumps. Left hand plots show an upward jump in prices (bin k = 30), whereas right hand plots show a downward jump in prices (bin k = 27). Both price jumps are associated with a significant contemporaneous upward jump in spot volatility ­ indicated by the black horizontal lines. The p-value in both examples chases 0.00. On the first example date 08/13/2013 Carl Icahn has taken a large stake of AAPL stocks. On May 14th, the downward jump example date, figures of mobile phone sales have been reported. We find evidence for frequent occurrences of simultaneous jumps in price and volatility. Yet, by far not all detected price jumps are accompanied by volatility jumps. Even large adjustments can take place without influencing the volatility much. For instance, on January 28th we find one jump for INTC and the p-value of the test is ca. 0.4. That day Intel Corp. announced that its board promoted five corporate officers and elected three new corporate vice presidents. On 23rd July, when Intel revealed information on forthcoming Atom processors C2000, we detect one price jump for INTC and a pvalue of ca. 0.98 which indicates no contemporaneous volatility jump. We find similar examples for several days and all considered stocks.
6 Conclusion
We present a new test for the presence of contemporaneous jumps of price and volatility based on high-frequency data. The test transfers the methodology of Jacod and Todorov (2010) to a setup accounting for microstructure noise by employing a spectral estimation of the spot volatility and an accurate test function. The nonparametric spot volatility estimator shows appealing asymptotic and finite-sample qualities and is of interest beyond the scope of this article. The estimation of the underlying spot volatility opens up several new ways for inference in models of high-frequency data with noise. Our data study reveals cogent significance of price and volatility co-jumps in NASDAQ high-frequency data. This has consequences for the future modeling of price and volatility. Investigating why many price jumps are accompanied by volatility adjustments, but others not, appears important through the lenses of economic theory of information processing and surprise elements. The presented methods can be generalized in various directions. For instance, our methods guide the way how a test for correlation of price and volatility jumps, as presented by Jacod et al. (2013) for a non-noisy observation design, can be constructed.
Acknowledgement
Financial support from the Deutsche Forschungsgemeinschaft via CRC 649 `O¨ konomisches Risiko', Humboldt-Universita¨t zu Berlin, is gratefully acknowledged. Data has been provided by LOBSTER academic data, powered by NASDAQ OMX.
20

A Proofs

A.1 Preliminaries
On the finite time horizon [0, 1], we may augment local boundedness to uniform boundedness in Assumption (H-r), such that we can assume that there exists a constant  with

max {|bs()|, |cs()|, |Xs()|, |(s, x)|/(x)}   ,

for all (, s, x)  (, R+, R). This standard procedure can be found in Jacod (2012), Lemma 6. 6 in Section 6. 3. Throughout the proofs K is a generic constant and Kp a constant and emphasizing dependence on p. We decompose the semimartingale X in the continuous part

t t

Ct = X0 + bs ds +

cs dWs ,

00

and the jumps

tt

Jt =

(s, 1x) {|(s,x)|1}(µ - )(ds, dx) +

(s, x)1{|(s,x)|>1}µ(ds, dx) .

0R

0R

The process

t
C~t =
0

c sh-n 1 hn dWs

(25)

serves as an approximation of Ct by a simplified process without drift and with locally constant volatility. We separate jumps with absolute value bounded from above by some  < 1 and larger jumps:

tt

Jt = J ()t +

(s, x)1{|(s,x)|1}(µ - )(ds, dx) +

(s, 1x) {|(s,x)|>1}µ(ds, dx) ,

0 R\A

0R

with A = {z  R|(z)  } and later let   0. Let us recall some usual estimates on Assumption (H-r) which are crucial for the following proofs. For the continuous semimartingale part we have

p  1, s, t  0 : E |Cs+t - Cs|p Fs  Kptp/2 .

(26a)

For given 0 <  < 1, for J() the estimate

p  1, s, t  0 : E

|J ()s+t - J ()s|p Fs

(s+t)

p

 Kp E

(2(x)  1)µ(d, dx) 2

s A



Kp

t(

p 2

1)

(

p 2

1)

,

(26b)

21

holds with  = A 2(x)  1 (dx)  K(2-r). The continuous semimartingale increments satisfy a local Gaussianity in the sense that

p  1, s, t  0 : E

|Cs+t

-

Cs

-

 ( cs(Ws+t

-

Ws))|p

Fs

s+t p

 Kp E

| - s|2 d 2 Fs

s

p
 Kp t 2 E sup (| - s|p) Fs

 [s,s+t]



Kpt

p 2

(1+(21)).

(26c)

Large jumps occur seldom what precisely means that the expectation of jumps with absolute value larger than  is bounded by:

s, t  0 : E |Js+t - Js - (J ()s+t - J ()s) | Fs  Kt-r .

(26d)

On Assumption (H-r) with r  1, the jumps satisfy

s, t  0 : E |Jt - Js|p Fs  Kp E

t (r(x)  1)(dx)ds 1/r
sR

 Kp|t - s|(1/r) ,

(26e)

and with the same reasoning for r = 2, we can conclude that the volatility under (-) satisfies E[|ct - cs| |Fs] = |t - s|(1/2). Proofs of these bounds by routine stochastic calculus can be found in Jacod (2012), among others. Recall the definition of the weights (10). The magnitude of these
weights is

wjk  Ijk =

ckhn

+

 n

jk

-2 n

-2
=O

j2 -2 1 + nh2n



O(1) =
O(j-4n2hn4 )

for j  nhn 
for j > nhn

,

(27)

with

jk

-2 n



2j2h-n 2

=

1 0

j2k

(t)

dt

-1

=

jk -2.

A.2 Stable convergence of the spot squared volatility estimators

We shall establish stable central limit theorems for the estimators (12a) and (12b). Since we may consider the continuous martingale part of X time-reversed, the mathematical analysis for both follows the same arguments and principles and we restrict ourselves to treat the right-limit case explicitly. The proof takes several steps according to the following decomposition:

n/2 c^srn - cs = n/2

sh-n 1 +rn-1
1rnkad(Y ) {hn|kad(Y )|un}
k= sh-n 1 +1

- cs

22

= n/2

sh-n 1 +rn-1
rnk(C~ + ) - cs

k= shn-1 +1

+ n/2

shn-1 +rn-1
rn k(C + ) - k(C~ + )

k= sh-n 1 +1

+ n/2

sh-n 1 +rn-1
rn
k= shn-1 +1

k(Y 1) {hn|k(Y )|un} - k(C +

)

+ n/2

shn-1 +rn-1
rn
k= shn-1 +1

1 1kad(Y ) {hn|kad(Y )|un} - k(Y ) {hn|k(Y )|un}

.

In the first step we establish the stable CLT for the spectral estimator built from observations of the process C~ in the simplified model with noise:

Step 1 :

n/2

shn-1 +rn-1
rnk(C~ + )
k= sh-n 1 +1

- cs

-(st) M N (0, 8c3s/21/2) .

(28)

Proof of Step 1: In order to establish a point-wise central limit theorem we verify three conditions: one addressing the expectation, one the variance and one Lindeberg-type criterion. Additionally we have to show that the weak convergence holds stably in law. Recall the summation by parts identity for spectral statistics from Altmeyer and Bibinger (2014):

Sjk =

jk

-2 n

nn

in X j k

i n

-

i + 1/2 1 i jk n n

i=1 i=1

,

with jk(t) = 2h-n 1/2 cos jh-n 1(t - khn) 1[khn,(k+1)hn](t). Thereby unbiasedness of the local
estimates (9) follows from an elementary calculation, analogously as in Altmeyer and Bibinger (2014): E[k(C~ + )] = ckhn for all k. Altmeyer and Bibinger (2014) have worked under i.i.d. noise, the generalization to serially dependent noise relies on Lemma 1 of Bibinger et al. (2014b). For the

expectation of the left-hand side in (28), we deduce that

n/2

sh-n 1 +rn-1
rnE[k(C~ + ) - cs|Fkhn ]
k= sh-n 1 +1

= n/2

shn-1 +rn-1
rn(ckhn - cs)
k= sh-n 1 +1

= OP

shn-1 +rn-1

n/2rn

(khn)(1/2)

k= sh-n 1 +1

= OP n/2(hn/rn)(1/2)

= OP n((1/2)+1/2)n-1/2(1/2) log(1/2)(n) = OP(1) ,

23

because  > 0 and  < (2 + 1)-1 for any  implying  < 1/4 for  < 1/2. For the sum of conditional variances of the left-hand side of (28) we obtain

sh-n 1 +rn-1
n rn2 Var k(C~ + )|Fkhn
k= shn-1 +1

= nrn

sh-n 1 +rn-1 Jn
rnwj2kIj-k1 + OP(1)
k= shn-1 +1 j=1

= log (n)I-1 c sh-n 1 hn + Rn .

The remainder in the first equality is due to fourth moments of the noise when the noise is non-

Gaussian and handled as in Altmeyer and Bibinger (2014). Here we write wjk, Ijk, Ik as functions of

the

squared

volatility:

Ij (c)

=

1 2

c+

jk

-2 ^ nn

-2, I(c) =

Jn j=1

Ij

(c)

and

wj (c)

=

(I (c))-1 Ij (c).

Note that

jk

-2 n

is equal

for all k

such that

time-dependence of I, Ij, wj

is

solely through the

squared volatility c. We exploit the bound on the derivative of the weights w.r.t. c:

wj(c) = O wj(c) log2 (n) ,

(29)

here and several times below. The bound is proved in Altmeyer and Bibinger (2014) on page 40. Observe that by the chain and product differentiation rule

d dc

wj2 (c)(Ij (c))-1

= 2wj(c)wj(c)(Ij(c))-1 + wj2(c)4 c +

jk

-2 ^ nn

.

Thus we can find an upper bound for the remainder Rn using

Jn

1

jk

-2 n

n-1

j=1

1  jk n8 n4

=O

 nhn

Jn

1+

jk 6nn3

j=1 j=1

= O(log6 (n))

 Rn = OP

shn-1 +rn-1

n rn2

log6 (n) ckhn - c sh-n 1 hn

k= sh-n 1 +1

= OP log7 (n)(hn/rn)(1/2)

with (27), which tends to zero as n   because  > 0 and  < 1/2. The Lindeberg condition is proved by the Lyapunov criterion considering fourth moments:

sh-n 1 +rn-1
n2 rn4 E
k= sh-n 1 +1

k4(C~ +

) Fkhn

sh-n 1 +rn-1

 n2

rn4

k= sh-n 1 +1

= O n- log11(n) = O(1) ,

Jn
wjk E
j=1

S~j2k

-

^ n

jk

-2 n

4

1 4

4

using Jensen's and Minkowski's inequalities with S~jk being the spectral statistics (8) based on obser-

vations of (C~ +

).

The order of the term readily follows with E[S~jpk]  Kp

1 + n-p/2

jk

-p n

,

what is shown by equations (48) and (49) in Altmeyer and Bibinger (2014). Equation (48) carries

over and the proof of equation (49) can easily be adapted along the same lines including finitely many

24

autocovariances of the noise. We obtain the variance in (28), since the bin-wise Fisher informations

1 Jn Ik = 2

ckhn +

jk

-2  nn

-2

j=1

satisfy the following convergences (see Altmeyer and Bibinger (2014) for a detailed proof for the integrated version):

1 log (n) Ik

-

1 02

ckhn + 2x2

-2
dx =

8 c3k/h2n 1/2

-1
,

(30)

and the reciprocal right-hand side thus constitutes the asymptotic variance of the spot squared volatility estimator in Theorem 1. Finally, stability of the weak convergence is proved similarly as in Proposition 8.2 of Jacod and Todorov (2010). For later use, let us consider a collection of times where we consider estimates of the spot volatilities. In particular, for our test, we shall focus on finitely many jumps of X with absolute value larger than some constant. Consider a finite set (Sp)1pP with fix P <  of ordered stopping times exhausting those jump arrivals of X on [0, 1]. The restriction of  to

n =   |S1 > rn-1hn, SP < 1 - rn-1hn, p : (Sp - Sp-1) > 2rn-1hn

(31)

satisfies P(n)  1 as n  . We aim at establishing for

n = n/2 c^Srnp - cSp , n/2 c^Srnp- - cSp- 1pP

(32)

that E[Zg(n)]  E[Zg()] with  = 22cS3/p41/4Up, 22c3S/p4-1/4Up 1pP for any F -measurable bounded random variable Z and continuous bounded function g and for (Up, Up) a sequence of stan-

dard normals defined on an exogenous space being independent of F. This is the definition of the

claimed stable convergence. Denote by DSrnp-, DSrnp 1pP statistics calculated in the same way

as our spot estimators (12a), (12b), but when the local volatility is fixed equal to 1. Then, the

DSrnp-, DSrnp 1pP are local means of bin-wise spectral statistics

Jn j=1

wjk

(Sjk)2 -

jk

-2 ^ nn

,

where

n

Sjk =

jk

-1 n

inW + i - i-1 jk

i n

.

i=1

From the above considerations for the point-wise clt, we obtain that

n/2 c^rSnp - c3S/p4DSrnp -P 0 , and analogously for c^Srnp-. Therefore, we are left to prove that for

(33)

~n = n/2 DSrnp - 1 , n/2 DSrnp- - 1 1pP

25

 the condition E[Zg(~n)]  E[Zg(~)] = E[Z]E[g(~)] with ~ = 2 21/4Up, 2 21/4Up 1pP and (Up, Up) a sequence of exogenous standard normals independent of F is valid. The strategy is to
exclude intervals on which the spot estimators are built and conditioning. Thereto, define

P
Bn = [(Sp - (rn-1 + 1)hn)  0, (Sp + (rn-1 + 1)hn)  1]
p=1
and Gtn as the smallest filtration to which W is adapted and such that the -field generated by the Poisson measure which determines S1, . . . , SP lies in G0n. Then each ~n is G1n-measurable. The following decomposition of W is well-defined:

t
W (n)t = 1Bn(s) dWs , W¯ (n)t = Wt - W (n)t .
0
It is enough to consider Z being G1-measurable, as we can simply substitute with E[Z|G1] otherwise. When Hn is the -field generated by G0n and W¯ (n)t, Hn n is an isotonic sequence and n Hn = G1n. Since E[Z|Hn]  Z in L1(P), it is enough to show

E[Z1ng(~n)]  E[Z]E[g(~)]

(34)

for Z Hq-measurable for some q. Restricted to n the vector ~n includes only increments inW from W (n)t and independent of W¯ (n)t. Then for all n  q, conditional on Hq, the vector ~n has
a law independent of W¯ (n)t such that E[Z1ng(~n)] = E[Z1n]E[g(~n)], n  q, and the ordinary
central limit theorem implies the claimed convergence. We have verified all conditions and infer the
stable limit theorem (28).

To prove that the same CLT as (28) is valid for n/2 c^srn - cs , we show for the other addends above that they converge to zero in probability for all s  (0, 1). We proceed with

Step 2 :

n/2

sh-n 1 +rn-1
rn
k= shn-1 +1

k(C + ) - k(C~ + )

= OP(1) .

(35)

This remainder due to approximating C by the simplified process C~ has exactly the same structure as the one for the integrated squared volatility examined in paragraph 6.3 of Altmeyer and Bibinger (2014). We incorporate the additional jump component in the volatility using (26e). Then, repeating the proof along the same lines, only changing the mean over all bins to the mean over local windows of size rn-1hn, renders with  < 1/2 the order:

k(C + ) - k(C~ + ) = OP hn(1/2) = OP n-/2 ,

26

uniformly for all k. For this remainder the Ho¨lder smoothness of the drift is needed because hn is chosen a logarithmic factor larger than the usual order n-1/2 of band-widths in related works as
Barndorff-Nielsen et al. (2008) and Jacod et al. (2009).

Step 3 :

n/2

sh-n 1 +rn-1
rn k(Y 1) {hn|k(Y )|un} - k(C + )
k= sh-n 1 +1

= OP(1) .

(36)

Proof of Step 3: It suffices to prove that uniformly for all k:

|k(Y 1) {hn|k(Y )|un} - k(C + )| = OP n-/2 .
We distinguish between two disjoint subsets of  according to whether hn|k(C + )| > un = chn for some fixed   (0, 1), or not. Consider first the subset on which hn|k(C + )| > un. If we choose N0  N, such that hnN0(1-) = O(n-/2-) for some  > 0, we have

|k(C +

)|  |k(C +

)|N0

+1

(

 c

)-N0

hnN0

(1-

)

=

OP

log2N0+2(n)hnN0(1- )

= OP n-/2

,

|k(Y ) - k(C +

)|  |k(Y ) + k(C +

)||k(C +

)|N0

(

 c

)-N0

hnN0(1-

)

= OP log2N0+2(n)hnN0(1- ) = OP n-/2 .

We use bounds for the moments of |k(C + )|p = OP(log2p(n)), p  2, which follow by the moment bounds for S~jk with Minkowski's and Jensen's inequalities as for fourth moments in Step 1 above and with Step 2. Note that these bounds are not sharp, as can be seen for the second moment which increases logarithmically, but sufficient for the proofs. The first bound in case of truncation on bin k
and the second one analogously in case of non-truncation imply (36). Next, consider the subset of  on which hn|k(C + )|  un. We have the decomposition

Jn

k(Y )= k(C + )+

wjk

jk

-2 n

j=1

n

inJ jk

i n

i=1

2n

n

+2

inJ jk

i n

vn C j k

v n

i=1 v=1

,

neglecting cross terms of jumps and noise. All cross terms can be bounded using Cauchy-Schwarz. We focus in the sequel on the addend with jump increments ni J. The bounds (26b) and (26d) for the probability of jumps above a certain magnitude occurring on different time instants show that cross terms of the squared sum are asymptotically negligible. Therefore, using Jensen's inequality twice we find that

Jn

E

wjk

jk

-2 n

j=1

n

inJ jk

i n

i=1

p 2

Jn

 wjkE

j=1

n

jk

-n 2(inJ )2j2k

i n

i=1

Jn n
 wjk

jk

-2 j2k

i n

nn

npE |ni J |2p

+ O(1) = O(1) .

j=1 i=1

p
+ O(1)

27

With these moment bounds at hand, we obtain in case of truncation, which means

Jn n

hn|k(Y )| > un  hn

wjk

jk

-2 n

inJ jk

i n

j=1 i=1

2
> ~un

for some ~ > 0, the following bound:

|k(C +

)|



|k(C

+ )|hnN0(1- ) (~/c)N0

Jn

wjk

jk

-2 n

n

ni J jk

i n

j=1 i=1

2 N0 = OP n/2 .

In case of non-truncation, hn|k(Y )|  un, we derive

E

Jn n

wjk

jk

-2 n

ni J



 un

2j2k

i n

j=1 i=1

= O un1-r/2 ,

and hence if we can ensure that hn(1-r/2) = O(n-/2):

Jn n

|k(Y ) - k(C + )|  K

wjk

jk

-2 n

ni J



 un

2j2k

i n

j=1 i=1

+ OP n-/2 = OP n-/2 .

The conditions  <  (1 - r/2) as well as r < 2 is exactly what we need here to guarantee (36).

Step 4 :

n/2

sh-n 1 +rn-1
1 1rn kad(Y ) {hn|kad(Y )|un} - k(Y ) {hn|p(Y )|un}
k= sh-n 1 +1

= OP(1) . (37)

Proof of Step 4: In Step 3 we have not used the specific form of the oracle weights (10) and the proof analogously extends to

n/2

shn-1 +rn-1
rn
k= shn-1 +1

1kad(Y ) {hn|kad(Y )|un} - kad(C +

)

= OP(1) .

(38)

Thus it suffices to prove that

n/2

shn-1 +rn-1
rn kad(C + ) - k(C + )
k= sh-n 1 +1

= OP(1) .

(39)

We decompose this remainder as follows. First, consider the difference of pre-estimated and oracle

28

weights, when the pilot estimator is the same for the whole window:

shn-1 +rn-1

Jn

rn

k= sh-n 1 +1 j=1

wj c^rsnh,p-ni1lothn

- wj c sh-n 1 hn

Sj2k

-

^ n

jk

-2 n

-

ckhn

Jn

 rn

wj c^rsnh,p-ni1lothn

j=1

- wj c sh-n 1 hn

sh-n 1 +rn-1 k= sh-n 1 +1

Sj2k

-

^ n

jk

-2 n

-

ckhn


Jn

= OP rn1/2

1 + jk n-2n-1 wj c shn-1 hn

j=1

 log (n)n = OP n-/2 .

Here we have used that the expectation of the difference is zero and that the weights do not hinge on
k. We have bounded the variance using the derivative bound (29) on the weights and that covariances of the Sj2k over different bins tend to zero. Finally, we denote the rate of the pilot estimator n here and since rn1/2 = n-/2 log (n) some n < n- for any  > 0 is enough here, while we actually attain n = n-/2. It remains to bound

sh-n 1 +rn-1


Jn

rn2 Var 

k= shn-1 +1

j=1

wj c^rknh,npilot

- wj c^rsnh,pn-i1lothn

shn-1 +rn-1


Jn

+ rn2 Var 

k= sh-n 1 +1

j=1

wj ckhn

- wj

c sh-n 1 hn

= O rn log5 (n) n-  (rn-1hn)2 = O n- .



Sj2k

-

^ n

jk

-2 n

-

ckhn





Sj2k

-

^ n

jk

-2 n

-

ckhn



This proves (37) and completes the proof of Theorem 1.

A.3 Asymptotics of the test statistics

For test functions which are twice continuously differentiable with bounded second derivatives, Taylor's formula yields

g(x1, x2)

-

g(a1,

a2)

=

g x1 (a1, a2)(x1

-

a1)

+

g x2 (a1,

a2)(x2

-

a2)

+

2g 2 x21 (a1,

a2)(x1

-

a1)2

+

2g 2 x22

(a1,

a2)(x2

-

a2)2

+

2g x1x2

(a1,

a2)(x1

-

a1)(x2

-

a2)

+ O max (x1 - a1)2, (x2 - a2)2 .

We apply a generalized -method and set (a1, a2) = (cs, cs-) and the random vector (x1, x2) = (c^rsn, c^srn-) with estimators (12a) and (12b). Denote by {1, . . . , N1} a sequence of stopping times exhausting the jumps of X on [0, 1] with

29

|Xi| > a for all i and some a  R+ and the Le´vy measure of X does not have an atom in {a}. We shall prove that

N1
T0(rn, hn, g) -P g(ci , ci-) ,
i=1

(40)

and, furthermore, establish a limit distribution theory under H(a)[0,1], when the right-hand side above equals zero. We restrict ourselves to prove a stable limit theorem for the test statistic in case that we only consider jumps with |Xi| > a. More general limit theorems in the vein of Jacod and Todorov (2010) may also apply, but a proof is beyond our scope here. For our purpose the point-wise stable
limit theorems of the spot squared volatility estimators together with some standard considerations
suffice. We are a bit sketchy at this stage where we use similar reasoning as before. The core point is that we may restrict to a subset of  again on which |i+1 - i| > 2rn-1hn for all i = 1, . . . , N1 - 1, and also 1 > rn-1hn, N1 < 1 - rn-1hn. The asymptotic distribution of the test statistic is derived with the following three convergences:

n/2

c^rn
i

h-n 1

hn

- ci

-(st) M N 0, 8c3i/21/2 ,

n/2 c^rnih-n 1 hn - - ci- -(st) M N 0, 8c3i/-2 1/2 ,

h-n 1-rn-1-1

1 1n

{hn|kad(Y )|>una2} -

{|Xs|>a} -P 0 ,

k=rn-1

s1

which hold jointly. The stable limit theorems of the spot volatility estimators are given in Theorem 1. The convergence of the set of bin-wise statistics (9) above the threshold to the set of N1 jumps is also clear from above. Concerning joint convergence of the spot estimates, note that on the considered subset of  all spot squared volatility estimates are computed from disjoint data subsets. In particular this applies to left and right-hand estimates at a particular jump time i. Therefore, covariations between all estimates converge to zero in probability which is enough to conclude joint weak convergence. Crame´r-Wold's theorem gives equivalence to weak convergence of linear combinations. Stability of the convergence of the vector readily follows by stability (joint weak convergence with any measurable bounded random variable) of the single estimates. Next, focus on the test function (18) in Theorem 2. It holds that

g g x1 (ci , ci ) = x2 (ci , ci ) = g(ci , ci ) = 0 .

30

The second order term comes into play and the equalities

2g x21 (ci , ci )

=

2g x22 (ci , ci )

=

2g - x1x2 (ci , ci )

=

1 8

c-i3/2

.

Under H(a)[0,1] when ci = ci- for all i, the limit of nT0(hn, rn, g) can be described by a random variable

N1 i=1

2g 2 x21 (ci ,

ci )Zi2

+

2g 2 x22

(ci

,

ci

)Z~i2

+



2g x1x2

(ci

,

ci

)Zi

Z~i

8c3i/21/2 ,

where Zi and Z~i, i = 1, . . . , N1, are two independent collections of i.i.d. standard normals defined on

the orthogonal throughout our

extension analysis.

Soifn(ce ,(F1/,P)2)i(nZtihe-pZr~oi)duacrte

space that accommodates all random variables i.i.d. standard normals the 2 distribution with

N1 degrees of freedom appears as limiting distribution. The claim of Theorem 2 follows from bino-

mial formula, the second derivatives of the test function (18) and the fact that we have an estimator ^1/2 = 1/2 + OP(n-1/2). Even though the limit above could depend on the particular choice of stopping times its F-conditional law does not. Corollary 3.1 readily follows from the above asymptotic

considerations.

If we consider g~(x1, x2) = (x1 - x2), the asymptotic normality results (14a) and (14b) and that

covariations between left and right estimates tend to zero in probability give rise to the convergence:

N1

n/2 T0(rn, hn, g~) -(st)

Zi - Z~i

i=1

8c3i/21/2 1/2 ,

on H(a)[0,1], when ci = ci- for all i = 1, . . . , N1, where again (Zi, Z~i)1iN1 is a collection of i.i.d. standard normals accommodated on the orthogonal extension of the probability space. Standardization with the pre-estimated Fisher informations readily yields the feasible limit theorem in (21).

References
A¨it-Sahalia, Y., J. Jacod, and J. Li (2012). Testing for jumps in noisy high frequency data. Journal of Econometrics 168, 207­222.
A¨it-Sahalia, Y., L. Zhang, and P. A. Mykland (2005). How often to sample a continuous-time process in the presence of market microstructure noise. Review of Financial Studies 18, 351­416.
Altmeyer, R. and M. Bibinger (2014). Functional stable limit theorems for efficient spectral covolatility estimators. CRC 649 discussion paper 2014-05.
Andersen, T. G. and T. Bollerslev (1998). Answering the skeptics: Yes, standard volatility models do provide accurate forecasts. International Economic Review 39, 885­905.
31

Andersen, T. G., T. Bollerslev, P. Christoffersen, and F. X. Diebold (2007). Practical volatility and correlation modeling for financial market risk management. in "The Risks of Financial Institutions", edited by Mark Carey and Rene´ M. Stulz, University of Chicago Press.
Andersen, T. G., T. Bollerslev, F. X. Diebold, and P. Labys (2001). The distribution of realized exchange rate volatility. Journal of the American Statistical Association 96, 42­55.
Bandi, F. M. and R. Reno` (2013). Price and volatility co-jumps. working paper.
Barndorff-Nielsen, O. E., P. R. Hansen, A. Lunde, and N. Shephard (2008). Designing realised kernels to measure the ex-post variation of equity prices in the presence of noise. Econometrica 76(6), 1481­1536.
Barndorff-Nielsen, O. E. and N. Shephard (2002). Econometric analysis of realized volatility and its use in estimating stochastic volatility models. Journal of the Royal Statistical Society 64(2), 253­280.
Bibinger, M., N. Hautsch, P. Malec, and M. Reiß (2014a). Estimating the quadratic covariation matrix from noisy observations: Local method of moments and efficiency. The Annals of Statistics 42(4), 80­114.
Bibinger, M., N. Hautsch, P. Malec, and M. Reiß (2014b). Estimating the spot covariation of asset prices - statistical theory and empirical evidence. preprint, HU Berlin.
Bibinger, M. and L. Winkelmann (2013). Econometrics of cojumps in high-frequency data with noise. CRC 649 discussion paper 2013-021.
Curci, G. and F. Corsi (2012). Discrete sine transform for multi-scales realized volatility measures. Quantitative Finance 12, 263­279.
Dewachter, H., D. Erdemlioglu, J. Y. Gnabo, and C. Lecourt (2014). The intra-day impact of communication on euro-dollar volatility and jumps. Journal of International Money and Finance 43, 131­154.
Eraker, B. (2004). Do stock prices and volatility jump? reconciling evidence from spot and option prices. The Journal of Finance 59(3), 1367­1404.
Eraker, B., M. Johannes, and N. Polson (2003). The impact of jumps in volatility and returns. The Journal of Finance 58, 1269­1300.
Jacod, J. (2008). Asymptotic properties of realized power variations and related functionals of semimartingales. Stochastic Processes and their Applications 118(4), 517­559.
Jacod, J. (2012). Statistics and high frequency data. Proceedings of the 7th Se´minaire Europe´en de Statistique, La Manga, 2007: Statistical methods for stochastic differential equations, edited by M. Kessler, A. Lindner and M. Sørensen.
32

Jacod, J., C. Klu¨ppelberg, and G. Mu¨ller (2013). Testing for non-correlation between price and volatility jumps. preprint.
Jacod, J., Y. Li, P. A. Mykland, M. Podolskij, and M. Vetter (2009). Microstructure noise in the continous case: the pre-averaging approach. Stochastic Processes and their Applications 119, 2803­2831.
Jacod, J. and V. Todorov (2010). Do price and volatility jump together? The Annals of Applied Probability 20(4), 1425­1469.
Lee, S. and P. A. Mykland (2008). Jumps in finacial markets: A new nonparametric test and jump dynamics. Review of Financial Studies 21, 2535­2563.
Li, J. (2013). Robust estimation and inference for jumps in noisy high frequency data: a local-tocontinuity theory for the pre-averaging method. Econometrica 81, 1673­1693.
Mancini, C. (2009). Non-parametric threshold estimation for models with stochastic diffusion coefficient and jumps. Scandinavian Journal of Statistics 36(4), 270­296.
Reiß, M. (2011). Asymptotic equivalence for inference on the volatility from noisy observations. The Annals of Statistics 39(2), 772­802.
Tauchen, G. and V. Todorov (2011). Volatility jumps. Journal of Business and Economic Statistics 29, 356­371.
Zhang, L., P. A. Mykland, and Y. A¨it-Sahalia (2005). A tale of two time scales: Determining integrated volatility with noisy high-frequency data. Journal of the American Statistical Association 100(472), 1394­1411.
33

SFB 649 Discussion Paper Series 2014
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "Principal Component Analysis in an Asymmetric Norm" by Ngoc Mai Tran, Maria Osipenko and Wolfgang Karl Härdle, January 2014.
002 "A Simultaneous Confidence Corridor for Varying Coefficient Regression with Sparse Functional Data" by Lijie Gu, Li Wang, Wolfgang Karl Härdle and Lijian Yang, January 2014.
003 "An Extended Single Index Model with Missing Response at Random" by Qihua Wang, Tao Zhang, Wolfgang Karl Härdle, January 2014.
004 "Structural Vector Autoregressive Analysis in a Data Rich Environment: A Survey" by Helmut Lütkepohl, January 2014.
005 "Functional stable limit theorems for efficient spectral covolatility estimators" by Randolf Altmeyer and Markus Bibinger, January 2014.
006 "A consistent two-factor model for pricing temperature derivatives" by Andreas Groll, Brenda López-Cabrera and Thilo Meyer-Brandis, January 2014.
007 "Confidence Bands for Impulse Responses: Bonferroni versus Wald" by Helmut Lütkepohl, Anna Staszewska-Bystrova and Peter Winker, January 2014.
008 "Simultaneous Confidence Corridors and Variable Selection for Generalized Additive Models" by Shuzhuan Zheng, Rong Liu, Lijian Yang and Wolfgang Karl Härdle, January 2014.
009 "Structural Vector Autoregressions: Checking Identifying Long-run Restrictions via Heteroskedasticity" by Helmut Lütkepohl and Anton Velinov, January 2014.
010 "Efficient Iterative Maximum Likelihood Estimation of HighParameterized Time Series Models" by Nikolaus Hautsch, Ostap Okhrin and Alexander Ristig, January 2014.
011 "Fiscal Devaluation in a Monetary Union" by Philipp Engler, Giovanni Ganelli, Juha Tervala and Simon Voigts, January 2014.
012 "Nonparametric Estimates for Conditional Quantiles of Time Series" by Jürgen Franke, Peter Mwita and Weining Wang, January 2014.
013 "Product Market Deregulation and Employment Outcomes: Evidence from the German Retail Sector" by Charlotte Senftleben-König, January 2014.
014 "Estimation procedures for exchangeable Marshall copulas with hydrological application" by Fabrizio Durante and Ostap Okhrin, January 2014.
015 "Ladislaus von Bortkiewicz - statistician, economist, and a European intellectual" by Wolfgang Karl Härdle and Annette B. Vogt, February 2014.
016 "An Application of Principal Component Analysis on Multivariate TimeStationary Spatio-Temporal Data" by Stephan Stahlschmidt, Wolfgang Karl Härdle and Helmut Thome, February 2014.
017 "The composition of government spending and the multiplier at the Zero Lower Bound" by Julien Albertini, Arthur Poirier and Jordan RoulleauPasdeloup, February 2014.
018 "Interacting Product and Labor Market Regulation and the Impact of Immigration on Native Wages" by Susanne Prantl and Alexandra SpitzOener, February 2014.
SFSBF6B4694, 9S,pSapnadnaduaeureSrtrSatßraeß1e, 1D,-D10-1107187B8eBrleinrlin htthpt:t/p/:/s/fbs6fb4694.w9.iwwiiw.hiu.h-bue-brleinrl.idne.de
ThTishrisesreasrecahrcwhaws assupsuppoprtoerdtebdybtyhethDeeDuetsucthseche ForFsocrhsuchnugnsgesgmeeminesicnhsachftatfht rtohuroguhgthhethSeFSBF6B4694"9Ec"oEnconmoimc RicisRki"s.k".

SFB 649 Discussion Paper Series 2014
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
019 "Unemployment benefits extensions at the zero lower bound on nominal interest rate" by Julien Albertini and Arthur Poirier, February 2014.
020 "Modelling spatio-temporal variability of temperature" by Xiaofeng Cao, Ostap Okhrin, Martin Odening and Matthias Ritter, February 2014.
021 "Do Maternal Health Problems Influence Child's Worrying Status? Evidence from British Cohort Study" by Xianhua Dai, Wolfgang Karl Härdle and Keming Yu, February 2014.
022 "Nonparametric Test for a Constant Beta over a Fixed Time Interval" by Markus Reiß, Viktor Todorov and George Tauchen, February 2014.
023 "Inflation Expectations Spillovers between the United States and Euro Area" by Aleksei Netsunajev and Lars Winkelmann, March 2014.
024 "Peer Effects and Students' Self-Control" by Berno Buechel, Lydia Mechtenberg and Julia Petersen, April 2014.
025 "Is there a demand for multi-year crop insurance?" by Maria Osipenko, Zhiwei Shen and Martin Odening, April 2014.
026 "Credit Risk Calibration based on CDS Spreads" by Shih-Kang Chao, Wolfgang Karl Härdle and Hien Pham-Thu, May 2014.
027 "Stale Forward Guidance" by Gunda-Alexandra Detmers and Dieter Nautz, May 2014.
028 "Confidence Corridors for Multivariate Generalized Quantile Regression" by Shih-Kang Chao, Katharina Proksch, Holger Dette and Wolfgang Härdle, May 2014.
029 "Information Risk, Market Stress and Institutional Herding in Financial Markets: New Evidence Through the Lens of a Simulated Model" by Christopher Boortz, Stephanie Kremer, Simon Jurkatis and Dieter Nautz, May 2014.
030 "Forecasting Generalized Quantiles of Electricity Demand: A Functional Data Approach" by Brenda López Cabrera and Franziska Schulz, May 2014.
031 "Structural Vector Autoregressions with Smooth Transition in Variances ­ The Interaction Between U.S. Monetary Policy and the Stock Market" by Helmut Lütkepohl and Aleksei Netsunajev, June 2014.
032 "TEDAS - Tail Event Driven ASset Allocation" by Wolfgang Karl Härdle, Sergey Nasekin, David Lee Kuo Chuen and Phoon Kok Fai, June 2014.
033 "Discount Factor Shocks and Labor Market Dynamics" by Julien Albertini and Arthur Poirier, June 2014.
034 "Risky Linear Approximations" by Alexander Meyer-Gohde, July 2014 035 "Adaptive Order Flow Forecasting with Multiplicative Error Models" by
Wolfgang Karl Härdle, Andrija Mihoci and Christopher Hian-Ann Ting, July 2014 036 "Portfolio Decisions and Brain Reactions via the CEAD method" by Piotr Majer, Peter N.C. Mohr, Hauke R. Heekeren and Wolfgang K. Härdle, July 2014 037 "Common price and volatility jumps in noisy high-frequency data" by Markus Bibinger and Lars Winkelmann, July 2014
SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

