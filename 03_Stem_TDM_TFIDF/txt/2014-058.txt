BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2014-058
Boiling the frog optimally: an experiment on survivor curve shapes and internet
revenue
Christina Aperjis* Ciril Bosch-Rosa** Daniel Friedman*** Bernardo A. Huberman*4
*Power Auctions (formerly at HP Labs) **Technische Universit‰t Berlin, Germany
***University of California Santa Cruz, United States of America *4 HP Labs
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universit‰t zu Berlin Spandauer Straﬂe 1, D-10178 Berlin

Boiling the frog optimally: an experiment on survivor curve shapes and internet
revenue

Christina

Aperjis

1,

Ciril


Bosch-Rosa

2,

Daniel

Friedman3

and

Bernardo

A.

Huberman4

1Power Auctions (formerly at HP Labs) 2Chair of Macroeconomics, Technical University Berlin 3Economics Department, University of California Santa Cruz
4HP Labs

September 11, 2014

Abstract
When should a necessary inconvenience be introduced gradually, and when should it be imposed all at once? The question is crucial to web content providers, who in order to generate revenue must sooner or later introduce advertisements, subscription fees, or other inconveniences. Assuming that eventually people fully adapt to changes, the answer
depends only on the shape of the survivor curve S(x), which represents the fraction of a user population willing to tolerate inconveniences of size x (Aperjis and Huberman 2011).
We report a new laboratory experiment that, for the rst time, estimates the shape of survivor curves in several dierent settings. We engage laboratory subjects in a series of six desirable activities, e.g., playing a video game, viewing a chosen video clip, or earning money by answering questions. For each activity we introduce a chosen level
x  [xmin, xmax] of a particular inconvenience, and each subject chooses whether to tolerate
the inconvenience or to switch to a bland activity for the remaining time. Our key nding is that, in general, the survivor curve is log-convex. Theory suggests
therefore that introducing inconveniences all at once will generally be more protable for web content providers.
Keywords : Internet monetization; online advertising; pricing; reference points; adaptation; laboratory
experiment
JEL classication: C91, D40, L11.
Corresponding author:cirilbosch@gmail.com, phone (+49) 030-314-24737.We would like to thank Albert Satorra and Manel Baucells for their helpful comments. We would also like to thank HP Labs for nancial support and James Pettit for programming help.Ciril Bosch-Rosa also acknowledges support by the Deutsche Forschungsgemeinschaft (DFG) through the SFB 649 "Economic Risk".

1

1 Introduction

Here is how not to boil a live frog: boil
up a pan of water, pick up the frog and throw it in the pan. The art of frog-boiling is an ancient one
How to boil a live frog (Goldstein 2000)

A goal of content providers is to turn attention to their websites into revenues that will at least oset their costs. Achieving this goal is not easy, even for providers with established audiences.
Providers may charge subscription fees, present advertisements or some mix (Baye and Morgan 2000, Prasad et al. 2003, Kumar and Sethi 2009). But all revenue strategies take a toll  while some users see the nuisance as a fair exchange for the value obtained, other users see the nuisance as intolerable and leave the website, and some potential users are deterred from joining. The issue is especially acute with increasingly intrusive rich media advertising formats (Godes et al. 2009).
In this paper we do not investigate which revenue strategy is best, nor how to choose the optimal nuisance level in steady state; presumably the best choices are very situation specic. Instead we ask a simpler question: should a content provider introduce the necessary nuisance in gradual steps or all at once? One view is that website visitors are like Goldstein's proverbial frogs, and that very few of them will leave if the inconvenience is introduced suciently gradually. Another view is that it is best to introduce inconvenience all at once.
An incorrect answer can cause lasting damage. A case in point is TimeSelect a subscription service started by the New York Times on May 2005 which allowed subscribers to read op-ed columnists and other features for a yearly subscription of $49.95. The service was discontinued on September 2007 when it became clear that the number of subscribers was insucient. A second example is Digg's disastrous release on August 25, 2010 of its advertising-heavy v4. Netix's share price crashed from $295 in July 2011 just prior to announcing an abrupt price hike on their old and new products, and hovered around $65 in November 2011. (After adjusting access and delivery options, Netix recovered and their stock price reached new highs in 2014.) Of course, the issue of all at once versus gradual introduction is not conned to the internet; witness the swimmers' perennial debate of whether to jump into cold water or to wade in gradually.
After a brief literature review, we begin in Section 3 by recalling the model of Aperjis and Huberman (2011, 2012). It establishes that, under a set of auxiliary assumptions, the answer to
the question hinges on the shape of the survivor curve S(x), the fraction of a human population xwilling to tolerate an inconvenience of magnitude . If the logarithm of S(x) is convex, then
the content provider maximizes value by introducing the necessary nuisance all at once. If the
logarithm of S(x) is concave, then the nuisance is best introduced gradually according to a
schedule that balances the number of long-term users against more rapid revenue acquisition. Are survivor curves typically log-concave, log-convex, or neither? To the best of our knowl-
edge, previous research provides no clear evidence. Behavior in natural settings is dicult to interpret because visitors leave for many reasons unrelated to the chosen inconvenience incre-
x xment , while new visitors arrive that may have dierent reactions to and to the content. xMoreover, when a change is introduced, visitors may form beliefs about further inconveniences
that may be introduced later, and such beliefs could vary widely across visitors. Competitors' adjustments in inconvenience might also have a major impact.

2

Laboratory experiments are especially helpful to answer the shape question, because one
xcan control for all these confounding factors, and can systematically vary the nuisance size .
In section 4 we describe a recent experiment designed to discover the shape of the survivor function over a variety of domains. The experiment confronts 112 human subjects with six
dierent tasks interrupted by nuisances of magnitude x  [xmin, xmax]. It generates 636 binary
observations of decisions whether to stay with an enjoyable activity or to leave after the nuisance has been imposed.
Section 5 collects the results. Summary statistics and preliminary analysis show that the
chosen ranges [xmin, xmax] are reasonably well calibrated, that order eects are unimportant,
and that behavior is reasonably consistent across tasks. The main nding concerns the shape parameters in Weibull distributions estimated for data from each of the six tasks. Estimation requires extension of established techniques to deal (for the rst time that we know of ) with doubly censored data. Surprisingly (at least to some of the coauthors), the overall estimate of the shape parameter is well inside the log-convex region.
The concluding discussion notes some caveats, suggests broader applications and implications, and points to future research.
2 Related Literature
We know of no studies estimating the shape of survivor curves for scalable nuisances. Ownprice demand elasticity is a distantly related topic with a vast literature. Perhaps the most relevant article here is Popescu and Wu (2007), which argues theoretically that rms with risk averse customers maximize prots by gradually increasing or gradually decreasing price. In an adaptation model, Fibich et al. (2005) nd that price elasticities increase over time, and that data suggest a faster adaptation for price decreases than for price increases.
A separate strand of literature on adaptation theory considers how users react over time to an introduced inconvenience. A number of papers consider adaptation in the context of repeatpurchase markets and characterize optimal dynamic pricing policies (Kopalle et al. 1996, Fibich et al. 2003, Popescu and Wu 2007, Nasiry and Popescu 2010). In these papers, a rm (usually a monopolist) is facing consumers whose purchase decisions are inuenced by past prices through reference price eects. The demand in a given period is assumed to be a function of the current price and the reference price (but does not depend on the number of people that purchased the product in the previous period). In a laboratory experiment, Kahneman et al. (1993) suggest that duration plays a role in the recollection of aversive experiences, with reference points being formed at the peak and end of the negative experience.1
In fact, there is an active theoretical literature on reference points (Kahneman and Tversky 1979, Frederick and Loewenstein 1999, KÆszegi and Rabin 2006) which has inspired many recent laboratory experiments, including Gneezy (2005) and Baucells et al. (2011). Abeler et al. (2011) nd empirical evidence supporting KÆszegi and Rabin (2006): payo expectations seem to anchor reference points, as identied by subjects' eort choices. By contrast Heetz and List (2011) nd no support for the expectations reference point hypothesis. Closely related to this literature we nd a number of experimental and empirical studies that focus on the formation of reference points (surveys are provided by Kalyanaram and Winer 1995, Mazumdar et al. 2005). In these studies, the inconvenience is the price of a product, and thus the reference point is a reference price. Even though the role of historic prices in forming price expectations
1The empirical adaptation literature is also related to studies such as Ariely (1998) that examine how
remembered pain relates to the time path of pain intensity. It may be worth pointing out that our own concerns are quite dierent: we shall examine empirically how stay/remain decisions (not recollections) depend on oneshot intensities (not time paths) of nuisances (not pain) in a variety of modalities.
3

is supported in many of these studies, there has not been sucient evidence to validate any specic model on how consumers update their reference prices.
Finally, there is a classic psychology literature on just noticeable dierences, which is associated with failures in the transitivity of preferences as in the self-torturer example of Quinn (1990), or in the Sorites paradox.2 Finally, there is eld data suggesting that rms generally prefer subdividing price increases but not price decreases (Chen et al. 2008).

3 Theory

We consider the setting of Aperjis and Huberman (2011). In discrete time t = 1, 2, 3, ...,

each period the content provider has the option to adjust the total inconvenience level (e.g.,
Xadvertisement level, subscription cost) t. Let xt  Xt - Xt-1 denote the adjustment in inconvenience at time t.
t rAssume that in period , users have a reference point t and use the website with probability S(Xt - rt), where S : R  [0, 1]. That is, we assume that this probability only depends on Sthe dierence between the current inconvenience and the reference point. We assume that is

a decreasing function: the larger the dierence between total inconvenience and the reference

point, the smaller the probability of using the website.

Aperjis and Huberman (2011) rely on adaptation theory to describe reference point dynam-

ics. That theory says that as time goes on people tend to adapt and become less aware of past
xchanges. In the present context, an increase in inconvenience by an amount initially decreases

a user's utility. However, as time goes by the user's reference point gradually adapts and, as a

result, his experienced utility gradually increases if no additional inconvenience is experienced.

Here we focus on the special case of complete adaptation within a single period. That is,

r = Xwe assume that t

t-1. In this case, the probability that a user continues using the website

at time t is equal to S(Xt - Xt-1) = S(xt). Thus subsequent theoretical analysis assumes that

Sthe survivor curve is the same in each period and depends only on the most recent change

in inconvenience.

Other simplifying assumptions are straightforward. Once a user leaves, he never returns, so

tthe fraction of users remaining on the site at time
to maximize the present value of his prot stream,

is t  t=0

=

t j=1

S

tt(Xt),

(xj). The where 

provider wishes is the provider's

discount factor and the current per-unit prot level (Xt) is an increasing function of the

current inconvenience level.

The main conclusion of Aperjis and Huberman (2011) is that, under current assumptions,
the provider's optimal schedule of inconvenience changes (x1, x2, ...) depends entirely on the
shape of the survivor curve. There are two important cases.
Log-concave survivor curve. A function is log-concave if its logarithm is concave. All

concave and linear functions are log-concave, but there also exist convex functions that are
log-concave. Examples include S(x) = e-xk with k > 1 and S(x) = (1 - x)k ∑ 1{x[0,1]} with k > 1, where 1{∑} is the indicator function. An important property of a log-concave survivor
curve is that
S(x + y)S(0)  S(x)S(y)

for any x, y  0. Here S(x)S(y) represents the probability that a current user will continue x yto be a user if inconvenience increased by last period and then by this period, while

2In Greek, soros means heap. The paradox is attributed to Eubulides of Miletus, a disciple of the Megarian
school of philosophy who presented the following paradox: no one grain of wheat can be identied as making the dierence between being a heap and not being a heap. Given then that one grain of wheat does not make a heap, it would seem to follow that two do not, thus three do not, and so on. In the end it would appear that no amount of wheat can make a heap. (Hyde 2011)

4

Figure 1: A comparison between a log-convex and a log-concave function.

S(x + y)S(0) represents the corresponding probability when the entire inconvenience change x + y was introduced in the current period. Iterating the inequality, it is intuitively clear that Swhen is log-concave, more users will remain if an increase in inconvenience is introduced

gradually than if it is introduced all at once.

Aperjis and Huberman (2011) conrm the intuition, and show that in the log-concave case

it will be optimal for the provider to increase inconvenience gradually in order to give people

time to adapt to changes. That paper then derives a specic schedule of changes that optimizes

the tradeo between maximizing the number of users in the long term and achieving a higher

revenue per user sooner.
Log-convex survivor curve. A function is log-convex if its logarithm is convex. For
instance, this is the case if S(x) = 1/(1 + x)k with k > 0 or S(x) = e-xk with k  (0, 1). If S is log-convex, then S(x + y)S(0)  S(x)S(y) for any x, y  0, and therefore a user is more likely

to stay if an increase in inconvenience is introduced at once than if it introduced gradually.

When the survivor curve is log-convex, it is optimal for the provider to increase inconvenience

once; this is shown by Aperjis and Huberman (2011) in a more general setting than the one we

notconsider here. Note that this is

Sa result of selection, because the function is assumed to

not change over time.

To get some intuition for the distinction between log-concave and log-convex survivor curves,
e econsider Figure 1 which shows the log-concave function -x2 and the log-convex function -x1/2 .
xNote that for small deviations from the reference point, the dashed line is above the solid

line, indicating that a user is more likely to use the website when his behavior is described by

x > 1the log-concave function. On the other hand, for large deviations (

in the Figure) the

comparison is reversed, suggesting that if the survivor function is log-convex, it is better to

make one large change.

Given that the optimal way to introduce inconvenience is so dierent for log-concave and

log-convex survivor curves, it is important to understand whether one of the two shapes prevails.

This motivates us to measure the survivor curves in the laboratory for a number of dierent

activities and types of inconvenience.

4 Methods
The laboratory experiment presented subjects with tasks of the following sort. First, they engaged in a pleasurable activity, such as putting on earphones and watching an 8 minute video clip  their choice of an interview of John Stewart at The O'Reilly Factor, or a selection of the 10 most popular ads shown to viewers of the 2010 Super Bowl. (Pilot experiments included

5

a longer list of videos, but these two were the most popular.) Then, after 100 seconds, an
annoying computer-generated voice at x  [30, 80] decibels began reading the decimal expansion of  = 3.14159... . Subjects knew that the only way to escape the auditory nuisance was to
click a button that immediately switched them to a bland activity, in this case watching a video of gentle waves breaking at La Jolla beach, for the remaining 6 minutes or so. Of course, a
higher fraction of subjects switched when x = 80 decibels than when x = 30, and intermediate xfractions switched at intermediate values of the nuisance.
Figure 2: SAT task with nuisance x = 0.15
We also presented subjects with visual nuisances, like ashing pop-up ads that interrupted
a video clip for 15 seconds every x seconds, with x ranging from x = 5 to x = 30. Figure
2 shows a text-based nuisance for the task of answering SAT questions, with a $0.40/$0.10 payment for each correct/incorrect answer. The nuisance is the random omission of each letter
with probability x  [0.06, 0.21]; in Figure 2, x = 0.15. Subjects could escape the nuisance
entirely by clicking a button, but then would be paid for the remainder of the 8 minute period at the much lower rate of $0.10/$0.02.
We presented each subject with six distinct tasks that shared the common structure depicted in Figure 3. The subject starts with an engaging activity (A activity), which after a certain
xamount of seconds is interrupted by a scalable nuisance of size that remains attached to the
A activity thereafter. She can escape the nuisance at any time by clicking a button to switch to a bland activity (B activity) where she will remain for the rest of the 6-8 minute period.
Her choice of whether or not to switch is a data point that helps us estimate the shape of S(x).
Table 4 summarizes the six combinations of A activity, scalable nuisance, and B activity 6

Figure 3: Task structure. The inconvenience is introduced to activity A after 100 seconds and remains for the rest of the 6-8 minute period.

Task
Movie/Pi Movie/Pop
Slug Read SAT Pay

Activity A
Watch Movie Watch Movie
Slug ($$$$) Read Article SAT Questions ($$$$) Watch Movie

Activity B
Watch Waves Watch Waves
Slug ($) Count Bits SAT Questions ($) Watch Waves

Inconvenience:
 digits
15 sec Pop-up Jitter
Drop Letters Drop Letters Pay to Stay

Range of x
[30, 80] decibels every [5, 30] sec [0.10, 0.25] rate [0.15, 0.30] rate [0.06, 0.21] rate [1, 23] cent fee

Table 1: Task specication.

presented to each subject. Of the entries not yet mentioned, Slug is a simple video game similar
to Snake (see Appendix B for a detailed description of the activity), and the jitter nuisance
involves a random turn (left or right) each pixel with probability x  [.10, .25]. The Pay to xStay nuisance is a one time fee of cents deducted from a 500 cent endowment, which can
be avoided only by switching to the B activity. The B activity Count Bits is illustrated in
Figure 4 below. Paid activities are indicated by ($$$$), and B activities paid at 1/4 the rate
are indicated by ($).
The nuisance ranges [xmin, xmax] were chosen to avoid inecient sampling when S(x) is very close to 0 or 1. Based on a few pilot sessions, we aimed to have S(xmin) in the vicinity of 0.8 and S(xmax) in the vicinity of 0.20. Nuisance levels were chosen to span the range by six evenly
spaced levels, as detailed in Appendix A.

Figure 4: Counting Bits. The subject is asked to count the number of ones in a random binary string of 15 digits. If incorrect, she is asked to try again. If correct, she goes on to a new string. The task repeats until the end of the 6 minute period.
7

4.1 Procedure
We recruited 112 human subjects, most of them undergraduates, majoring in Economics, Biology or Engineering. Each subject participated in only one of the 16 sessions we ran. Sessions lasted 70 to 90 minutes, including the time used to read instructions and to pay subjects.
Upon arrival, each subject was assigned to an isolated computer terminal, and general instructions for the experiment were read; a copy is attached in Appendix C. Next, subjects practiced all B activities, in order to ensure that they knew exactly what they would do if they decided to switch to a bland activity. Subjects were then given specic instructions for the rst of the six tasks, after completion they received instructions for the second task, completed it and were given instructions for the third task, etc. The order of the six tasks was varied in a balanced manner across sessions. In each session we randomly assigned each subject's nuisance
level x, but limited the choice to one of the two nuisance bins that we created; either x = 1, 3, 5 or x = 2, 4, 6 in each session. These bins allowed us to have in each session a sizeable number
of observations with the same treatment level in each activity. Before each round it was announced whether A and B would be paid activities. If they
were, then a detailed description of the payment system was given. If they weren't paid, then we emphasized it in the instructions. Subjects would know how much money they had made at the end of each paid round, and once the experiment was over, they were paid individually. Payos ranged from $27 (some subjects proved very procient at Slug) to $12 (some were not that apt), including the $5 show-up fee. On average subjects made around $16.
5 Results
The experiment yielded 636 data points (Yi,j ), observations of whether or not subject i decided x jto switch after experiencing inconvenience level in task . Due to implementation glitches,
we lost one Slug data point and the SAT data in two sessions (35 data points); hence the
slight shortfall from the intended 6 ◊ 112 = 672 observations. Figure 5 summarizes the data
graphically.
As a rst step in the data analysis, we run a Probit regression of the binary outcome (Yi,j )
on dummies for inconvenience levels 2-6, task numbers 2-6 as in Table 2, and the task sequence or session3.
As we can see in Table 2 all levels of inconvenience have a highly signicant eect, as one would hope. So do most tasks, except Movie/Pop, which is not signicantly dierent than the baseline task, Movie/Pi. Appendix A reports additional robustness checks, and conrms that there were no important session or sequence eects.
Finally, we use a Fisher Exact test to compare the proportion of subjects switching for
x xeach value of across activities. The results show that for any value of the dierence in
proportion is not statistically signicant, pointing towards a similar underlying distribution of subject tolerance for nuisance levels across activities. This conclusion will be tested more sharply in our survivor curve estimates below.
5.1 Estimation Strategy
The main objective of our experiment is to detect log-concavity or log-convexity of S(x) sepa-
rately in each of our six tasks. To do this we will consider each observation (switch or not) for
i jeach subject as an independent observation for each separate curve .
3The errors are clustered at the subject level.
8

2.treatment 3.treatment 4.treatment 5.treatment 6.treatment 2.activity 3.activity 4.activity 5.activity 6.activity cons
N
Order Dummies

(1) Switch 0.299 (0.180) 0.578 (0.171) 0.524 (0.165) 0.746 (0.164) 0.737 (0.179)
-0.524 (0.125) 636 No

(2) Switch
0.0511 (0.174) 0.551 (0.174) 1.029 (0.172) 1.144 (0.199) 0.428 (0.170) -0.540 (0.125)
636 No

(3)
Switch 0.359
(0.190) 0.633
(0.187) 0.642
(0.175) 0.845
(0.178) 0.859
(0.196)
0.0591
(0.176) 0.583
(0.176) 1.072
(0.174) 1.238
(0.191) 0.444
(0.177) -1.133
(0.186)
636
No

(4)
Switch 0.735
(0.280) 0.649
(0.177) 0.968
(0.257) 0.913
(0.199) 1.265
(0.281)
0.180
(0.194) 0.708
(0.185) 1.322
(0.243) 1.339
(0.238) 0.554
(0.185) -1.282
(0.221)
636
Yes

Standard errors in parentheses
 p < 0.10 ,  p < 0.05 ,  p < 0.01

Table 2: Switching Probit Model.

9

Figure 5: Overview of raw data. Ovals are proportional in each task to the number of obser-
vations of outcome Y = 1 (Switch) and of outcome Y = 0 (No Switch, or Stay) for the given
inconvenience level.

The main complication with our data comes from censoring. If Yij = 1, i.e., if subject j xswitches to the bland activity B when facing nuisance level i, then we infer that her switching threshold X is somewhere in the interval (0, xi), and thus observation is left censored (LC).
Therefore the likelihood of the observation is given not by the density of the distribution of
x Fthresholds at i but rather by the cumulative distribution function evaluated at that point:

F (xi)  P (X  xi)

On the other hand, if Yij = 0, i.e., if subject j stays in activity A, then we infer that his threshold is in the interval (xi, ), and the observation is right censored (RC). The likelihood
of such an observation is
1 - F (xi) = P (X > xi),
where S(xi)  1 - F (xi) is the probability that the subject survives the introduction of the
inconvenience.
This likelihood function applies to any parametric family of survivor curves. We use the
standard two-parameter Weibull family. Recall that the Weibull distribution has density

f (x; , ) =

 

(

x 

)-1e-(

x 

)

if x  0

0 if x < 0,

where  > 0 is the shape parameter and  > 0 is a scale parameter for the distribution. The

10

corresponding

cdf

is

F

(x; , )

=

1

-

e-(

x 

)

,

and

thus

the

survivor

function

is

S (x; , )

=

e-(

x 

)

.

Besides being standard, the Weibull family has the extremely convenient property that the
shape parameter  determines whether the survival function S(x) is log-convex or log-concave

(Bagnoli and Bergstrom 2005):

∑ S(x) is log-convex (and the hazard rate is strictly decreasing) if 0 <  < 1, and

∑ S(x) is log-concave (and the hazard rate is increasing) if   1.

Econometric packages usually include the Weibull distribution, and sometimes can deal with
singly censored data, but we must build our own likelihood function to deal with doubly censored
data. YIt follows from the preceding discussion that the likelihood function for data = (Yij )
is:

L(, |Y ) =

P (X < xi|, )

P (X > xi|, )

Yij LC

Yij RC

=

1

-

e-(

xi 

)

e-(

xi 

)

.

Yij LC

Yij RC

(1)

We maximize Function (1) over the parameter space using standard non-linear minimization techniques (a Newton-type algorithm) in the statistical package R to obtain point estimates
of the shape parameter . The results are reported in Table 3 along with a 90% condence
interval obtained through the bootstrapping procedures appropriate for nite samples.

Task
Movie/
Movie/Pop Slug Read SAT Pay
All Six Tasks
Five Estimable Tasks

Shape Parameter
1.17 0.43 0.60
0.92 0.62
0.49 0.64

90% Condence Interval
[0.59, 1.99] [0.11, 0.89] [0.23, 1.09]
[0.48, 1.48] [0.24, 1.10]
[0.32, 0.66] [0.49, 0.81]

Table 3: Weibull estimation results. Estimates in the next to last line pool all data, and those in the last line pool data for all tasks except Read.

Several things stand out in Table 3. First, four of the six point estimates are for a shape
parameter below 1. The two exceptions include Movie/ , which has an estimate close to 1, but

with a condence interval that includes a considerable interval below 1. The other exception is

the task Read, where MLE does not converge. Looking back at Figure 5, one gets the impression
that there is insucient variation across the chosen range [0.15, 0.30] of the nuisance (letter drop

probability). Perhaps a contributing factor is that some of the subjects apparently enjoyed the

B activity, bit counting, more than the A activity.

 > 1Looking at individual activities, then, in no case do we have clear log-concavity (

).

Three of the tasks (Movie/Pop, Slug and Pay) have condence intervals mainly or entirely
in the log-convex region ( < 1), and two (SAT and Movie/) have condence intervals that straddle  = 1. The remaining task (Read) permits no estimate of .

The pooled data, whether or not we include the problematic Read data, yield a shape

parameter clearly below 1. Indeed, the bootstrap histograms shown in Figure 6 have negligible

 > 1probability mass for

.. Overall, then, the survivor curve of subjects is log-convex.

11

Figure 6: Histogram of bootstrap estimations of the shape parameter for the aggregate data
across all tasks. The average estimate is shown as a red vertical line, and the 90% condence interval is bounded by the two blue vertical lines.

6 Discussion

The lab results for the pooled data are unambiguous: the Weibull shape parameter estimate is

 < 1well inside the log-convex region

. Looking at the results for individual tasks, the estimates

are never inconsistent with a log-convex shape, but in half the cases they are ambiguous. We

believe that the ambiguities are not intrinsic, but result from the limited data. Overall, then,

our study  the rst to estimate the shape of survivor curves in response to avoidable nuisances

 concludes that log-convexity is typical.
A direct implication of a Weibull shape parameter  < 1 is that the hazard rate (in other
contexts sometimes called the failure rate) is decreasing.4 This means that, proportionately

speaking, we lose more participants at low intensity; the few who remain at high intensity are

less apt to switch when we ratchet up intensity a bit more.

The implication is straightforward within the theoretical framework of Aperjis and Huber-

man (2011): web content providers should introduce their necessary nuisances all at once. In other words; it seems like the best way to boil a frog is by dropping it a pan of boiling water5.

As with any empirical results, several caveats are in order. Our results are based on the

decisions of more than 100 human subjects recruited from a subject pool consisting mostly of

undergraduate students in a US university. It is entirely possible that other populations would

be more or less tolerant of nuisances than ours, and thus have survivor curves with dierent

scale or location. However, it seems to us rather implausible that they would yield survivor

shapecurves with much dierent

than ours, but of course that can only be conrmed through

further research.

4 To see this, recall that the hazard rate h(x) = f (x)/S(x) is the density for switching at nuisance level x
conditional on not switching at a lower level, and for the Weibull distribution this function is proportional to
x-1. Thus h(x) is an increasing function if  > 1 and is decreasing if  < 1.
5Anecdotally, our result is in line with those of real frog boiling attempts, as reported in online interviews by
Dr. Victor Hutchinson Emeritus Professor of Biology at the University of Oklahoma http://srel.uga.edu/ outreach/ecoviews/ecoview071223.htm

12

A second caveat is that we have worked within the framework of a simple model, which neglected potentially important aspects of reality. For example, it ignored the arrival of new users. A slight extension of the model could easily incorporate them if their survivor curves resembled those of the original users. Although new users might dier from the originals in various ways, again there is no reason to suppose that their survivor curves have radically dierent shape.
Perhaps the more important caveat, and the most intriguing, is that the adaptation process may dier from that envisaged in the theoretical model. As noted in the literature survey, there is considerable recent empirical research on such matters, much of it inspired by Prospect Theory and in particular by KÆszegi and Rabin (2006). So far the work seems inconclusive, but when a consensus emerges on reference point dynamics, it should be incorporated into a richer model of dynamic decision making.
13

7 Appendix A: Details

In Table 4 we present the dierent nuisance levels for each activity, and report the number of observations at each level.

Inconvenience
Pi volume Pop-up Jitter Reading SAT
Movie Pay

Level 1
30[11] 30[11] .10[11] .15[11]
.6[9] 1[11]

Level 2
40[20] 25[19] .13[21] .18[21]
.9[8] 5[19]

Level 3
50[12] 20[12] .16[12] .21[12] .12[11] 9[12]

Level 4
60[22] 15[22] .19[22] .24[21] .15[11] 13[22]

Level 5
70[13] 10[13] .22[13] .27[13] .18[12] 17[13]

Level 6
80[20] 5[21] .25[19] .30[20] .21[12] 23[21]

Table 4: Nuisance Values [and Numbers of Observations].

In Table 5 we present the robustness checks for the probit model of Table 2, and present
the results for ordering (i.order), and a series of dummies pibigpopi,j , popbigpii,j , readbigsati,j , satbigreadi,j that test the eects of having similar activities with dierent levels of nuisance. For example, pibigpopi,j (popbigpii,j ) is a dummy for the case when the nuisance for Movie/Pi (Movie/Pop) is bigger than that for Movie/Pop (Movie/Pi); similarly readbigsati,j (satbigreadi,j )
is a dummy for the case where Reading (SAT) has a bigger nuisance level than SAT (Reading).
The results show that ordering has no statistical eect on the decisions of subjects, while
dierent levels of inconvenience for similar activities seem to have an eect when Movie/Pi has
a bigger nuisance than Movie/Pop (note that we only have 8 cases of this). Finally, for the 16
session dummies only one is signicantly dierent (at the 5%) from our baseline.
We conclude thus that our results are robust, and even if we have a few dummies with
signicant eects, these are probably due to small sample bias.

14

(4) Switch

[1em] 2.order [1em] 3.order [1em] 4.order [1em] 5.order [1em] 6.order [1em] 7.order [1em] 1.readbigsat [1em] 1.satbigread [1em] 1.popbigpi [1em] 1.pibigpop [1em] cons
N

-0.315 (0.223) -0.552 (0.382) -0.516 (0.334) -0.0737 (0.287) -0.248 (0.356)
0.443 (0.408) -0.249 (0.261) 0.0678 (0.515) -0.302 (0.408) 1.155 (0.536) -1.282 (0.221)
636

Session Dummies

Yes

Table 5: Switching Probit Model, Continued.

15

8 Appendix B: Description of activities

In this appendix we list all the activities that were not described in detail in the methods

section.
Movie/Pop: Subjects were presented with a menu of two video clips (an interview of Zack

Galianakis by Letterman, and a clip on how to do crossover moves in basketball). After 100

seconds of visualization, a 15 second long pop-up would appear on the screen. This pop-up

would partially cover the video clip, and have ashing colors; moreover, while the pop-up was

on the screen, the movie clip would continue playing in the background but with no sound. The

unit of the nuisance x  [5, 30] is the number of seconds between consecutive pop-ups, e.g., if a

x = 5subject was assigned a nuisance level of

, then she would have a 15 second pop-up every

5 seconds. If the subject decided that the nuisance was too big, then she could switch to the

bland activity which, as in all movie activities, was a video of gentle waves breaking at La Jolla

beach. Once a subject switched to the bland activity she would remain there until the end of

the round. Rounds lasted 8 minutes.

Note on wave watching: The bland activity for all movie activities is watching waves.

We decided to use this video because as it has no plot, that is, its replay value is very high,

allowing us to reuse it with almost no loss in its (relative) attractiveness.
Slug: Slug is a version of the classic video game Snake. Snake was a popular arcade game

in the 1970's but gained world-wide acceptance in 1998 as it became the standard pre-loaded

game in Nokia phones. The game has been used as Easter egg by both Youtube and Gmail.

In this game the objective is to get food, which corresponds to colored pixels that appear at

random points of the enclosed playing space. Each time the player gets to food she earns

points, but the slug increases in size, making it harder to maneuver. To get to the food subjects

control the slug with the keyboard arrows. If the slug bumps into the walls of the enclosed

playing space, or if it hits itself, the player loses. Losing has no cost in points, the subject just

need to restart the game by pressing the refresh button (F5 on the keyboard), and the game

starts over with the same amount of accumulated points. As mentioned, points are awarded by

getting to food; 10 points for regular food and 40 points for bonus food. The dierence between

these two types of food is that bonus food only stays on screen during 10 seconds, while normal

food is there until eaten. Food is color coded, with bonus food being yellow, and regular food

blue. Each point was worth $0.01. The jitter nuisance would start 50 seconds into the round,
and involves a random turn (left or right) each pixel with probability x  [.10, .25]. The bland

activity towards which subjects could switch was the same exact game without the jittering

nuisance, but paying only one fourth of the amounts in the original activity (i.e., 10 points per

bonus food, and 5 points for each piece of regular food eaten). Each round lasted 7 minutes.
Read: Subjects are given a menu with a series of articles from the New York Times (an

article on the Proposition B for LA county, an article on veterans of the Iraq war coming back
to the US, and an article on fee increase at the UC system). The nuisance x  [.15, .30] is the

(independent) probability for each letter of being dropped. The rst 15% of the text would be

nuisance free. On the other hand, the text was presented broken into paragraphs. To ensure

that subjects actually read the text, they could only move to the next paragraph by clicking a

next button that would appear 10 seconds after the start of every new paragraph. The bland

activity was counting bits, which presented subjects with a binary string of 15 digits, and asked

them to count how many 1's were in the string. If the answer was correct, then a new string

was generated. If the answer was wrong the subject would be given a new opportunity until

he answered correctly. This would last until the end of the round, which was 6 minutes long.
SAT: Subjects could pick between two dierent texts taken from an SAT practice web-

page. The text would be presented to subjects along with only one of the 8 multiple choice

16

questions they had in this round. All answers were nal, and once a choice was made the next question would appear, with no way of going back. This was a paid activity and each correct answer would pay $0.40, while each incorrect answer would penalize $0.10. The nuisance for this activity was letter dropping, and worked exactly as in the Read activity. In this case each
letter was dropped with probability x  [0.06, 0.21]. The bland activity was the same task with
all the letters, but paying one fourth (i.e., $0.10 for each correct answer and -$0.02 per incorrect answer). If a subject decided to switch, she would not start over all the questions, but would start the bland activity at the same question where she switched to activity B.
17

9 Appendix C: Instructions
Upon entering the lab subjects were read an initial set of instructions that described the structure of the experiment but did not give any details on the activities or inconveniences they would encounter; subjects were told that detailed instructions would be given before each round. These instructions appeared on separate pages for each separate task. However, to save space below, we omit the page breaks and put the detailed task instructions together in a single document.
9.1 General instructions
Welcome! This is an economics experiment. You will be a player in many periods of an interactive decision-making game. If you pay close attention to these instructions, you can earn a signicant sum of money. It will be paid to you in cash at the end of the last period.
It is important that you remain silent and do not look at other people's work. If you have any questions, or need assistance of any kind, please raise your hand and we will come to you. We expect and appreciate your cooperation today.
The Experiment: This experiment will have six dierent rounds. In each round you will begin with an enjoyable activity that we refer to as Activity A. At any time during the round you can switch to another activity, Activity B. The experimenter will announce the A and B activities for that round before it starts. At the same time, the experimenter will also announce an annoyance that will accompany Activity A at some point during that round. If, after experiencing the annoyance, you think you would prefer Activity B, then simply click the button on your screen. It will immediately switch you to B, where you will remain for the rest of the round. You will never be interrupted by any annoyance in Activity B. Key points:
∑ You will start each round participating in an A activity.
∑ A activities will be interrupted by specic annoyances (announced before the round).
∑ At any point during the round you can switch from activity A to activity B (announced
before the round)
∑ You can switch from A to B, but never from B to A.
∑ B activities do not have any interruptions.
Also note:
∑ Some rounds include a paid Activity and some do not.
∑ You automatically get to experience an A activity each round. To make sure that you are
familiar with all with B activities, you will practice with all of them before the experiment starts.
∑ For some of the activities the audio output is needed. Please check if you have headphones
attached to your computer. If you have your own, feel free to use them. You will be able to adjust the volume through the speaker icon on the upper right corner of your screen.
∑ Do not start Activity A until the experimenter announces that it is time to do so.
18

9.2 Specic activity instructions
Round Movie/Pi (8 minutes):
Activity A: Watching a video. You will choose it from a menu that will appear on screen. Annoyance: While watching the video, at some point you will start to hear a computerized
voice reading the rst few thousand digits of the decimal expansion of  = 3.14159 . . . This will
continue at the same volume until the end of the round, or until you switch to activity B.
Activity B: Watching a video of waves breaking at La Jolla beach. This is not a paid
round.
Round Movie/pop (8 minutes):
Activity A: Watching a video. You will choose it from a menu that will appear on screen. Annoyance: While watching the video, at some point a pop-up will appear on your screen
and mute the audio. These pop-ups are 15 second long, and will appear at regular intervals on your screen. The time remaining is shown on the pop-up.
Activity B: Watching a video of waves breaking at La Jolla beach. This is not a paid
round.
Round Slug (7 minutes):
Activity A: Playing a game called Slug, very similar to the popular game Snake. Use
your arrow keys to control a hungry slug. The slug gets longer as it eats food, and you earn points:
∑ Regular food (Blue Pixel): will stay on screen until you eat it, each piece that you eat
which gives you 20 points.
∑ Bonus food (Yellow Pixel): gives you 40 points, will appear randomly and only lasts for
10 seconds on screen, if you don't eat it during this time it disappears.
Your slug will die whenever it collides either with an edge of its rectangle or with its own body. But the points you earned are stored and accumulated, and you can begin again with a new slug. Just hit the refresh page key (F5) and the game will restart with a new short slug.
Annoyance: At some point the slug starts to jitter. That is, with some probability, it
will change direction randomly each time it reaches a new pixel. The jitter rate (probability) will remain the same for Activity A the rest of the round.
Activity B: Playing the same game, Slug, but with two dierences:
∑ The slug will not jitter ∑ You will earn points at 1/4 the previous rate: 5 points per blue pixel, 10 per yellow.
19

Round Read (6 minutes):
Activity A: Reading newspaper articles. You will choose one from a menu, and the text
will appear on your screen. The text will be broken up into dierent pages. After 10 seconds next page button will appear. Just click the button to move to the next page. On the last page, please press the button to indicate when you are done reading the article.
Annoyance: In this activity the annoyance will be that some letters of the text will be
missing. With a certain probability letters will be dropped from the article. This will apply to all the text, except the very beginning. As usual, press the button if you would rather go to the B activity than continue trying to read the article with missing letters.
Activity B: Counting the number of 1's in a string of 0's and 1's. If enter the correct
number, then you will get 1 point and a new array of numbers will be randomly generated for you to count. If your answer is incorrect, then you will not get any points and will still have the same array of binary numbers for you to count. There is no limit to the number of attempts for each array. This is a activity  you get no money for the points!
Round SAT (8 minutes):
Activity A: Answering SAT questions. You will pick one of two sets of multiple choice
questions. You will get paid 40 points per correct answer and will lose 10 points for incorrect answers. Your points are accumulated as you go and are shown on the screen. You will get to see 1 question at a time which you will be able to answer. Once you have answered a question you will NOT be able to change it, so you choice is always nal.
Annoyance:: Except for the rst question, some letters of the text will be missing. With
a certain probability each letter will be dropped from each SAT question. As usual, you can press the button that takes you to activity B at any moment of the round.
Activity B: In this case the B activity will be the same SAT text, except it will have all
the letters in the text, and it will pay you 10 points per correct answer and subtract 2 points if the answer is incorrect. If you switch to activity B you will start at the same point where you decided to change from A to B. So, for example, if you decided to switch at question 3, you will start activity B at question 3. Note that you can come out with negative earnings from this activity.
Movie/Pay (8 minutes):
Activity A: In this round you will be oered to pick from a series of clips to watch. On
top of this you will be endowed with 500 points for you to keep.
Annoyance: Some seconds into the video you will be asked to pay a fee (in experimental
points) if you want to continue watching the video.
Activity B: If you don't pay, the video will switch to waves breaking at La Jolla beach.
20

References
Johannes Abeler, Armin Falk, Lorenz Goette, and David Human. Reference points and eort provi-
sion. The American Economic Review, 101(2):470492, 2011. Christina Aperjis and Bernardo A. Huberman. Adaptation and the provider's dilemma. Available at
SSRN 1672820, 2011. Christina Aperjis and Bernardo A. Huberman. Introducing revenue-generating features. Patent. US
8271312, 2012.
Dan Ariely. Combining experiences over time: The eects of duration, intensity changes, and on-
line measurements on retrospective pain evaluations. Journal of Behavioral Decision Making, 11:
1945, 1998.
Mark Bagnoli and Ted Bergstrom. Log-concave probability and its applications. Economic Theory, 26
(2):445469, 2005.
Manel Baucells, Martin Weber, and Frank Welfens. Reference-point formation and updating. Management Science, 57(3):506519, 2011.
M. R. Baye and J. Morgan. A simple model of advertising and subscription fees. Economics Letters,
69:345351, 2000.
H.A. Chen, D. Levy, S. Ray, and M. Bergen. Asymmetric price adjustment in the small. Journal of Monetary Economics, 55(4):728737, 2008.
Gadi Fibich, Arieh Gavious, and Oded Lowengart. Explicit solutions of optimization models and
dierential games with nonsmooth (asymmetric) reference-price eects. Operations Research, 51
(5):721734, 2003.
Gadi Fibich, Arieh Gavious, and Oded Lowengart. The dynamics of price elasticity of demand in the
presence of reference price eects. Journal of the Academy of Marketing Science, 33(1):6678,
2005.
Shane Frederick and George Loewenstein. Hedonic adaptation. In Daniel Kahneman and Ed Diener,
editors, Well-being: The foundations of hedonic psychology, pages 302329. 1999. Uri Gneezy. Deception: The role of consequences. The American Economic Review, 95(1):384394,
2005.
David Godes, Elie Ofek, and Miklos Sarvary. Content vs. advertising: The impact of competition on
media rm strategy. Marketing Science, 28(1):2035, 2009. Laurence Goldstein. How to boil a live frog. Analysis, 60(266):170178, April 2000. ISSN 1467-
8284. doi: 10.1111/1467-8284.00220. URL http://onlinelibrary.wiley.com/doi/10.1111/ 1467-8284.00220/abstract.
Ori Heetz and John A. List. Is the endowment eect a reference eect? NBER Working Paper 16715,
2011.
Dominic Hyde. Sorites paradox. In Edward N. Zalta, editor, The Stanford Encyclopedia of Philosophy.
Winter 2011 edition, 2011.
D. Kahneman, B.L. Fredrickson, C.A. Schreiber, and D.A. Redelmeier. When more pain is preferred
to less: Adding a better end. Psychological Science, 4(6):401405, 1993. Daniel Kahneman and Amos Tversky. Prospect theory: An analysis of decision under risk. Economet-
rica, 47(2):263292, 1979.
Gurumurthy Kalyanaram and Russell S. Winer. Empirical generalizations from reference price research.
Marketing Science, 14(3):161169, 1995.
Botond KÆszegi and Matthew Rabin. A model of reference-dependent preferences. 121(4):11331165, 2006.
Praveen K. Kopalle, Ambar G. Rao, and Joao L. Assuncao. Asymmetric reference price eects and
dynamic pricing policies. Marketing Science, 15(1):6085, 1996.
21

Subodha Kumar and Suresh P. Sethi. Dynamic pricing and advertising for web content providers.
European Journal of Operational Research, 197:924944, 2009.
Tridib Mazumdar, S.P. Raj, and Indrajit Sinha. Reference price research: Review and propositions.
Journal of Marketing, 69:84102, 2005.
Javad Nasiry and Ioana Popescu. Dynamic pricing with loss averse consumers and peak-end anchoring.
INSEAD Working Paper No. 2010/102/DS, 2010. Ioana Popescu and Yaozhong Wu. Dynamic pricing strategies with reference eects. Operations
Research, 55(3):413429, 2007.
Ashutosh Prasad, Vijay Mahajan, and Bart Bronnenberg. Advertising versus pay-per-view in electronic
media. Intern. J. of Research in Marketing, 20:1330, 2003. W.S. Quinn. The puzzle of the self-torturer. Philosophical studies, 59(1):7990, 1990.
22

SFB 649 Discussion Paper Series 2014
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.

001 002 003 004 005 006 007 008 009 010 011 012 013 014 015 016 017 018

"Principal Component Analysis in an Asymmetric Norm" by Ngoc Mai Tran, Maria Osipenko and Wolfgang Karl H‰rdle, January 2014. "A Simultaneous Confidence Corridor for Varying Coefficient Regression with Sparse Functional Data" by Lijie Gu, Li Wang, Wolfgang Karl H‰rdle and Lijian Yang, January 2014. "An Extended Single Index Model with Missing Response at Random" by Qihua Wang, Tao Zhang, Wolfgang Karl H‰rdle, January 2014. "Structural Vector Autoregressive Analysis in a Data Rich Environment: A Survey" by Helmut L¸tkepohl, January 2014. "Functional stable limit theorems for efficient spectral covolatility estimators" by Randolf Altmeyer and Markus Bibinger, January 2014. "A consistent two-factor model for pricing temperature derivatives" by Andreas Groll, Brenda LÛpez-Cabrera and Thilo Meyer-Brandis, January 2014. "Confidence Bands for Impulse Responses: Bonferroni versus Wald" by Helmut L¸tkepohl, Anna Staszewska-Bystrova and Peter Winker, January 2014. "Simultaneous Confidence Corridors and Variable Selection for Generalized Additive Models" by Shuzhuan Zheng, Rong Liu, Lijian Yang and Wolfgang Karl H‰rdle, January 2014. "Structural Vector Autoregressions: Checking Identifying Long-run Restrictions via Heteroskedasticity" by Helmut L¸tkepohl and Anton Velinov, January 2014. "Efficient Iterative Maximum Likelihood Estimation of HighParameterized Time Series Models" by Nikolaus Hautsch, Ostap Okhrin and Alexander Ristig, January 2014. "Fiscal Devaluation in a Monetary Union" by Philipp Engler, Giovanni Ganelli, Juha Tervala and Simon Voigts, January 2014. "Nonparametric Estimates for Conditional Quantiles of Time Series" by J¸rgen Franke, Peter Mwita and Weining Wang, January 2014. "Product Market Deregulation and Employment Outcomes: Evidence from the German Retail Sector" by Charlotte Senftleben-Kˆnig, January 2014. "Estimation procedures for exchangeable Marshall copulas with hydrological application" by Fabrizio Durante and Ostap Okhrin, January 2014. "Ladislaus von Bortkiewicz - statistician, economist, and a European intellectual" by Wolfgang Karl H‰rdle and Annette B. Vogt, February 2014. "An Application of Principal Component Analysis on Multivariate TimeStationary Spatio-Temporal Data" by Stephan Stahlschmidt, Wolfgang Karl H‰rdle and Helmut Thome, February 2014. "The composition of government spending and the multiplier at the Zero Lower Bound" by Julien Albertini, Arthur Poirier and Jordan RoulleauPasdeloup, February 2014. "Interacting Product and Labor Market Regulation and the Impact of Immigration on Native Wages" by Susanne Prantl and Alexandra SpitzOener, February 2014.

SFSBF6B4694, 9S,pSapnadnaduaeureSrtrSatﬂraeﬂ1e, 1D,-D10-1107187B8eBrleinrlin htthpt:t/p/:/s/fbs6fb4694.w9.iwwiiw.hiu.h-bue-brleinrl.idne.de
ThTishrisesreasrecahrcwhawsassupsuppoprtoerdtebdybtyhethDeeDuetsucthseche ForFsocrhsuchnugnsgesgmeeminesicnhsachftatfht rtohuroguhgthhethSeFSBF6B4694"9Ec"oEnconmoimc RicisRki"s.k".

SFB 649 Discussion Paper Series 2014
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
019 "Unemployment benefits extensions at the zero lower bound on nominal interest rate" by Julien Albertini and Arthur Poirier, February 2014.
020 "Modelling spatio-temporal variability of temperature" by Xiaofeng Cao, Ostap Okhrin, Martin Odening and Matthias Ritter, February 2014.
021 "Do Maternal Health Problems Influence Child's Worrying Status? Evidence from British Cohort Study" by Xianhua Dai, Wolfgang Karl H‰rdle and Keming Yu, February 2014.
022 "Nonparametric Test for a Constant Beta over a Fixed Time Interval" by Markus Reiﬂ, Viktor Todorov and George Tauchen, February 2014.
023 "Inflation Expectations Spillovers between the United States and Euro Area" by Aleksei Netsunajev and Lars Winkelmann, March 2014.
024 "Peer Effects and Students' Self-Control" by Berno Buechel, Lydia Mechtenberg and Julia Petersen, April 2014.
025 "Is there a demand for multi-year crop insurance?" by Maria Osipenko, Zhiwei Shen and Martin Odening, April 2014.
026 "Credit Risk Calibration based on CDS Spreads" by Shih-Kang Chao, Wolfgang Karl H‰rdle and Hien Pham-Thu, May 2014.
027 "Stale Forward Guidance" by Gunda-Alexandra Detmers and Dieter Nautz, May 2014.
028 "Confidence Corridors for Multivariate Generalized Quantile Regression" by Shih-Kang Chao, Katharina Proksch, Holger Dette and Wolfgang H‰rdle, May 2014.
029 "Information Risk, Market Stress and Institutional Herding in Financial Markets: New Evidence Through the Lens of a Simulated Model" by Christopher Boortz, Stephanie Kremer, Simon Jurkatis and Dieter Nautz, May 2014.
030 "Forecasting Generalized Quantiles of Electricity Demand: A Functional Data Approach" by Brenda LÛpez Cabrera and Franziska Schulz, May 2014.
031 "Structural Vector Autoregressions with Smooth Transition in Variances ≠ The Interaction Between U.S. Monetary Policy and the Stock Market" by Helmut L¸tkepohl and Aleksei Netsunajev, June 2014.
032 "TEDAS - Tail Event Driven ASset Allocation" by Wolfgang Karl H‰rdle, Sergey Nasekin, David Lee Kuo Chuen and Phoon Kok Fai, June 2014.
033 "Discount Factor Shocks and Labor Market Dynamics" by Julien Albertini and Arthur Poirier, June 2014.
034 "Risky Linear Approximations" by Alexander Meyer-Gohde, July 2014 035 "Adaptive Order Flow Forecasting with Multiplicative Error Models" by
Wolfgang Karl H‰rdle, Andrija Mihoci and Christopher Hian-Ann Ting, July 2014 036 "Portfolio Decisions and Brain Reactions via the CEAD method" by Piotr Majer, Peter N.C. Mohr, Hauke R. Heekeren and Wolfgang K. H‰rdle, July 2014 037 "Common price and volatility jumps in noisy high-frequency data" by Markus Bibinger and Lars Winkelmann, July 2014 038 "Spatial Wage Inequality and Technological Change" by Charlotte Senftleben-Kˆnig and Hanna Wielandt, August 2014 039 "The integration of credit default swap markets in the pre and postsubprime crisis in common stochastic trends" by Cathy Yi-Hsuan Chen, Wolfgang Karl H‰rdle, Hien Pham-Thu, August 2014
SFB 649, Spandauer Straﬂe 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

SFB 649 Discussion Paper Series 2014
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
040 "Localising Forward Intensities for Multiperiod Corporate Default" by Dedy Dwi Prastyo and Wolfgang Karl H‰rdle, August 2014.
041 "Certification and Market Transparency" by Konrad Stahl and Roland Strausz, September 2014.
042 "Beyond dimension two: A test for higher-order tail risk" by Carsten Bormann, Melanie Schienle and Julia Schaumburg, September 2014.
043 "Semiparametric Estimation with Generated Covariates" by Enno Mammen, Christoph Rothe and Melanie Schienle, September 2014.
044 "On the Timing of Climate Agreements" by Robert C. Schmidt and Roland Strausz, September 2014.
045 "Optimal Sales Contracts with Withdrawal Rights" by Daniel Kr‰hmer and Roland Strausz, September 2014.
046 "Ex post information rents in sequential screening" by Daniel Kr‰hmer and Roland Strausz, September 2014.
047 "Similarities and Differences between U.S. and German Regulation of the Use of Derivatives and Leverage by Mutual Funds ≠ What Can Regulators Learn from Each Other?" by Dominika Paula Galkiewicz, September 2014.
048 "That's how we roll: an experiment on rollover risk" by Ciril Bosch-Rosa, September 2014.
049 "Comparing Solution Methods for DSGE Models with Labor Market Search" by Hong Lan, September 2014.
050 "Volatility Modelling of CO2 Emission Allowance Spot Prices with RegimeSwitching GARCH Models" by Thijs Benschopa, Brenda LÛpez Cabrera, September 2014.
051 "Corporate Cash Hoarding in a Model with Liquidity Constraints" by Falk Mazelis, September 2014.
052 "Designing an Index for Assessing Wind Energy Potential" by Matthias Ritter, Zhiwei Shen, Brenda LÛpez Cabrera, Martin Odening, Lars Deckert, September 2014.
053 "Improved Volatility Estimation Based On Limit Order Books" by Markus Bibinger, Moritz Jirak, Markus Reiss, September 2014.
054 " Strategic Complementarities and Nominal Rigidities" by Philipp Kˆnig, Alexander Meyer-Gohde, October 2014.
055 "Estimating the Spot Covariation of Asset Prices ≠ Statistical Theory and Empirical Evidence" by Markus Bibinger, Markus Reiss, Nikolaus Hautsch, Peter Malec, October 2014.
056 "Monetary Policy Effects on Financial Intermediation via the Regulated and the Shadow Banking Systems" by Falk Mazelis, October 2014.
057 "A Tale of Two Tails: Preferences of neutral third-parties in three-player ultimatum games" by Ciril Bosch-Rosa, October 2014.
058 "Boiling the frog optimally: an experiment on survivor curve shapes and internet revenue" by Christina Aperjis, Ciril Bosch-Rosa, Daniel Friedman, Bernardo A. Huberman4, October 2014.
SFB 649, Spandauer Straﬂe 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

