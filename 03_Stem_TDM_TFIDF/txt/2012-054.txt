BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2012-054
Modeling Time-Varying Dependencies between Positive-Valued HighFrequency Time Series
Nikolaus Hautsch * Ostap Okhrin *
Alexander Ristig *
* Humboldt-Universit‰t zu Berlin, Germany
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universit‰t zu Berlin Spandauer Straﬂe 1, D-10178 Berlin

Modeling Time-Varying Dependencies between Positive-Valued High-Frequency Time Series
Nikolaus Hautsch, Ostap Okhrin and Alexander Ristig
Abstract Multiplicative error models (MEM) became a standard tool for modeling conditional durations of intraday transactions, realized volatilities and trading volumes. The parametric estimation of the corresponding multivariate model, the so-called vector MEM (VMEM), requires a specification of the joint error term distribution, which is due to the lack of multivariate distribution functions on R+d defined via a copula. Maximum likelihood estimation is based on the assumption of constant copula parameters and therefore, leads to invalid inference, if the dependence exhibits time variations or structural breaks. Hence, we suggest to test for time-varying dependence by calibrating a time-varying copula model and to reestimate the VMEM based on identified intervals of homogenous dependence. This paper summarizes the important aspects of (V)MEM, its estimation and a sequential test for changes in the dependence structure. The techniques are applied in an empirical example.
Keywords: vector multiplicative error model, copula, time-varying copula, highfrequency data
JEL classification: C32, C51
Acknowledgements The financial support from the Deutsche Forschungsgemeinschaft via SFB 649 O® konomisches Risiko, Humboldt-Universita®t zu Berlin is gratefully acknowledged.
Nikolaus Hautsch Professor, Chair of Econometrics, Humboldt-Universita®t zu Berlin, School of Business and Economics, Germany, e-mail: nikolaus.hautsch@wiwi.hu-berlin.de Ostap Okhrin Assistant Professor, Ladislaus von Bortkiewicz Chair of Statistics, Humboldt-Universita®t zu Berlin, School of Business and Economics, Germany, e-mail: ostap.okhrin@hu-berlin.de Alexander Ristig Research Fellow, Ladislaus von Bortkiewicz Chair of Statistics, Humboldt-Universita®t zu Berlin, School of Business and Economics, Germany, e-mail: ristigal@hu-berlin.de
1

2 Nikolaus Hautsch, Ostap Okhrin and Alexander Ristig
1 Multiplicative error models
MEMs are frequently applied to describe autocorrelated positive-valued processes. The multiplicative structure became popular in the context of (G)ARCH models, see [8, 2]. [9] adopted this multiplicative approach to analyze the conditional duration of irregularly spaced financial transaction data under the assumption that the error term follows an Exponential or Weibull distribution. This extends directly to MEMs, when other positive-valued random variables such as, e.g., trading volumes, are considered. As stressed by [9], a joint model including volumes, transaction prices and time variations in liquidity gives a better understanding of the fundamental mechanisms of stock markets than individual univariate analyses.

1.1 Univariate MEM

Let xi be a non-negative univariate time series, with time index i = 1, . . . , n. The univariate MEM is defined as

xi = µi i µi d=ef E (xi|Fi-1;  ) ,

(1)

where  denotes an m-dimensional vector of parameters and the scale factor µi is assumed to be measurable with respect to the information set Fi-1. Furthermore, assume that i follows an iid process with E (i) = 1 and density f (∑). The condi-
tional mean can be specified in several ways, e.g.,

PQ
 µi =  +  jxi- j +  j µi- j, j=1 j=1

(2)

with   0,  j  0 and  j  0,  j,  = (, 1, . . . , P, 1, . . . , Q) . Based on the

filters



(L)

=

Rj=1



j

L

j

=

Rj=1

(

j

+



j

)

L

j

,



(L)

=

Q
 j=1



j

L

j

and

the

martingale

difference series i = xi - µi, (2) can be transformed to an ARMA(R, Q) model

xi =  +  (L) xi + {1 -  (L)} i,

(3)

where R = max (P, Q) and L denotes the lag operator with L jxi = xi- j. Accord-

ing to standard time series arguments, (3) is guaranteed to be weakly stationary, if

Pj=1



j

+

Q
 j=1



j

<

1.

Given

the

above

set

of

assumptions,

we

implicitly

assume

an

exponential decay of the autocorrelation function (∑), i.e., liml lj=-l | ( j)| <

. However, in case of financial high-frequency data this assumption is often not

fulfilled.

As such data typically reveal long memory, we provide a short review of the

fractionally integrated MEM (FIMEM), which allows the autocorrelation function

Modeling Time-Varying Dependencies between Positive-Valued Time Series

3

of the underlying random variable to decay hyperbolically. Formally, xi exhibits long

memory

if

liml

l
 j=-l

|

(

j)|

=

.

Following

[1],

[14]

specifies

the

FIMEM

in

the

context of conditional durations by introducing the fractional difference operator

(1 - L) to equation (3), i.e.,

{1 -  (L)} (1 - L) xi =  + {1 -  (L)} i,

(4)

with   [0, 1] the fractional integration parameter. [13] defines the fractional difference operator by a binomial series:

 
(1 - L) =
j=0

 j


(-1) j L j =  jL j.
j=0

(5)

Substituting the martingale difference series defined above in (4) leads to

{1 -  (L)} µi =  + 1 -  (L) - {1 -  (L)} (1 - L) xi µi =  {1 -  (1)}-1 +  (L) xi,

(6)

where  (L) = j=1  jL j. The linear filter  (L) implies an infinite number of parameter restrictions to guarantee the non-negativity of µi, i.e.,  j  0,  j. As a

consequence, in practice the filter  (L) is truncated to a finite number of lags or

one needs to apply Theorem 3 of [6] to verify that the combination of parameters

of the FIMEM(P;  ; Q) are within the feasible parameter space. To emphasize this

point, consider the following two extreme examples for which we assume that  lies

within the unit interval, such that  j < 0, for j > 0. Then, (i) µi can become nega-

tive although all parameters are greater than zero and (ii) µi can be positive almost

surely for all i, even though all parameters except  are negative. Note, that these

restrictions play a fundamental role for the validity of forecasts.

The first unconditional moment of xi is not defined, since the fractional difference

operator evaluated at L = 1 equals zero. As a result, the FIMEM is not covariance

stationary.

If

the

parameters

are

non-negative

and

P
 j=1



j

+

Q
 j=1

j

<

1,

then

the

strict stationarity and ergodicity of the FIMEM can be deduced from the stationarity

and ergodicity of the integrated MEM, since the infinite-order representation of (6)

is dominated in an absolute value sense by the coefficients of the corresponding

integrated MEM, cf. [3, 1]. Alternative covariance stationary long memory MEMs

are discussed in [12].

In general, parametric ML estimation of univariate MEMs leads to asymptot-

ically efficient and unbiased estimates, if the distribution of the innovations i is

specified correctly. Typical candidates to describe i are the standard Exponential

or Weibull distribution, but flexible distributions as the generalized Gamma or F

distribution can also be considered. In a standard ML framework for time series

models, where i( ), i = 1, . . . , n, denotes the i-th contribution to the log likeli-

hood

( ) = ni=1

i( ),

Hn( )

=

ni=1

{



2 

i( )} denotes the Hessian matrix

and

Sn( )

=

in=1{

 

i(

)



 

i( )} the outer product of scores, the limiting dis-

4 Nikolaus Hautsch, Ostap Okhrin and Alexander Ristig

tribution of the estimator ^ is given by Hn( )-1Sn( )Hn( )-1 -1/2 n(^ -  ) L N (0m, Im} ,

(7)

with identity matrix Im. Statistical inference is based on the finite sample approximation of (7), i.e., the Hessian matrix and the outer score product are replaced by the consistent estimates Hn(^) and Sn(^).
Furthermore, [9] adopts the asymptotic theory of [16] and proposes a quasi-ML setup which leads to consistent estimates for the linear and integrated MEM even if the true error term distribution does not correspond to the assumed standard Exponential distribution. In this case, ^ converges under some regularity conditions to the asymptotic distribution of (7) as long as the conditional mean is correctly specified.

1.2 Vector MEM

[5] formalizes the VMEM as

xi = µi i,

(8)

where denotes the Hadamard product and xi = (xi1, . . . , xid) , i = 1, . . . , n, is the vector of positive valued processes. The multivariate scale factor µi d=ef E (xi|Fi-1;  ) and the vector of error terms i are (d ◊ 1) vectors. The natural multivariate exten-
sion of (6) is given by

[Id - B (L)] µi =  + [Id - B (L) - {Id -  (L)} D] xi,

(9)

with  (L) = A (L) + B (L) and A, B being (d ◊ d) matrices. Short-run effects enter equation (9) through the linear filters A(L) and B(L) and  denotes the vector of constants. The univariate fractional difference operator from (6) extends to the diagonal matrix diag (D) = {(1 - L)1 , ∑ ∑ ∑ , (1 - L)d }, which contains the individual fractional difference operators, with  j  [0, 1], j = 1, . . . , d. By this restriction, we exclude deterministic low frequency patterns between the marginal time series. Note that the individual mean equations of (9) collapse to the univariate FIMEM (6), if A and B are diagonal and to the linearly parameterized MEM (2), if additionally  j = 0, j = 1, . . . , d. Based on the diagonality assumption for A and B the model can be estimated equation by equation and is stationary.
For the full parametric specification of the VMEM we need to define an innovation process i, i = 1, . . . , n, which must follow a distribution with only positive probabilities on Rd+ = [0, )d and E (i j) = 1, j = 1, . . . , d. However, the distribution function of a univariate error term process does not have a natural multivariate equivalent. Therefore, the d marginal distributions are coupled together with a copula splitting a multivariate distribution function into its margins and a pure dependence component ≠ the copula. Copulae are introduced in [23] stating that if F is an arbitrary d-dimensional continuous distribution function of the random variables

Modeling Time-Varying Dependencies between Positive-Valued Time Series

5

X1, . . . , Xd, then the associated copula is unique and defined as a continuous function C : [0, 1]d  [0, 1] which satisfies the equality

C(u1, . . . , ud) = F{F1-1(u1), . . . , Fd-1(ud)}, u1, . . . , ud  [0, 1],

(10)

where F1-1(∑), . . . , Fd-1(∑) are the quantile functions of the continuous marginal distribution functions F1(x1), . . . , Fd(xd). Based on the copula density c (∑, . . . , ∑;  ), the log likelihood of the VMEM can be written as

nd

 ( ,  , |Fi-1) =

log i j ( j) f j i j ( j) ;  j - log xi j

i=1 j=1

(11)

n
+ log c [F1 {i1 (1) , 1} , . . . , F1 {id (d) , d} ;  ] , i=1

with xi/µi ( ) |Fi-1 = i ( ) |Fi-1  C [F1 {i1 (1) , 1} , . . . , F1 {id (d) , d} ;  ] having expectation one, where  denotes the copula-,  the marginal- and  the mean-parameters, cf. [5]. Conversely to the Hadamard product, xi/µi denotes element-wise division. The efficient approach to obtain parameter estimates is given by full ML estimation, as the multivariate density function is assumed to be known, i.e., the product of the marginal densities multiplied with the copula density. On the other hand, full ML estimation is difficult to implement even if the induced dependence is non-elliptical. E.g., if we assume a Vine- or hierarchical Archimedean copula (HAC), (see Section 2), the copula density varies with the structure of the underlying copula. Thus, the log likelihood must be optimized for each possible structure and the parameter vector generating the largest log likelihood value is selected as ML estimate. To avoid this computationally intensive method, a two-step procedure similar to [4] can be straightforwardly applied, since (11) can be decomposed into a marginal and a copula part as follows: First, the parameters of the mean equation are estimated to filter the residuals, for which only the information about the marginal distributions is used. Then, the copula is calibrated to the fitted values of the residuals' empirical distribution functions.
Similar to classical risk management applications, where several time-varying models for correlations and copulae are proposed, e.g., [7, 22], time-varying dependence cannot be excluded in our context and consequently, the copula estimated at the second step may contain time variations. Yet, the final target of VMEMs is not to predict, e.g., tail dependencies or risk measures, but to produce forecasts of µi, which crucially depend on precise parameter estimates and thus on the complete log likelihood and the most recent data for which the dependence between the variables is constant. Thus, we suggest to re-estimate the parameters of µi by maximizing (11) with fixed  for time intervals at which the copula model calibrated at the second step supports constant dependence.

6 Nikolaus Hautsch, Ostap Okhrin and Alexander Ristig
2 Hierarchical Archimedean Copulae
Among other important families, there exists the class of Archimedean copulae (AC), which (i) permits modeling non-elliptical dependencies, (ii) can describe different types of tail dependencies and (iii) has a closed form expression. Formally, AC are defined through the generator function   L = { : [0; )  [0, 1] |  (0) = 1,  () = 0; (-1)i(i)  0; i  N} and (-1)i(i)(x) being nondecreasing and convex on [0, ), for x > 0, which commonly depends on a single parameter  , i.e.,
C(u1, . . . , ud;  ) =  -1(u1) + ∑ ∑ ∑ + -1(ud) , u1, . . . , ud  [0, 1]. (12)
Properties of Archimedean copulae are reviewed and investigated in [18, 15]. [19] discusses generator families depending on two parameters. The restricted dependence structure induced by Archimedean generators is the major disadvantage of d-dimensional ACs, since this assumption is mostly violated in practice.
To permit more flexibility, arguments of an AC can be replaced by further ACs leading to the concept of HAC, which can adopt arbitrary complicated structures denoted by s in the following. The generators of a single HAC,  j, can come from different generator families. However, if the j 's come from the same family, the required complete monotonicity of -j+11  j imposes constraints on the parameters 1, . . . , d-1. The flexibility induced by the structure is accompanied by larger amounts of parameters, as each generator composition corresponds to one additional parameter. Sufficient conditions on the generator functions guaranteeing that C is a copula are stated in [17]. It holds that if j  L, for j = 1, . . . , d - 1, and -j+11  j have completely monotone derivatives, then C is a copula for d  2. The major advantage of HACs compared to ACs is the non-exchangeability of the arguments beyond a single node, which is imposed by the structure of a HAC. Similar to the dependence parameters, s is generally unknown and can be regarded as an additional parameter to estimate.
A sequential estimation procedure for HACs is discussed by [20] providing statistical inference for parametric and nonparametric estimated margins. The procedure uses Proposition 1 of [21] stating that HACs can be uniquely reconstructed from marginal distributions and bivariate copula functions. The estimation procedure can be summarized in the following way: at the first step, estimate all binary copula parameters of a specified Archimedean family under the assumption of known marginal distribution functions. Select the largest parameter and fix the binary copula as pseudo-variable. At next steps, assume the estimated margins and sub-copulae from lower levels are known and estimate all binary copula parameters by considering pairs of margins, pairs of pseudo variables and pairs of margins and pseudo variables. Then, choose the largest parameter and fix the corresponding copula as a pseudo variable. This procedure leads a binary approximation of an arbitrary HAC. Let i = {i1, . . . , id} be the sample, i = 1, . . . , n, and  = (1, . . . , d-1) be the copula parameters ordered from the lowest to the highest hierarchical level.

Modeling Time-Varying Dependencies between Positive-Valued Time Series

7

The multi-stage ML-estimator, ^ , provides a solution for the following system of equations

where

 1 , . . . ,  d-1  1  d-1

= 0,

n

j =  l j(i), for j = 1, . . . , d - 1,

i=1

(13)

l j(i) = log c {Fm(im)}msj ; s j,  j

f^m(im)

ms j

for i = 1, . . . , n,

where denotes the copula part of (11) and s j contains the indices, which are structured according to the fixed subcopulae (and margins) at lower hierarchical levels.

3 Change point detection

The time intervals for which the parameters of µi should be re-estimated are identified by calibrating a time-varying copula. In this context, [11] proposes a framework,
which incorporates time-varying HAC parameters i and si, and is closely related to the local change point (LCP) procedure applied in [24]. As a detailed discussion of
this sophisticated method is beyond the scope of this paper, this section describes
only the main ideas of the data driven LCP.
Let i, si be the unknown time-varying parameters and structure of the HAC C. Let I = [i0 - m, i0] denote an interval with reference point i0, m > 0 and let I ( , s) = iI K {c (∑, i, si) , c (∑;  , s)} be a random quantity, where K (∑, ∑) denotes the Kullback-Leibler divergence. Furthermore, let I ( , s)   be the small modeling bias (SMB) condition with   0 and constant parameters  , s. As K (∑, ∑) measures the discrepancy between two densities, the data generating process can be well approximated by the local constant copula C (∑;  , s) on I in the sense of the SMB condition. Based on this condition [11] proposes testing whether a HAC with
time-varying parameters and structure can be locally approximated by a HAC with
constant parameters and structure.
Under the null hypothesis assume that the SMB condition holds for interval I and parameters { , s} and define the set of possible change points TI for interval I, which is tested for a single but unknown change point   TI. The test hypotheses are formalized as

H0 :    TI, i =  , si = s,  i  I = J  JC = [, i0]  [i0 - m, )
H1 :    TI, i = 1, si = s1,  i  J = [, i0] , and i = 2 = 1 or si = s2 = s1,  i  JC = [i0 - m, ).

(14)

8 Nikolaus Hautsch, Ostap Okhrin and Alexander Ristig
The null hypothesis is rejected, if the likelihood ratio (LR) test statistic

TI = max
 TI

max {
1 ,s1

J (1, s1)} + max {
2 ,s2

JC

(2,

s2)}

-

max
 ,s

{

I ( , s)}

,

(15)

exceeds the critical value zI. In practice, the length of the homogenous interval and the parameters of interest { , s} are estimated simultaneously due to their relation through the test statistic. For a well performing choice of the critical value, which is found via a Monte-Carlo simulation from the local parametric model and implicitly defines the significance level of the test statistic TI, we refer to [24].

4 Empirical analysis

The considered time span of NASDAQ trade data for Apple (AAPL) starts at the January 2nd and ends at December 31th, 2009. Similar to the cleaning of TAQ data sets as, e.g., applied in [12], all non-executed trades, trades with a price smaller or equal to zero and outliers are removed from our tick-by-tick high-frequency data set. To overcome the phenomenon of simultaneous observations, trades with the same time stamp are merged and the corresponding values are aggregated by their median. A cleaned tick-by-tick data set provides information about (i) the price series p j, (ii) the amount of traded shares s j and (iii) the time stamp of the trades t j, j = 1, . . . , n, where n is the number of daily observations. To investigate the relationships between these series, we construct the series of high-low ranges (HL), average volumes (Vol) and the number of trades (NT) on a sampling frequency of 10 min, i.e.,

HLi = max p j|t j  (ti-1,ti]

NTi = # t j|t j  (ti-1,ti] ,

Voli = NTi-1

sj,

t j(ti-1,ti]

- min

p j|t j  (ti-1,ti]

,

(16)

for i = 1, . . . , n, where # counts the elements of the set {∑}. Note, that other proxies
for price variations as, e.g., the 10 min realized volatility or the squared returns, can
replace the high-low range.
To remove the U-shaped daily seasonal pattern provided by the variables defined
above, the individual seasonal components are approximated by fitting cubic splines
and each series is divided by the respective estimated seasonal factor. Then, model (8) with mean (9) is calibrated to the process, where A(L) and B(L) are restricted
to be diagonal and to the first lag. The infinite sums of the mean equations of the FIMEMs are truncated to 400 lagged coefficients, i.e., l4j0=00 lj Llj , since the parameters  j are almost unaffected by including additional lj 's, j = 1, . . . , d. Despite these restrictions, the estimated models produce uncorrelated residuals. Figure 1
presents scatterplots of the filtered residuals. The lower diagonal elements of Figure

Modeling Time-Varying Dependencies between Positive-Valued Time Series

9

1 do not reveal elliptical dependencies, thus the Gaussian copula is inappropriate in this case. In the following, we prefer an approximation of the dependence structure by the hierarchical or simple Archimedean Gumbel copula, since the bivariate contour plots indicate almost the same dependencies as the underlying scatterplots.

HL

0.12 0.12 0.12

0.04 0.06
0.08 0.1 0.02

Vol

0.04 0.08

0.06 0.02

0.1

0.04 0.08

0.06 0.02

0.1

NT

Fig. 1 The upper diagonal elements show the pairwise dependence between the filtered residuals. The lower diagonal elements present the values of the standard normal quantile applied to the values of the empirical distribution functions. Scales of the axes are not presented as they differ slightly. The origins of the coordinate planes of the upper diagonal elements correspond to zero.
The approach proposed in Section 3 considers only one single interval I, whose subintervals, defined through the set of possible change points TI, are tested for homogeneity. This method turns out to be time-varying, when it is applied as a sequential testing procedure. For this purpose, define the set I , which contains the geometrically growing sequence of nested interval-candidates I0  I1  . . .  Ik  . . .  IK, with Ik = [i0 - mk, i0], reference point i0, geometric grid mk = [1.25km0], and the sets of possible change points TIk = [t0 - mk-1,t0 - mk-2] for all Ik  I . [x] means the integer part of x and m0 = 40. If the null hypothesis of constant dependence is not rejected for interval Ik, the interval length is extended and interval Ik+1 is tested for homogeneity. This procedure is continued until a change point is identified or the largest interval IK is accepted as interval of homogeneity. If a change point is detected at k + 1, the local adaptive estimates are given by ^ = ~k, s^ = s~k, where ~k, s~k denote the ML-estimates from Section 2. While other time-varying methods

10 Nikolaus Hautsch, Ostap Okhrin and Alexander Ristig
permit only the parameter(s) to vary over time, the structure of this time-varying HAC may change as well.
Based on the Gumbel family, we apply the LCP procedure to the filtered residuals, because an application of the LCP procedure to the full VMEM is cumbersome due to the large number of parameters. The first panel of Figure 2 shows the changing HAC-structure estimated for an accepted interval of homogeneity, whose length is shown in the fourth panel. The two thick solid lines (grey and black) in the second panel present the time-varying parameters in terms of Kendall's ^. For the relationship between bivariate Archimedean generators and Kendall's  see [10]. Based on these results, we propose to re-estimate the parameters of the VMEM's scale function µi for at least three intervals separated by the dashed vertical lines, using full ML with fixed copula parameters. The first interval ending in the middle of March can be clearly identified, as the structure is constant and the estimates of Kendall's  exhibit a certain distance. The HAC for this interval is given by s1HAC = ((NT Vol)1.69HL)1.55 and the simple AC by s1AC = (NT Vol HL)1.58, where the subscript is related to ^ . The second interval is characterized by an alternating structure, while the values of Kendall's ^ can almost be distinguished. This makes it, however, difficult, to decide, whether a HAC or a simple AC should be used for re-estimating the VMEM. In general, the corresponding HAC, sH2 AC = ((NT Vol)1.63HL)1.40, and AC, sA2C = (NT Vol HL)1.45, indicate a weaker dependence than the fitted copulas of the first interval. In the third interval beginning in June, the underlying copula corresponds with high probability to a simple AC, since the structure changes frequently and both parameters are very close to each other. The HAC of this interval, sH3 AC = ((NT HL)1.52Vol)1.40, shows a different structure and the AC, sA3C = (NT Vol HL)1.42, a weaker dependence than the calibrated copulas of the first and second interval. We admit, at this point, that shorter interval specifications are possible, as the method provides a sensitive picture of the timevarying dependence. Note, that shorter time intervals are accompanied with less data and therefore, imply a loss in efficiency. The estimated HAC based on the entire sample is given by sHAC = ((Vol NT)1.56HL)1.41 and the respective simple AC by sAC = (NT HL Vol)1.45. We investigated the time-varying dependence for a few of other stocks and found similar results.
The third and fourth panels illustrate the performance of the LCP procedure. As proposed in Section 3, the LR test statistic measures the stability of the fitted model. Therefore, the length of the accepted intervals increase continuously in periods of a stable fit, whereas the interval length is typically short if the ML process is volatile. The dynamic of the ML process is presented in the third picture and allows to reproduce this relationship. The ML process exhibits a higher volatility in the last two months of the observed sample. This implies shorter intervals, for which the hypotheses of homogeneity are accepted, since the LR test statistics are smaller. [11] illustrates in a simulation study, that the procedure detects dependence changes with a short delay and [24] investigates the quality of the local adaptive estimators. A simple alternative approach is the rolling window method, which also allows for time-varying parameters but detects changes in the dependence with a larger delay.

Modeling Time-Varying Dependencies between Positive-Valued Time Series

11

179RO+/

VWUXFWXUH
+/9RO17

+/179RO















OHQJWK 0/
        

ÌÌ

ÌÌ

ÌÌ

ÌÌ

Fig. 2 Results of the LCP-procedure of AAPL. The first panel shows changes in the structure, the second the estimates of Kendall's  and the third variations of the ML process for the intervals of homogeneity, whose varying length is presented in the lower panel.

12
References

Nikolaus Hautsch, Ostap Okhrin and Alexander Ristig

1. Baillie, R.T., Bollerslev, T., Mikkelsen, H.O.: Fractionally integrated generalized autoregressive conditional heteroskedasticity. Journal of Econometrics 74, 3≠30 (1996)
2. Bollerslev, T.: Generalized autoregressive conditional heteroskedasticity. Journal of Econometrics 31(3), 307≠327 (1986)
3. Bougerol, P., Picard, N.: Stationarity of GARCH processes and of some nonnegative time series. Journal of Econometrics 52(1-2), 115≠127 (1992)
4. Chen, X., Fan, Y.: Estimation and model selection of semiparametric copula-based multivariate dynamic models under copula misspecification. Journal of Econometrics 135(1-2), 125≠154 (2006)
5. Cipollini, F., Gallo, G.M.: Automated variable selection in vector multiplicative error models. Computational Statistics & Data Analysis 54(11), 2470≠2486 (2010)
6. Conrad, C., Haag, B.R.: Inequality constraints in the fractionally integrated GARCH model. Journal of Financial Econometrics 4(3), 413≠449 (2006)
7. Engle, R.: Dynamic conditional correlation - a simple class of multivariate GARCH models. Journal of Business and Economic Statistics 20(3), 339≠350 (2002)
8. Engle, R.F.: Autoregressive conditional heteroscedasticity with estimates of the variance of united kingdom inflation. Econometrica 50(4), 987≠1007 (1982)
9. Engle, R.F., Russell, J.R.: Autoregressive conditional duration: A new model for irregularly spaced transaction data. Econometrica 66(5), 1127≠1162 (1998)
10. Genest, C., Rivest, L.P.: Statistical inference procedures for bivariate Archimedean copulas. Journal of the American Statistical Association 88, 1034≠1043 (1993)
11. Ha®rdle, W.K., Okhrin, O., Okhrin, Y.: Time varying hierarchical Archimedean copulae. SFB 649 discussion paper 2010, 018, SFB 649, Economic Risk, Berlin (2010)
12. Hautsch, N.: Econometrics of Financial High-Frequency Data. Springer, Berlin (2012) 13. Hosking, J.R.M.: Fractional differencing. Biometrika 68(1), 165≠176 (1981) 14. Jasiak, J.: Persistence in intertrade durations. Finance 19, 166≠195 (1998) 15. Joe, H.: Families of m-variate distributions with given margins and m(m - 1)/2 bivariate de-
pendence parameters. In: L. Ru®schendorf, B. Schweizer, M. Taylor (eds.) Distribution with Fixed Marginals and Related Topics, IMS Lecture Notes ≠ Monograph Series. Institute of Mathematical Statistics (1996) 16. Lee, S., Hansen, B.: Asymptotic theory for the GARCH(1, 1) quasi-maximum likelihood estimator. Econometric Theory 10, 29≠52 (1994) 17. McNeil, A.J.: Sampling nested archimedean copulas. Journal of Statistical Computation and Simulation 78, 567≠581 (2008) 18. McNeil, A.J., Neslehova¥, J.: Multivariate Archimedean copulas, d-monotone functions and l1 norm symmetric distributions. The Annals of Statistics 37(5b), 3059≠3097 (2009) 19. Nelsen, R.B.: An Introduction to Copulas, 2 edn. Springer Verlag, New York (2006) 20. Okhrin, O., Okhrin, Y., Schmid, W.: On the structure and estimation of hierarchical Archimedean copulas. Under Second Revision in Journal of Econometrics (2012) 21. Okhrin, O., Okhrin, Y., Schmid, W.: Properties of hierarchical Archimedean copulae. to appear in Statistics and Risk Modeling (Former Statistics and Decisions) (2012). DOI 10.1524/strm. 2012.1107 22. Patton, A.J.: Modelling asymmetric exchange rate dependence. International Economic Review 47, 527≠556 (2006) 23. Sklar, A.: Fonctions de re¥partition a` n dimension et leurs marges. Publications de l'Institut de Statistique de l'Universite¥ de Paris 8, 299≠231 (1959) 24. Spokoiny, V.: Multiscale local change point detection with applications to value-at-risk. The Annals of Statistics 37(3), 1405≠1436 (2009)

SFB 649 Discussion Paper Series 2012
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "HMM in dynamic HAC models" by Wolfgang Karl H‰rdle, Ostap Okhrin and Weining Wang, January 2012.
002 "Dynamic Activity Analysis Model Based Win-Win Development Forecasting Under the Environmental Regulation in China" by Shiyi Chen and Wolfgang Karl H‰rdle, January 2012.
003 "A Donsker Theorem for LÈvy Measures" by Richard Nickl and Markus Reiﬂ, January 2012.
004 "Computational Statistics (Journal)" by Wolfgang Karl H‰rdle, Yuichi Mori and J¸rgen Symanzik, January 2012.
005 "Implementing quotas in university admissions: An experimental analysis" by Sebastian Braun, Nadja Dwenger, Dorothea K¸bler and Alexander Westkamp, January 2012.
006 "Quantile Regression in Risk Calibration" by Shih-Kang Chao, Wolfgang Karl H‰rdle and Weining Wang, January 2012.
007 "Total Work and Gender: Facts and Possible Explanations" by Michael Burda, Daniel S. Hamermesh and Philippe Weil, February 2012.
008 "Does Basel II Pillar 3 Risk Exposure Data help to Identify Risky Banks?" by Ralf Sabiwalsky, February 2012.
009 "Comparability Effects of Mandatory IFRS Adoption" by Stefano Cascino and Joachim Gassen, February 2012.
010 "Fair Value Reclassifications of Financial Assets during the Financial Crisis" by Jannis Bischof, Ulf Br¸ggemann and Holger Daske, February 2012.
011 "Intended and unintended consequences of mandatory IFRS adoption: A review of extant evidence and suggestions for future research" by Ulf Br¸ggemann, Jˆrg-Markus Hitz and Thorsten Sellhorn, February 2012.
012 "Confidence sets in nonparametric calibration of exponential LÈvy models" by Jakob Sˆhl, February 2012.
013 "The Polarization of Employment in German Local Labor Markets" by Charlotte Senftleben and Hanna Wielandt, February 2012.
014 "On the Dark Side of the Market: Identifying and Analyzing Hidden Order Placements" by Nikolaus Hautsch and Ruihong Huang, February 2012.
015 "Existence and Uniqueness of Perturbation Solutions to DSGE Models" by Hong Lan and Alexander Meyer-Gohde, February 2012.
016 "Nonparametric adaptive estimation of linear functionals for low frequency observed LÈvy processes" by Johanna Kappus, February 2012.
017 "Option calibration of exponential LÈvy models: Implementation and empirical results" by Jakob Sˆhl und Mathias Trabs, February 2012.
018 "Managerial Overconfidence and Corporate Risk Management" by Tim R. Adam, Chitru S. Fernando and Evgenia Golubeva, February 2012.
019 "Why Do Firms Engage in Selective Hedging?" by Tim R. Adam, Chitru S. Fernando and Jesus M. Salas, February 2012.
020 "A Slab in the Face: Building Quality and Neighborhood Effects" by Rainer Schulz and Martin Wersing, February 2012.
021 "A Strategy Perspective on the Performance Relevance of the CFO" by Andreas Venus and Andreas Engelen, February 2012.
022 "Assessing the Anchoring of Inflation Expectations" by Till Strohsal and Lars Winkelmann, February 2012.
SFB 649, Spandauer Straﬂe 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

SFB 649 Discussion Paper Series 2012
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
023 "Hidden Liquidity: Determinants and Impact" by Gˆkhan Cebiroglu and Ulrich Horst, March 2012.
024 "Bye Bye, G.I. - The Impact of the U.S. Military Drawdown on Local German Labor Markets" by Jan Peter aus dem Moore and Alexandra Spitz-Oener, March 2012.
025 "Is socially responsible investing just screening? Evidence from mutual funds" by Markus Hirschberger, Ralph E. Steuer, Sebastian Utz and Maximilian Wimmer, March 2012.
026 "Explaining regional unemployment differences in Germany: a spatial panel data analysis" by Franziska Lottmann, March 2012.
027 "Forecast based Pricing of Weather Derivatives" by Wolfgang Karl H‰rdle, Brenda LÛpez-Cabrera and Matthias Ritter, March 2012.
028 "Does umbrella branding really work? Investigating cross-category brand loyalty" by Nadja Silberhorn and Lutz Hildebrandt, April 2012.
029 "Statistical Modelling of Temperature Risk" by Zografia Anastasiadou, and Brenda LÛpez-Cabrera, April 2012.
030 "Support Vector Machines with Evolutionary Feature Selection for Default Prediction" by Wolfgang Karl H‰rdle, Dedy Dwi Prastyo and Christian Hafner, April 2012.
031 "Local Adaptive Multiplicative Error Models for High-Frequency Forecasts" by Wolfgang Karl H‰rdle, Nikolaus Hautsch and Andrija Mihoci, April 2012.
032 "Copula Dynamics in CDOs." by Barbara Choro-Tomczyk, Wolfgang Karl H‰rdle and Ludger Overbeck, May 2012.
033 "Simultaneous Statistical Inference in Dynamic Factor Models" by Thorsten Dickhaus, May 2012.
034 "Realized Copula" by Matthias R. Fengler and Ostap Okhrin, Mai 2012. 035 "Correlated Trades and Herd Behavior in the Stock Market" by Simon
Jurkatis, Stephanie Kremer and Dieter Nautz, May 2012 036 "Hierarchical Archimedean Copulae: The HAC Package" by Ostap Okhrin
and Alexander Ristig, May 2012. 037 "Do Japanese Stock Prices Reflect Macro Fundamentals?" by Wenjuan
Chen and Anton Velinov, May 2012. 038 "The Aging Investor: Insights from Neuroeconomics" by Peter N. C. Mohr
and Hauke R. Heekeren, May 2012. 039 "Volatility of price indices for heterogeneous goods" by Fabian Y.R.P.
Bocart and Christian M. Hafner, May 2012. 040 "Location, location, location: Extracting location value from house
prices" by Jens Kolbe, Rainer Schulz, Martin Wersing and Axel Werwatz, May 2012. 041 "Multiple point hypothesis test problems and effective numbers of tests" by Thorsten Dickhaus and Jens Stange, June 2012 042 "Generated Covariates in Nonparametric Estimation: A Short Review." by Enno Mammen, Christoph Rothe, and Melanie Schienle, June 2012. 043 "The Signal of Volatility" by Till Strohsal and Enzo Weber, June 2012. 044 "Copula-Based Dynamic Conditional Correlation Multiplicative Error Processes" by Taras Bodnar and Nikolaus Hautsch, July 2012
SFB 649, Spandauer Straﬂe 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

SFB 649 Discussion Paper Series 2012
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
045 "Additive Models: Extensions and Related Models." by Enno Mammen, Byeong U. Park and Melanie Schienle, July 2012.
046 "A uniform central limit theorem and efficiency for deconvolution estimators" by Jakob Sˆhl and Mathias Trabs, July 2012
047 "Nonparametric Kernel Density Estimation Near the Boundary" by Peter Malec and Melanie Schienle, August 2012
048 "Yield Curve Modeling and Forecasting using Semiparametric Factor Dynamics" by Wolfgang Karl H‰rdle and Piotr Majer, August 2012
049 "Simultaneous test procedures in terms of p-value copulae" by Thorsten Dickhaus and Jakob Gierl, August 2012
050 "Do Natural Resource Sectors Rely Less on External Finance than Manufacturing Sectors? " by Christian Hattendorff, August 2012
051 "Using transfer entropy to measure information flows between financial markets" by Thomas Dimpfl and Franziska J. Peter, August 2012
052 "Rethinking stock market integration: Globalization, valuation and convergence" by Pui Sun Tam and Pui I Tam, August 2012
053 "Financial Network Systemic Risk Contributions" by Nikolaus Hautsch, Julia Schaumburg and Melanie Schienle, August 2012
054 "Modeling Time-Varying Dependencies between Positive-Valued HighFrequency Time Series" by Nikolaus Hautsch, Ostap Okhrin and Alexander Ristig, September 2012
SFB 649, Spandauer Straﬂe 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

