BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2006-022
Barrier Option Hedging under Constraints:
A Viscosity Approach
Imen Bentahar* Bruno Bouchard**
* Technische Universität Berlin, Germany ** Université Paris VI, LPMA, and CREST, Paris, France
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universität zu Berlin Spandauer Straße 1, D-10178 Berlin

Barrier option hedging under constraints: a viscosity approach

Imen Bentahar
TU Berlin, Germany imen@math.tu-berlin.de

Bruno Bouchard
Universit´e Paris VI, LPMA, and CREST Paris, France
bouchard@ccr.jussieu.fr

February 28, 2006

Abstract We study the problem of finding the minimal initial capital needed in order to hedge without risk a barrier option when the vector of proportions of wealth invested in each risky asset is constraint to lie in a closed convex domain. In the context of a Brownian diffusion model, we provide a PDE characterization of the super-hedging price. This extends the result of Broadie, Cvitanic and Soner (1998) and Cvitanic, Pham and Touzi (1999) which was obtained for plain vanilla options, and provides a natural numerical procedure for computing the corresponding super-hedging price. As a by-product, we obtain a comparison theorem for a class of parabolic PDE with relaxed Dirichet conditions involving a constraint on the gradient.
Key words : Super-replication, barrier options, portfolio constraints, viscosity solutions.
MSC Classification (2000): 91B28, 49L25, 35B05.
This work was partly supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk"
1

1 Introduction
The problem of super-hedging under portfolio constraints has attracted a lot of attention since the seminal work of Cvitani`c and Karatzas [5]. One of the original motivations came from the hedging of plain vanilla options with discontinuous payoffs, such as digital options. For such options the delta and gamma may take very large values when the remaining maturity is small, which makes them difficult to delta-hedge.
Within diffusion models, the remarkable result of Broadie, Cvitani`c and Soner [3] shows that the optimal hedge under constraints is obtained by considering the Black-Scholes type hedging strategy of some modified payoff. Thus, hedging the original claim under constraints corresponds to hedging a modified one without constraints. This is the socalled 'face-lifting' procedure. Within the Black-Scholes model, this allows to explicit the optimal hedge. In more general Markov diffusion models, an explicit solution may not be available but the super-hedging price can still be characterized as the solution of some Hamilton-Jacobi-Bellman equation, see Cvitani`c, Pham and Touzi [6] and the review paper Soner and Touzi [12]. In the general semi-martingale case, no explicit solution is available but a general dual formulation was obtained by F¨ollmer and Kramkov [7].
Similar problems may appear for path-dependent options such as barrier options. For instance, the delta of knock-out barrier options may explode when the maturity is small and the underlying asset is close to the barrier. This more difficult issue was recently considered by Shreve, Schmock and Wystup [11]. In this paper, the authors solve the problem of hedging a knock-out call option in a one dimensional Black-Scholes model under a constraint on the short position, i.e. the proportion of wealth invested in the risky asset is bounded from below. This result is obtained by extending the dual formulation of Cvitani`c and Karatzas [5] and by solving the associated stochastic control problem.
The aim of the present paper is to provide a PDE characterisation of the super-hedging price of barrier-type options. Our model is more general than the one studied in Shreve, Schmock and Wystup [11] in two aspects. First, we consider general payoffs of the form g(, X ) where  is the first exit time of a d-dimensional price process X from a given domain O. Secondly, our constraints on the proportions of wealth invested in the risky
2

assets is described by a rather general closed convex set.
Our derivation of the associated PDE relies on the dual formulation of Cvitani`c and Karatzas [5] as in Cvitani`c, Pham and Touzi [6]. Here, the main difficulty comes from the boundary condition on O before maturity, a problem which does not appear in the above paper. As in the vanilla option case, we have to consider as boundary condition a 'face-lifted' pay-off, but in the case of barrier options this is not sufficient. Indeed, the example considered in Shreve, Schmock and Wystup [11] shows that the boundary condition on [0, T ) × O may not be assumed continuously by the value function, even when the payoff is 'face-lifted' (in their case g = 0 before T ). This implies that this boundary condition has to be considered in a weak sense.
In this paper, we give an appropriate sense to the boundary condition and show that the super-hedging price is a (discontinuous) viscosity solution of the corresponding Hamilton-Jacobi-Bellman equation. We also show that it can actually be further characterized as its smallest viscosity supersolution. Finally, under mild additional assumptions, we prove a comparison theorem for the associated PDE which ensures uniqueness of the solution and opens the door to the implementation of a numerical scheme. Here, the difficulty comes from the constraint on the gradient of the value function which also appears in the relaxed boundary condition. To the best of our knowledge, this is the first time that such an equation is considered.
The rest of the paper is organized as follows. The super-hedging problem and its dual formulation are presented in Section 2. In Section 3, we describe the associated PDE and state our main results. A numerical application is presented in Section 4. The remaining sections contain the proofs.
Notations: All elements x = (xi)id of Rd are identified with column vectors with Euclydian norm | · | and transposed vector x . The positive orthant of Rd is denoted by R+d and the set of d × d matrices by Md. We write diag [x] to denote the diagonal matrix of Md whose i-th diagonal element is xi. If y  Rd, we write xy for (xiyi)id, xy for id(xi)yi and xey for (xieyi)id, whenever it is well defined. The trace of M  Md is denoted by Tr[M ] and |M | denotes its Euclydian norm when viewed as an element of Rd2. Given a family (aij)i,jd of real numbers, we denote by [aij]i,j the matrix A whose
3

component (i, j) is given by aij. The closure of a set E  Rd is denoted by E¯, E stands for its boundary and int(E) for its interior. Given  > 0, B(x, ) denotes the open ball of radius  centered on x. Given a smooth function (t, x)  [0, T ] × Rd  (t, x)  R, we denote by D its (partial) Jacobian matrix with respect to x and by D2 its (partial) Hessian matrix with respect to x. All inequalities involving random variables have to be understood in the P - a.s. sense.

2 The super-hedging price under contraints and its
dual formulation
In all this paper, T > 0 is a finite time horizon and W = (Wt)tT is a d-dimensional Brownian motion defined on a complete probability space (, F, P). We assume that the P-augmented filtration generated by W , F = (Ft)tT , satisfies F0 = {, } and FT = F .

2.1 The barrier option hedging problem

The financial market is composed by a non-risky asset B with price process normalized to unity, i.e. Bt = 1 for all t  T , and d risky assets X = (X1, . . . , Xd) whose dynamics is given by the stochastic differential equation

t
X(t) = X0 + diag [X(s)] (s, X(s))dWs , t  T
0
for some X0  (0, )d. Here,  : [0, T ] × Rd+  Md is assumed to satisfy

(2.1)

 (i)  is continuous, bounded and invertible with bounded inverse.  

(ii) The map (t, x)  [0, T ] × Rd+  diag [x] (t, x)

 

is Lipschitz continuous in x, uniformly in t.

(2.2)

Remark 2.1 As usual there is no loss of generality in assuming that X is a local martingale since, under mild assumptions on the original dynamics, we can always reduce to this case by passing to an equivalent probability measure. The normalization B = 1 means that we consider discounted processes, i.e. we take B as a num´eraire.

4

A financial strategy is described by a d-dimensional predictable process  = (1,...,d) satisfying the integrability condition

T
|t|2dt <  P - a.s.
0

(2.3)

where ti is the proportion of wealth invested at time t in the risky asset Xi. To an initial dotation y  R and a financial strategy , we associate the induced wealth process Yy defined as the solution on [0, T ] of

tt
Y (t) = y + Y (s)sdiag [X(s)]-1 dX(s) = y + Y (s)s(s, X(s))dWs , (2.4)
00
where stands for transposition.

Remark 2.2 Since in our model the financial strategies are described by the proportions of total wealth invested in each risky asset, the no-bankruptcy condition always holds provided that the initial dotation is non-negative. Indeed, it is clear from (2.4) that for y  0, the induced wealth process satisfies Yy(t)  0, for all t  [0, T ], a.s.

The constraints on the portfolio strategy is described by a closed convex set K  Rd. We say that a financial strategy  is admissible if it satisfies, in addition to the condition (2.3), the constraint

  K dt × dP - a.e.

(2.5)

and we denote by K the set of admissible financial strategies. All over this paper, we shall assume that

0  K = Rd .

(2.6)

The left hand-side condition just means that 0  K while the inequality is natural since otherwise there would be no constraint on the portfolio.
The barrier option is described by a map g defined on [0, T ] × Rd+ and an open domain O of Rd such that

g  0 on O¯  R+d and g = 0 on [0, T ] × O¯c ,

(2.7)

5

where O¯c := (0, )d \ O¯. The buyer of the option receives the payment g(, X( )) at the (stopping-) time  defined as the first time when X exists O if this occurs before T and T otherwise:

 := inf{t  [0, T ] : X(t) / O}  T ,

with the usual convention inf  = . The super-replication cost under constraint of the claim g(, X( )) is thus defined as
v(0, X0) := inf y  R+ : Yy( )  g(, X( )) for some   K . (2.8)
Remark 2.3 The condition g = 0 on [0, T ] × O¯c can be seen as a convention. Indeed, it is clear that v(0, X0) does not depend on the value of g on this set when X0  O¯, while for X0  O¯c the problem has no interest.

Hereafter we present examples of barrier option which enter into our framework.

Example 2.1 Up-and-out call : Let d = 1. The pay-off of an up-and-out call on a single asset X1, with strike price  and knock-out barrier B is equal to

X1(T ) - 

1{ }+
max0tT X1(t)<B

.

In our framework this corresponds to : O = (-, B) and g(t, x) = (x - )+ 1{t=T,x<B}.

Example 2.2 Down-and-out basket put option : A basket option is an option whose pay-off depends on a weighted average of a set of underlyings' values. Let d = 2, we consider the down-and-out barrier option whose payoff is given by

X1(T ) + X2(T ) +

- 2

1{ }min0tT X1(t)+X2(t)>2B .

In our framework this correponds to O = {x  (0, )2 , x1 + x2 > 2B} and g(t, x) =



-

x1+x2 2

+
1{t=T,x1+x2>2B} .

6

2.2 The dual formulation
The dual formulation for hedging problems under general convex constraint was first established by Cvitani`c and Karatzas [5] in the diffusion case and then extended to the semi-martingale case by F¨ollmer and Kramkov [7], see also Karatzas and Shreve [9] and the review paper Soner and Touzi [12].
To state the dual formulation, we first need the characterization of the closed convex set K in terms of its support function . For   Rd set

() = sup    0 ,
K
where the last inequality follows from the left hand-side of (2.6), and define

(2.9)

K~ := {  Rd : () < } ,

the domain of . Observe that the right hand-side of (2.6) implies that K~ = {0}.

Moreover, it is a standard result of convex analysis, see e.g. [10], that K can be

characterized in terms of

K~1 := {  K~ : || = 1}

by

  K  H(1, )  0 and   int(K)  H(1, ) > 0

(2.10)

where H(u, p) := inf{()u -  p,   K~1} for (u, p)  R × Rd .
Remark 2.4 Assume for a while that 0  int(K). Then, there is cK > 0 such that B(0, cK)  K. Thus, for all   K~1, cK  K and therefore
()  cK > 0 .

The dual formulation is constructed as follows. Let us denote by K~ the set of bounded adapted processes  taking values in K~ . To such a process, we associate the martingale M  defined on [0, T ] as the solution of
t
Mt := 1 + Ms (s, X(s))-1s dWs ,
0
7

recall (2.2). We then define the P-equivalent probability measure Q by

dQ dP

=

MT .

It follows from Girsanov's Theorem that the process W  defined by

t
Wt = Wt - (s, X(s))-1sds t  T ,
0
is a Brownian motion under Q. In the following, we shall denote by E the expectation
operator associated to Q.

To   K~, we finally associate the process E defined by

Et

:=

e-

Rt
0

(s)ds

tT .

Theorem 2.1 The following holds.

v(0, X0) = sup E Eg (, X( )) .
K~

(2.11)

Proof. The above result is a direct consequence of Theorem 6.2 and Remark 6.11 in [9]. For the convenience of the reader, we provide here its short proof. 1. First observe that

v(0, X0) = inf y  R+ : Yy(T )  g(, X( )) for some   K .

Indeed, it follows from (2.4) and condition (2.3) that, for all y  R+ and   K, the process Yy is a non-negative local P-martingale on [t, T ]. Hence it is a supermartingale and, by taking conditional expectation, Yy(T )  g(, X( )) implies Yy( )  g(, X( )). From this we deduce the first inequality :

v(0, X0)  inf y  R+ : Yy(T )  g(, X( )) for some   K .
For the converse inequality, notice that if Yy( )  g(, X( )), then YTy,~  g(, X( )) where ~ = 1[s,] belongs to K. 2. Since g  0, see (2.7), it follows from Theorem 6.2 and Remark 6.11 in [9] that

v(0, X0) = sup E ETg (, X( )) .
K~

8

Observe that the process E is positive, non-increasing in time and recall that g  0,

then the last equality leads to (2.11).

2

In order to derive the PDE characterization of the super-hedging price, we shall use a
standard dynamic programming principle for the dual formulation of Theorem 2.1.
Before to state it, we need to extend the definition of v to general initial conditions (t, x)  [0, T ] × (0, )d. For (t, x)  [0, T ] × (0, )d, y  R+ and   K, we define (Xt,x, Yt,x,y) as the solution of (2.1)-(2.4) on [t, T ] with initial condition (Xt,x(t), Yt,x,y(t)) = (x, y). The value function v is then defined on [0, T ] × (0, )d by

v(t, x) := inf y  R+ : Yt,x,y(t,x)  g(t,x, Xt,x(t,x)) for some   K , (2.12)

where

t,x := inf{s  [t, T ] : Xt,x(s) / O}  T .
Remark 2.5 Observe that for (t, x)  ([0, T ]×O)({T }×O¯), we have v(t, x) = g(t, x) by construction.

In the sequel, we shall denote by Tt,T the set of all stopping times with values in [t, T ]. Given   K~ and t < T , we also set

Est, := Es/Et for s  t .

The following result is a consequence of Proposition 6.5 in [9].

Proposition 2.1 For all (t, x)  [0, T ) × O and   Tt,T ,

v(t, x)

=

sup E
K~

Et,v

(, Xt,x()) 1<t,x

+

E t,
t,x

g

t,x , Xt,x(t,x )

1t,x

.

(2.13)

Proof. It follows from Proposition 6.5 in [9] that

v(t, x)

=

sup E
K~

E t,
t,x

v

  t,x , Xt,x(  t,x )

.

where by definition of v, see Remark 2.5, v t,x, Xt,x(t,x) = g(t,x, Xt,x(t,x)). This

provides the required result.

2

9

3 The PDE characterization
Our main result consists in a PDE characterization of the value function v. Before to state it, we describe the PDE associated to v and explain in which sense it has to be considered.

3.1 The associated PDE
Set O = O  (0, )d. In view of [6] and [13], it is natural to expect that the value function v is a viscosity solution on
D := [0, T ) × O

of the partial differential equation

min {-Lv , Hv} = 0 ,

where for a smooth function  on [0, T ] × Rd+, we set

H(t, x) = inf ()(t, x) -  diag [x] D(t, x),   K~1

L(t, x) =

1 (t, x) + Tr

a(t, x)D2(t, x)

t 2

,

with a defined on [0, T ] × R+d by

a(t, x) := diag [x] (t, x)(t, x) diag [x] .

(3.1)

The first part of the equation corresponds to the usual Black-Scholes equation, while the second part is due to the portfolio constraint. Indeed, assuming that v is smooth, positive, and writing formally that the hedging portfolio satisfies Yy(t) = v(t, X(t)), we deduce from Ito^'s Lemma that t must coincide with diag [X(t)] Dv(t, X(t))/v(t, X(t)). Since it has to belong to K, the characterization of K given by (2.10) implies that H(1, diag [X(t)] Dv(t, X(t))/ v(t, X(t))), or equivalently H(v(t, X(t)), diag [X(t)] Dv(t, X(t))), must be non-negative.
In order to provide a full characterization of v, it remains to define the boundary conditions on xD := [0, T ) × O and T D := {T } × O¯ where
O := O  (0, )d and O¯ := O¯  (0, )d .

10

It is known from [6], see also [12] and [13], that the boundary condition on T D has to be written

v = g^

(3.2)

where, for x  (0, )d,
g^(T, x) = sup e-()g(T, xe) .
K~
This corresponds to the `face-lifting' procedure which was already observed by [3]. This `face-lifting' is due to the portfolio constraint, g^ being the smallest function above g which, in a sense, satisfies Dg^/g^  K.

Remark 3.1 Observe that (2.7) allows to define g^(T, ·) on (0, )d as
g^(T, x) = sup e-()g(T, xe) ,
K~ (x,O¯)
with the convention sup  = 0 and
K~ (x, E) :=   K~ : xe  E for E  O¯ .

(3.3) (3.4)

The fact that v satisfy (3.1)-(3.2) in the viscosity sense can be shown by following the arguments of [6] and is not difficult.

The difficulty comes from the boundary condition on xD. In this paper, we shall show that g has also to be modified on xD, i.e. replaced by g^ defined on [0, T ) × (0, )d by

g^(t, x) = sup e-()g(t, xe) ,
K~ (x,O)

(3.5)

with the convention sup  = 0. This result is expected and will be obtained under a smoothness condition on O, see HO below. But this is only a first step in the derivation of the appropriate boundary condition. Actually, [11] provides an example of super-hedging price for up-and-out call option for which g^(t, x) = 0 for t < T and v(t , x ) does not converge to 0 when (t , x )  D goes to (t, x)  xD. This shows that the constraint on the portfolio may prevent the value function to assume the boundary condition continuously and leads to the natural formulation of a relaxed boundary condition on xD

min {v - g^ , Hv} = 0 .

(3.6)

11

However, we shall see in Remark 6.1 below that the above equation has to be corrected in order to admit a viscosity supersolution and therefore have a sense. Given a smooth function , we therefore define

Hd(t, x) = inf ()(t, x) -  diag [x] D(t, x),   K~1(x, O¯) , where, for x  E  O¯,

K~1(x, E) :=   K~1 :  0 > 0 s.t.   K~ (x, E) for all   [0, 0] . (3.7)

To sum up, we introduce the following operators

 min {-L , H} on D  
B := min { - g^ , H} on xD ,

 



-

g^

on T D

Bd :=

B on D  T D , min { - g^ , Hd} on xD

and we say that a locally bounded function w on D is a discontinuous viscosity solution of

Bd = 0

(3.8)

on D¯  := D¯  ([0, T ] × (0, )d) if w and w defined on D¯ as

w(t, x) :=

lim inf w(t~, x~) and w(t, x) :=

lim sup w(t~, x~)

(t~,x~)D, (t~,x~)(t,x)

(t~,x~)D, (t~,x~)(t,x)

are respectively viscosity super- and subsolution of Bd = 0 and B = 0 on D¯ .
More generally, we shall say that w is a (discontinuous) viscosity supersolution (resp. subsolution) of B = 0 on D¯  if w is a supersolution of Bd = 0 (resp. subsolution of B = 0) on D¯ .

Remark 3.2 Assume that the conditions of Theorem 3.1 below hold. Let us write

B(t, x)

as

B(t, x, (t, x),

 t

(t,

x),

D(t,

x),

D2(t,

x))

and

Bd(t, x)

similarly.

Then,

one easily checks that the upper-semicontinuous envelope of Bd as a map on D¯  × R ×

R × Rd × Md is given by

(Bd)+(t,

x,

(t,

x),

 t

(t,

x),

D(t,

x),

D2(t,

x)))

=

max {Bd(t, x) ,

min {-L(t, x), H(t, x)} } ,

12

and that its lower-semicontinuous envelope is

(Bd)-(t,

x,

(t,

x),

 t

(t,

x),

D(t,

x),

D2(t,

x)))

=

min {B(t, x) , -L(t, x) } .

From the arguments of the proof of Proposition 6.3 and Proposition 6.6 below, we deduce that (Bd)+ = 0 (resp. (Bd)- = 0) has the same supersolutions as Bd = 0 (resp. subsolutions that B = 0) on D  xD, for the terminal condition  = g^ at T . In other words, Bd can be viewed as being upper-semicontinuous with lowersemicontinuous envelope given by B. This justifies the above definition of a viscosity solution of Bd = 0, and shows that it is in accordance with Definition 7.4 in [4]. This remark will be used in the example section to prove the convergence of the discretization
scheme we shall consider for a particular example.

3.2 Main results
In order to establish that v is a discontinuous viscosity solution of (3.8), we shall appeal to the following additional assumptions.
Our first condition concerns the convex set K describing the portfolio constraints. It is stated in terms of K~ (x, O), recall (3.4).
HK~ : (i) For all x  O,   K~ (x, O) implies   K~ (x, O) for all   [0, 1). (ii) For all x  O, the closure of K~ (x, O) is equal to K~ (x, O¯). (iii) If (xn)n is a sequence in O such that xn  x  O and   K~ (x, O¯) then there exists a sequence n   such that, up to a subsequence, n  K~ (xn, O¯)  n  1.
Remark 3.3 The conditions (i) and (ii) of HK~ are automatically satisfied whenever the set ln(O) = {(ln(xi))id, x  O} is convex. Indeed, we easily check that in this case, for all x  O, K~ (x, O) is convex, and since 0  K~ (x, O), this provides (i). The convexity of ln(O) also implies that if   K~ (x, O) and ¯  K~ (x, O¯), then +(1-)¯  K~ (x, O) for all   (0, 1). Since 0  K~ , this shows that for all x  O the closure of K~ (x, O) contains K~ (x, O¯), while the converse inclusion is obvious.

13

We shall also impose some regularity assumptions on g:
Hg : (i) g is lower semi-continuous on [0, T ] × O and on {T } × O¯. (ii)  Cg > 0 and ¯  K  Rd+ s.t. |g(·, x)|  Cg (1 + x¯)  x  O¯, (iii) g^ is upper semi-continuous on [0, T ] × (0, )d and has linear growth.
Under HK~ and (i)-(ii) of Hg, one can already derive the following qualitative properties of v.

Proposition 3.1 Assume that HK~ and (i)-(ii) of Hg hold. Then, for all (t, x)  D, we have

v(t, x)  0 ,

(3.9)

and there is a constant C > 0, independent of (t, x), such that
|v(t, x)|  C (1 + x¯) .
Moreover, for all (t, x)  D¯ ,
v(t, x) = sup e-()v(t, xe) .
K~ (x,O¯)
The proof will be provided in Section 5.

(3.10) (3.11)

In order to derive the appropriate boundary condition on xD, we shall also need some regularity on the domain O.

HO :

There exists a map d : (0, )d  R such that (i) {x  (0, )d : d(x) > 0} = O . (ii) {x  (0, )d : d(x) = 0} = O . (iii) x  O, , r > 0 s.t. d  C2(B(x, r)) .

This essentially amongs to say that O is C2, see [8].
Using HK~ , Hg and HO, we can already characterize v not only as a discontinuous solution of (3.8) but also as its smallest supersolution.

14

Theorem 3.1 Assume that HK~ , Hg and HO hold. Then, (i) v is a discontinuous viscosity solution of (3.8), (ii) v is lower-continuous on D, (iii) v is the smallest supersolution of (3.8) in the class of locally bounded functions satisfying (3.10).
Finally, under the additional assumptions
H : (i) Either O¯ is bounded or  > 1 s.t. ¯  K  (0, )d, (ii) int(K) =  and either 0  int(K) or O¯  R+d = , (iii)  x  O    K~1 s.t. Dd(x) diag [x]  > 0,
we will be able in Section 7 to provide a comparison theorem for (3.8). It will imply our last result which characterizes v as the unique solution of (3.8) in a suitable class of functions.
Theorem 3.2 Let the conditions of Theorem 3.1 hold and assume further that H is satisfied. Then, (i) v = v on D¯ , (ii) v is continuous on D, (iii) v is the unique discontinuous viscosity solution of (3.8) in the class of locally bounded function satisfying (3.10).
Remark 3.4 Recall the examples of barrier options of Section 2. 1. If we hedge the up-and-out call of the Example 2.1 with shortsales constaints, i.e. K = [-, +), with  > 0, then it is easy to verify that all of the conditions HK~ , Hg, HO and H hold true. 2. These conditions are also satisfied when we hedge the down-and-out basket put of
2
the Example 2.2 with bounded portfolio, i.e K = [-i, ¯i], i, ¯i > 0 for i = 1, 2.
i=1
Remark 3.5 To conclude this section, let us comment the assumption H . As already mentioned, Theorem 3.2 is based on a comparison result for (3.8) stated in Theorem 7.1 below. A first difficulty in proving this theorem comes from the growth condition (3.10) which is non-standard. In the case where O¯ is not bounded, the second assumption in (i) is used to construct a suitable penalty function which allows us to reduce to a
15

bounded domain. The second difficulty comes from the term H appearing in B.
It is handled by using the first assertion of (ii) under which we can construct a strict super-solution of H = 0. A third difficulty is due to the fact that the equation in written only on O¯  (0, )d. In the case where O¯  Rd+ = , we need to introduce an other penalty function which permits to reduce the analysis to (0, )d. We then appeal
to the second assertion of (ii). Finally, a major difficulty comes from the boundary condition on xD which is written in a weak sense. It is treated by using the condition (iii) which allows to "avoid" this boundary. We refer to step 4. of the proof of Theorem
7.1 below for a more detailed discussion of these assumptions (i) and (ii).

4 A numerical application

In this section, we study a numerical scheme for the resolution of Bd = 0 in the simple example considered in [11] : superhedging of a knock-out call with a short-sale
constraint. The general case will be discussed in the companion paper [2].
The model corresponds to our general framework with d = 1, (t, x) =  > 0, a fixed constant, O = (-, B), K = [-, ) and g(t, x) = [x - ]+1{t=T, x<B}, with  > 0, B >  > 0. In this case K~ = (-, 0], the function g^(t, x) is equal to

g^(t, x) = e-(x)[xe-(x) - K]+1t=T with (x) = [- ln(B/x)]+ ,

and all the assumptions of Theorem 3.2 are satisfied.

In order to solve numerically the equation Bd = 0, we propose the following discretization. We fix a regular grid h = {ti := (irh)  T, 0  i  Ih} of [0, T ] and h := {xi := (ih)  B, 0  i  Nh} of [0, B]. Here, h > 0 is a fixed parameter, Nh := inf{k  N : k  B/h} and Ih := inf{k  N : k  T /rh} with rh = h2. The approximation vh of v is defined as follows. 1. For i = Ih, we use the boundary condition at t = T to set : vh(tIh, xj) = g^(tIh, xj), j = 0, . . . , Nh. 2. For i = Ih - 1, . . . , 0, we use the following procedure : 2.a. We initialize : vh(ti, 0) = 0. 2.b. Then, we solve on j = 1, . . . , Nh the system

vh(ti, xj) =

max Ah(vh, i, j) ; Bh(vh, i, j) max 0 ; Bh(vh, i, j)

if j = Nh otherwise

16

with

Ah(vh, i, j)

:=

(rh)-1vh(ti+1, xj) + (2h2)-12x2j (vh(ti, xj+1) + vh(ti, xj-1)) (rh)-1 + (h2)-12xj2

Bh(vh, i, j)

:=

xj

h-1vh(ti, xj-1)  + xj h-1

,

The initialization of step 2.a. is justified by the continuity of v at 0 which is easily checked in this simple model by using the dual formulation of Theorem 2.1. The system given in 2.b. follows from the approximation of H = Hd and L by

Hh(ti, xj, vh(ti, xj), vh)

=

vh(ti

,

xj

)

+

xj

vh

(ti,

xj

)

- vh(ti, h

xj-1)

,

Lh(ti, xj, vh(ti, xj), vh)

=

vh(ti+1, xj) - vh(ti, xj) rh

+

1 2

2xj2

vh(ti,

xj+1)

+

vh(ti, xj-1) h2

-

2vh(ti, xj)

.

Observing that vh is non-negative and uniformly bounded from above by B, the convergence of the scheme easily follows from Remark 3.2, Theorem 3.2, Remark 7.1 below and [1].

Figure 1:

10 Estimated values
9

12% 11%

Relative error

10%

8 9%

7
=0.1

6

=1 =10

5 Payoff

8% 7% =0.1
=1
6% =10 5%

4 4% 3%
3 2%

2 1% 0%
1 -1%

0 5

7,5

10

12,5

15

17,5

20

-2% 5

7,5 10 12,5 15 17,5 20

In Figure 1, we plot the estimation of v obtained with this scheme for  = 0.3,  = 10, B = 20, T = 1 and for   {0.1, 1, 10}. The relative error is computed by using
17

the closed form solution obtained in [11]. We took Nh = 200. We observe that the estimation is very sharp with a relative error less than 1% in absolute value, except for small values of X0 for which v is almost equal to 0.

5 Growth and monotonicity properties

In this section, we provide the proof of Proposition 3.1.

Proof of (3.9)-(3.10). The lower bound of (3.9) is an immediate consequence of the assumption g  0 and the dual formulation (2.11). We now prove (3.10). Let   K be defined by t = ¯ for all t  T . Since  is bounded, see (2.2), one easily checks from the dynamics of the processes Xt,x and Yt,x,1 that

d
1 + (Xti,x(u))¯i  C
i=1

d
1 + (xi)¯i
i=1

Yt,x,1(u)

for all u  [0, T ], P - a.s. ,

where C > 0 depends only on |¯| and the bound on ||. Then, after possibly changing the value of the constant C, Hg-(ii) implies

g(u, Xt,x(u))  C (1 + x¯) Yt,x,1(u) for all u  [0, T ], P - a.s. ,

and since yYt,x,1 = Yt,x,y for y > 0, we deduce from the last inequality that v(t, x) 

C (1 + x¯).

2

Proof of (3.11). Since 0  K~ (x, O¯), we only have to show that

v(t, x)  sup e-()v(t, xe) .
K~ (x,O¯)

1. We first consider the case where (t, x)  D. Since by lower-semicontinuity of v and (ii) of HK~

sup e-()v(t, xe) = sup e-()v(t, xe) ,

K~ (x,O)

K~ (x,O¯)

it suffices to show that

v(t, x)  sup e-()v(t, xe) .
K~ (x,O)

(5.1)

18

Fix   K~ (x, O) and consider the sequence of processes n in K~ defined on [t, T ] by n := n1[t,tn] with tn := t + n-1 for n large enough so that tn < T . By Proposition 2.1

v(t, x)  En e-n()(n-1(t,x -t)) v (tn, Xt,x(tn)) 1tn<t,x + g t,x , Xt,x(t,x ) 1tnt,x

.

(5.2)

Let Xn be the solution on [t, T ] of

ss
Xn(s) = x + diag [Xn(r)] nr dr + diag [Xn(r)] (r, Xn(r))dWr
tt
so that Xn(s) = snHsn with

(Hsn)i := E

ds
ij(r, Xn(r))dWrj
j=1 t

and

sn

:=

Rs
xe t

nr

dr

,

where E denotes the Doleans-Dade exponential. By Girsanov's theorem, (5.2) can be

rewritten as

v(t, x)  E e-n()(n-1(n-t)) (v (tn, Xn(tn)) 1tn<n + g (n, Xn(n)) 1tnn )

(5.3)

where

n := inf {s  [t, T ] : Xn(s) / O}  T .

Since



is

bounded,

see

(2.2),

Hn
ntn



(1, . . . , 1)

P - a.s.,

after

possibly

passing

to

a

subsequence. Also observe that

n
ntn

=

xe[(n(n-t))1]

.

By HK~

and

the

assumption





K~ (x, O),

it

follows

that,

P - a.s.,

Xn
ntn



O

and

therefore tn < n for large values of n. In particular,

(Xn(tn), 1tn<n) - (xe, 1) P - a.s.

Thus, passing to the limit in (5.3) and applying Fatou's Lemma shows the required result, recall (3.9).

2. We now consider the case where (t, x)  D. Let (tn, xn)n be a sequence in D that
converges to (t, x) such that v(tn, xn)  v(t, x). Fix   K~ (x, O¯). By HK~ , there is a sequence (n)n with values in K~ (xn, O¯) such that n  . Using 1., we deduce that

v(tn, xn)  e-(n)v(tn, xnen). Passing to the limit shows that v(t, x)  e-()v(t, xe)

by lower-semicontinuity of v.

2

19

Remark 5.1 Fix (t, x)  D¯  and assume that (0, 0)  R+ × K~ are such that xe00  O¯. By (i) HK~ , the map   [0, 0]  e-(0)v(t, xe0) is well defined and it follows from (3.11) that it is non-increasing.

6 The viscosity solution property
In this section, we provide the proof of Theorem 3.1. We start with the supersolution and subsolution properties. Then, we use an approximation argument combined with a comparison theorem to prove that v is the smallest supersolution of (3.8).

6.1 Supersolution property
In this section, we show that v is a supersolution of (3.8) on D¯ . This is a consequence of Proposition 6.1, 6.2, 6.3 and 6.4 below.

Proposition 6.1 Assume that HK~ -Hg hold. Let (t0, x0)  D¯  and   C2(D¯ ) be such that (t0, x0) is a local minimum on D¯  of v -  satisfying (v - )(t0, x0) = 0. Then,

Hd(t0, x0)  0 .

Proof. By (3.11), for all   K~1(x, O¯) and  > 0 small enough, we must have

(t0, x0) = v(t0, x0)  e-()v(t0, x0e)  e-()(t0, x0e) .

Thus, dividing by  and sending  to 0 leads to the required result.

2

Remark 6.1 Assume that HO holds and that for all (t0, x0)  D¯  and  as in Proposition 6.1, we have

H(t0, x0)  0 .
Let (t0, x0) and  be as in Proposition 6.1 with x0  O. Recall from HO the definition of the function d and observe that (t0, x0) is also a local minimum of (v - )(t, x) + -1d(x) on D¯  for all  > 0. Thus, if the above assertion is true,  - -1d must satisfy
()v(t0, x0) -  diag [x0] D(t0, x0) - -1Dd(x0)  0 for all   K~1 .

20

Now observe that for   K~1 \ K~1(x0, O¯), there is a sequence of positive parameters n  0 such that d(x0en) < 0 = d(x0) for all n, recall (3.7). This implies that  diag [x0] Dd(x0) < 0. Hence, sending   0 in the above inequality leads to a contradiction if K~1 \ K~1(x0, O¯) = .
Proposition 6.2 Let (t0, x0)  D and   C2(D¯ ) be such that (t0, x0) is a local minimum on D¯  of v -  satisfying (v - )(t0, x0) = 0. Then,

-L(t0, x0)  0 .

(6.1)

Proof. The proof is standard. Let V be a bounded open neighborhood of (t0, x0) such that (t0, x0) is a minimum on V¯  D¯  of v -  and let (tn, xn)n be a sequence in V  D such that (tn, xn)  (t0, x0) and v(tn, xn)  v(t0, x0). For ease of notations we write (n, Xn) = (tn,xn, Xtn,xn). Given a sequence (n)n of positive numbers such that tn + n < T for all n, we set
n := inf {s  [tn, T ] : (s, Xn(s)) / V  D}  (tn + n) .
Since 0  K~ , (2.13), the assumption g  0, see (2.7), and the inequality v   on V imply that

v(tn, xn)  E  n, Xnn 1n<n .

Set n := v(tn, xn) - (tn, xn) and observe that n converges to 0 as n goes to infinity. Moreover, it follows from It^o's Lemma that

nE

n
L(s, Xn(s))ds 1n<n .
tn

Using standard estimates, we then observe that

(6.2)

n

lim inf E
n

n-1

tn

L(s, Xn(s))ds 1n<n

 L(t0, x0) ,

whenever n  0. Thus, choosing (n)n such that n/n  0 and using (6.2) leads to

the required result.

2

Proposition 6.3 Assume that HK~ -Hg holds. Then, v  g^ on xD.

21

Proof. 1. We first prove that for all (t0, x0)  xD and   C2(D¯ ) such that

we have

0

=

(v - )(t0, x0)

=

min
D¯ 

(strict)(v

-

)

,

max {v(t0, x0) - g(t0, x0) ; - L(t0, x0)}  0 .

(6.3)

Assume to the contrary that

max {(t0, x0) - g(t0, x0) ; - L(t0, x0)}  -2

(6.4)

for some  > 0. Let (tn, xn)n be a sequence in D converging to (t0, x0) such that

v(tn, xn)  v(t0, x0) .

By (2.2) and Hg, there is an open ball B centered on (t0, x0) such that

-L  0 on B  D¯  and  - g  - on B  xD .

(6.5)

Obviously, we can assume that (tn, xn)  B. Set (n, Xn) = (tn,xnXtn,xn) and let n be the first exit time of (Xn(s))stn from B. Observing that  := minBD¯ (v - ) > 0, using Ito^'s Lemma and (6.5) one obtains

(tn, xn)  E [ (n  n, Xn( n  n))]  -(  ) + E [g (n, Xn( n))) 1nn + v (n, Xn(n)) 1n>n] .
Since ((tn, xn) - v(tn, xn))  0 and 0  K~ , this leads to a contradiction to (2.13) for n large enough.

2. We now prove that v(t0, x0)  g(t0, x0) for all (t0, x0)  xD. To see this, we assume to the contrary that

v(t0, x0) < g(t0, x0)

(6.6)

for some (t0, x0)  xD and work toward a contradiction to (6.3). Let   C2(D¯ ) be such that

0

=

(v - )(t0, x0)

=

min (strict)(v - ) .
D¯ 

22

For  > 0, define  on D¯  by

(t, x) = (t, x) - d(x) - d(x)2 , 

where d is defined in HO.

Since

d(x)

-

d(x)2 

> 0 when 0 < d(x) < , it follows that

(t0, x0) is a strict local minimum of (v - ) for each  > 0. By (6.3) and (6.6), we

must therefore have

-L(t0, x0) + Tr a(t0, x0)D2d(x0)

1

-

Tr 

[a(t0,

x0)Dd(x0)Dd(x0)

]



0,

which leads to a contradiction to (2.2) when  tends to 0. 3. In view of 2. and the definition of g^ in (3.5), (3.11) concludes the proof.

2

Proposition 6.4 Assume that HK~ -Hg holds. Then, v(T, ·)  g^(T, ·) on O¯.
Proof. Fix x0  O¯ and let (tn, xn)n be a sequence in D converging to (T, x0) such that v(tn, xn)  v(T, x0). Set (n, Xn) = (tn,xn, Xtn,xn). Since  is bounded, see (i) of (2.2), one easily checks that (n, Xn(n))  (T, x0) P - a.s., after possibly passing to a subsequence. In view of Hg, it follows that

lim inf
n

(g(n,

X n (n ))1n <T

+

g(T ,

Xn(T ))1n=T )



g(T, x0) .

Since g  0 by assumption and 0  K~, it follows from Fatou's Lemma and (2.11) that

v(T, x0)  g(T, x0). The proof is concluded by using (3.11) and recalling the definition

of g^(T, ·) in (3.3).

2

6.2 Subsolution property

In view of Proposition 6.1, 6.2, 6.3 and 6.4, we already know that v is a supersolution of Bd = 0 on D¯ . To conclude the proof of (i) of Theorem 3.1, it remains to show that v is a subsolution of B = 0 on D¯ . This is a consequence of Proposition 6.5, 6.6 and
6.7 below.

Proposition 6.5 Let (t0, x0)  D and   C2(D¯ ) be such that (t0, x0) is a local maximum on D¯  of v -  satisfying (v - )(t0, x0) = 0. Then,

min {-L(t0, x0) ; H(t0, x0)}  0 .

(6.7)

23

Proof. The proof is standard. We assume that

G(t0, x0) := inf {-L(t0, x0) + ()(t0, x0) -  diag [x0] D(t0, x0)} > 0 , (6.8)
K~
and work towards a contradiction. If (6.8) holds, then it follows from (i) of (2.2) that there exists some  > 0 such that

G(t, x) > 0 for all (t, x)  B0 := B(t0, ) × B(x0, )  D .

(6.9)

Let (tn, xn)n0 be a sequence in B0 such that (tn, xn)  (t0, x0) and v(tn, xn)  v(t0, x0). Observe that n := (tn, xn) - v(tn, xn)  0. Set Xn = Xtn,xn and define the stopping times

n := T  inf {s  [tn, T ] : (s, Xn(s))  B0} .
Let pB0 = [t0, t0 + ] × B(x0, )  {t0 + } × B¯(x0, ) denote the parabolic boundary of B0 and observe that
0 > - := sup (v - )(t, x) .
(t,x)pB0
Then, we deduce from Ito^'s Lemma applied on , (6.9), Girsanov's Theorem, see the discussion in Section 2.2, and the above assertion that

v(tn, xn) + n   + sup E Env(n, Xn(n)) .
K~
Since by construction n < tn,xn and n  0, we obtain a contradiction to (2.13). 2
Proposition 6.6 Assume that HO-Hg holds. Let (t0, x0)  xD and   C2(D¯ ) be such that (t0, x0) is a local maximum on D¯  of v -  satisfying (v - )(t0, x0) = 0. Then,

min {v(t0, x0) - g^(t0, x0) ; H(t0, x0)}  0 .

Proof. 1. By using similar arguments as in the proof of Proposition 6.5, we first obtain that

min {v(t0, x0) - g(t0, x0) ; - L(t0, x0) ; H(t0, x0)}  0 .

(6.10)

24

2. We now proceed by contradiction as in 2. of the proof of Proposition 6.3 to show that
min {v(t0, x0) - g(t0, x0) ; H(t0, x0)}  0 .
As usual, we can assume that (t0, x0) is a strict local maximum of v - on D¯ . Assume that for some  > 0,

min v(t0, x0) - g(t0, x0) ; inf ()v(t0, x0) -  diag [x0] D(t0, x0)
K~ 1
Let  > 0 be a fixed parameter to be chosen later and for  > 0 set on D¯ 

> .

(t, x)

=

d2(x) (t, x) + d(x) -



where

d

is

defined

in

HO.

For

x

O¯

such

that

d(x)

< 

we

have

d(x) -

d2(x) 

 0.

It follows that (t0, x0) is a local maximum of v - . Moreover,

min v(t0, x0) - g(t0, x0) ; inf ()v(t0, x0) -  diag [x0] D(t0, x0) > 0 ,
K~ 1

for  > 0 small enough since d(x0) = 0 and therefore D(t0, x0) = D(t0, x0) + Dd(x0) - 2Dd(x0)d(x0)/ = D(t0, x0) + Dd(x0). Thus, it follows from 1. that we must have

-L((t0,

x0)

+

d(x0))

+

1 Tr


[a(t0,

x0)Dd(x0)Dd(x0)

]



0.

Sending   0 leads to a contradiction to (i) of (2.2).

2

Proposition 6.7 Assume that Hg holds. Then, v(T, ·)  g^(T, ·) on O¯.

Proof. 1. Let (tn, xn)n be a sequence in D which converges to (T, x0) and such that
v(tn, xn)  v(T, x0). Set (n, Xn) = (tn,xn, Xtn,xn). By the dual formulation (2.11), there is some n  K~ such that

v(tn, xn)



En

e-

R n
tn

(sn

)dsg

(n

,

X

n

(n

))

+ n-1 .

Since K~ is a convex cone,  is sublinear and g  0, it follows that

e-

R n
tn

(ns )ds

g(n

,

X

n

(n))



e-(Rtnn snds)g(n, X n(n)) 

sup

g^

t,

X

n(t)e-

Rt
tn

sn

ds

tntT

25

by definition of g^ in (3.3)-(3.5). In view of the above inequalities and the definition of (tn, xn), it remains to show that

lim sup En sup g^ (t, Zn(t))

n

tntT

where

Zn

:=

X en

-

R·
tn

ns ds

solves

on

[tn, T ]

 g^(T, x0) ,

(6.11)

dZn(t) = diag [Zn(t)] (t, Xn(t))dWtn , Zn(tn) = xn ,
and W n is a standard Brownian motion under Qn, recall the discussion of Section 2.2. Using the boundedness assumption on , see (2.2), we deduce from standard arguments that there is a constant C > 0 independent of n such that

En sup |Zn(t) - x0|  C |xn - x0| + (T - tn)1/2 .
tntT
We shall prove in 2. that, for each  > 0, there is a Lipschitz function  such that |g^(T, x0) - (T, x0)|   and   g^. It follows that, for each , we can find some finite K > 0 such that

lim sup En sup g^ (t, Zn(t))

n

tntT

 lim sup En sup  (t, Zn(t))

n

tntT

 (T, x0) + lim sup K |xn - x0| + (T - tn)1/2
n

= (T, x0) .

By definition of  this implies that

lim

sup

n
E

sup g^ (t, Zn(t))

 g^(T, x0) +  ,

n

tntT

and the proof of (6.11) is concluded by sending  to 0.

2. We conclude this proof by constructing the sequence of functions ()>0. For (t, x)  [0, T ] × (0, )d, we define

Gk(t, x) =

sup [g^(s, z) - k (|s - t| + |z - x|)] , k  1 .

(s,z)[0,T ]×(0,)d

Clearly, Gk  g^ and Gk is k-Lipschitz. Moreover, taking k large enough, it follows from the linear growth and upper-semicontinuity assumptions on g^, see Hg, that, for

26

all (t, x)  [0, T ] × (0, )d, the maximum is attained in the above definition by some (tk(t, x), xk(t, x)). In particular,
Gk(t, x) = g^(tk(t, x), xk(t, x)) - k (|tk(t, x) - t| + |xk(t, x) - x|)  g^(t, x) .
Using the linear growth of g^ again, we deduce that (tk(t, x), xk(t, x))  (t, x) as k   after possibly passing to a subsequence. Since g^ is upper-semicontinuous, this also implies that

g^(T, x0)  lim sup g^(tk(T, x0), xk(T, x0))  lim sup Gk(T, x0)  g^(T, x0) .

k

k

We can then choose k such that |Gk(T, x0) - g^(T, x0)|   and set  := Gk.

2

6.3 Characterization of v as the smallest supersolution

In this section, we prove that v = v on D and that v is the smallest supersolution of (3.8).
To this end, we introduce a sequence of approximating control problems as follows. For all   1, we define K~ as the set of elements   K~ such that ||   and K~ as the set of elements   K~ that take values in K~. We then define on D¯ 

w(t, x) = sup E Eg t,x, Xt,x(t,x) .
K~ 

(6.12)

It is clear that w is a non-decreasing sequence and it follows directly from Theorem 2.1 and the definition of K~ that

lim




w (t,

x)

=

v(t, x)

for all (t, x)  D¯  .

For   1, let us introduce the operator G defined for smooth functions by

(6.13)

G(t, x) := min {-L(t, x) + ()(t, x) -  diag [x] D(t, x)} .
K~ 
Proposition 6.8 Let the conditions Hg-HO hold. Then, for all   1, w is a viscosity subsolution on D of

G(t0, x0) = 0 . Moreover, w  g^ on xD  T D.

(6.14)

27

Proof. The proof is standard. Set   C2(D) and let (t0, x0) be a strict global maximizer of w -  on D¯  such that (w - )(t0, x0) = 0. 1. If (t0, x0)  D then the result follows from the same arguments as in the proof of Proposition 6.5.
2. Arguing as in Proposition 6.5 again, we deduce that

min w(t0, x0) - g^(t0, x0) , G(t0, x0)  0 ,

if (t0, x0)  xD. The required result is then obtained by arguing as in 2. of the proof

of Proposition 6.6.

3. Since w  v, the inequality w(T, ·)  g^(T, ·) follows from Proposition 6.7.

2

Proposition 6.9 Assume that Hg hold. Let u (resp. w) be a viscosity subsolution (resp. supersolution) of (6.14) on D satisfying the growth condition (3.10). If u  w on xD  T D, then u  w on D¯ .

Proof. 1. Given  > 0, we set u~(t, x) = etu(t, x) and w~(t, x) = etw(t, x) so that u~ and v~ are respectively sub- and supersolutions of

G~(t, x) := min {( + ())(t, x) - L(t, x)} = 0 ,
K~ 
where for   K~

L(t, x) := L(t, x) +  diag [x] D(t, x) .

Recall the definition of ¯ in Hg and set

Define on D¯ 

 = 2¯  R+d , ~ = (2, . . . , 2)  (0, )d .

(t, x) := e(T -t) 1 + x + x~

(6.15)

Observing that
 (t, x) = - (t, x) , diag [x] D(t, x) = e(T -t) x + x~~ t Tr a(t, x)D2(t, x) = e(T -t) xTr [ (t, x)M ] + x~Tr  (t, x)M~

28

with M := [i(i - 1)1i=j + ij1i=j]ij and M~ defined similarly, it follows from (i) of (2.2) and the compactness of K~ that we can find  > 0 such that

G~(t, x)  0 on D¯  .

(6.16)

2. We now argue by contradiction and assume that

sup (u~ - w~) > 0 .
D¯ 
2.1. In view of the growth condition on u~, w~ and (6.15), we then have

0 < 2m := sup (u~ - w~ - 2) < 
D¯ 
for  > 0 small enough. For x  D¯ , set

(6.17)

d
f (x) = (xi)-2 .
i=1

(6.18)

Combining the growth condition on u~, w~ with (6.15) and the definition of f implies that, for each  > 0, the upper-semicontinuous function

 := u~ - w~ - 2( + f )

admits a maximum (t, x) on D¯ . By (6.17), we can choose  small enough so that

(t, x)  m > 0 .

(6.19)

Let (t0, x0) be a sequence in D such that (t0, x0)  2m. By (6.17) and definition of (t, x), we have

lim inf
0

(2m - 2f (x))



lim inf
0

(u~

-

w~

-

2(

+

f ))(t, x)



lim
0

(u~

-

w~

-

2(

+

f

))(t0,

x0 )

= 2m .

This shows that

d

lim sup f (x) = lim sup  (xi )-2 = 0 ,

0

0

i=1

29

which, by (i) of (2.2) and the compactness of K~, implies

lim sup sup  (|f (x)| + |Lf (x)|) = 0 .
0 K~

(6.20)

2.2. For (t, x)  [0, T ] × Rd, set G(t, x) = |t - t|4 + |x - x|4. Given n > 0, it follows from similar arguments as above that the map

n(t, x, y)

:=

u~(t, x) - w~(t, y) - n |x - y|2 -  ((t, x) + (t, y)) 2

-  (f (x) + f (y) + G(t, x)) ,

also admits a maximum point (tn, xn, yn )  D¯  which necessarily satisfies n (tn , xn, yn )  n (t, x, x) = (t, x)  m > 0 .

(6.21)

Using the growth assumption on u and w, (6.15) and the definition of f again, one
easily checks that this implies that the sequence (tn , xn, yn )n is bounded and therefore converges, after possibly passing to a subsequence. Moreover, (6.21) implies that n|xn - yn |2 + f (xn ) is bounded. Thus, there is (t¯, x¯)  D¯  such that (tn, xn , yn )  (t¯, x¯, x¯)
and, by definition of (t, x) and (6.21), we must have

(t, x)  (t¯, x¯)



lim sup
n

(t¯,

x¯)

-

n 2

|xn

-

yn |2

-

G(tn,

xn)

 (t, x) .

This shows that, up to a subsequence, (tn , xn )  (t, x)  D¯  , n (tn, xn, yn )  (t, x) and n|xn - yn |2  0
as n  .

(6.22)

3. Since the upper-semicontinuous function u - w is non-positive on xD  T D, it follows from (6.19) that (t, x)  D and that we may assume that (tn , xn , yn )  [0, T ) × O2 for each n > 0. Using Ishii's Lemma and following standard arguments, see

Theorem 8.3 and the discussion after Theorem 3.2 in [4], we deduce from the viscosity property of u~ and w~ that for some ^n in the compact set K~

0



(

+

(^n ))(w~(tn,

yn )

-

u~(tn,

xn))

+

1 Tr
2

[a(tn,

xn )An

-

a(tn ,

yn )Bn ]

+ (^n) diag [xn - yn ] qn + L^n( + [f + G])(tn, xn) + L^n ( + f )(tn , yn )

30

where

qn := n(xn - yn )

(6.23)

and An , Bn are two symmetric matrices satisfying

-3n Id 0 0 Id

 An 0

 3n Id -Id

0 -Bn

-Id Id

.

(6.24)

Using (6.16), (6.21), (6.22), (6.23), (6.24) and (i) of (2.2), we then deduce that

0  -m( + (^n )) + C n|xn - yn |2 - ( + (^n )) {(f + G)(tn, xn) + f (yn )} +  L^n(f + G)(tn, xn ) + L^n f (yn )

for some C > 0 independent of n. Sending n to , it follows from the compactness of K~ and (6.22) that

0  -m( + (^)) + 2 L^f (x) - ( + (^))f (x)

for some ^  K~. Sending  to 0 and using (6.20) finally leads to a contradiction since

, m > 0 and   0 by (2.9).

2

We now conclude the proof of Theorem 3.1.

Proof of (ii) and (iii) of Theorem 3.1. Observe that a supersolution u of Bd = 0 on D¯  is also a supersolution of (6.14) on D, and, by Proposition 6.8, satisfies u  w

on xD  T D for all   1. In view of Proposition 6.9 and (6.13), it follows that

u  lim  w = v on D whenever u satisfies (3.10). In particular, since v is a

supersolution of (3.8) satisfying (3.10), see Proposition 3.1, we have v  v so that

v = v  u on D and v  u on D¯ .

2

7 A uniqueness result
We now proceed with the proof of Theorem 3.2. It is an immediate consequence of Proposition 3.1, Theorem 3.1 and the following comparison result.
Theorem 7.1 Assume that the conditions of Theorem 3.2 hold. Let u be an uppersemicontinuous viscosity subsolution of B = 0 on D¯ . Assume furthermore that u satisfies the growth condition (3.10). Then, u  v on D¯ .
31

Remark 7.1 1. It will be clear from the proof that the above Theorem can be stated as follows. Let u and w be respectively sub- and supersolution of B = 0 and Bd = 0 on D  xD satisfying the growth condition (3.10). Assume further that w satisfies
C:  (t, x)  D  xD and   K~1(x, O¯),  0 > 0 s.t.   [0, 0]  w(t, xe)e-() is non-increasing.

Then, u  w on T D implies u  w on D¯ . 2. One can actually show that any supersolution of Hd = 0 satisfies the condition C. Since it is not useful for our main result, we do not provide the proof which is rather long. 3. Combining the above assertions provides a general comparison result for super- and subsolutions of, respectively, Bd = 0 and B = 0 on D  xD.

In order to prove Theorem 7.1, we need the following intermediate Lemma.

Lemma 7.1 Assume that HO holds. Fix x0  O. If   K~1 satisfies

Dd(x0) diag [x0]  > 0 ,
then there exists some positive parameters r0 and 0 such that xe   O for all x  B(x0, r0)  O¯ and   (0, 0).
Proof. Recall from HO that the function d is C2 on a neighbourhood of x0. Thus, Dd(x0) diag [x0]  > 0 implies that for some 0, r0 > 0

Dd(x¯) diag [x]   0 for all x¯, x  B(x0, r0) .

(7.1)

Given that xe - x = diag [x]  + o(), we can fix some 0 > 0 such that, for all

x  B(x0, r0/2) and   (0, 0)

[x, xe]  B(x0, r0)

and

|xe - x - diag [x] | < 1+

0/2 max |Dd(x)|

.

(7.2)

xB¯ (x0 ,r0 )

Let x be in B(x0, r0/2)  O¯, so that d(x)  0. Since d is C1, for each   (0, 0) there exists x¯  [x, xe ]  B(x0, r0) such that

d(xe ) = d(x) + Dd(x¯) xe  - x

= d(x) + Dd(x¯) diag [x]  + Dd(x¯) xe  - x - diag [x]   d(x) +  0 > 0 ,
2

32

where the last inequality follows from (7.1) and (7.2). This shows that xe   O. 2

Proof of Theorem 7.1: In order to avoid too many complications, we make the proof under the assumption

H : (i)  > 1 s.t. ¯  K  (0, )d, (ii) 0  int(K), (iii)  x  O    K~1 s.t. Dd(x) diag [x]  > 0 ,
in place of H . We shall explain in the last step how to adapt this proof when O¯ is bounded but (i) of H does not hold, or 0 / int(K) but O¯  Rd+ =  and int(K) = .

1. Given some positive parameter , we introduce the functions u~(t, x) := etu(t, x), v~(t, x) := etv(t, x) and g~(t, x) := etg^(t, x). One easily checks that the function u~ (resp. v~) is a viscosity subsolution (resp. supersolution) of B~ = 0 (resp. B~d = 0),
where for a smooth function 



 min L~ , H

on D





B~ = min { - g~ , H} on xD



 

 - g~

on T D

B~d =

B~ on D  T D min { - g~ , Hd} on xD

and

L~ :=  - L .

Let  R be as in H , i.e.  := ¯  K  (0, )d

and

>1.

(7.3)

Since 0  int(K) by H , it follows from (2.9) and Remark 2.4 that the map defined by (t, x) = e(T -t) (1 + x) on D¯  satisfies

H ((t, x), diag [x] D(t, x))  cK > 0 for all (t, x)  D¯  .

(7.4)

Moreover, by the same computations as in the proof of Proposition 6.9, one easily checks that we can choose  large enough so that

L~  0 on D¯  .

(7.5)

33

2. We argue by contradiction. We assume that

sup (u - v) > 0
D¯ 
and work towards a contradiction. 2.1. In this step, we follow the same construction as in the proof of Proposition 6.9. By the growth condition on u~, v~ and (7.3), we deduce that

0 < 2m := sup (u~ - v~ - 2) < 
D¯ 

(7.6)

for  > 0 small enough. Fix  > 0 and let f be defined as in (6.18). Arguing as in the proof of Proposition 6.9, we obtain that

 := u~ - v~ - 2( + f )

admits a maximum (t, x) on D¯ , which, for  > 0 small enough, satisfies (t, x)  m > 0 .

(7.7)

Moreover, using the same arguments as in 2.1 of the proof of Proposition 6.9, we obtain that

lim sup sup  (|f (x)| + |diag [x] Df (x)| + |Lf (x)|) = 0 .
0 K~1
Finally, since , f  0 and v(T, ·)  u(T, ·), (7.7) implies that t < T , i.e.

(t, x)  [0, T ) × O¯ .

2.2. In the following, we fix   K~1 such that

 := 0

if x  O

Dd(x) diag [x]  > 0 if x  O ,

see (iii) of H . By Lemma 7.1 and (3.11), we can fix r,  > 0, such that

xe   O and e-()v~(t, xe)  v~(t, x)

for all t  (t - r, t + r)  [0, T ), x  B := B(x, r)  O¯ and   (0, ) .

(7.8) (7.9) (7.10) (7.11)

34

For n  1 and   (0, 1), we then define the function n , on [0, T ] × (O¯)2 by

n, (t,

x,

y)

:=

(t,

x,

y)

-

(f (x)

+

f (y))

-

 (|x

-

x|2

+

|t

-

t|2)

-

n2

|xe

 n



-

y|2

,

where

(t, x, y) := u~(t, x) - v~(t, y) -  ((t, x) + (t, y)) .

It follows from (7.3) and the growth condition (3.10) satisfied by v~ and u~ that n,

attains its maximum at some (tn, xn , yn )  [0, T ]×(O¯)2. The inequality n ,(tn , xn , yn )



n , (t,

x

,

xe

 n



)

implies

that

(tn, xn, yn )



(t,

x,

xe

 n



)

-



f

(x)

+

f

(xe

 n



)

+

n2|xn

e

 n



-

yn |2

+



|xn - x|2 + |tn - t|2

+  (f (xn) + f (yn )) ,

which

combined

with

the

growth

condition

(3.10)

and

(7.3)

shows

that

n2

|xn

e

 n



-

yn |2 + f (xn) is bounded in n so that, up to a subsequence,

(i)

xn

e

 n



,

xn, yn

---
n

x¯



O¯

and

tn

---
n

t¯



[0,

T]

.

Let

n

be

large enough so that

 n

<

.

Recall from (7.11) that this implies that

v~(t,

x

e

 n



)



v~(t,

x

)e

 n

()

,

which

combined

with

the

previous

inequality

yields

(tn , xn , yn )



u~(t,

x)

-

v~(t,

x)e

 n

()

-



(t,

x)

+



(t,

xe

 n



)

-



f

(x)

+

f

(xe

 n



)

+

n2|xn

e

 n



-

yn |2

+



|xn - x|2 + |tn - t|2

+  (f (xn ) + f (yn )) .

Sending n   and using the maximum property of (t, x), we get

0  (t¯, x¯) - (t, x)



lim sup

n2

|xn e

 n



-

yn |2

+



|xn - x|2 + |tn - t|2

n

Recalling (7.7) and (7.9), this shows that

.

(ii)

n2

|xn e

 n



-

yn |2

+



|xn - x|2 + |tn - t|2

--- 0 ,
n

(iii)

u~(tn ,

xn)

-

v~(tn,

yn )

---
n

(u~ - v~) (t, x)



m + 2(t, x) + 2f (x) ,

(iv) (tn, xn)  [0, T ) × O¯ for n large enough.

35

3. From Theorem 8.3 in [4], we deduce that, for each  > 0, there are real coefficients b1,n, b2,n and symmetric matrices Xn, and Yn, such that

b1,n, pn, Xn,  P¯O+¯ u~(tn , xn) and

-b2,n, qn , Yn,  P¯O-¯ v~(tn, yn ) ,

see [4] for the standard notations P¯O+¯ and P¯O-¯ , where

pn

:=

2n2(xn

e

 n



-

yn

)e

 n



+

2 (xn

-

x)

+

D(tn,

xn)

+

Df (xn )

qn

:=

2n2(xn

e

 n



-

yn )

-

D(tn ,

yn )

-

Df (yn )

,

and b1,n, b2,n, Xn, and Yn, satisfy

 

b1,n + b2,n = 2(tn - t) -  ((tn, xn) + (tn , yn ))



Xn,

0

 

0 -Yn,

 (An + Bn ) + (An + Bn )2

(7.12)

with

An := Bn :=

2n2

diag[e2

 n



]

+

2 Id

-2n2

diag[e

 n



]

-2n2

diag[e

 n



]

2n2Id

D2(tn , xn) + D2f (xn )

0

0 D2(tn, yn ) + D2f (yn )

.

3.1. We now show that, up to a subsequence,

yn  O .

(7.13)

In view of (ii), this is clearly true when x  O. In the case x  O, we deduce from (ii) that

yn

=

xn

e

 n



+

o(n-1)

=

xn

+

 diag
n

[xn]



+

o(n-1)

.

This implies that, for some n  0,

d(yn )

=

d(xn)

+

 n

(Dd(xn)

diag

[xn ]



+

n) ,

so that (7.13) is a consequence of (7.10), the continuity of Dd and (ii).

3.2. In this step, we show that there is a subsequence of (tn , xn, yn ) such that

xn



O

and

u~(tn ,

xn)

-

b1,n

-

1 2

Tr

[a(tn,

xn )Xn,]



0

.

(7.14)

36

First observe that we can not have xn  O and u~(tn , xn)  g~(tn, xn ) for all n. In view of (ii), this is obvious if x  O. If x  O, it follows from (7.9) and the viscosity property of v~ that v~(t, x)  g~(t, x). Since g~ is upper-semicontinuous, see Hg, this would imply that u~(tn, xn)  v~(tn, yn ) + m/2 for n large enough, see (ii), thus leading to a contradiction to (iii) since , f  0. By (iv) and the viscosity subsolution property
of u~, we then deduce that either (7.14) holds or

H (u~(tn, xn), diag [xn ] pn )  0 .

(7.15)

Thus, it remains to prove that the above inequality leads to a contradiction. Using the supersolution property of v~, (7.13), (ii)-(iii) and (2.9), we observe that (7.15) implies

0  H (u~(tn, xn ), diag [xn ] pn ) - H (v~(tn, yn ), diag [yn ] qn )

  {H ((tn, xn ), diag [xn ] D(tn , xn )) + H ((tn , yn ), diag [yn ] D(tn, yn ))}

+  {H (f (xn ), diag [xn] Df (xn)) + H (f (yn ), diag [yn ] Df (yn ))}

+

inf
K~ 1

()

[(tn

,

xn

,

yn )

-



(f

(xn

)

+

f

(yn

))]

-

sup

2n2 diag

xn

e

 n



-

yn

xn

e

 n



-

yn

+ 2 diag [xn] (xn - x)

K~ 1

 inf ()(m/2) + 2H((t, x), diag [x] D(t, x))
K~ 1

+ n +  {H (f (x), diag [x] Df (x)) + H (f (y), diag [y] Df (y))}

where n  0 when n  , but depend on . Recalling (7.4) and (7.8), we get a contradiction for  small and n large enough. This concludes the proof of (7.14).

3.3. We can now provide the required contradiction and conclude the proof. Let ~ be defined on D¯ by ~(t, x) = diag [x] (t, x). By the viscosity supersolution property of v~, (7.13), (7.14) and (7.12), (tn, xn, yn ) must satisfy

 (u~(tn, xn) - v~(tn , yn ))



b1,n

+

b2,n

+

1 Tr
2

[a(tn ,

xn )Xn,

-

a(tn ,

yn )Yn,]

 2(tn - t) -  ((tn , xn) + (tn, yn ))

+

1 Tr
2

(tn , xn, yn )

An + Bn + (An + Bn )2

where

(tn, xn, yn ) :=

~(tn , xn )~ (tn, xn ) ~(tn , yn )~ (tn, xn) ~(tn , xn)~ (tn, yn ) ~(tn, yn )~ (tn , yn )

37

is a non-negative symmetric matrix. Using (ii)-(iii), (7.5) and (7.8), it follows that for  small and n large enough

 m/2   (u~(tn, xn ) - v~(tn , yn ) - ( + f )(tn, xn ) - ( + f )(tn, yn ))



2 (tn

-

t)

+

1 Tr
2

(tn , xn , yn )

An + (An + Bn )2

+ (, n)

where (, n) is independent of (, ) and satisfies

lim sup lim sup |(, n)| = 0 .
0 n

Sending   0 in the previous inequality provides

 m/2



2 (tn

-

t)

+

1 Tr
2

[(tn ,

xn ,

yn )An]

+

(,

n)

,

so that

(7.16)

 m/2  2(tn - t) + Tr [~(tn , xn)~ (tn , xn )]

+

n2

diag

xn

e

 n



2
(tn , xn) - diag [yn ] (tn , yn ) + (, n) .

Using (2.2), we now observe that

diag

xn

e

 n



(tn,

xn e

 n



)

-

(tn,

xn)



diag

xn

e

 n



(tn,

xne

 n



)

-

diag

[xn]

(tn ,

xn )

+ diag

xn

e

 n



-

xn

(tn , xn)

 C

xne

 n



-

xn

 C n-1 ,

and

diag

xn

e

 n



(tn,

xn

e

 n



)

-

diag

[yn ]

(tn, yn )

2



C

xne

 n



- yn

2

where C > 0 denotes a generic constant independent of n and . Plugging this in the previous inequality implies that there is some C > 0 independent of n and  for which

 m/2



2(tn - t) + Tr [~ (tn, xn )~(tn, xn)] + C



+

n2

|xn

e

 n



-

yn |2

+ (, n) .

Finally, using (ii) and sending n to  and then  to 0 in the last inequality implies

 m/2  lim sup (, n) ,
n
38

which by (7.16) provides the required contradiction and concludes the proof.
4. We now explain how to adapt this proof to the alternative assumptions of H . 4.1. Observe that the penalty function  is introduced in order to obtain a finite supremum for u~-v~-2 and existence of an optimum for  and n,. If O¯ is bounded, the introduction of such a penalty function is not required and we can reproduce the same proof with   0 whenever 0  int(K). Indeed, by Remark 2.4, infK~1 () > 0 so that we still obtain a contradiction at the end of 3.2. The arguments of 3.3 also work with   0. The case where 0 / int(K) is discussed below. 4.2. Similarly, the map f is introduced only to prevent the different maxima to take values outside O¯. If O¯  R+d = , this penalty function is useless and can be fixed to f  0. In this case, one can also fix some   int(K), if non-empty, and add the term e(T -t)x in the definition of . Thus,  becomes e(T -t) (1 + x + x) or e(T -t) (1 + x) depending whether O¯ is bounded or not, see 4.1. For fixed  > 0, we deduce from Remark 2.4 and the fact that   int(K) that H((t, x), diag [x] D(t, x)) > 0. Since f = 0, there is no  to send to 0 at the end of 3.2 and 3.3, and we obtain the same contradictions by simply sending n to  and  to 0.
2
References
[1] Barles G. and P.E. Souganidis (1991). Convergence of approximation schemes for fully nonlinear second order equations. Asymptotic analysis, 4, 271-283.
[2] Bouchard B. and I. Bentahar (2006). Numerical resolution of the barrier option pricing problem under constraints. Forthcoming.
[3] Broadie M., J. Cvitani`c and M. Soner (1998). Optimal replication of contingent claims under portfolio constraints. The Review of Financial Studies, 11 (1), 5979.
[4] Crandall M. G., H. Ishii and P.-L. Lions (1992). User's guide to viscosity solutions of second order Partial Differential Equations. Amer. Math. Soc., 27, 1-67.
39

[5] Cvitani`c J. and I. Karatzas (1993). Hedging contingent claims with constrained portfolios. Annals of Applied Probability, 3, 652-681.
[6] Cvitani`c J. , H. Pham and N. Touzi (1999). Super-replication in stochastic volatility models with portfolio constraints. Journal of Applied Probability, 36, 523-545.
[7] Fo¨llmer H. and D. Kramkov (1997). Optional decomposition under constraints. Probability Theory and Related Fields, 109, 1-25.
[8] Gilbarg D. and N. S. Trudinger (1977). Elliptic partial differential equations of second order. Springer-Verlag.
[9] Karatzas I. and S. E. Shreve (1998). Methods of mathematical finance. SpringerVerlag.
[10] Rockafellar R.T. (1970). Convex Analysis. Princeton University Press, Princeton, NJ.
[11] Shreve S. E., U. Schmock and U. Wystup (2002). Valuation of exotic options under shortselling constraints. Finance and Stochastics, 6, 143-172.
[12] Soner H. M. and N. Touzi (2004). The problem of super-replication under constraints. To appear in Paris-Princeton Lectures in Mathematical Finance, Lecture Notes in Mathematics, Springer-Verlag.
[13] Touzi N. (2000). Direct characterization of the value of super-replication under stochastic volatility and portfolio constraints. Stochastic Processes and their Applications, 88, 305-328.
40

SFB 649 Discussion Paper Series 2006
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "Calibration Risk for Exotic Options" by Kai Detlefsen and Wolfgang K. Härdle, January 2006.
002 "Calibration Design of Implied Volatility Surfaces" by Kai Detlefsen and Wolfgang K. Härdle, January 2006.
003 "On the Appropriateness of Inappropriate VaR Models" by Wolfgang Härdle, Zdenk Hlávka and Gerhard Stahl, January 2006.
004 "Regional Labor Markets, Network Externalities and Migration: The Case of German Reunification" by Harald Uhlig, January/February 2006.
005 "British Interest Rate Convergence between the US and Europe: A Recursive Cointegration Analysis" by Enzo Weber, January 2006.
006 "A Combined Approach for Segment-Specific Analysis of Market Basket Data" by Yasemin Boztu and Thomas Reutterer, January 2006.
007 "Robust utility maximization in a stochastic factor model" by Daniel Hernández­Hernández and Alexander Schied, January 2006.
008 "Economic Growth of Agglomerations and Geographic Concentration of Industries - Evidence for Germany" by Kurt Geppert, Martin Gornig and Axel Werwatz, January 2006.
009 "Institutions, Bargaining Power and Labor Shares" by Benjamin Bental and Dominique Demougin, January 2006.
010 "Common Functional Principal Components" by Michal Benko, Wolfgang Härdle and Alois Kneip, Jauary 2006.
011 "VAR Modeling for Dynamic Semiparametric Factors of Volatility Strings" by Ralf Brüggemann, Wolfgang Härdle, Julius Mungo and Carsten Trenkler, February 2006.
012 "Bootstrapping Systems Cointegration Tests with a Prior Adjustment for Deterministic Terms" by Carsten Trenkler, February 2006.
013 "Penalties and Optimality in Financial Contracts: Taking Stock" by Michel A. Robe, Eva-Maria Steiger and Pierre-Armand Michel, February 2006.
014 "Core Labour Standards and FDI: Friends or Foes? The Case of Child Labour" by Sebastian Braun, February 2006.
015 "Graphical Data Representation in Bankruptcy Analysis" by Wolfgang Härdle, Rouslan Moro and Dorothea Schäfer, February 2006.
016 "Fiscal Policy Effects in the European Union" by Andreas Thams, February 2006.
017 "Estimation with the Nested Logit Model: Specifications and Software Particularities" by Nadja Silberhorn, Yasemin Boztu and Lutz Hildebrandt, March 2006.
018 "The Bologna Process: How student mobility affects multi-cultural skills and educational quality" by Lydia Mechtenberg and Roland Strausz, March 2006.
019 "Cheap Talk in the Classroom" by Lydia Mechtenberg, March 2006. 020 "Time Dependent Relative Risk Aversion" by Enzo Giacomini, Michael
Handel and Wolfgang Härdle, March 2006. 021 "Finite Sample Properties of Impulse Response Intervals in SVECMs with
Long-Run Identifying Restrictions" by Ralf Brüggemann, March 2006. 022 "Barrier Option Hedging under Constraints: A Viscosity Approach" by
Imen Bentahar and Bruno Bouchard, March 2006.
SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

