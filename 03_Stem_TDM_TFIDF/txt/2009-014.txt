BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2009-014
Properties of Hierarchical Archimedean Copulas
Ostap Okhrin* Yarema Okhrin** Wolfgang Schmid***
*Humboldt-Universit‰t zu Berlin, Germany **Universit‰t Ber n , Switzerland
***Universit‰t Viadrina Frankfurt (Oder), Germany
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universit‰t zu Berlin Spandauer Straﬂe 1, D-10178 Berlin

5th March 2009
Properties of Hierarchical Archimedean Copulas
Ostap Okhrin
Institute for Statistics and Econometrics, Humboldt-Universit®at zu Berlin, D-10099 Berlin, Germany
Yarema Okhrin1
Department of Economics, University of Bern, Schanzeneckstr. 1, CH-3012 Bern, Switzerland
Wolfgang Schmid
Department of Statistics, European University Viadrina, D-15230 Frankfurt (Oder), Germany
Abstract: In this paper we analyse the properties of hierarchical Archimedean copulas. This class is a generalisation of the Archimedean copulas and allows for general non-exchangeable dependency structures. We show that the structure of the copula can be uniquely recovered from all bivariate margins. We derive the distribution of the copula value, which is particularly useful for tests and constructing confidence intervals. Furthermore, we analyse dependence orderings, multivariate dependence measures and extreme value copulas. Special attention we pay to the tail dependencies and derive several tail dependence indices for general hierarchical Archimedean copulas.
Keywords: copula; multivariate distribution; Archimedean copula; stochastic ordering; hierarchical copula. JEL Classification: C16, C46.
0 The financial support from the Deutsche Forschungsgemeinschaft via SFB 649 "Okonomisches Risiko", Humboldt-Universit®at zu Berlin is gratefully acknowledged.
1Corresponding author. Department of Economics, University of Bern, Schanzeneckstr. 1, CH-3012 Bern, Switzerland. Email: yarema.okhrin@vwi.unibe.ch. Phone: +41 (0) 31 631 4792.
1

1 Introduction

Copulas play an increasingly important role in econometrics. For an arbitrary multivariate distribution they allow to separate the marginal distributions and the dependency model. As a result we obtain a convenient tool to analyse the complex relationship between variables. In particular, all common measures of dependence can be given in terms of the copula function. Modeling using copulas offers wide flexibility in terms of the form of dependence and is often encountered in applications from financial econometrics, hydrology, medicine, etc.
The copulas were first introduced in the seminal paper of Sklar (1959). Here we restate the Sklar's theorem.
Theorem 1. Let F be an arbitrary k-dimensional continuous distribution function. Then the associated copula is unique and defined as a continuous function C : [0, 1]k  [0, 1] which satisfies the equality
F (x1, . . . , xk) = C{F1(x1), . . . , Fk(xk)}, x1, . . . , xk  R,
where F1(x1), . . . , Fk(xk) are the respective marginal distributions.

Alternatively the copula can be defined as an arbitrary distribution function on [0, 1]k with all margins being uniform. As it follows form the theorem, the copula function captures the dependency between variables, with the impact of the marginal distributions being eliminated. The Sklar's Theorem allows to express the copula function directly by
C(u1, . . . , uk) = F {F1-1(u1), . . . , Fk-1(uk)}, u1, . . . , uk  [0, 1],
where F1-1(∑), . . . , Fk-1(∑) are the corresponding quantile functions.
If the cdf F belongs to the class of elliptical distributions, for example, the Normal distribution, then this results in an elliptical copula. Note, however, that this copula cannot be given explicitly, because F and the inverse marginal distributions Fi have only integral representations. This depreciates the usefulness of the elliptical copulas. As a result, an important class of Archimedean copulas has evolved. The k-dimensional Archimedean copula function C : [0, 1]k  [0, 1] is defined as

C(u1, . . . , uk) = {-1(u1) + ∑ ∑ ∑ + -1(uk)}, u1, . . . , uk  [0, 1],

(1)

where  with (0) = 1 and () = 0 is called the generator of the copula. McNeil and Neslehov¥a (2008) provide necessary and sufficient conditions for  to generate a feasible Archimedean copula. The generator  is required to be k-monotone, i.e. differentiable up to the order k - 2, with (-1)i(i)(x)  0, i = 0, . . . , k - 2 for any x  [0, ) and with (-1)k-2(k-2)(x) being nondecreasing and convex on [0, ). We consider a stronger assumption that  is a completely monotone function, i.e. (-1)i(i)(x)  0 for all i  0. The class of feasible generator functions we define by (see Kimberling (1974), Theorem 1 and Theorem 2)

L = { : [0; )  [0, 1] | (0) = 1, () = 0; (-1)i(i)  0; i = 1, . . . , }.

A detailed review of the properties of Archimedean copulas can be found in McNeil and Neslehov¥a (2008). Table 4.1 of Nelsen (2006) contains a list of common one-parameter generator functions. Throughout the paper we also consider only the generator functions with a single parameter, however, most of the theory can be easily extended to the case of several parameters.

2

From the Bernstein's Theorem (Bernstein (1928)) it follows that each   L is a Laplace

transform of some distribution function. This allows us to relate the Archimedean copulas

to the Laplace transforms (see Joe (1996)). Let M be the cdf of a positive random variable and

 denotes its Laplace transform, i.e. (t) =

 0

e-tw

dM

(w).

For

an

arbitrary

cdf

F

there

exists

a unique cdf G, such that


F (x) = G(x)dM () = {- ln G(x)}.

0

Now consider a k-variate cumulative distribution function F with margins F1, . . . , Fk. Then it holds that


F (x1, . . . , xk) = G1 (x1) ∑ ∑ ∑ ∑ ∑ Gk (xk)dM () = 
0

k
- ln Gi(xi)
i=1

k
=  -1{Fi(xi)} .
i=1

This implies that the copula of F is given by (1). The representation of the copula in terms of the Laplace transforms is very useful for simulation purposes (see Whelan (2004), McNeil (2008), Hofert (2008), Marshall and Olkin (1988)).

Note that the Archimedean copula is symmetric with respect to the permutation of variables, i.e.
the distribution is exchangeable. Furthermore, the multivariate dependency structure depends
on a single parameter of the generator function . This is very restrictive and we can use Laplace transforms to derive flexible extensions. First, note that G1 ∑ ∑ ∑ ∑ ∑ Gk can be seen as a product copula of the cumulative distribution functions G1, . . . , Gk. Second, note that the whole model depends on a single cumulative distribution function M . Replacing the product copula G1 ∑ ∑ ∑ ∑ ∑ Gk with an arbitrary multivariate copula K(G1 , . . . , Gk ) and replacing M () with some k-variate distribution Mk, such that the jth univariate margin has Laplace transform j, j = 1, . . . , k, we obtain a more general type of dependency (Joe (1997)). This implies, for example, the following copula

C(u1, . . . , uk) =

(2)



. . . G1 1 (u1)G2 1 (u2)dM1(1, 2) G3 2 (u3)dM2(2, 3) . . . Gkk-1 (uk)dMk-1(k-1).

00

This generalisation of the multivariate Archimedean copulas leads to the class of hierarchical Archimedean copulas (HAC). Other orders of integration and combinations of Gi functions lead to different dependencies. For example, the fully nested (2) HAC C(u1, . . . , uk) can be rewritten in terms of the generator functions arising from the cumulative distribution functions M1, . . . , Mk-1 as

C(u1, . . . , uk) =
= 1[-1 1  2{. . . [k--12  k-1{k--11(u1)+ + k--11(u2)} + k--12(u3)] ∑ ∑ ∑ + -2 1(uk-1)} + 1-1(uk)] = 1{1-1  C2(u1, . . . , uk-1) + 1-1(uk)} = C1{C2(u1, . . . , uk-1), uk}.

The sufficient conditions on the generator functions which guarantee that C is a copula are given in Theorem 4.4 McNeil (2008). Let L denote the class of functions with a completely monotone
first derivative

L = { : [0; )  [0, ) | (0) = 0, () = ; (-1)i-1(i)  0; i = 1, . . . , }.

3

Table 1: Sufficient conditions on the parameters of generator function of Nelsen (2006), Table

4.1 to guarantee the existence of HAC.

family



-1

Gumbel exp{-x1/}

(- ln t)

Clayton (x + 1)-1/ Nel. 4.2.2 1 - x1/

1 

(x-

-

1)

(1 - x)

Nel. 4.2.3 Frank

1- ex -

-

1 

ln{e-x(e-

-

1)

+

1}

ln

1-(1-x) x

-

ln

e-t -1 e- -1

-11  2 x1 /2

1 1

{(2x

+

1)1/2

-

1}

x1 /2

ln

ex (1 -1)+2 -1 2 -1

- ln {1+e-t(e-2-1)}1/2 -1
e-1 -1

conditions 1  2,   [1, ) 1  2,   (0, ) 1  2,   [1, ) 1  2,   [0, 1)
1  2,   (0, )

It holds that if i  L for i = 1, . . . , k - 1 and i  i+1  L has a completely monotone derivative for i = 1, . . . , k - 2 then C is a copula. As noted by Lemma 4.1 in McNeil (2008), the fact that i  i+1  L for i = 1, . . . , k - 2 also implies that i  i+h  L for i = 1, . . . , k - 2.
Note that generators i within a HAC can come either from a single generator family or from different generator families. If i's belong to the same family, then the complete monotonicity of i  i+1 imposes some constraints on the parameters 1, . . . , k-1. Table 1 provides these constrains for different generators from Nelsen (2006), Table 4.1. For the majority of the copulas the parameters should decrease from the lowest to the highest level, to guarantee a feasible HAC. However, if we consider the generators from different families within a single HAC, the condition of complete monotonicity is not always fulfilled and each particular case should be analysed separately.
The aim of this paper is to provide distributional properties of HACs. First we show that if the true distribution is based on HAC then we can completely recover the true structure of HAC from all bivariate marginal distributions. This property is helpful in applications, when we estimate the HAC from data. For Normal distribution, for example, the form of the dependency is fixed and only the correlation coefficients must be estimated. For HAC both the structure and the parameters of the generators function are unknown. The established result implies that we can first estimate all bivariate copulas and then recover the tree of the HAC. Alternatively, we are forced to enumerate all possible trees, estimate the corresponding multivariate copulas and apply goodness-of-fit tests to determine the HAC with the best fit. This approach is computationally much more demanding compared with the aggregation of bivariate copulas.
Further we derive the distribution of the value of the HAC. This generalises the results of Genest and Rivest (1993) to the HAC. We take explicitly into account the hierarchical structure of the HAC and provide recursive formulas for the cdf by different types of aggregation. The results given in Section 3 can be used for developing of confidence intervals and goodness-of-fit tests. Section 4 summarises the multivariate dependence measures used in the multivariate setup and argues which of them are most convenient to be used with HAC. Section 5 contains results on the dependence orderings of HAC-based distributions. It is shown under which conditions on the generator functions one HAC is more concordant than another one. Finally Section 5 discussed the properties of HAC from the perspective of extreme value theory and provides a detailed analysis of tail dependence. In this section we establish the form of the extreme value copula and provide explicit formulas for two upper and lower tail dependence measures. All proofs are given in the appendix.

4

2 Determining the structure

In contrary to other distributional models, in HAC both the structure and the parameters of the copula must be specified or estimated. Okhrin, Okhrin and Schmid (2009) consider empirical methods for determining and estimation of the structure. If the structure is fixed, we can apply the maximum-likelihood approach to estimate the parameters. However, the choice of the structure itself is not obvious. One possible approach is to enumerate all structures, estimate the parameters and apply a goodness-of-fit test to determine the best one. This method is, however, unrealistic in higher dimensions. The results established in this section help to overcome this problem. In particular we show that if the true distribution is based on HAC, then we can completely recover the true distribution from all bivariate margins. This implies that instead of estimating all multivariate structures it suffices to estimate all bivariate copulas and use then to recover the full distribution. This makes the estimation of HAC particularly attractive in terms of computational efforts. The next proposition summarises the result.
Proposition 1. Let F be an arbitrary multivariate distribution function based on HAC. Then F can be uniquely recovered from the marginal distribution functions and all bivariate copula functions.

Assuming that marginal distributions are continuous, from the Sklar Theorem we know that the multivariate distribution function F can be split into margins and the copula function. Therefore, to recover the distribution we need to recover the structure of the HAC. The proof of the proposition consists of three parts. First, we show that any bivariate margin is a copula with the generator function which is equal to one of the generators of the full structure. Second, we show that the for any bivariate copula with a generator function from the full structure, there exists a couple of variables with the same joint bivariate distribution. Third, we suggest an aggregation procedure and show that the recovered HAC is unique.
Let
Fk1 = {Ck1 : [0; 1]k  [0; 1] : Ck1 = [-1(u1)+. . .+- 1(uk)],   L,   , u1, . . . , uk  [0; 1]}
be the family of simple k-dimensional Archimedean copulas, where  is the set of allowable parameters of . The elements of  could be of any dimension, but in general they are scalars. Based on this class we introduce the family of k-dimensional HACs with r nodes

Fkr =

Ckr : [0; 1]k  [0; 1] :

Ckr = C{Ck1r1 (uk0=1, . . . , uk1 ), . . . , Ckm-km-1,rm (ukm-1+1, . . . , ukm=k)},
m

C  Fk1, Cki-ki-1,ri  Fki-ki-1,ri , i = 1, . . . , m,

ri = r - 1 ,

i=1

where ri denotes the number of nodes in the i-th subcopula and the variables are reordered without loss of generality. If ki - ki-1 = 1 then ri = 1 and C11(ui) = ui. For example, C = C1{C2(u1, u2), u3}  F3,2, where C1, C2  F2,1 are nodes, which are also copulas. Let N (C) denote the set of the generator functions used in the HAC C. Let also Cn denote the operator which returns a k-dimensional copula given a generator functions
Cn(f )(u1, . . . , uk) = f {f -1(u1) + . . . f -1(uk)}.

5

Based on this notation, C2{N (C)}  F2,1 is the set of all bivariate Archimedean copulas used in the structure of C  Fkr.
Let now a k-dimensional HAC C  Fkr be fixed. The next remark shows that for any bivariate copula with generator from N (C) there exists a pair of variables with the same bivariate distribution.
Remark 1. i, j = 1, . . . , k, i = j, !Cij  C2{N (C)}  F2,1 : (Xi, Xj)  Cij.

As an example we consider the following 4-dimensional case with

C(u1, . . . , u4) = C1{C2(u1, u2), C3(u3, u4)} with C2{N (C)} = {C1, C2, C3}.

For an arbitrary pair of variables ui and uj from u1, . . . , u4, there exists a copula Cij from {C1, C2, C3} such that (ui, uj)  Cij. For example (u1, u3)  C1{C2(u1, 1), C3(u3, 1)} = C1(u1, u3). This implies that the bivariate margins use the same generators as the generators in the nodes of the HAC.
The second step of the proof of proposition shows the inverse relationship between the bivariate margins and the set of all bivariate copulas with the generator function from N (C). In particular it shows that for a generator on any node, there exists a pair of variables with the bivariate distribution given by an Archimedean copula with the same generator.
Remark 2. Ci,j  C2{N (C)}  F2,1, i, j = 1, . . . , k : (Xi, Xj)  Cij.

Next we describe the algorithm of recovering the structure from the bivariate margins. Let C1 denote such bivariate copula that each variable belongs to at least one bivariate margin given by C1. This copula is the top-level copula. From the Remark 1 if the copula
C = C1{C2(u1, . . . , uk1 ), . . . , Cm(ukm-1+1, . . . , uk)}
then (ui, uj)  C1, where i  [i1, i2]  N, j  ([1, k]\[i1, i2])  N, (i1, i2)  {(1, k1), . . . , (km-1 + 1, k)}.
At the next step we drop all bivariate margins given by C1 and identify the sets of pairs of variables with the bivariate distributions given by C2 to Cm. For the subtrees we proceed in the same way as for C1. To show that the structure, that we recovered is equal to the true one, one needs to explore all bivariate margins. A difference at one of the nodes would imply a change in one or several bivariate margins. But the bivariate marginal distribution coincide by construction.
For simplicity let us consider an example:
C(u1, . . . , u6) = C1[C2(u1, u2), C3{u3, C4(u4, u5), u6}].
The bivariate marginal distributions are then given by

(u1, u2)  C2(u1, u2), (u1, u3)  C1(u1, u3), (u1, u4)  C1(u1, u4), (u1, u5)  C1(u1, u5), (u1, u6)  C1(u1, u6),

(u2, u3)  C1(u2, u3), (u2, u4)  C1(u2, u4), (u2, u5)  C1(u2, u5), (u2, u6)  C1(u2, u6), (u3, u4)  C3(u3, u4),
6

(u3, u5)  C3(u3, u5), (u3, u6)  C3(u3, u6), (u4, u5)  C4(u4, u5), (u4, u6)  C3(u4, u6), (u5, u7)  C3(u5, u6).

In line with Remarks 1 and 2 the set of bivariate margins is equal to
C2{N (C)} = {C1(∑, ∑), C2(∑, ∑), C3(∑, ∑), C4(∑, ∑)}.
We observe that each variable belongs to at least one bivariate margin given by C1. This implies that the distribution of u1, . . . , u6 has C1 at the top level. Next we drop all margins given by C1. Further we proceed similarly with the rest of the margins, in particular with C3 since it covers the largest set of variables u3, u4, u5, u6. This implies that C3 is at the top level of the subcopula containing u3, u4, u5, u6. Having information only for the copulas C1 and C3
u1, . . . , u6  C1{u1, u2, C3(u3, u4, u5, u6)}.
The remaining copula functions are C2 and C4 and they join u1, u2 and u4, u5 respectively. Summarising we obtain
(u1, . . . , u6)  C1[C2(u1, u2), C3{u3, C4(u4, u5), u6}]
This results in the correct structure. Similarly we can apply inverse procedure by joining variables into pseudo-random variables, using low-level copulas. This problem is related to the multidimensional scaling problem, where having all paired distances between the cities, one has to recover the whole map, see Ha®rdle and Simar (2007).

3 Distribution of HAC

For testing purposes and construction of confidence intervals we are interested in the distributions of the empirical and the true copula. Let V = C{F1(X1), . . . , Fk(Xk)} and let K(t) denote the distribution function (K-distribution) of the random variable V . Genest and Rivest (1993) introduced a nonparametric estimator of K in the case k = 2. It is based on the concept of Kendall's process. Suppose that an independent random sample X1 = (X11, . . . , X1k) , . . . , Xn = (Xn1, . . . , Xnk) of the vector X = (X1, .., Xk) is given. Let

Vi,n

=

n

1 +

1

n

I{Xj  Xi}

j=1,j=i

and Kn denote the empirical distribution function of the Vi,n's. Here the inequality a  b means that all components of the vector a are less or equal than those of the vector b. Then the Kendall process is given by
 n(t) = n{Kn(t) - K(t)}.

Barbe, Genest, Ghoudi and R¥emillard (1996) examine the limiting behavior of the empirical process n(t) for k  2 and derived explicit formulas of its density (t) and its distribution function K(t) for general multivariate copulas. The authors provide explicit results for product and multivariate exchangeable Archimedean copulas. The paper of Wang and Wells (2000) used Kendall's process to determine the copula for failure data. In this section we adopt and extend the results of Barbe et al. (1996) to find the K-distribution of a HAC.

At the first step we exploit the hierarchical structure of the HAC. We consider a HAC of the form
C1{u1, C2(u2, . . . , uk)}. Let Ui  U [0, 1] and let V2 = C2(U2, . . . , Uk)  K2. In the next theorem we propose a recursive procedure for calculating the distribution function of V1 = C1(U1, V2) which is based on the knowledge of the distribution function of V2. This approach is particularly useful when applied to fully nested HACs.

7

Theorem 2. Let U1  U [0, 1], V2  K2 and let P (U1  x, V2  y) = C1{x, K2(y)} with C1(a, b) =  -1(a) + -1(b) for a, b  [0, 1]. Assume that  : [0, )  [0, 1] is strictly decreasing with (0) = 1 and () = 0 and that  is strictly increasing and continuous.
Moreover, suppose that K2 is continuous. Suppose that the random variable V2 takes values in [0, 1]. Then the distribution function K1 of the random variable V1 = C1(U1, V2) is given by

-1(t)

K1(t) = t -

 -1(t) + -1 [K2{(u)} - u] du for t  [0, 1].

0

(3)

In Theorem 2 V2 is an arbitrary random variable on [0, 1] and not necessarily a copula. In the special case that V2 is uniformly distributed on [0, 1] formula (3) reduces to Theorem 4.3.4 of Nelsen (2006) or to the result of Genest and Rivest (1993).

Next we consider a copula of the type V3 = C3(V4, V5) with V4 = C4(U1, . . . , U ) and V5 = C5(U +1, . . . , Uk). Making use of the distribution functions of V4 and V5 a representation of the distribution function of V3 is given in the next theorem.

Theorem 3. Let V4  K4 and V5  K5 and P (V4  x, V5  y) = C3{K4(x), K5(y)} with C3(a, b) =  -1(a) + -1(b) for a, b  [0, 1]. Assume that  : [0, )  [0, 1] is strictly
decreasing with (0) = 1 and () = 0 and that  is strictly increasing and continuous. Moreover, suppose that K4 and K5 are continuous and that -1  K4   and -1  K5   are of bounded variation on [0, -1(t)]. Suppose that the random variables V4 and V5 take values in
[0, 1] then the distribution function K3 of the random variable V3 = C3(V4, V5) is given by

-1(t)

K3(t) = K4(t) -

 -1[K5{(u)}] + -1 K4[{-1(t) - u}]

0

d-1 [K4{(u)}] (4)

for t  [0, 1].

If -1[K4{(x)}] has a continuous derivative then (4) can be written as

-1(t)
 K3(t) = K4(t) -
0

-1 [K5{(u)}] + -1 K4[{-1(t) - u}]  {(-1  K4  )-1(u)}

K4{(u)} (u)du

and similarly for the second representation. Theorem 3 reduces to Theorem 2 if V4 or V5 are uniformly distributed on [0, 1]. Moreover, by taking the derivative of the generator function it can be shown that the expression in (4) is symmetric with respect to K4 and K5.

Note that using these two results we can establish the distribution function for an arbitrary
grouping of the variables at the top level. For example, consider the copula C1{u1, u2, C2(u3, . . . , uk)}. From the properties of Archimedean copulas, this copula is equivalent to C1[u1, C1{u2, C2(u3, . . . , uk)}] and thus the result of Theorem 2 can be applied.

Theorem 2 and Theorem 3 provide recursive presentations for certain copula structures. In the
next theorem we provide a direct formula for the distribution function of a copula of the form
C{u1, Ck-1(u2, . . . , uk)}. It is an extension of the result of Barbe et al. (1996). Here we assume that uk lies on the top level of the copula. Other cases could be derived for every single form of the copula, but it is difficult to present a general result.

8

Theorem 4. Consider a HAC of the form

C(u1, . . . , uk) = C1{u1, C2(u2, . . . , uk)} = 1 k-1(uk) + 1-1{C2(u2, .., uk)} .

Assume that 1 : [0, )  [0, 1] is strictly decreasing and continuously differentiable with 1(0) = 1. Then the distribution function K1 of C(u1, .., uk) is equal to

tt

K1(t) = k(x) dx =

∑ ∑ ∑ hk{x, u2, . . . , uk} du2 . . . duk dx for t  [0, 1],

0 0 (0,1)k-1

where

hk(t, u2, . . . , uk)

=

1 1-1(t) - 1-1  C2(u2, . . . , uk) 1{1-1(t)}

◊ c 1{-1 1(t) - 1-1  C2(u2, . . . , uk)}, u2, . . . , uk

◊ I C2(u2, . . . , uk) > t for (u2, . . . , uk)  [0, 1]k-1.

c(u1, .., uk) denotes the copula density of C.

The practical calculation of K1 using Theorem 4 seems to be quite difficult because of multivariate integration. As an example we consider the Clayton family.

Example 1. Here we consider the simplest three-dimensional fully nested Archimedean copula with Clayton generator functions

(t) = (t + 1)-1/.

The copula function is given by

C(u1, u2, u3; 1, 2)

=

C2 {C1 (u1, u2), u3}

=

{(u1-1

+ u2-1

-

1)-

2 1

+

u3-2

-

-
1}

1 2

and

h3(u1, u2, t; 1, 2) =

u21 - u11 u21 - 1

-2
(u1

u2

)1

-1

p1

r

1+2 1

p1

+

r

2 1

-1

-3-

1 2

◊

1 - t1 (p2 - 1)

-1-

1 1

p1(1

+

1

+

2)

+

r 2 1

(1

-

2)

+

2

-

1

◊ (1 + 2) I

u1-1

+

u-2 2 - 1

t-1

-

1

<

0

with pi =

-i+3
u1-i + u2-i - 1 i for i = 1, 2

r = 1 + t-1 - p2.

4 Multivariate Dependence Measures
If we consider a multivariate random vector we are often interested in the dependency measures between the components of the vector. In case of the Gaussian distribution the whole dependence
9

can be uniquely characterized by the linear correlation coefficients. Since it is a measure of the linear dependency between random variables, it is not an appropriate measure for non-linear relationships. As an alternative correlation coefficients based on ranks of the ordered data can be considered. The most popular measure is Kendall's  . For a bivariate copula it is defined as

11

2 = 4

C(u1, u2) dC(u1, u2) - 1.

00

The extension to the multivariate case is not straightforward and unique. A multivariate version of Kendall's  and its empirical representation is proposed in Barbe et al. (1996) as an affine transformation of the expectations of the variables V and Vn respectively.

k

=

2k 2k-1 -

1

E(V

)

-

1

=

2k 2k-1 - 1

t dK(t)

-

1

=

2k 2k-1 -

1

t(t) dt - 1,

^kn

=

2k 2k-1 -

1

∑

1 n

n

Vn(X1i, . . . , Xki) - 1

=

2k 2k-1 - 1

i=1

t dKn(t) - 1,

where (t) is the density function of the cdf K(t). This justifies the name Kendall's process in the last section as coined by Genest and Rivest (1993).

Another popular measure of dependence is Spearman's . In the bivariate case it is given by

2 =

1 0

1 0

u1

u2

dC (u1

,

u2)

-

1

12 2

=

12

1 0

1 0

C (u1 ,

u2)

du1

du2

-

1 3

-

1 4

1 4

1
= 12
0

1
C(u1, u2) du1 du2-3.
0

Two alternative multivariate extensions are given by

k1

=

k+1 2k - (k + 1)

2k

C(u) du - 1 ,

[0,1]k

k2

=

k+1 2k - (k + 1)

2k

u1 . . . uk dC(u) - 1 .

[0,1]k

k1 was introduced by Wolff (1980) and k2 in Joe (1997) and Nelsen (2006). Both measures were thoroughly investigated by Schmid and Schmidt (2006a) and Schmid and Schmidt (2006b).
The explicit computation of k1 and k2 is difficult for almost all copula functions. Therefore, as a simplification a pairwise version of Spearman's  was proposed in Kendall (1970)

kr = 22

k -1 2

Cml(u,

v) dudv

-

1

=

3(k

2 -

1)k

(2,kl + 3) - 1,

m<l

[0,1]2

m<l

where Cml is the bivariate copula for the variables um and ul and 2,kl denotes the bivariate Spearman's  for uk and ul. The last representation of Spearman's  is very useful for HACs, because all bivariate sub copulas in a HAC are simple bivariate Archimedean copulas. Hence
kr could be easily computed for a HAC by calculating all bivariate Spearman's 's.

Example 2. For the simple exchangeable Archimedean copula the pairwise Spearman's kr is

kr

=

(k

- 2)! 24

(2

+

3)

-

1,

where 2 is the bivariate Spearman's  based on the generator function of the given copula.

10

As the third multivariate dependence measure we discuss Blomqvist's . In the bivariate and in the multivariate cases it is computed as follows

2 = P{(x - x~)(y - y~) > 0} - P{(x - x~)(y - y~) < 0},

k

=

2k-1 2k-1 -

1

{C

(1/2,

.

.

.

,

1/2)

+

C

(1/2,

.

.

.

,

1/2)

-

21-k

},

where x~ and y~ are the population medians, and C(u) = 1 + sS (-1)|s|Cs(uj; j  s) is the survival copula and S is the set of all subsets of {1, . . . , k}. Schmid and Schmidt (2006c) provide
a detailed discussion of these measures.

Example 3. For the k-dimensional exchangeable Archimedean copula the Blomqvist's  in terms of the generator functions is given by

k

=

2k-1 2k-1 -

1

{k-1(1/2)} +

k
(-1)i

k i

{i-1(1/2)} - 21-k

.

i=1

Example 4. Blomqvist's  for the simplest two-dimensional fully nested Archimedean copula
C(u1, u2, u3, 1, 2) = C2{C1(u1, u2), u3} with the generator functions 1 and 2 respectively is given by

3

=

8 3

2

{2-21(1/2)}

+

4 3

1

{2-11

(1/2)}

-

1.

For different generator functions this reduces to the expressions summarized in the following table.

family
Clayton Gumbel Nelsen 4.2.2

3

4 3

21+1 - 1

-1/1

+

8 3

22+1 - 1

-1/2 - 1

-1

+

4 3

exp{-21/1 ln 2} + 2 exp{-21/2 ln 2}

1 3

9 - 21+1/1 - 22+1/1

The considered measures depend on the copula function and can be used to measure the dependence of copula-based distributions. Unfortunately, there are numerous drawbacks of these measures. First, there is no unique decision on the superiority of one of the measures. There are papers which compare these measures in the bivariate framework (Chen (2004), Durrleman, Nikeghbali and Roncalli (2000), Fredricks and Nelsen (2004), etc.), however, nothing similar has been done in the multivariate case. Second, it is very restrictive to use a single scalar measure to quantify all the relationships between the components of a k-dimensional random vector. Third, Kendall's  and Spearman's  are difficult to compute explicitly because of the multivariate integrals of the copula functions. Nevertheless, the estimators are readily available. Fourth, there is no unique method how to extend a bivariate dependence measure to the multivariate case. This inflates the number of candidates for dependence measures and makes the conclusions of empirical studies less transparent. Summarizing, due to their simplicity, we recommend to use the multivariate extension of Blomqvist's  or the pairwise multivariate Spearman's kr for the HAC models.

11

5 Dependence Orderings

Dependence orderings allows us to compare the strength of the dependence imposed by different copula functions. In this section we show some necessary conditions under which one HAC is more concordant than other. By definition (Joe (1997), p.37), C is more concordant than C if
C c C  C(x)  C (x) and C(x)  C (x) x  [0; 1]k.
This type of the ordering is also called positive quadrant ordering (PQD) or upper orthant ordering (see Mu®ller and Stoyan (2002)). The case of two multivariate normal distributions gives us interesting insights into this ordering. Let X  Nk(µ, ) and X  Nk(µ ,  ). If µi = µi, ii = ii for i = 1, . . . , k, and ij  ij for 1  i < j  k then X c X .
In the bivariate case the most concordant is the Fr¥echet upper bound and the most discordant copula is the Fr¥echet lower bound. Another peculiarity of the bivariate case is the relationship between the concordance ordering the dependence measures. It appears that if C1 and C2 are two copulas with Kendall's taus 1, 2, Spearman rhos 1, 2, tail dependence parameters 1, 2, Blomqvist's betas 1, 2 respectively, then C1 c C2 implies that 1  2, 1  2, 1  2 (Joe (1997)) and 1  2 (Schmid and Schmidt (2006c)).
Several interesting results can be derived if C is an Archimedean copula. First note that there is no sharp lower bound for the general class of copulas, however McNeil and Neslehova¥ (2008) construct the sharp lower bound in the class of Archimedean copulas. Thus there is an Archimedean copula CL, such that CL c C for any Archimedean copula C. Joe (1997) considers in Theorem 4.8, 4.9 and 4.10 three and four dimensional HACs with different fixed structures. The theorems provide the conditions on the top level generator functions to guarantee the concordance of the HACs, assuming that the generators at lower levels are the same. In Joe (1997) the author also states that these theorems could be easily extended to any messy structure of the copula. Next we provide a general results for an arbitrary tree. The proof uses explicitly the hierarchical structure of the copula.
Theorem 5. If two feasible hierarchical Archimedean copulas C1 and C2 differ only by the generator functions on the top level satisfying the condition -1 1  2  L, then C1 c C2.

In the next theorem we generalize this result to changes at an arbitrary level of the copula.

Theorem differ only

6. by

If two hierarchical Archimedean the generator functions on the

copulas C1 level r as

=

C1 1 (u1,

.

.

.

,

uk )

and

C2

=

C2 2 (u1,

.

.

.

,

uk )

1 = (1, . . . , r-1, , r+1, . . . , p) and 2 = (1, . . . , r-1, , r+1, . . . , p) with -1    L, then C1 c C2.

Note that the condition we impose on the generator function is the sufficient condition to construct a HAC (see Theorem 4.4 of McNeil (2008)). For example, consider two HACs with the same structure and with the same generator functions on the corresponding levels. For some fixed level, let 1 be the parameter of the generator function for the first copula, and 2 for the second. If the conditions given in the last column hold, then the first copula is more concordant than the second.

12

6 Extreme Value Theory and Tail Dependency

6.1 Extreme Value Copula

In the univariate case the distribution of the maxima or minima of a sample is defined as follows (see Embrechts, Klu®ppelberg and Mikosch (2001))

Definition 1. For independent identically distributed random variables Xn if there exist con-

stants bn

>

0,

an



R,

a non-degenerating function F 

with

m+-bn an

d

F

where m+

=

max{X1, . . . , Xn}, then

F (, m+) = exp

-

1

-



m+ - b

a

1/

with

1

-



m+-a b

> 0 and  = (, a, b).

The multivariate extreme value distribution can be characterised by the following theorem
Theorem 7 (Deheuvels (1978)). Let {X1i, . . . , Xki}i=1,...,n be a sequence of the random vectors with the distribution function F , marginal distributions F1, . . . , Fk and copula C. Let also Mj(n) = max1in Xji, j = 1, . . . , k be the componentwise maxima. Then

lim P
n

M1(n) - a1n b1n



x1,

.

.

.

,

Mm(n) - bkn

akn

 xk

= F (x1, . . . , xk), (x1, . . . , xk)  Rk

with bjn > 0, j = 1, . . . , k, n  1 if and only if

1. for all j = 1, . . . , k there exist some constants ajn and bjn and a non-degenerating limit distribution Fj such that

lim P
n

Mj(n) - bjn

ajn



xj

= Fj(xj),

xj  R;

2. there exists a copula C such that

C  (u1 ,

.

.

.

,

uk )

=

lim
n

C n (u11/n ,

.

.

.

,

u1k/n).

In this case we say that copula C is the extreme valued copula and the copula C belongs to the maximum domain of attraction of the copula C (written C  M DA(C)). This implies that a multivariate distribution with all margins being extreme-valued distributions and with an extreme-valued copula is a multivariate extreme-valued distribution. Genest and Rivest (1989) show that the only Archimedean extreme-valued copula is the Gumbel copula. Thus, each bivariate Archimedean copula belongs to the domain of attraction of the Gumbel copula. Using Proposition 1 and the result of Genest and Rivest (1989) we state the next theorem.
Theorem 8. If C  Fnr1, C  Fnr2 and C  M DA(C) then r1 = r2,   N (C),  = exp{-x1/} and the structure of C is equal to the structure of C.

13

6.2 Tail Dependency

Next we consider the tail dependence of HAC. The tail behavior characterises the tendency of random variables to take extreme values simultaneously. The upper and lower tail indices of two random variables X1  F1 and X2  F2 are given by

U

=

lim
u1-

P {X2

>

F2-1(u)

|

X1

>

F1-1(u)}

=

lim
u1-

C(u, u) 1-u

=

2

-

lim
u1-

1

- C(u, u) 1-u

L

=

lim
u0+

P {X2



F2-1(u)

|

X1



F1-1(u)}

=

lim
u0+

C (u, u

u) .

The upper index is equal to limit of the probability that one variable exceed some predetermined limit conditional on the fact that another variable exceeded this limit. Similarly the lower limit describes the tendency to simultaneous undershooting some limit. We replicate the Corollary 5.4.3 of Nelsen (1997) which states explicitly the tail dependency indices for bivariate Archimedean copulas.

Theorem 9 (Nelsen (1997)). For a bivariate Archimedean copula with the generator  it holds

U

=

2

-

lim
u1-

1

-

{2-1(u)} 1-u

=

2

-

lim
w0+

1 - (2w) 1 - (w)

,

L

=

lim
u0+

{2-1(u)} u

=

lim
w

(2w) (w)

.

In this section we extend the concept of the tail dependence to multivariate distributions and consider several alternative definitions of it. First we consider the straightforward extension of the bivariate definition. Let K = {1, . . . , k} and s is a subset of K. Then we denote by Cs the marginal copula of the variables with indices in s, i.e. Cs(ui, i  s) = C(u1, . . . , uk|uj = 1, j  s). Let the upper and lower tail indices of k random variables Xi  Fi for i = 1, . . . , k are given by

U(1)(u1, . . . , uk|ui)

=

lim
u0+

P

{.

.

.

,

Xi-1

>

Fi--11(1 - ui-1u), Xi+1

>

Fi-+11(1 - ui+1u), . . .

|

Xi

>

Fi-1(1 - uiu)}

=

lim
u0+

C (1

-

u1u, . . . uiu

,

1

-

uku)

1- = lim
u0+

sK,s=(-1)|s|+1Cs(1 - uj u, j  s) uiu

=

(-1)|s|+1 lim

sK,s=

u0+

1 - Cs(1 - uju, j uiu



s)

=:

1 ui

s,
sS ,s=

(L1)(u1, . . . , uk|ui)

=

lim
u0+

P

{.

.

.

,

Xi-1



Fi--11(ui-1u), Xi+1



Fi-+11(ui+1u), . . .

|

Xi



Fi-1(uiu)}

=

lim
u0+

C(u1u, . . . uiu

,

uku)

=:

1 ui

(L1)(u1,

.

.

.

,

uk

).

(U1)(u1, . . . , uk) defines the limit of the probabilities that all random variables simultaneously exceed the thresholds 1-uju conditional on the fact that one particular random variable exceeded

14

its limit 1 - uiu as u  0+. Similar motivation holds for (L1) too. By setting uj = u for all j = 1, . . . , k we obtain a definition similar to the bivariate definition above. For example,

(L1)

:=

L(1)(1, . . . , 1)

=

lim
u0+

P

{.

.

.

,

Xi-1



Fi--11(u), Xi+1



Fi-+11(u), . . .

|

Xi



Fi-1(u)}

=

lim
u0+

C (u,

.. u

.

,

u) ,

and

similarly

for

L(2)

:=

L(2)(1, . . .

, 1)

=

limu1-

C(u,...,u) u

.

From Theorem 9 it follows that the tail indices of Archimedean copulas are closely related to the regular variation of the generator functions. Here we replicate the definition of regular variation of functions at zero and and infinity following Shorack (2000).

Definition 2. Call V (∑) > 0 regularly varying at 0 with characteristic exponent (tail index)  > 0 (written V  R) if limt0+ V (tx)/V (t) = x-.

From the monotone density theorem (see Shorack (2000), Theorem 9.1) it follows that

V  R iff

lim tV (t)/V (t) = .
t0+

Definition 3. Call V (∑) > 0 on (0, ) regularly varying at infinity with characteristic exponent  > 0 (written V  U) if limt V (tx)/V (t) = x-.

The limits exist for a very wide family of functions and all common generator functions of Archimedean copulas. Since the dependency of the copula is uniquely determined by its structure and generator functions, the multivariate tail indices can be given in terms of the tails indices of generator functions. For further exposition we find useful the following proposition which relates the variability of a function with the variability of the inverse function. Here restrict the discussion only to generator functions.

Proposition 2. Let for the non-increasing generator function   L it holds that

lim
t

(xt) (t)

=

1(x),

lim
t0+

1 - (xt) 1 - (t)

=

2(x),

where i(x)  const and i   for i = 1, 2. Then for the inverse generator function -1, i.e. -1(y) = inf{x : (x)  y} it holds that

lim
t0+

-1(xt) -1(t)

=

1-1(x),

lim
t0+

-1(1 - xt) -1(1 - t)

=

2-1(x).

Relying on these results, the next theorem extends Theorem 9 to HAC. We derive both measures for a HAC of an arbitrary structure and with arbitrary generator functions. The theorem provides a recursive method for determining the lower and upper tail dependencies depending on the functions i for i = 1, 2. We discuss the case when the generator function is regularly varying at zero and/or infinity in remarks below.
Theorem 10. Let X1, . . . , Xk  C such that
C(u1, . . . , uk) = C0{C1(u1, . . . , uk1 ), . . . , Cm(ukm-1+1, . . . , ukm ), ukm+1, . . . , uk},

15

where C0 is an Archimedean copula with the generator 0  L and Ci for i = 1, . . . , m are
Archimedean or hierarchical Archimedean copulas with the upper and lower tail dependence indices (U1,)i and L(1,)i respectively. Further we assume that for the generator 0 it holds that i(x)  const and i(x)   for i = 1, 2. Then the upper and lower tail dependency indices
for C are given by

(L1)(u1, . . . , uk|ui)

=

1 ui

1

mk

1-1{(L1,)i(uki-1+1, . . . , uki )} +

-1 1(uj )

i=1 j=km+1

(U1)(u1, . . . , uk|ui)

=

1 ui

(-1)|s|+12
sK,s=

ms

-2 1(si) +

-2 1(uj )

i=1 is\jm=s1sj

,

where

si's

denote

the

limits

limu0+

1-Csi (1-uj u,jsis) u

for

the

first-level

subcopulas

of

Cs{Cs1 (ui, i  s1), . . . , Csms (ui, i  sms ), u|s|ms +1, . . . , u|s|}

with |s|ms =

ms i=1

|si|.

The last theorem gives a recursive tool for determining the tail index of a HAC with arbitrary
structure. Next we consider several special simplifying examples. First, assume that u1 = ∑ ∑ ∑ = uk = 1. Thus we consider the same threshold for each variable. In this case the upper and lower tail indices are given by

(L1)(1, . . . , 1)

=

lim
u0+

u-1P (Xi

<

Fi-1(u)

for

all

i

=

1, . . . , k)

m

= 1

-1 1(L(1,)i) + k - km

i=1

(U1)(1, . . . , 1)

=

lim
u0+

u-1P (Xi

>

Fi-1(1

-

u)

for

all

i

=

1,

.

.

.

,

k)

ms

=

(-1)|s|+12

2-1(si) + |s| - |s|ms ,

sS ,s=

i=1

Second, let C be a k-dimensional Archimedean copula with the generator function 0. Let 1 denote the tail index of 0 at infinity and 2 denotes the tail index of 1 - 0 at zero. Then

L(1)

=

lim
u0+

C(u, . . . , u) u

=

lim
u0+

{k-1(u)} u

=

lim
w

(kw) (w)

=

1(k)

=

k-1

U(1)

=

k
lim (-1)i+1
u0+ i=1

k i

1 - {i-1(1 - u)} u

=

k
(-1)i+1
i=1

k i

2(i)

=

k
(-1)i+1

k i

i-2 .

i=1

Next we discuss the lower tail dependency index in more details. Let the generator function 0

be regularly varying at infinity, i.e.

0

 U

and

1(x)

=

limt

0(tx) 0(t)

= x- .

Note that

1-1(uj) = u-j 1/ > 1 for uj  [0, 1]. This implies that the argument of 1 in the expression

for (L1)(u1, . . . , uk|ui) is larger than one. It follows that 1(x) = x-  [0, 1] for x > 1 and,

16

therefore, (L1)(u1, . . . , uk)  [0, 1]. If u1 = ∑ ∑ ∑ = uk = 1 the strength of the dependence increases as (L1)(1, . . . , 1) increases from zero to one.
The following two special cases deserve additional discussion. The weakest dependency (lower tail independence) is achieved if the tail index  of the generator 0 at the top level is zero. Thus the generator function is a slowly varying function at infinity. This leads to 1(x)  0, -1 1(x)  1 and L(1)(1, . . . , 1) = 0. In the general case the tail independency implies that the probability of exceeding the threshold by all variables is independent on the crossing the threshold by the benchmark variable. The strongest dependence (perfect dependence) is obtained if  tends to infinity and implies that the generator function is a strongly varying function with 1(x)  1 and -1 1(x)  . In this case the tail index of the HAC is ui and equals the probability that the i-th variable exceeds the threshold. This implies that the variables take extremely small values always simultaneously. Note that in these extreme cases the tail dependency index is independent on the generator functions and tails indices at lower level. It is completely characterised by the behaviour of the top-level generator.

For the upper tail dependency index the situation is slightly different. Let the generator function

1 - 0 be regularly varying at zero. From the monotonicity properties of the generator function

it

follows

that

2(x)

=

limt0+

1-0(tx) 1-0(t)

= x0 .

This implies that 2-1(x) = x1/0.

Similarly

as for the lower tail, the weakest dependence (upper tail independence) is achieved for 0 = 1,

while the strongest (perfect upper tail dependence) is attained if 0 tends to zero.

Remark on non-strict generators
A generator 0 is strict if 0() = 0. In this case we have a correctly specified inverse generator. If the generator is not strict, then there exists a constant c1 such that 0(t) = 0 for all t > c1. Additionally there exists another constant c2, such that -0 1(0) = c2. This implies that 1-1  1 and 1 is not specified uniquely. However, if we recall that regularly varying function -1 1(x) = x-1/, then for non-strict generators the tail index equals  = 0. This implies 1  0. Thus a non-strict generator at the top level of the copula implies lower tail index equal to zero. This result is independent on the tail indices or strictness of the generators at lower
levels. Note that it must hold that 0(0) = 1 to guarantee the properties of the distribution function.

Now we consider a generalisation of the above definition of the multivariate tail dependency. (U2) defines the probabilities that all random variables simultaneously exceed the thresholds ui
conditional on the fact that a subset S of the random variable exceeded them and similarly for L(2).

U(2)(u1, . . . , uk|ui, i  S)

=

lim
u0+

P {Xi

>

Fi-1(1

-

uiu)

for

i  S  K = {1, . . . , k} =

| Xj

> Fj-1(1 - uju)

for

j  S}

|K|

= lim C(1 - u1u, . . . , 1 - uku) = lim u0+ C(1 - uj1 u, . . . , 1 - uj|S|u) u0+

s1K(-1)|s1|+1{1 - Cs1 (1 - uj u, j  s1)} s2S (-1)|s2|+1{1 - Cs2 (1 - uj u, j  s2)}

|S |

17

Table 2: Functions 1 and 2 for all strict generator functions from (Nelsen, 2006), Table 4.1.

 1(x) 2(x)

1 x-1/

x

30

x

4 0 x1/

50

x

6 0 x1/

90

x

10 0

x

 1(x) 2(x) 12 x-1/ x1/

13 0

x

14 x-1 x2/

16 x-1

x

17 0

x

19 1

x

20 1

x

(L2)(u1, . . . , uk|ui, i  S)

=

lim
u0+

P {Xi



Fi-1(uiu)

for

i  S  K = {1, . . . , k} | Xj  Fj-1(uju)

for

j  S}

|K|

=

lim
u0+

C(1 - u1u, . . . , 1 - uku) C(1 - uj1 u, . . . , 1 - uj|S| u)

.

|S |
The next theorem readily follows from Theorem 10.

Theorem 11. Let X1, . . . , Xk  C such that

C(u1, . . . , uk) = C0{C1(u1, . . . , uk1 ), . . . , Cm(ukm-1+1, . . . , ukm ), ukm+1, . . . , uk},

where C0 is an Archimedean copula with the generator 0  L and Ci for i = 1, . . . , m are
Archimedean or hierarchical Archimedean copulas. Let S be an arbitrary subset of the variables, such that (U1)(uj, j  S)  0 and (L1)(uj, j  S)  0. Then the upper and lower tail dependence indices for C are given by

(L2)(u1, . . . , uk|ui, i



S)

=

(L1)(u1, . . . , uk) (L1)(ui, i  S)

and

U(2)(u1, . . . , uk|ui, i



S)

=

U(1)(u1, . . U(1)(ui, i

., 

uk ) S)

.

Example 5. Next we provide the expressions for the function 1 and 2 for different strict

generator functions (see Nelsen (2006), Table 4.1). Note, that the generators provided in Nelsen

(2006) correspond to -1 in our notation. By setting k = 2 we obtain the results in Nelsen

(2006), p. 215. The possible values of the functions 1 and 2 provide interesting insights into the tail dependencies of copulas. If i(x) is independent on the parameter  then the tail index depends only on the structure and the parameters at different levels do not influence the strength

of the dependency in the tails. Note that most of the generators imply lower and upper tail

independency. This observation is particularly important for applications and shows the need

for new generator families, which allow for tail dependencies.

7 Appendix
Proof of Remark 1. We consider here two cases. First let ui and uj be on different subnodes of the first level of the copula
C(u1, . . . , ui, . . . , uj, . . . , uk) = Ckr{. . . , Ck -k -1,r (uk -1+1, . . . , ui, . . . , uk ), . . . , . . . , Ck -k -1,r (uk -1+1, . . . , uj, . . . , uk ), . . .},
18

where r is the number of all nodes, Ck1,r1  Fk1,r1 , . . . , Ckm-km-1,rkm  Fkm,rm the subcopulas on the first level and the root Ckr  Fm,1. From the properties of multivariate distributions the bivariate margin of ui and uj is given by
(ui, uj)  C(1, . . . , ui, . . . , uj, . . . , 1) = Ckr{. . . , Ck -k -1,r (1, . . . , ui, . . . , 1), . . . , Ck -k -1,r (1, . . . , uj, . . . , 1), . . .}.
Since C(1, . . . , 1, u, 1, . . . , 1) = u and C(1, . . . , 1) = 1 it follows that
(ui, uj)  C(1, . . . , ui, . . . , uj, . . . , 1) = Ckr(1, . . . , ui, . . . , uj, . . . , 1) = {-1(1) + . . . + -1(ui) + . . . + -1(uj) + . . . + -1(1)} = {-n 1(ui) + -1(uj)} = Cn,2(ui, uj)
where Ck2  F2,1 and Ck2  C{N (C)} by construction. Thus we showed, that if two variables lie in different subcopulas of the top level, their bivariate distribution is given by the top level copula. On the other case if ui and uj be on the different subnodes of the second level in the copula then
C(u1, . . . , ui, . . . , uj, . . . , uk) = Ckr{. . . , Ck -k -1,r (uk -1+1, . . . , ui, . . . , uj, . . . , uk ), . . . , . . . , Ck -k -1,r (uk -1+1, . . . , . . . , uk ), . . .}.
Proceeding with the copula Ck -k -1,r with generator 2 in the same way as with the original copula C in the first part of Remark, we obtain that (ui, uj)  2{2-1(ui)+-2 1(uj)}. Continuing the recursion we complete the proof.
Proof of Remark 2. The proof is similar to the proof of Remark 1. Let us fix the bivariate copula C2  C2{N (C)}. Without loss of generality assume that the generator  = N (C2) is used to construct the subcopula at the second level of the original copula C. We reorder the variables for simplicity. Then
C(u1, . . . , uk) = Ckr{. . . , C2(u1, . . . , um), . . . } = Ckr[. . . , 1{-1  C1(∑), . . . , -1  Cp(∑)}, . . . ].
Now we proceed as in Remark 1 by taking two variables from different subcopulas of the second level of C2. Without loss of generality we take one variable u from copula C2 and another v from Cp. This shows that there exist a pair of random variables (u, v) with the joint bivariate distribution function given by C2(u, v).
Proof of Theorem 2. Let t  [0, 1] be fixed. a) Then it holds that {V1  t}  {U1  t} = {U1  t} since U1  t is a subset of V1  t. Moreover,
{V1  t}  {U1 > t} = {V2  gt(U1)}  {U1 > t}
19

with gt(x) = (-1(t) - -1(x)) for x  [t, 1]. The function gt(.) : [t, 1]  [0, 1] is strictly decreasing with gt(t) = 1. Consequently it follows that

P (V1  t) = P (V1  t  U1  t) + P (V1  t  U1 > t) = t + P {V2  gt(U1)  U1 > t}

(5) (6)

because P (U1  t) = t. b) In order to calculate the second quantity of (6) we consider a partition t = t0 < t1 < .. < tN = 1 of the interval [t, 1]. Then it holds that

N

P {V2  gt(U1)  U1 > t} =

P {V2  gt(U1)  ti-1 < U1  ti}

i=1

 

N i=1

P (V2



gt(ti-1)



ti-1

<

U1



ti)



N i=1

P (V2



gt(ti)



ti-1

<

U1



ti)

since gt(ti)  gt(U1)  gt(ti-1) if ti-1 < U1  ti. c) First we consider the upper bound. We get that

P {V2  gt(ti-1)  ti-1 < U1  ti} = P {U1  ti  V2  gt(ti-1)} -
- P {U1  ti-1  V2  gt(ti-1)}
= C1[ti, K2{gt(ti-1)}] - C1[ti-1, K2{gt(ti-1)}] =  -1(ti) + -1[K2{gt(ti-1)}] - -  -1(ti-1) + -1[K2{gt(ti-1)}] .

Now we determine the partition by choosing tN-i = (iw/N ) for i = 0, .., N with w = -1(t).
This choice fulfills the requirement that t = t0 < t1 < .. < tN  1. Moreover, gt(ti) = tN-i. With the notation (x) = -1[K2{(x)}] - x there exists such N,i that

P {V2  gt(ti-1)  ti-1 < U1  ti}

=



w-

w N

+

i

- N

1

w

-

w+

i

- N

1

w

=

-

w N



w+

i

- N

1

w

- N,i

with 0  N,i  w/N . Now let  > 0. Since  is strictly decreasing it holds for N  N0 that

P {V2



gt(ti-1)



ti-1

<

U1



ti}



-

w N



w-+

i

- N

1

w

.

Because

lim
N 

N i=1

-

w N



w-+

i

- N

1

w

w
= -  {w -  + (x)}dx
0

it follows that

w

w

P

(V1



t



U1

>

t)



lim inf
0

-

 {w -  + (x)}dx = -

 {w + (x)}dx.

00

20

d) Next we consider the lower bound. We obtain by analogy to c) and with N,i as above that

P {V2  gt(ti)  ti-1 < U1  ti}

=

-

w N



w+

i N

w

- N,i



-

w N



w+

i N

w

.

Consequently
w
P (V1  t  U1 > t)  -  {w + (x)}dx.
0
Because the upper and the lower bound are the same this completes the proof.

Proof of Theorem 3. The proof is based on a similar argumentation as the proof of Theorem 2. Using the above arguments we get that

P (V3  t) = K4(t) + P (V3  t  V4 > t)

and  
P (V3  t  V4 > t)  
a) Moreover,

N i=1

P {V5



gt(ti-1)



ti-1

<

V4



ti}

.

N i=1

P {V5



gt(ti)



ti-1

<

V4



ti}

P {V5  gt(ti-1)  ti-1 < V4  ti} = P {V4  ti  V5  gt(ti-1)} -

- P {V4  ti-1  V5  gt(ti-1)}

= C3[K4(ti), K5{gt(ti-1)}] - C3[K4(ti-1), K5{gt(ti-1)}] =  -1{K4(ti)} + -1[K5{gt(ti-1)}] - -  -1{K4(ti-1)} + -1[K5{gt(ti-1)}]

=



4

w

-

i N

w

+ 5

i

- N

1

w

-

-



4

w

-

i

- N

1w

+ 5

i

- N

1

w

with 4(x) = -1[K4{(x)}] and 5(x) = -1[K5{(x)}]. Then

P {V5  gt(ti-1)  ti-1 < V4  ti} =

4

w

-

i N

w

- 4

w

-

i

- N

1w

◊

5

i

- N

1

w

+ 4 w - ~N,iw

with (i - 1)/N  ~N,i  i/N . Because 5{w(i - 1)/N }  5(w~N,i) it follows that

N
P {V5  gt(ti-1)  ti-1 < V4  ti} 

N

4

w

-

i N

w

- 4

w

-

i

- N

1w

i=1 i=1

◊  5(w~N,i) + 4(w - w~N,i)

21

1w
 -  {5(tw) + 4(w - tw)} d4(w - tw) = -  {5(u) + 4(w - u)} d4(u).
00
b) For the lower bound we get

P {V5  gt (ti)  ti-1 < V4  ti}

=



4

w

-

i N

w

+ 5

i N

w

-

-



4

w

-

i

- N

1

w

+ 5

i N

w

=

4

w

-

i N

w

- 4

w

-

i

- N

1w

◊

5

i N

w

+ 4 w - wN ,i

◊

with (i - 1)/N  N ,i  i/N . Since 5(wi,N )  5(wi/N ) we obtain that

N
P {V5  gt(ti-1)  ti-1 < V4  ti} 

N

4

w

-

i N

w

- 4

w

-

i

- N

1w

i=1 i=1

◊  5(wN ,i) + 4(w - wN ,i)

◊

and thus the result follows as in a).

Proof of Theorem 4. We follow the idea of the proof of Theorem 2 of (Barbe et al., 1996). The copula is given by

C(u1, . . . , uk) = 1{k-1(uk) + 1-1  Ck-1(u2, . . . , uk)} = P {F1(X1)  u1, . . . , Fk(Xk)  uk}.

Since -1 1(1) = 0 it holds that C(1, u2, . . . , uk) = C2(u2, . . . , uk). Differentiating C with respect to u1 we get that

C(u1, . . . , uk) u1

=

1[-1 1(u1) + 1-1{C2(u2, . . . , uk)}] 1{-1 1(u1)}

>

0.

Next consider conditional copula P {F1(X1)  u1|F2(X2)  u2, . . . , Fk(Xk)  uk} which we

denote

as

C(u1|u2, . . . , uk)

=

Ck Ck-1

(u1 (u1

,...,uk ) ,...,uk-1

)

.

Thus

it

follows

that

P {C(u1, . . . , uk)  t} = P {C(u1|u2, . . . , uk) ∑ C2(u2, . . . , uk)  t}

=

P

C(u1|u2, . . .

,

uk )



t C2(u2, . . .

,

uk )

.

Let us consider the following function

Q(t) = inf{u1  [0, 1] : C(u1|u2, . . . , uk)  t}

22

for t  [0, 1]. It follows as in the proof of Theorem 2 of Barbe et al. (1996) that

K1(t)

=

 t

Q

(0,1)k-1 :C2 (u2 ,...,uk )t

t C2(u2, . . . , uk)

◊

ck Q

t C2(u2, . . . , uk)

, u2, . . . , uk du2 . . . duk.

Next

we

compute

 t

Q

t C2 (u2 ,...,uk )

. Note that by definition of Q it holds that

CQ

t C2(u2, . . . , uk)

, u2, . . . , uk

= t.

Differentiation with respect to t leads to

1=

C(u1, . . . , uk)

u1

u1=Q

t C2(u2,...,uk )

∑

 t

Q

t C2(u2, . . . , uk)

.

Thus using the fact that C is a HAC with the generator  at the highest level we obtain

 t

Q

t C2(u2, . . . , uk)

-1

=

C(u1, . . . , uk)

u1

u1=Q

t C2(u2,...,uk )

=

1{1-1  C2(u2, . . . , uk) + -1 1(u1)}

1{1-1(u1)}

u1=Q

t C2(u2,...,uk )

= 1{-1 1(t)}

1 1-1  Q

t C2 (u2 ,...,uk )

+ 1-1  C2(u2, . . . , uk)

=

1{-1 1(t)}

.

1  -1 1  C Q

t Ck-1(u1,...,uk-1)

, u2, . . . , uk

-1

Using the following algebraic and probabilistic transformations

Qu2,...,uk = inf

t C(1, u2, . . . , uk)

=

u1



[0, 1]

:

C(u1|u2, . . . , uk)



t C(1, u2, . . . , uk)

= inf {u1  [0, 1] : P {F1(X1)  u1 | F2(X2)  u2; . . . ; Fk(Xk)  uk}

◊ P {F2(X2)  u2; . . . ; Fk(Xk)  uk}  t}

= inf {u1  [0, 1] : P {F1(X1)  u1; . . . ; Fk(Xk)  uk}  t}

= inf {u1  [0, 1] : C(u1, . . . , uk)  t}
= inf u1  [0, 1] : 1{-1 1(u1) + 1-1  C2(u2, . . . , uk)}  t = inf u1  [0, 1] : u1  1{1-1(t) - -1 1  C2(u2, . . . , uk)} = 1{-1 1(t) - 1-1  C2(u2, . . . , uk)}

we get the final form of ht

hk(t, u2, . . . , uk)

=

1 -1 1(t) - -1 1  C2(u2, . . . , uk) 1{-1(t)}

◊ c 1(-1 1(t) - -1 1  C2(u2, . . . , uk)), u2, . . . , uk

◊ I C2(u2, . . . , uu) > t for (u1, . . . , uk)  [0, 1]k.

23

Further simplification of the previous formula is unfortunately too difficult because of unknown recursive formula for the HAC density, which is difficult to derive in general form.

Proof of Theorem 5. Let X  C1 and X  C2. To show the concordance property it is necessary to prove that

P {Xi  xi, i = 1, . . . , k}  P {Xi  xi, i = 1, . . . , k} and

(7)

P {Xi > xi, i = 1, . . . , k}  P {Xi > xi, i = 1, . . . , k}.

(8)

for all x  (0, 1)k. The first inequality is identical to that C1(x)  C2(x), for all x  (0, 1)k, while the second one is equivalent to C1(x)  C2(x), for all x  (0, 1)k, where C is the survival copula of C.

As mentioned in Chapter 1, Archimedean copulas arise from the Laplace transform

k

{-1(u1) + ∑ ∑ ∑ + -1(uk)} =

G-1 (u) dM(),

0 i=1

where the generator function (s) =

 0

e-sw

dM(w),

s



0

is

a Laplace

transform

of

the

some

univariate cumulative distribution function M(∑) of a positive random variable and G-1(u) =

exp{--1(u)}. From the statement of the theorem, C1 and C2 are proper HACs and they differ

only by the generator function on the highest level such as 1-1  2  L. If we denote the

second level copulas as the zi, i = 1, . . . , m then

C1(u) = C1{Ck1r1 (u1, . . . , uk1 ), . . . , Ckm-km-1,rm (ukm-1+1, . . . , ukm=k)} = 1[-1 1{Ck1r1 (u1, . . . , uk1 )} + ∑ ∑ ∑ + -1 1{Ckm-km-1,rm (ukm-1+1, . . . , ukm=k)}] = 1{-1 1(z1) + ∑ ∑ ∑ + -1 1(zm)}
C2(u) = C2{Ck1r1 (u1, . . . , uk1 ), . . . , Ckm-km-1,rm (ukm-1+1, . . . , ukm=k)} = 2[-2 1{Ck1r1 (u1, . . . , uk1 )} + ∑ ∑ ∑ + 2-1{Ckm-km-1,rm (ukm-1+1, . . . , ukm=k)}] = 2{2-1(z1) + ∑ ∑ ∑ + -2 1(zm)}

Let  = -1 1  2  L, then from Theorem A.2 ((Joe, 1997)) (u) = exp{-(u)} is the Laplace transform of some M(∑; ). This means that

(u) = exp{1-1  2(u)} = e-udM(, ).
0

24

Similarly to the case of Archimedean copulas C1 and C2 ca be then transformed as follows

C1 = 1{1-1(z1) + ∑ ∑ ∑ + -1 1(zm)} = 1{  -2 1(z1) + ∑ ∑ ∑ +   2-1(zm)}

 m

=

e-

m i=1

{2-1(zi)}dM1 ()

=

e-{2-1(zi)} dM1 ()

0 m

0 i=1 m







=

{2-1(zi)} dM1 () =

 e--2 1(zi) dM (, ) dM1 ()

=

0 i=1 m
0 i=1


 G2-1 (zi)
0

dM

(,

 )

0 i=1 0
dM1() =

1

  -

1 

log

m i=1


G-2 1 (zi)
0

dM ( ,

  )

C2 = 2{2-1(z1) + ∑ ∑ ∑ + 2-1(zm)} = 1  {-2 1(z1) + ∑ ∑ ∑ + 2-1(zm)}



= exp[-{-2 1(zi) + ∑ ∑ ∑ + -2 1(zm)}]dM1() =  2-1(zi) + ∑ ∑ ∑ + 2-1(zm) dM1()

00



m

=

e-

m i=1

2-1 (zi )

dM ( ,

)dM1 ()

=

e-2-1(zi) dM (, )dM1 ()

=

0 
0

0 m
0 i=1

G-2 1

(zi)

dM ( ,

)dM1 ()

=

1

0 0

-

1 

i=1
log

m 0 i=1

G2-1 (zi)

dM ( ,

 )

.

Note that 1{-a log(∑)} is decreasing as a composition of continuous monotone decreasing functions. Since the concordance order is invariant under monotone transformations, to prove (7) it is sufficient to show that

n

n

i=1 0

G-2 1 (zi) dM (, ) 
0

i=1 G-2 1 (zi) dM (, ).

For simplicity and to emphasise the argument with respect to which we integrate, we write

n

n

gi() dM(, ) 

gi() dM(, ),

i=1 0

0 i=1

where gi( of exp{∑},

w) h=ileGG2-1-2(1z(iz)i)ar=e

bounded and decreasing functions in   0 from the properties exp{-2-1(zi)}. To prove the inequalities we can use the same

approach as in Joe (1997). Each bounded decreasing function can be represented as a limit of

an infinite sum of a piecewise constant functions j cjI[0,bj] for positive constants cj and bj. As the both sides of the inequality are linear in each gi() it is sufficient to prove the inequality
for gi() = I[0,yj](), j = 1, . . . , k. Let B1, . . . , Bn  M(∑, ) for some fixed  and are iid. By the Fr¥echet upper bound inequality holds that P {Bj  yj, j = 1, . . . , n}  P {B1  minj yj} = minj P {Bj  yj} this proves the inequality (7). This means, that the copula C1 is less positively lower orphant dependent than the copula C2. To show the whole concordance order we have to

prove that the copula C1 is less positively upper orphant dependent than the copula C2. Thus

we need to prove the same inequality but for the survival functions.

The usual representation of the survival copula is given by
C(u) = 1 + (-1)|s|Cs(uj; j  s).
sS

25

In terms of the Laplace transforms the survival copula differs from the copula by taking H-1(u) = 1 - G-1(u) = 1 - exp{--1(u)} instead of the function G-1(u). Let us denote H-1,(u) = 1 - G-1(u). Moreover, all zi, i = 1, . . . , m are replaced by zi, i = 1, . . . , m which correspond to the respective components of the survival copula. For example if

z1 = -1{C31(u1, u2, u3)}

= -1[C31{C21(u1, u2), u3}]

= -1  [-1  {-1(u1) + -1(u2)} + -1(u3)]


G-1 (z1) =

G-1 (u1)G-1 (u2)dM-1(, )G-1 (u3)dM-1(, ),

00

then the corresponding z1 is

H-1,(z1) = 1 - G-1 (z1)

= {1 - G-1 (u1)}{1 - G-1 (u2)}dM-1(, ){1 - G-1 (u3)}dM-1(, )
00 
= H-1, (u1)H-1, (u2)}dM-1(, )H-1,(u3)}dM-1(, ).
00

Using similar transformation as in the case of positive lower orphant concordance, we have to prove the following inequality

m

m

H2-1, (zi) dM (, ) 

H2-1, (zi) dM (, )

i=1 0

0 i=1

or

(9)

m

m

hi() dM(, ) 

hi() dM(, ),

i=1 0

0 i=1

where hi() Similarly as

= in

cHase2-p1,re(szein)te=d

a1b-ovGe,a-2n1y,

(zi) are bounded and increasing increasing and bounded function

functions in   0. can be approximated

by the series j cjI[bj,). It is sufficient to consider only one component of the sum. Similarly taking B1, . . . , Bm  M(∑, ) for some fixed , it holds by the Fr¥echet upper bound inequality

that P {Bj > yj, j = 1, . . . , m}  P {B1 > maxj yj} = minj P {Bj > yj}. This proves the inequality (8) and completes the proof of C1  C2.

Proof of Theorem 8. Consider X1 = (X11, . . . , X1k) , . . . , Xn = (xn1, . . . , xnk) as a random sample from C(u1, . . . , uk), and then M1 = max{Xi1}, . . . , Mk = max{Xik}, follow the distribution
P {M1  x1, . . . , Mk  xk} = Cn(x1, . . . , xk),
where the copula Cn have the same structure as copula C but is based on the generator functions  n = [ (t)]n, = 1, . . . , r, and inverse generator functions -n1 = -1(t1/n), = 1, . . . , r. For example in a three dimensional example with the copula function
C(u1, u2, u3) = C1{C2(u1, u2), u3} = 1[-1 1  2{-2 1(u1) + -2 1(u2)} + 1-1(u3)]
26

the extreme value copula is given by
P {M1  x1, M2  x2, M3  x3} = 1[1-1  2{2-1(x1) + 2-1(x2)} + -1 1(x3)] n = 1n -1n1 [2{2-1(x1) + -2 1(x2)}]n + -1n1(x3n) = 1n[-1n1  2n{2-n1(x1n) + 2-n1(xn2 )} + 1-n1(x3n)] = Cn(x1, x2, x3).

Next step we have to prove the existence of the limit of Cn(x1, . . . , xk) when n tends to infinity. By mimicking Genest and Rivest (1989) this limit exist if and only if exists

[-1(t)/(-1) (t)] t

, where = 1, . . . , k.

t=1

Taking into account that extreme-value distribution belong to its own domain of attraction we have

Cn(x1, . . . , xk) = C(x1, . . . , xk), for 0 < x1, . . . , xk < 1.

(10)

Let us fix some numbers 1  j1 < j2  k then, for xj = 1, j  {1, . . . , k} \ {j1, j2} copula C(1, . . . , 1, xj1, 1, . . . , 1, xj2, 1, . . . , 1) is a simple bivariate Archimedean copula with some generator function  12, where 12  {1, . . . , k}

C (1,

.

.

.

,

1,

xj1 ,

1,

.

.

.

,

1,

xj2 ,

1,

.

.

.

,

1)

=

C1(xj1 ,

xj2 )

=

-1 { 12

12 (xj1 )

+



12 (xj2 )}

with the property Cn(1, . . . , 1, xj1, 1, . . . , 1, xj2, 1, . . . , 1) = C(1, . . . , 1, xj1, 1, . . . , 1, xj2, 1, . . . , 1), from this implying Genest and Rivest (1989) we get that 1 is the Gumbel generator. Similarly by taking all other possible pairs 1  j1 < j2  k could be proved that  ,  {1, . . . , k} are Gumbel generators. As given in the statement of the theorem that the extreme-value copula
belong also to HAC family than by Proposition 1 we finish the proof, because all the bivariate
margins are uniquely determined by the previous steps of the proof.

Lemma 1. If f (x) is the continuous monotone function for x  R and f (x, n) is continuous with respect to both arguments and monotone with respect to the first argument function for x, n  R such that

f (x, n) - f (x), x  R
n
then the inverse of the function f (x), x  R exists and exists the inverse with respect to the second argument of the functions f (x, n), x, n  R and holds that

f -1(x, n) - f -1(x), x  R.
n

Proof. For the proof of Lemma see (Billingsley, 1995), (Resnick, 1998).

Proof of Proposition 2.

a.

Let Gt(x) =

(xt) (t)

,

while

(t)

is

decreasing

then

Gt(x)

is

increasing

for all t. Since limt Gt(x) = 1(x) it follows from Lemma 1, that limt G-t 1(y) =

-1 1(y). Note that Gt(x) = (xt)/(t) = y and x = -1{y(t)}/t = Gt-1(y). Since

limt (t) = 1 it follows that

1-1(y)

=

lim
t

G-t 1(y)

=

lim
t

-1{y(t)} t

t:==-1(t)

lim
t0+

-1(yt) -1(t)

.

27

b.

Let

Ht(x) =

1-(xt) 1-(t)

,

while

(t)

is

decreasing

then

Ht(x)

is

also

decreasing

for

all

t.

Since

limt0+ Ht(x) = 2(x) it follows from Lemma 1 (see Appendix), that limt0+ Ht-1(y) =

2-1(y). Note that Ht(x) = {1 - (xt)}/{1 - (t)} = y and x = -1[1 - y{1 - (t)}]/t =

Ht-1(y). Similar as above it follows that

-2 1(y)

= t:==-1(t)

lim
t0+

Ht-1(y)

=

lim
t0+

-1[1

-

y{1 t

-

(t)}]

lim
t1-

-1{1 - y(1 - t)} -1(t)

t:==1-t

lim
t0+

-1(1 - yt) -1(1 - t)

.

Proof of Theorem 10. From the definition of L(1) it follows that

L(1)(u1,

.

.

.

,

uk )

=

lim
u0+

1 u

C

(u1u,

.

.

.

,

uku)

= lim
u0+

1 u

0

-0 1{C1(u1u, . . . , uk1 u)} + ∑ ∑ ∑ + 0-1{Cm(ukm-1+1u, . . . , ukm u)}

k
+ -0 1(uju) ,

j=km+1

We write 0-1(Cj) for 0-1{Cj(ukj-1+1u, . . . , ukj u)} with k0 = 0 to simplify the notation. Since limu0+ Cj /u = L(1,)j (ukj-1+1, . . . , ukj ) we obtain

L(1)(u1,

.

.

.

,

uk )

=

lim
u0+

1 u

0

k

-0 1(u ∑ C1/u) + ∑ ∑ ∑ + -0 1(u ∑ Cm/u) +

-0 1(uju)

j=km+1

=

lim
u0+

1 u

0

k

0-1(u ∑ (L1,)1) + ∑ ∑ ∑ + 0-1(u ∑ (L1,)m) +

-0 1(uju)

j=km+1

=

lim
u0+

1 u

0

mk

-0 1(L(1,)i ∑ u) +

-0 1(uju) .

i=1 j=km+1

From Proposition 2 it follows that

L(1)(u1,

.

.

.

,

uk )

=

lim
u0+

1 u

0

m i=1

0-1((L1,)i ∑ -0 1(u)

u)

∑

-0 1(u)

+

k j=km+1

0-1 (uj u) -1(u)

∑

-1(u)

=

lim
u0+

1 u

0

mk

-1 1(L(1,)i) +

-1 1(uj ) -0 1(u)

i=1 j=km+1

=u:=-0 1(u)

lim
u

1 0(u)

0

mk

-1 1(L(1,)i) +

1-1(uj) u

i=1 j=km+1

mk

= 1

1-1{L(1,)i(uki-1+1, . . . , uki )} +

1-1(uj) .

i=1 j=km+1

To prove the statement for (U1) it is sufficient to derive the expression for a single s. Without

28

the loss of generality, we consider



=

lim
u0+

1 u

1 - C0{C1(1 - u1u, . . . , 1 - uk1u), . . . , Cm(1 - ukm-1+1u, . . . , 1 - ukmu),

1 - ukm+1u, . . . , 1 - uku}

=

lim
u0+

1 u

1 - 0

mk

-0 1(Ci) +

0-1(1 - uju)

i=1 j=km+1

=

lim
u0+

1 u

1 - 0

m
0-1
i=1

1

-

1

- Ci u

∑

u

k
+ 0-1(1 - uju)
j=km+1

=

lim
u0+

1 u

1 - 0

mk

-0 1(1 - iu) +

0-1(1 - uju)

i=1 j=km+1

=

lim
u0+

1 u

1 - 0

m i=1

0-1(1 - iu) 0-1(1 - u)

0-1(1

-

u)

+

k j=km+1

-0 1(1 - uju) -0 1(1 - u)

∑

0-1(1

-

u)

=

lim
u0+

1 u

1 - 0

mk

2-1(i) +

2-1(uj) 0-1(1 - u)

i=1 j=km+1

u:=1-=0(u) 2

mk

-2 1(i) +

2-1(uj )

i=1 j=km+1

The expressions for i's are then derived in a recursive way.

References
Barbe, P., Genest, C., Ghoudi, K. and R¥emillard, B. (1996). On Kendalls's process, Journal of Multivariate Analysis 58: 197≠229.
Bernstein, S. N. (1928). Sur les fonctions absolument monotones, Acta Mathematica pp. 1≠66.
Billingsley, P. (1995). Probability and Measure, John Wiley & Sons, New York.
Chen, Y.-P. (2004). A note on the relationship between Spearman's  and Kendall's  for extreme order statistics, Journal of Statistical Planning and Inference 137(7): 2165≠2171.
Deheuvels, P. (1978). Caract¥erisation compl`ete des lois extr^emes multivari¥ees et de la convergence des types ext^emes, Publ. Inst. Statist. Univ. Paris 23: 1≠36.
Durrleman, V., Nikeghbali, A. and Roncalli, T. (2000). A note about the conjecture about Spearman's rho and Kendall's tau, Working paper, Operations Research and Financial Engineering, Princeton University.
Embrechts, P., Klu®ppelberg, C. and Mikosch, T. (2001). Modelling Extremal Events for Insurance and Finance, Springer, Berlin.
Fredricks, G. A. and Nelsen, R. B. (2004). On the relationship between Spearman's rho and Kendall's tau for pairs of continuous random variables, Journal of Statistical Planning and Inference 137(7): 2143≠2150.
Genest, C. and Rivest, L.-P. (1989). A characterization of Gumbel family of extreme value distributions, Statistics and Probability Letters 8: 207≠211.
29

Genest, C. and Rivest, L.-P. (1993). Statistical inference procedures for bivariate Archimedean copulas, Journal of the American Statistical Association 88: 1034≠1043.
Ha®rdle, W. and Simar, L. (2007). Applied Multivariate Statistical Analysis, Springer, Berlin.
Hofert, J. M. (2008). Sampling Archimedean copulas, Working Paper 2007-10, Universit®at Ulm.
Joe, H. (1996). Families of m-variate distributions with given margins and m(m - 1)/2 bivariate dependence parameters, in L. Ru®schendorf, B. Schweizer and M. Taylor (eds), Distribution with fixed marginals and related topics, IMS Lecture Notes ≠ Monograph Series, Institute of Mathematical Statistics.
Joe, H. (1997). Multivariate Models and Dependence Concepts, Chapman & Hall, London.
Kendall, M. (1970). Rank Correlation Methods, Griffin, London.
Kimberling, C. H. (1974). A probabilistic interpretation of complete monotonicity, Aequationes Math. 10: 152≠164.
Marshall, A. W. and Olkin, J. (1988). Families of multivariate distributions, Journal of the American Statistical Association 83: 834≠841.
McNeil, A. J. (2008). Sampling nested Archimedean copulas, Journal Statistical Computation and Simulation . forthcoming.
McNeil, A. J. and Neslehova¥, J. (2008). Multivariate Archimedean copulas, d-monotone functions and l1 norm symmetric distributions, Annals of Statistics . forthcoming.
Mu®ller, A. and Stoyan, D. (2002). Comparison methods for stochastic models and risks, John Wiley & Sons, New York.
Nelsen, R. B. (1997). Dependence and order in families of Archimedean copulas, Journal of Multivariate Analysis 60(1): 111≠122.
Nelsen, R. B. (2006). An Introduction to Copulas, Springer Verlag, New York.
Okhrin, O., Okhrin, Y. and Schmid, W. (2009). On the structure and estimation of hierarchical Archimedean copulas, under revision in Journal of Econometrics .
Resnick, S. I. (1998). A Probability Path, Birkh®auser Boston, Cambridge.
Schmid, F. and Schmidt, R. (2006a). Bootstrapping Spearman's multivariate rho, in A. Rizzi and M. Vichi (eds), COMPSTAT, Proceedings in Computational Statistics, pp. 759≠766.
Schmid, F. and Schmidt, R. (2006b). Multivariate extensions of Spearman's rho and related statistics, Statistics and Probability Letters 77(4): 407≠416.
Schmid, F. and Schmidt, R. (2006c). Nonparametric inference on multivariate versions of Blomqvist's beta and related measures of tail dependence, Metrika 66(3): 323≠354.
Shorack, G. (2000). Probability for statisticians, Springer.
Sklar, A. (1959). Fonctions d¥e repartition ¥a n dimension et leurs marges, Publ. Inst. Stat. Univ. Paris 8: 299≠231.
Wang, W. and Wells, M. (2000). Model selection and semiparametric inference for bivariate failure-time data, Journal of the American Statistical Association 95: 62≠76.
30

Whelan, N. (2004). Sampling from Archimedean copulas, Quantitative Finance 4: 339≠352. Wolff, E. (1980). N-dimensional measures of dependence, Stochastica 4(3): 175≠188.
31

SFB 649 Discussion Paper Series 2009
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "Implied Market Price of Weather Risk" by Wolfgang H‰rdle and Brenda LÛpez Cabrera, January 2009.
002 "On the Systemic Nature of Weather Risk" by Guenther Filler, Martin Odening, Ostap Okhrin and Wei Xu, January 2009.
003 "Localized Realized Volatility Modelling" by Ying Chen, Wolfgang Karl H‰rdle and Uta Pigorsch, January 2009.
004 "New recipes for estimating default intensities" by Alexander Baranovski, Carsten von Lieres and AndrÈ Wilch, January 2009.
005 "Panel Cointegration Testing in the Presence of a Time Trend" by Bernd Droge and Deniz Dilan Karaman ÷rsal, January 2009.
006 "Regulatory Risk under Optimal Incentive Regulation" by Roland Strausz, January 2009.
007 "Combination of multivariate volatility forecasts" by Alessandra Amendola and Giuseppe Storti, January 2009.
008 "Mortality modeling: Lee-Carter and the macroeconomy" by Katja Hanewald, January 2009.
009 "Stochastic Population Forecast for Germany and its Consequence for the German Pension System" by Wolfgang H‰rdle and Alena Mysickova, February 2009.
010 "A Microeconomic Explanation of the EPK Paradox" by Wolfgang H‰rdle, Volker Kr‰tschmer and Rouslan Moro, February 2009.
011 "Defending Against Speculative Attacks" by Tijmen DaniÎls, Henk Jager and Franc Klaassen, February 2009.
012 "On the Existence of the Moments of the Asymptotic Trace Statistic" by Deniz Dilan Karaman ÷rsal and Bernd Droge, February 2009.
013 "CDO Pricing with Copulae" by Barbara Choros, Wolfgang H‰rdle and Ostap Okhrin, March 2009.
014 "Properties of Hierarchical Archimedean Copulas" by Ostap Okhrin, Yarema Okhrin and Wolfgang Schmid, March 2009.
SFB 649, Spandauer Straﬂe 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

