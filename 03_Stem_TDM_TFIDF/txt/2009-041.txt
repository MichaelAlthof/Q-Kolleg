BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2009-041
Shape invariant modelling pricing kernels and risk aversion
Maria Grith* Wolfgang H‰rdle*
Juhyun Park**
* Humboldt-Universit‰t zu Berlin, Germany ** Lancaster University, United Kingdom
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universit‰t zu Berlin Spandauer Straﬂe 1, D-10178 Berlin

Shape invariant modelling pricing kernels and risk aversion

Maria Grith

Wolfgang Ha®rdle

Juhyun Park

Abstract
Pricing kernels play a major role in quantifying risk aversion and investors' preferences. Several empirical studies reported that pricing kernels exhibit a common pattern across different markets. Mostly visual inspection and occasionally numerically summarise are used to make comparison. With increasing amount of information updated every day, the empirical pricing kernels can be viewed as an object evolving over time. We propose a systematic modelling approach to describing the evolution of the empirical pricing kernels. The approach is based on shape invariant models. It captures the common features contained in the shape of the functions and at the same time characterises the variability between the pricing kernels based on a few interpretable parameters. The method is demonstrated with the European options and returns values of DAX index.
Keywords: pricing kernels, risk aversion, risk neutral density. JEL classification: C14, C32, G12. AMS classification: 62G08, 62M10, 62P05.

The financial support from the Deutsche Forschungsgemeinschaft via SFB 649 "O® konomisches Risiko", Humboldt-Universita®t zu Berlin is gratefully acknowledged.
CASE ≠ Center for Applied Statistics and Economics, Humboldt-Universita®t zu Berlin, Spandauer Straﬂe 1, 10178 Berlin, Germany.
Corresponding author. Department of Mathematics and Statistics, Lancaster University, Lanaster, LA1 4YF, U.K. Phone:+44 1524 593606. Email: juhyun.park@lancaster.ac.uk.
1

1 Introduction

Risk analysis and management drew much attention in quantitative finance recently. Un-

derstanding the basic principles of financial economics is a challenging task in particular

in a dynamic context. With the formulation of utility maximisation theory, individuals'

preferences are explained through the shape of the underlying utility functions. The

basic utility functions that undermine individuals' preferences are thought to be charac-

terized by a concave, convex or linear utility function, describing risk averse, risk seeking

or risk neutral behaviour. An economic consideration states that one unit gain and loss

does not carry the same values for every individual. This view of state dependent risk

behaviour extends the possible shape of utility functions. The comparison is often made

through the Arrow-Pratt measure of absolute risk aversion (ARA), as a summary of ag-

gregate investor's risk-averseness. The quantity is originated from the expected utility

theory and is defined by

ARA(u) = - U

(u) ,

U (u)

where U is the individual utility as a function of wealth.

The fundamental problem is that individual agents are not directly observable but the dynamics of the market is assumed to reflect in the prices of goods traded in the market. Several efforts are made to relate price processes of assets traded in a market to risk behaviour of investors, by examining stock prices and option prices, since options are securities guarding against losses in risky stocks.

A standard option pricing model in a complete market assumes a risk neutral distribution of returns, which is the fair price, multiplied by risk-free interest, under a no arbitrage assumption. The assumption of no arbitrage assures the existence of risk neutral distributions. If markets are not complete, there are more risk neutral distributions and the fair price depends on the hedging problem. In this paper, we assume that markets are complete. The subjective or historical distribution of observed returns reflects a risk-adaptive behaviour of investors based on subjective assessment of the future market. Then the equilibrium price is the arbitrage free price and the transition from risk neutral pricing to subjective rule is achieved through the pricing kernel. Assuming those densities exist, the pricing kernel K is defined by the ratio of those densities:

K(u) = q(u) , p(u)

where q is the risk neutral density and p is the historical density. Through the intermediation of these densities, we can create a link between the pricing kernel and ARA, see for example Leland (1980):

ARA(u) = p (u) - q (u) = - d log K(u) .

p(u) q(u)

du

2

2 1

0.8 1 1.2
Figure 1: Examples of intertemporal pricing kernels with various maturities in years: 0.097 (blue/dash-dottted) 0.0694 (red/circle) 0.0611 (magenta/dashed) 0.0472 (cyan/solid) respectively on 12-May-2006 (blue/dash-dotted), 17-May-2006 (red/circle), 22-May-2006 (magenta/dashed), 25-May-2006 (cyan/solid). Expiration date is 02-Jun2006 for all pricing kernels.

In this way, rather than specifying a priori preferences of agents (risk neutral, averse or risk seeking) and implicitly the monotonicity of the pricing kernel, we can infer the risk patterns from the shape of the pricing kernel. When considering several markets simultaneously, we introduce the time index t in the pricing kernel as Kt and thus the corresponding ARA at time t can be derived from the pricing kernel Kt as

ARAt

(u)

=

-

d

log Kt(u) du

.

(1)

From a statistical perspective, the properties of the pricing kernel are intrinsically related to the assumptions about the data generation process. A very restrictive model, with normal marginal distributions, is the Black-Scholes model, as it will be illustrated in Section 2. This results in an overall decreasing pricing kernel in wealth, which is consistent with overall risk-averse behaviour. These preferences are often assumed in the classical economic theory of utility maximizing agent and correspond to a concave

3

2
1
0.8 1 1.2
Figure 2: Examples of monthly pricing kernels from the first 6 months in 2006 for maturity one month: Dates are 18-Jan-2006 (blue/dash-dotted), 15-Feb-2006 (red/circle), 22-Mar-2006 (magenta/dashed), 19-Apr-2006 (cyan/solid), 17-May-2006 (black/dotted).
indirect von Neumann and Morgenstern utility function. However, under richer parametric specifications or nonparametric models monotonicity of the pricing kernel has been rejected in practice (Engle and Rosenberg, 2002; Ait-Sahalia and Duarte, 2003). A plot of estimates of pricing kernels in 2006 is shown in Figures 1 and 2. Figure 1 depicts inter-temporal pricing kernels with various maturities in May-June 2006, while Figure 2 depicts monthly pricing kernels with fixed maturity one month. To make these comparable, they are shown on a returns scale, as explained in Section 2.4. The sample of curves appears to have a bump around 1 and have convexity followed by concavity in all cases. The location as well as the magnitude of the bump vary among curves, which reflects individual variability on different dates or under different market conditions. Some features that are of particular economic interest include the maximum of the bump, the spread or duration of the bump and the location of the bump. These characteristics are also reported in the literature and shown to be consistent across different markets. This observation motivated us to consider a common shape modelling approach for the
4

series of pricing kernels with explicit components of location and scale known as shape invariant modelling. Detailed account of this approach is given in Section 2. With an ease of recovering pricing kernels embedded in the market data, the shape invariant modelling approach provides a systematic treatment in examining discrepancy between empirical findings and theoretical exposition. Furthermore, this modelling approach facilitates characterisation of time varying risk perception. Time varying parameters of the utiliy finction can be found also under Black-Scholes model assumptions but their interpretation is limited also due to errors induced by the misspecification of the pricing kernel model. In view of these considerations, the pricing kernel is the natural intermediary in risk management. In particular, the relationship between properties, especially shape, of utility functions and risk-adaptive behaviours are captured through the pricing kernel. For this modelling approach, we first need to recover pricing kernels empirically.
1.1 Empirical pricing kernels
With increasing availability of large market data, several approaches to recovering pricing kernels from empirical data have been proposed. As many of them estimate p and q separately to recover K, potentially relevant are many studies focusing on recovering risk neutral density, see e.g. Jackwerth (1999), Bondarenko (2003) for comparison of different approaches. For the estimation of p nonparametric kernel methods or parametric models such as GARCH or Heston models are popular choices.
Most of earlier works adopt a static viewpoint, showing a snap shot of markets on selected dates but report that there is a common pattern across different markets. The first dynamic viewpoint appears in Jackwerth (2000), who recovers a series of pricing kernels in a consecutive time and claims that these do not correspond to the basic assumption of asset pricing theory. In a similar framework Giacomini and Ha®rdle (2008) perform a factor analysis based on the so-called dynamic semiparametric factor models, while Giacomini et al. (2008) introduce time series analysis of daily summary measures of pricing kernels to examine variability between curves.
Due to evolution of markets over time under different circumstances, these quantities are intrinsically time varying. Thus, approaches that do not take into account the changing market make limited use of information available in the current data. On the other hand, changes over time may not be completely arbitrary, as there are common rules and underlying laws that assure the dynamic evolution of the market system. Moreover, variability observed in pricing kernels, as shown in Figures 1 and 2, is not necessarily linear, and thus factors constructed from a linear combination of observations are only meaningful for explaining aggregated effects.
We take a dynamic viewpoint but focus on the common characteristics observed across
5

different studies and markets. We then explain individual variability as a deviation from a reference. This strategy is transferred to characterisation of changes in risk behaviour. The changes in corresponding ARA measures can be examined together and especially the one corresponding to the reference pricing kernel may be viewed as a typical pattern of risk behaviour.
1.2 Common shape modelling
The new message here is an analysis of a sequence of pricing kernels through shapeinvariant models. As noted earlier, the multiple curves share a common shape, but allow for individual variability which may be explained by shifts in horizontal as well as vertical directions. This is the assumption that we will consider in our analysis, a functional data analysis viewpoint (Ramsay and Silverman 2002 & 2005, Ferraty and Vieu 2006).
When multiple curves are viewed as realizations of a common function, treating curves individually wastes our resources. By combining all the information across the curves, the common functional form can be obtained efficiently. Assuming no horizontal variability, a principal component analysis (PCA) type linear decomposition procedure will further provide an optimal representation with a few common components. With additional variability in horizontal direction, however, a simple summary statistic such as mean obtained from a type of averaging operation becomes meaningless (Kneip and Gasser, 1992). Consequently, the PCA type of analysis without taking into account the obvious horizontal variability produces many more spurious directions of maximal variability and thus interpretation of components becomes arbitrary. It is possible though to remove the additional variability before applying PCA by estimating the horizontal transformation, nonparmetrically or parametrically, through curve alignments. Still interpretability of results may be an issue.
Instead, we directly model the pricing kernels using a semi-parametric approach where the common function is modelled nonparametrically but individual effects are in a parametric functional form. With this method we will be able to use the maximal information of multiple curves with interpretable individual effects. Further generalization is possible by allowing the transformation to be nonlinear or unspecified, see for example Kneip and Gasser (1992), Gasser and Kneip (1995), Ramsay and Li (1998) and Gervini and Gasser (2004) among many others. In the context of functional data analysis, this is dealt with under curve alignment, synchronization or registration. Inclusion of random shift and transformation as well as other covariate effects also can be achieved (Ke and Wang, 2001).
In this article we restrict to parametric specification as the data in consideration suggests a relatively simple structure and parameters are easily related to interpretation
6

of economic interest. The paper is organised as follows. Section 2 describes the shape invariant model in detail, which serves the basis of our analysis. Empirical results of empirical pricing kernels as well as risk aversion measures are provided in Section 3 followed by discussion and conclusion in Section 4.

2 Shape invariant modelling

Let {Ytj, t = 1, ∑ ∑ ∑ , T ; j = 1, ∑ ∑ ∑ , n} be a noisy sample of curves measured at {uj} in an interval J satisfying the model

Ytj = Kt(uj) + tj ,

where tj are independent errors with mean zero and standard deviation t2. To take into account the underlying shape relationship, we consider the form

Kt(u) = t1K0

u - t3 t2

+ t4 .

(2)

0123456 0123456

0.0 0.5 1.0 1.5 2.0

0.0 0.5 1.0 1.5 2.0

Figure 3: Example of location and scale shift pricing kernels (left) and corresponding utility functions (right) of a power utility. Solid line in each plot represents reference curves of K0(u) = u- and U0(u) = u1-/(1 - ) with  = 0.7 respectively. Parameters are t2 = 0, t1 = 1.1, t2 = 1 - t(11/), and t4 = 0 for dot-dashed (red) and t4 = 0.5 for dashed (blue) lines.
The common shape function K0 is a reference curve and deviation from the reference curve is described by four parameters (t1, t2, t3, t4) that represent a scale change and
7

a shift in horizontal and vertical direction. It is instructive to consider utility functions

implied by this family of pricing kernels together. The utility function can be derived

from

u
U (u) =  K(x) dx ,
0

for a constant . U0 denotes the utility function corresponding to K0. Figure 3 shows

an example of transformation based on a power utility function, which corresponds to

risk averse behaviour, marked as solid line. Pricing kernels Kt are shown on the left and

the corresponding utility functions Ut are on the right. The dashed and dot-dashed lines represent Kt and Ut with appropriate parameters  in the equation (2). Depending on

the choice of parameters, the utility function can be made increase quickly or slowly. As

an illustration, we consider the Black-Scholes model with power utility function. The

Black-Scholes model assumes that the stock price follows a geometric Brownian motion

dSt/St = µdt + dWt ,

which gives rise to a log normal density for the historical density p. Under the risk neutral measure, the drift µ is replaced by the riskless rate r and the density q is also log normal. The pricing kernel can be written as a power function
K(u) = u- , 0 <  < 1 ,

with appropriate constants  and . The corresponding utility function is a power utility

u1-

U (u)

=

 1

-



.

Assume that  = 1 and suppose that K0 is the Black-Scholes power function u-. Then the class of pricing kernel implied in (2) is given by

Kt(u)

=

t1

u - t3 t2

-
+ t4

= t1(u - t3)- + t4 ,

where t1 = t1t2. Notice that with this family of functions t1 and t2 are not identifiable and Kt is defined for u > t3. For the sake of argument we set t2 = 1 for the
moment. The corresponding utility function is

u

Ut(u) =

Kt(x) dx

t3

=

t1 1-

(u

-

t3)(1-)

+

t4(u

-

t3)

d=ef t1(u - t3)(1-) + t4(u - t3) .

When t4 = 0, this produces again a transformed power utility. When t4 = 0, there is additional linear term in the function. See Figure 3 for comparison.

8

The parametrisation in (2) is commonly referred as shape invariant models (SIM), originally introduced by Lawton et al. (1972), and includes as a special case complete parametric models with known K0. When the common function is unspecified, this type of approach needs self-modelling regression.

Model (2) is very general and needs further restriction. For example, the Black-Scholes family of power utility functions shown in Figure 3 has ambiguity between t1 and t2. Issues of identifiability of the common function as well as parameters are studied in Kneip and Gasser (1988). Basically unless there exist some qualitatively distinct common characteristics for each curve, the model is not identifiable. In the case of no prior structural information is available, it is enough to consider peaks and inflection points for smooth curves as reference points. At least two of such points called landmarks would be sufficient. Even with unique K0, some translation and scaling of parameters lead to multiple representation of the models. For uniqueness of parameters, we will impose normalizing conditions:

T
T -1 t1 = 1,
t=1

T
T -1 t2 = 1,
t=1

T
T -1 t3 = 0,
t=1

T
T -1 t4 = 0 .
t=1

in the sense that there exists an average curve, see Kneip and Engel (1995). This is not restriction at all and can be replaced by any appropriate combination of parameters. Alternatively, the restriction 1 = (1, 1, 0, 0) takes the first curve as a reference, as in Ha®rdle and Marron (1990) or an application-driven normalisation scheme can be introduced (Lawton et al., 1972).

2.1 Estimation of SIM

The model in (2) is equivalently written as

Kt(t2u + t3) = t1K0(u) + t4 , t1 > 0 , t2 > 0 .

(3)

The estimation procedure is developed using the least squares criterion based on nonparametric estimates of individual curves. If there are only two curves, parameter estimates are obtained by minimizing

{K^2(2u + 3) - 1K^1(u) - 4}2w(u) du ,

(4)

where K^i are nonparametric estimates of the curves. H®ardle and Marron (1990) studied comparison of two curves and Kneip and Engel (1995) extended to multiple curves with an iterative algorithm. We consider an adaption of such algorithm here.
The weight function w is introduced to ensure that the functions are compared in a domain where the common features are defined. We assume that there is an interval

9

[a, b]  J where boundary effects are eliminated and then define

w(u) = 1[a,b] (u - t3)/t2 .
t

The parameter estimates are compared only in the common region defined by w but the individual curve estimates are defined on the whole interval. Weights can be extended to account for additional variability.

The normalization leads to:

T
T -1 Kt(t2u + t3) = K0(u) .
t=1

(5)

Formula (5) was exploited also in the algorithm proposed by Kneip and Engel (1995). We adopt a similar strategy here.

∑ Initialize
≠ Estimate individual regression functions Kt by a nonparametric smoother. ≠ Set starting values (t(20), t(30)) for each t = 1, ∑ ∑ ∑ , T . ≠ Construct an initial estimate K0(0) by
T
K0(0)(u) = T -1 K^t(t(20)u + t(30)) .
t=1
∑ For rth step, r = 1, ∑ ∑ ∑ , R,
≠ Determine parameters (r) separately for each t = 1, ∑ ∑ ∑ , T by minimizing
{K^t(t2u + t3) - t1K0(r-1)(u) - t4}2w(u) du .

≠ Normalise parameters: for j = (1, 2) and k = (3, 4)

t(jr) 

t(jr) t t(jr)

,

t(kr)  t(kr) - T -1

t(kr) .

t

≠ Update K0(r-1) to

T
K0(r)(u) = T -1 K^t(t(2r)u + t(3r)) .
t=1

10

∑ Determine final estimates:
~t = (tR) ,
T
K~0(u) = T -1 K^t(~t2u + ~t3) .
t=1
This procedure is shown to provide consistent estimates. In particular despite nonparametric pilot curve estimates, the parameters are n consistent. Furthermore, Kneip and Engel (1995) showed in their analysis that the initial estimates of the curves are of minor importance compared to the final estimate of K0 and suggested the final estimates K~0 be re-estimated with new bandwidths. This improves precision of estimates because the pooled sample allows reduction in variance in K~0 and thus can accommodate undersmoothing at the final stage to reduce bias.
A notable difference in applying the model to the pricing kernels is that the original data available are not noisy realisations of the underlying function itself, but ratio of functions estimated with possibly non-equal bandwidths, and thus the updating of each estimator as a whole may not be practical. However we can take advantage of having smooth curves evaluated at finite points as data. It is easier to improve the initialisation step, explained in Section 2.2. This leads to simplification of the estimating procedure with little compromise of the quality of the fit. In fact, the number of iterations required is very small and often 3 or 4 is sufficient in practical terms. We found that when the initial estimates are determined sufficiently accurate, the iteration is not necessary.

2.2 Starting values

If there is no scale change in horizontal direction, due to prominent peaks in each curve,

the parameter 3 can be identified easily by the location of the individual peak. If the

models hold true, and there are two unique landmarks identifiable for each curve, simple

linear regression between the individual mark and the average mark provides an estimate

of the slope parameter 2. Suppose that the peak is identified by u satisfying Kt(u) = 0.

Then we have

0

=

Kt(u)

=

t1 t2

K0

u - t3 t2

.

Writing ut for Kt and u0 for K0 leads to a simple linear relation:

ut = t2u0 + t3 .

(6)

If an inflection point is used, we would have

0

=

Kt (u)

=

t1 t22

K0

u - t3 t2

,

11

which gives rise to the same relation as (6), with the corresponding ut and u0 substituted. The coefficients of intercept and slope estimates are used for starting values of t3 and t2 respectively.
3
2
1
0.8 1 1.2
Figure 4: Initial estimates of monthly pricing kernels with fixed maturity  = 1 in the first 14 curves in the sample. Marked are two landmarks identified. We used the peak and the inflection points around 1 as landmarks, marked in Figure 4. The location of the landmarks is defined by the zero crossings of the first and second derivatives. Because the initial observations Kt are a smoothed curve, we find that additional smoothing procedure is not required at this stage: a finite difference operation is sufficient to apply mean value theorem with linear interpolation. The slope between any two points did not vary much, which is consistent with the model specification. This step is also used as an informal check and should there be any nonlinearity detected, the model needs to be extended to include a nonlinear transformation. With our example, this was not the case.
12

2.3 Nonlinear optimisation

Given the estimates of (t2, t3), the nonlinear least squares optimisation uses (4), which is approximated by

K^t(t2uj + t3) - t1K^0(uj) - t4 2w(uj) .
j

(7)

When the initial values of (t2, t3) are sufficiently accurate, this produce is simplified to a linear regression. Conditional on t2, t3 and K^0, the solutions to the least square regression with response variable K^t(t2uj +t3) and explanatory variable K^0(uj) provide
(t1, t4). When a further optimisation routine is employed to improve the estimates,
these numbers serve as initial values for (t1, t4).

2.4 Initial estimates of K
The initial estimates of K are obtained from separate estimates for p and q. We use intraday European options data on DAX index, provided by European Exchange EUREX and maintained by the CASE, RDC SFB 649 (http://sfb649.wiwi.hu-berlin.de) in Berlin. The data contains the actually traded call prices, the implied index price corrected for the dividends from the futures derivatives on the DAX, the strike prices, the interest rates (linearly interpolated to approximate a riskless interest rate for the specific option's time to maturity), the maturity, the type of the options, calculated future moneyness, calculated Black and Scholes implied volatility, the volume and the date. The extracted observations for our analysis cover the period between April 2003 and June 2006.
Figure 4 shows the resulting estimates on the scale of (compounded) log returns using the estimation methods summarised below. All curves show prominent peak but the intensity as well as the location of the peak varies among the curves, which is further explained by SIM.

Estimation of the risk neutral density q: We begin with the call price option formula that links the call prices to the risk neutral density estimation. The European call price option formula is given by



C(K, , rt, , t, , St) = e-rt, 

max(ST - K, 0)q(ST |, rt, , t, , St) dST

0

where

∑ St: the underlying asset price at time t,

13

∑ K: the strike price, ∑  : the time to maturity, ∑ T = t +  : the expiration date, ∑ rt, : the deterministic risk free interest rate for that maturity, ∑ t, : the corresponding dividend yield of the asset.

Write q(ST ) for q(ST |, rt, , t, , St). For fixed t and  , assume rt, = r and t, = , the risk neutral density is expressed as

q (K )

=

er

2C K2

.

The relation is due to Breeden and Litzenberger (1978) and serves the basis of many current semi-parametric and nonparametric approaches. We employ the semiparametric estimates of Rookley (1997), where the parametric Black-Scholes formula is assumed except that the volatility parameter  is a function of the option's moneyness and the time to maturity  . In this work, we fix the maturity and consider one dimensional regression problems, where the local polynomial smoothing with order 2 is applied to the observations of implied volatility on moneyness scale. A detailed account of the method is found in Huynh et al. (2002).

We focus on options with maturity one month (31 working days/ 23 trading days) across several years, from DAX 30 Index European options traded on Eurex Exchange. Since daily trade is organized in such a manner that we will not find options with maturity one month in every trading day, we select only that days when such securities are traded. This procedure enables us to identify one string of options every month from April 2003 to June 2006; this adds up to 38 days.

The index stock price varies within one day and we would need to identify the price at which a certain transaction has taken place. However, several authors (e.g. Jackwerth (2000)) report that the change of the index price is stale and we use instead the prices of futures contracts closest to the time of the registered pair option strike to derive the corresponding stock price corrected for dividends, following a methodology described in Fengler (2005).

For each day, we use only at-the-money and out-of-the-money call options and in-the-

money puts to compute the Black-Scholes implied volatilities. This guarantees that

unreliable observations (high volatility) will be removed from our estimation samples.

Since, as mentioned before, the intraday stock price varies, we use its median to compute

the risk neutral density. For this price, we verify if our observations satisfy the no

arbitrage condition:

S  Ci  max(S - Kie-r , 0) ,

14

where S is the adjusted (for dividend) price.
Moneyness is computed for each pair (Si, Ki), where after we assume that the volatility does not depend on the changes in the intraday stock price. (Notice that the results in Figure 6 are defined on a returns scale (continuously compounded 1 month-period returns V = 1 + log(ST /St)) different from the moneyness definition used by Rookley (1997)). We have used the following transformation of probability measure:

St ev-1

P(V  v) = P(ST  Stev-1) =

q(ST )dST .

0

The risk neutral density q on the log returns is then

d dv

P(V

 v)

=

Stev-1q(ST )

(8)

Estimation of the historical density p: The return values provide information on the historical density p. In contrast to the option prices data, the number of observations at maturity is limited and additional modelling assumption on the evolution of stock prices is necessary. Jackwerth (2000), among many others, used GARCH models to simulate the return values at maturity, while Ait-Sahalia and Lo (2000) used a nonparametric kernel density estimates based on past return values. Alternatively the returns of the stock prices are assumed to vary slowly and thus the process can be assumed stationary for a short period of time. With this assumption, a nonparametric kernel density estimates is used in Ait-Sahalia and Lo (2000). Jackwerth (2000) argues that some discrepancies between estimates are attributed to overlapping and non-overlapping windows of the past observations selected. Nevertheless with varying degrees of assumptions on the model, common characteristics such as peaks and skewness are reportedly observed in a wide range of estimates (Ha®rdle et al., 2009).
In this work we use the nonparametric kernel density estimates similar to Ait-Sahalia and Lo (2000) based on the past two years' observations from the maturity. We experimented with varying sizes of the window of the past observations including non-overalpping and overlapping returns. According to our experiences the difference in shapes between them is not considerable but the prominence of peak varies more with the bandwidth choices.

2.5 Smoothing parameter selection
Initially individual estimates of p are obtained based on Gaussian kernel with bandwidth choice from the Silverman's rule of thumb (Wand and Jones, 1995) and then a common bandwidth is obtained by taking either the average or the maximum. The common bandwidth is introduced to avoid systematic bias driven by different bandwidth choices - difference in peaks can be amplified by different magnitude of the bias due to different
15

0.3 0.75
0.2 0
0.8 1 1.2 0.8 1 1.2
15 12
6 0
0.8 1 1.2 0.8 1 1.2
Figure 5: Example of q estimates with varying bandwidths (0.05, 0.1, 0.15, 0.20). The first three panels show estimates of implied volatility, its first and second derivative. The corresponding densities are shown in lower right panel. Estimates are stable for a wide range of bandwidths choices.
bandwidths introduced. However, we find that, due to inherent variability, taking the average of the initial bandwidths sometimes produce multi-modality and taking the maximum tends to oversmooth. So the final bandwidth is selected in the range between the mean and the maximum by visual inspection. The bandwidth selection for q is expected to be more influential than that of p in gauging performance of the estimates, as it involves derivative estimation. Figure 5 examines the effect of the bandwidth choices on q^. Top left panel shows the implied volatility estimates overlayed, the top right shows the first derivative estimates and bottom left shows the second derivative estimates respectively, which are used as inputs to create the estimates of q on bottom right panel. The bandwidths used are 0.05, 0.10, 0.15,
16

0.20. With the apparent undersmoothing at the smallest bandwidth, there is notable variability in terms of smoothness in estimation of implied volatility and its derivatives however the resulting density estimates demonstrate robustness. Similar observations are made to other dates. However by smoothing on implied volatility domain, we find that the estimates are stable with relatively a wide range of bandwidths. The reported estimates used 0.20 for all estimation.
2.6 Word on asymptotics
There are two layers of estimation involved. The first step deals with individual curve estimation and the second step introduces shape invariant modelling. The shape invariant modelling is largely robust to how the data are prepared before entering the iterative algorithm and the resulting estimates are interpreted as conditional on the individual curves. Therefore, the main estimation error arises in the first stage where p and q are separately estimated with possibly different sample sizes and separately chosen bandwidths.
In practical terms, the sample size used in estimating p is normally of smaller order, say n compared to N = nM for q for a constant M , due to the difference between collected daily observations for p and intraday observations for q. Thus it is expected that the estimation error will be dominated by the estimation error of p. On the other hand, the underlying function p for which simple kernel estimation is used is much simpler and more stable compared to q for which nonparametric second derivative estimation is required. Thus the source of error will partially be cancelled out.
Because the estimates of ratios are constructed from the ratio of the estimates, we can decompose the error as
K^(u) - K(u) = q^(u) - q(u) p^(u) p(u) q^(u) - q(u) - q(u) p^(u) - p(u) . p(u) p(u) p(u)
Numerical instability might occur in the region where p^  0 however this is not of theoretical concern. In fact, the pricing kernel is the Radon-Nikodym derivative of an absolutely continuous measure, and thus p and q are equivalent measures, that is, the null set of p is the same as the null set of q. So we can limit our attention to the case where p(u) > for some constant . Provided that p(u) > and q(u) > , the asymptotic approximation is straightforward and asymptotic bias and variance can be
17

computed from

E[K^(u) - K(u)]

E[q^(u) - q(u)] - q(u) E[p^(u) - p(u)] p(u) p(u) p(u)

= O(hq4) + O(h2p) + O(h2p + hq4) ,

Var[K^(u) - K(u)]

K2(u)

Var[q^(u)] Var[p^(u)] q2(u) + p2(u)

= O (N hq)-1 + O (nhp)-1 + O (N hq)-1 + (nhp)-1 .

Since q^ involves estimation of second derivative of a regression function, the error is dominated by the estimation of q. Ait-Sahalia and Lo (2000) showed in a similar framework that the error is dominant by the estimation of q and for the purpose of asymptotics p can be regarded as a fixed quantity.

Consistency and asymptotic normality of the parameter estimates are shown in Ha®rdle

and Marron (1990) for two curves and in Kneip and Engel (1995) for multiple curves.

So we may write that

^t  N(t, t) .

Due to the iterative algorithm, the asymptotic covariance matrix is more complicated
for multiple curves but Kneip and Engel (1995) shows that, as the number of curves in-
creases, the additional terms arising in the covariance matrix is of lower order than the
standard error term due to non-linear least square methods. There is no suggested esti-
mate for the asymptotic covariance matrix but a consistent estimate can be constructed as in standard non-linear least square methods. Define the residual e^tj = K^t(uj)-K~t(uj) where K^ is the initial estimates and K~ is the SIM estimates and let

n
^t2 = (n)-1 e^t2j .
j=1

The covariance matrix can be estimated as

n
^ t = ^t2 n-1
j=1

 K~t(uj; ~)

 K~t(uj; ~)

-1
,

where

K(u; ) is the first derivative of the function, given by

K(u) =
1

K0

u - 3 2

,

K(u) 2

= - 1 2

u - 3 2

K0

u - 3 2

,

K(u) 3

=

-

1 2

K0

u - 3 2

,

K(u) =
4

1.

18

To see whether the location or scale parameters are different between any pair of curves, we can compute the standard errors of the estimates to make a comparison. A formal hypothesis testing also appears in H®ardle and Marron (1990) for kernel-based estimates and in Ke and Wang (2001) for spline-based estimates. For example we might be interested in testing whether a location or a scale parameter can be removed. Although these results are practically relevant, we note that the methods mentioned all assume direct observations of the underlying function of interest, with one smoothing parameter selection involved. Obtaining comparable rigorous results for our estimator is complicated in the present situation due to the non-standard nature of the estimator being a ratio of two separate nonparametric estimates with independent bandwidths. We consider this out of scope of this paper and leave for separate work.
33
22
11
0.8 0.9 1 1.1 1.2 0.8 0.9 1 1.1 1.2
Figure 6: Estimated common shape function K0 (left) and transformed curves Kt(t2u+ t3) of those in Figure 4 on the common domain (right).
3 Pricing kernels and risk aversion
The common curve estimate of the pricing kernel, together with shifted curves are shown in Figure 6. The estimate is not defined outside the range where no information is available on the common shape. Figure 7 shows the parameter estimates from the model (2), with approximate 95% (pointwise) confidence intervals added. Note that the range in y axis of the location parameters (3, 4) and scale parameters (1, 2) differ. 1 and 4 correspond to the amplitude variability (vertical direction) and 2 and 3 correspond to phase variability (horizontal direction) across dates. In Section 2, we have discussed utility functions implied by the pricing kernel family. In
19

2 1.5
1 0.5
0 0
1 0.5
0 -0.5
-1 0

1 2

1.5

1

0.5

10 20 30 40

0 0

3 1

0.5

0

-0.5

10 20 30 40

-1 0

2
10 20 30 40 4
10 20 30 40

Figure 7: Parameter estimates of the shape invariant models for the EPK and their confidence intervals at 95% confidence level

general the utility function corresponding to Kt is given by

Ut(u)

=

t1t2U0

u - t3 t2

- U0

- t3 t2

+ t4u



t1U0

u - t3 t2

+ t4 + t4u .

The utility function Ut is a combination of a SIM class of the common utility function and a linear utility function. The ARA measure is given by

ARAt(u)

=

-

t1 t2

K0

u-t3 t2

t1K0

u-t3 t2

+ t4

.

For example, assuming K0(u) = u- with t2 = 1 gives

ARAt(u) =  (u - t3) + (t4/t1)(u - t3)+1 -1 .

(9)

When t4 = 0, this function is monotonically decreasing but in general this is not the case.

20

3 20
2 0
1 -20
0.8 1 1.2 0.8 1 1.2
3 20
2 0
1 -20
0.8 1 1.2 0.8 1 1.2
Figure 8: Estimated pricing kernels (left) and corresponding ARA measures (right) in 2003 (top) and 2004 (bottom). These are reconstructed based on the model parameters shown in Figure 6 and 7.
In order to gain some insights to these results, we take a closer look at the changes that individual effects in the family of scale and shift parameters have on the common function of empirical pricing kernel (EPK) and absolute risk aversion (ARA). These effects are demonstrated in Figures 10 and 11. We vary each i, with i = {1, 2, 3, 4} with respect to a baseline model - the reference curve for 0 = (1, 1, 0, 0) and then we show how these modifications translate into changes of the risk attitudes. For this exercise we first standardise the common curve that we have estimated via the shape invariant model so that the peak occurs at the value 0 on the abscissa. We observe that an increase in 1 has a positive scaling effect on the EPK curve. The absolute increase is larger for values of the EPK around the peak; the converse holds for a decrease in 1. However, when compared to the common curve, a change in 1 does
21

3 20
2 0
1 -20
0.8 1 1.2 0.8 1 1.2
3 20
2 0
1 -20
0.8 1 1.2 0.8 1 1.2
Figure 9: Estimated pricing kernels (left) and corresponding ARA measures (right) in 2005 (top) and 2006 (bottom). These are reconstructed based on the model parameters shown in Figure 6 and 7.
not have any effect on ARA because, as we can see from (9), ARA does not depend on 1 when 4 = 0. Yet, the effect of 1 on ARA can be analysed by considering two distinct cases: 4 > 0 and 4 < 0. These specifications are important because the direction of change in the slope of ARA is dictated by the sign of 4. In the present case - after normalisation - 1 varies around 0 and its effect on ARA is almost nil. A larger value in the parameter 2 as compared to a benchmark value of 1 slackens the EPK by stretching the x-axis, which implies larger spread of the bump. When we vary 2 alone the slope of ARA(2u) is 1/22 K02(u) - K0(u)/K0(u) /K02(u) . The term in brackets does not depend on 2; it is equal to the slope of ARA(u). Therefore, there is an inverse relationship between the direction of change in the parameter and that of the absolute value of the slope. These changes in slope occur arround an inflection point
22

33 22 11

-0.2 -0.1

0

0.1

0.2 -0.2

-0.1

0

0.1 0.2

33

22

11

-0.2 -0.1

0

0.1

0.2 -0.2

-0.1

0

0.1 0.2

Figure 10: EPK: 1 = 0.75 (red), 1 = 1.25 (blue) - up left, 2 = 0.75 (red), 2 = 1.25 (blue) - up right, 3 = -0.025 (red), 3 = 0.025 (blue) - bottom left, 4 = -0.25 (red), 4 = 0.25 (blue) - bottom right - compared to the baseline model 0 = (1, 1, 0, 0) (black).

that corresponds to the peak of the EPK.
A positive increment in 3 shifts both curves to the left without any modification in the shape. 4 simply translates EPK curves above or below the reference curve following a sign rule. Similarly to 2, the shape of ARA modifies around the fixed inflection point that marks the change from risk proclivity (negative ARA) to risk aversion (positive ARA). The effect of 4 on the values of ARA is straightforward: since 4 adds to the K0 in the denominator its increase will diminish the absolute ARA level and the other way around: absolute ARA level will increase with its reduction. Insulating the effects of a change in 4 on the slope of ARA(u) analytically proves to be a more complicated than in the case of 2 because the change in the slope depends jointly on the change in 4 and on the EPK values and its first two derivatives. In our case, the slope around

23

40 40

20 20

00

-20 -20

-0.2 -0.1

0

0.1

0.2 -0.2

-0.1

0

0.1 0.2

40 40

20 20

00

-20 -20

-0.2 -0.1

0

0.1

0.2 -0.2

-0.1

0

0.1 0.2

Figure 11: ARA: 1 = 0.75 (red), 1 = 1.25 (blue) - up left, 2 = 0.75 (red), 2 = 1.25 (blue) - up right, 3 = -0.025 (red), 3 = 0.025 (blue) - bottom left, 4 = -0.25 (red), 4 = 0.25 (blue) - bottom right - compared to the baseline model 0 = (1, 1, 0, 0) (black).

the inflection point increases when 4 decreases.
With this information at hand we can characterise the changes in risk patterns in relation with economic variables of interest. Before doing this, we should mention that in the case of nonstandard common curves - in our empirical example the peak does not occur at 0 - 2 introduces a shift effect in EPK together with its shape effect. We will then observe that a larger value in the parameter 2 as compared to a benchmark value of 1 slackens EPK and shifts it to the right. ARA suffers a transformation similar to EPK in the horizontal direction, but also a slight shrinking and translation effect in the vertical direction. This second effect becomes more evident for larger values of 2. Therefore, the effect of 3 must be interpreted only in conjunction with 2.
Following Engle and Rosenberg (2001) we try to link the parameters describing risk
24

1 2 3 4 Px Py C S Y C I R RDax

1 1.00* -0.71* 0.71* -0.93* -0.27*** 0.96* -0.30*** -0.02 0.01 0.68*

2
1.00* -0.99* 0.45* 0.41** -0.83* 0.19 -0.15 0.10 -0.57*

3
1.00* -0.45* -0.38** 0.83* -0.19 0.15 -0.08 0.56*

4
1.00* 0.1 -0.82* 0.31*** 0.11 -0.02 -0.59*

Px
1.00* -0.31*** 0.13 -0.21 0.53* -0.52*

Py
1.00* -0.28*** 0.03 -0.00 0.69

Table 1: Correlation coefficients between EPK risk aversion parameters and economic indicators of the business cycle

sig at 1% = * sig at 5% = ** sig at 10% = ***

attitudes to the business conditions. In this sense we compute the correlation coefficients between each parameter i and variables of interest. In addition, we build another two time series that account for the location of the peak: Px and Py and repeat the procedure. We use the following variables that have a revealed relation with the state of the economy: credit spread (CS) is the difference between the yield on the corporate bond1 and the government bond maturing in 5 years; the yield curve slope (YS) refers to the difference between the thirty-year government bond yield and three-months intebank rate; short term interest rate (IR) is the three-months intebank rate; and DAX 30 Performance index as a proxy for consumption (Ait-Sahalia and Lo (1998)). These are all daily time series. For our purpose we have selected the days that exactly match the dates of the one month pricing kernels. The data has been collected from the Datastream and refer to the German market.
All these time series are nonstationary (we have performed the Dickey-Fuller-Test for every series) and we prefer to use the first difference instead for a clear interpretation of the interdependencies (for the Dax index we compute the monthly percentage change (RDax)). Table 1 reports the result.
We interpret the peak as the transition between two decreasing pricing kernels corresponding to the area of losses and profits. A smooth transition indicates a reluctance
1Series Euro Area Corporate Bond Yield are based on the German CORPTOP Bond maturing in 3-5 years. Data are sourced from the Commerzbank.
25

to assume locally a risk loving behavior or, a higher constant risk aversion coefficient consistent with Black-Scholes power utility function.
A positive change in the short term interest rate shifts the location of the EPK peak to the right, to the areas of higher returns. Increasing short-term interest rate signals worsening investment opportunities connected with a price up of credit. The correlation of IR with both 2 and 3 is not statistically significant. Therefore, while the effect on the shape of ARA remains unclear, we can infer that the agents update their expectations for the Dax returns according to the changes of the risk free interest rate.
The credit spread is an indicator of the investor's believe with respect to the riskiness of an investment. The increase in the credit spread is negatively correlated with the change in the peak height. The correlation with both 1 and 4 is also significant. We know that only 4 has a significant effect on the shape of ARA for values of 4 around 0. CS and 4 have a positive and significant correlation; with other words, an increase of the credit spread leads to lower values of ARA around the inflection point. Thus, risk proclivity is less pronounced in periods of recessions, announced by larger credit spreads.
Positive returns on the DAX index shift the peak of the EPK to the left. There is a negative correlation between 2 and the DAX returns which means the if Dax index increases the ARA will have a higher slope around the inflexion point, the local risk proclivity is more pronounced, so the constant risk aversion coefficient decreases, which implies that agents assume more risk. The region where the value of a unit payment is greater when DAX returns are lower contracts: agents behave more risky on schrinking domains.
On the vertical axis, positive returns enhance the peak. Both correlations of 1 and 4 are significant. The negative correlation of 4 with DAX returns indicates that ARA values increase relative to the previous period when DAX index increases. More pronounced local risk aversion around the switching point is in line with the effect introduced through 2: Agents are locally more risk prone or overall less risk averse.
We haven't found any significant correlation with the change in the yield slope.
The sense of the relations between the indicators of the business cycle - here, statistically significant are the credit spread growth and the DAX returns - and the parameters that summarize risk preferences indicates that locally risk loving behavior is procyclical. Our finding are in line with the results of Following Engle and Rosenberg (2001). In addition, we have learned how agents change their believes in the sense that they update the expected value of the risky bets (the region on which they have nonstandard preferences) according to the business cycle: the domain on which we record risk prone behavior moves in the same sense with the indicators of economic contraction (the changes in the short term interest rate) and in oposite sense with the indicators of economic expansion (DAX returns). One possible explanation for it is the variation of the demand for
26

33 22 11

0.5 0.75 1 60

1.25 1.5 0.5 0.75 1 60

1.25

1.5

30 30

00

0.5 0.75 1

1.25 1.5 0.5 0.75 1

1,25

1.5

Figure 12: Decomposition of EPK - up and ARA - bottom (red/dashed) in individual effects: 1 (brown/triangle), 2 (blue/dash-dotted), 3 (green/dotted), 4 (magenta/star) as compared to the common curve (black), on 16-Jul-2003 (left) and 19-Apr-2006 (right)

insurance under different market conditions.
Furthermore, we observe that there are significant correlations between the variations of all i. Important for us is the negative strong correlation between 1 and 2: a decrease in the peakness comes along with an increase in the duration, which both lead to less pronounced locally risk loving behavior. Intuitivelly, we can assert that a concerted negative evolution of the economic indicators over several periods will lead eventually to overall risk averse behaviour.
The evolution that we observe for our estimated period can be sumarized by Figure 12. The graphs shown are a representative of a bundle of curves estimated at the beginning and the end of the period we analysed. We observe that shifting effects of 2 and 3 are of opposite sense and almost cancel each other. At the begining of the estimation period
27

2 is larger than one, indicating an expansion of the spread. This relation to the baseline parameter of one is roughly the case for 1 as well (see Figure 7). Dominantly negative 4 in the first stages brigs upon the slopes in ARA (larger values for risk aversion functions) relative to the reference. This effect interacts with the effect for slope introduced by 2. The credit spread growth does not have any clear pattern over the period we considered. Negative growth in the short term interest rates and positive returns on Dax index in the first period as oposed to the second period mark the transition from a prosperous business conditions to declining economy. In between these periods the market is unsettled.
4 Conclusions
We have explored a way of combining information contained in a series of empirical pricing kernels. We propose a systematic approach using shape invariant modelling that aims at capturing a common structure as a reference curve and explaining individual variability by the deviations on the horizontal and vertical directions from the reference curve. We have demonstrated the method using the European DAX options and returns data and quantified the variability with four parameters that are easy to interpret in the economic context. Inspection of these summaries would enhance our understanding of the potentially complex objects like pricing kernels. Based on the pricing kernels we derived the risk behaviour based on the ARA measures. We were also able to relate the changes in risk behaviour to economic variables of interest and we have found that local risk loving behaviour is procyclical.
Several extensions are left for future research. Although the shape invariant modelling framework is independent of the estimation of pricing kernels, this can serve an alternative framework for comparison of empirical pricing kernels and related quantities. Furthermore, time series analysis based on the estimated parameters for longer series will be useful to summarise the dynamics and can be used to develop formal statistical inference methods. We have only considered linear transformation and found it sufficient for our analysis. An extension to nonlinear transformation is relatively straightforward, if necessary. The real issue then would be to incorporate some formal statistical inference methods to distinguish the cases.
References
Ait-Sahalia, Y. and Duarte, J. (2003). Nonparametric option pricing under shape restrictions. Journal of Econometrics, 116:9 ≠ 47.
Ait-Sahalia, Y. and Lo, A. W. (2000). Nonparametric risk management and implied risk aversion. Journal of Econometrics, 94(1-2):9 ≠ 51.
28

Bondarenko, O. (2003). Estimation of risk-neutral densities using positive convolution approximation. J. Econometrics, 116(1-2):85≠112. Frontiers of financial econometrics and financial engineering.
Breeden, D. T. and Litzenberger, R. H. (1978). Prices of state-contingent claims implicit in option prices. The Journal of Business, 51(4):621≠651.
Engle, R. F. and Rosenberg, J. V. (2002). Empirical pricing kernels. Journal of Financial Economics, 64:341≠372.
Ferraty, F. and Vieu, P. (2006). Nonparametric functional data analysis. Springer Series in Statistics. Springer, New York. Theory and practice.
Gasser, T. and Kneip, A. (1995). Searching for structure in curve sample. Journal of the American Statistical Association, 90(432):1179≠1188.
Gervini, D. and Gasser, T. (2004). Self-modelling warping functions. Journal of the Royal Statistical Society. Series B (Statistical Methodology), 66(4):959≠971.
Giacomini, E. and H®ardle, W. (2008). Dynamic semiparametric factor models in pricing kernel estimation. In Dabo-Niang, S. and Ferraty, F., editors, Functional and Operational Statistics, Contributions to Statistics, pages 181≠187. Springer Verlag.
Giacomini, E., Ha®rdle, W., and Handel, M. (2008). Time dependent relative risk aversion. In Georg, B., Svetlozlar, R., and Reinhold, W., editors, Risk Assessment: Decisions in Banking and Finance, Contributions to Economics, pages 15≠46. Physica Verlag.
H®ardle, W., Kra®tschmer, V., and Moro, R. (2009). A microeconomic explanation of the epk paradox. Technical Report 2009-010, SFB 649 Discussion Paper. Submitted to Finance and Stochastics.
H®ardle, W. and Marron, J. S. (1990). Semiparametric comparison of regression curves. Ann. Statist., 18(1):63≠89.
Huynh, K., Kervella, P., and Zheng, J. (2002). Estimating state-price densities with nonparametric regression. In Applied quantitative finance, pages 171≠196. Springer, Berlin.
Jackwerth, J. C. (1999). Option-implied risk-neutral distributions and implied binomial trees: a literature review. Journal of Derivatives, 2(7):66≠82.
Jackwerth, J. C. (2000). Recovering risk aversion from option prices and realized returns. Rev. Financ. Stud., 13(2):433≠451.
Ke, C. and Wang, Y. (2001). Semiparametric nonlinear mixed-effects models and their applications. Journal of the American Statistical Association, 96:1272≠1298.
29

Kneip, A. and Engel, J. (1995). Model estimation in nonlinear regression under shape invariance. Ann. Statist., 23(2):551≠570.
Kneip, A. and Gasser, T. (1988). Convergence and consistency results for self-modeling nonlinear regression. Ann. Statist., 16(1):82≠112.
Kneip, A. and Gasser, T. (1992). Statistical tools to analyze data representing a sample of curves. Ann. Statist., 20(3):1266≠1305.
Lawton, W. H., Sylvestre, E. A., and Maggio, M. S. (1972). Self modeling nonlinear regression. Technometrics, 14(3):513≠532.
Leland, H. E. (1980). Who should buy portfolio insurance? Journal of Finance, 35(2):581≠94.
Ramsay, J. O. and Li, X. (1998). Curve registration. Journal of the Royal Statistical Society. Series B (Statistical Methodology), 60(2):351≠363.
Ramsay, J. O. and Silverman, B. W. (2002). Applied functional data analysis. Springer Series in Statistics. Springer-Verlag, New York. Methods and case studies.
Ramsay, J. O. and Silverman, B. W. (2005). Functional data analysis. Springer Series in Statistics. Springer, New York, second edition.
Rookley, C. (1997). Fully exploiting the information content of intra day option quotes: Applications in option pricing and risk management. Technical Report 2009-010, University of Arizona. Working paper.
Wand, M. P. and Jones, M. C. (1995). Kernel smoothing, volume 60 of Monographs on Statistics and Applied Probability. Chapman and Hall Ltd., London.
30

SFB 649 Discussion Paper Series 2009
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "Implied Market Price of Weather Risk" by Wolfgang H‰rdle and Brenda LÛpez Cabrera, January 2009.
002 "On the Systemic Nature of Weather Risk" by Guenther Filler, Martin Odening, Ostap Okhrin and Wei Xu, January 2009.
003 "Localized Realized Volatility Modelling" by Ying Chen, Wolfgang Karl H‰rdle and Uta Pigorsch, January 2009.
004 "New recipes for estimating default intensities" by Alexander Baranovski, Carsten von Lieres and AndrÈ Wilch, January 2009.
005 "Panel Cointegration Testing in the Presence of a Time Trend" by Bernd Droge and Deniz Dilan Karaman ÷rsal, January 2009.
006 "Regulatory Risk under Optimal Incentive Regulation" by Roland Strausz, January 2009.
007 "Combination of multivariate volatility forecasts" by Alessandra Amendola and Giuseppe Storti, January 2009.
008 "Mortality modeling: Lee-Carter and the macroeconomy" by Katja Hanewald, January 2009.
009 "Stochastic Population Forecast for Germany and its Consequence for the German Pension System" by Wolfgang H‰rdle and Alena Mysickova, February 2009.
010 "A Microeconomic Explanation of the EPK Paradox" by Wolfgang H‰rdle, Volker Kr‰tschmer and Rouslan Moro, February 2009.
011 "Defending Against Speculative Attacks" by Tijmen DaniÎls, Henk Jager and Franc Klaassen, February 2009.
012 "On the Existence of the Moments of the Asymptotic Trace Statistic" by Deniz Dilan Karaman ÷rsal and Bernd Droge, February 2009.
013 "CDO Pricing with Copulae" by Barbara Choros, Wolfgang H‰rdle and Ostap Okhrin, March 2009.
014 "Properties of Hierarchical Archimedean Copulas" by Ostap Okhrin, Yarema Okhrin and Wolfgang Schmid, March 2009.
015 "Stochastic Mortality, Macroeconomic Risks, and Life Insurer Solvency" by Katja Hanewald, Thomas Post and Helmut Gr¸ndl, March 2009.
016 "Men, Women, and the Ballot Woman Suffrage in the United States" by Sebastian Braun and Michael Kvasnicka, March 2009.
017 "The Importance of Two-Sided Heterogeneity for the Cyclicality of Labour Market Dynamics" by Ronald Bachmann and Peggy David, March 2009.
018 "Transparency through Financial Claims with Fingerprints ≠ A Free Market Mechanism for Preventing Mortgage Securitization Induced Financial Crises" by Helmut Gr¸ndl and Thomas Post, March 2009.
019 "A Joint Analysis of the KOSPI 200 Option and ODAX Option Markets Dynamics" by Ji Cao, Wolfgang H‰rdle and Julius Mungo, March 2009.
020 "Putting Up a Good Fight: The GalÌ-Monacelli Model versus `The Six Major Puzzles in International Macroeconomics'", by Stefan Ried, April 2009.
021 "Spectral estimation of the fractional order of a LÈvy process" by Denis Belomestny, April 2009.
022 "Individual Welfare Gains from Deferred Life-Annuities under Stochastic Lee-Carter Mortality" by Thomas Post, April 2009.
SFB 649, Spandauer Straﬂe 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

SFB 649 Discussion Paper Series 2009
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
023 "Pricing Bermudan options using regression: optimal rates of convergence for lower estimates" by Denis Belomestny, April 2009.
024 "Incorporating the Dynamics of Leverage into Default Prediction" by Gunter Lˆffler and Alina Maurer, April 2009.
025 "Measuring the effects of geographical distance on stock market correlation" by Stefanie Eckel, Gunter Lˆffler, Alina Maurer and Volker Schmidt, April 2009.
026 "Regression methods for stochastic control problems and their convergence analysis" by Denis Belomestny, Anastasia Kolodko and John Schoenmakers, May 2009.
027 "Unionisation Structures, Productivity, and Firm Performance" by Sebastian Braun, May 2009.
028 "Optimal Smoothing for a Computationally and Statistically Efficient Single Index Estimator" by Yingcun Xia, Wolfgang H‰rdle and Oliver Linton, May 2009.
029 "Controllability and Persistence of Money Market Rates along the Yield Curve: Evidence from the Euro Area" by Ulrike Busch and Dieter Nautz, May 2009.
030 "Non-constant Hazard Function and Inflation Dynamics" by Fang Yao, May 2009.
031 "De copulis non est disputandum - Copulae: An Overview" by Wolfgang H‰rdle and Ostap Okhrin, May 2009.
032 "Weather-based estimation of wildfire risk" by Joanne Ho and Martin Odening, June 2009.
033 "TFP Growth in Old and New Europe" by Michael C. Burda and Battista Severgnini, June 2009.
034 "How does entry regulation influence entry into self-employment and occupational mobility?" by Susanne Prantl and Alexandra Spitz-Oener, June 2009.
035 "Trade-Off Between Consumption Growth and Inequality: Theory and Evidence for Germany" by Runli Xie, June 2009.
036 "Inflation and Growth: New Evidence From a Dynamic Panel Threshold Analysis" by Stephanie Kremer, Alexander Bick and Dieter Nautz, July 2009.
037 "The Impact of the European Monetary Union on Inflation Persistence in the Euro Area" by Barbara Meller and Dieter Nautz, July 2009.
038 "CDO and HAC" by Barbara Choro, Wolfgang H‰rdle and Ostap Okhrin, July 2009.
039 "Regulation and Investment in Network Industries: Evidence from European Telecoms" by Michal Grajek and Lars-Hendrik Rˆller, July 2009.
040 "The Political Economy of Regulatory Risk" by Roland Strausz, August 2009.
041 "Shape invariant modelling pricing kernels and risk aversion" by Maria Grith, Wolfgang H‰rdle and Juhyun Park, August 2009.
SFB 649, Spandauer Straﬂe 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

