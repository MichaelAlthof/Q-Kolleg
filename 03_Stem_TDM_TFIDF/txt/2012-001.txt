BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2012-001
HMM in dynamic HAC models
Wolfgang Karl Härdle* Ostap Okhrin* Weining Wang*
* Humboldt-Universität zu Berlin, Germany
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universität zu Berlin Spandauer Straße 1, D-10178 Berlin

HMM in dynamic HAC models
Wolfgang Karl Härdle, Ostap Okhrin §, Weining Wang¶
January 2, 2012
Abstract
Understanding the dynamics of high dimensional non-normal dependency structure is a challenging task. This research aims at attacking this problem by building up a hidden Markov model (HMM) for Hierarchical Archimedean Copulae (HAC), where the HAC represent a wide class of models for high dimensional dependency, and HMM is a statistical technique to describe time varying dynamics. HMM applied to HAC provide flexible modeling for high dimensional non Gaussian time series. Consistency results for both parameters and HAC structures are established in an HMM framework. The model is calibrated to exchange rate data with a VaR application, where the model's performance is compared with other dynamic models, and in the second application we simulate rainfall process.
Keywords: Hidden Markov model, Hierarchical Archimedean Copulae, Multivariate Distribution
JEL classification: C13, C14, G50
1 Introduction
Modelling high-dimensional time series is an often underestimated exercise of routine econometrical and statistical work. This slightly pejorative attitude towards day to day statistical analysis is unjustified since actually the calibration of time series models in high dimensions for standard data sizes is not only a difficulty on the numerical side but also poses a challenge on the mathematical side. Computationally speaking, integrated models for high dimensional time series become more evolved when the parameter space is too high. An example is the multivariate GARCH(1,1)
The financial support from the Deutsche Forschungsgemeinschaft via SFB 649 Ökonomisches Risikö, HumboldtUniversität zu Berlin is gratefully acknowledged.
We thank Prof. Cheng-Der Fuh for his comments Professor at Humboldt-Universität zu Berlin and Director of CASE - Center for Applied Statistics and Economics, Humboldt-Universität zu Berlin, Spandauer Straße 1, 10178 Berlin, Germany. Email:haerdle@wiwi.huberlin.de §Assistant Professor at the Ladislaus von Bortkiewicz Chair of Statistics of Humboldt-Universität zu Berlin, Spandauer Straße 1, 10178 Berlin, Germany. Email:ostap.okhrin@wiwi.hu-berlin.de ¶Research associate at the Ladislaus von Bortkiewicz Chair of Statistics of Humboldt-Universität zu Berlin, Spandauer Straße 1, 10178 Berlin, Germany. Email:wangwein@cms.hu-berlin.de
1

BEKK model that for even two dimensions has an associated parameter space of dimension 12. For moderate sample sizes, the parameter space dimension might well be in the range of the sample size or even bigger. This data situation has evoked a new strand of literature on dimension reduction via penalty methods.
In this paper we are taking a different route by calibrating an integrated dynamic model with unknown dependency structure among the d dimensional time series variables. More precisely, the unknown dependency structure may vary among a set of given dependencies. The specific dependence at each time t is unknown to the data analyst, but depend on the dependency patter at time t - 1. Therefore, hidden Markov models (HMM) come naturally into play. This leaves us with the problem of specifying the set of dependencies.
An approach based assuming a multivariate Gaussian or mixed normal is limited in capturing important types of data features such as heavy tails, asymmetry and nonlinear dependence. Such a simplification might in practice be a too restrictive assumption and might lead to biased results. Copulae are one of possible approaches in solving these problems, see Joe (1996). Moreover, copulae allow us to separate the marginal distributions and the dependency model, see Sklar (1959). Over decades copula based models gained their popularity in various fields like finance, insurance, biology, hydrology, etc. Nevertheless, many basic multivariate copulae are still too restrictive and a simple extension by putting in more parameters would lead to the extreme of a total nonparametric approach that runs into a curse of dimensionality problem. A natural compromise is the class of hierarchical Archimedean copulae (HAC). A HAC allows a rich copula structure with a finite number of parameters. Recent works which have shown their flexibility are McNeil and Neslehová (2009), Okhrin, Okhrin and Schmid (2009b), Whelan (2004).
Many attempts have been done to give insights into the dynamics of the copulae: Chen and Fan (2005) assumes the underlying sequence is Markovian; Patton (2004) considers an asset-allocation problem with a time-varying parameter of bivariate copulae; Rodriguez (2007) studies financial contagion using switching-parameter bivariate copulae. A likelihood based local adaptive method is an alternative approach to understand the time evolution, see Giacomini, Härdle and Spokoiny (2009), Härdle, Okhrin and Okhrin (2011). Figure 1 presents the LCP (local change point method) window analysis of HAC for exchange rate data. One observes that the structure (upper panel) stays very often the same for a long time, and the parameters (lower panel) are slowly varying over time. This indicates that the dynamics of HAC functions is likely driven by Markovian sequence connected with structures and parameter values. This suggests us a different path of modeling the dynamics: instead of taking a local point view, we adopt a global dynamic model (HMM) for the change of both tree structure and parameters of HAC along time horizon. Under HMM, a stochastic process Y with a not directly observable underlying Markov process X, it is needed to determine state of distributions of Y . It has been widely applied to speech recognition see Rabiner (1989), molecular biology, digital communications over unknown channels. Estimation and inference issues in HMM see Bickel, Ritov and Rydén (1998) and Fuh (2003), among others.
In this paper, we propose a new type of dynamic models, called HMMHAC, by incorporating HAC into an HMM framework. The theoretical problems like parameter consistency and structure consistency are solved. The expectation maximization (EM) algorithm is developed in this framework for parameter estimation. See section 2 for model description, section 3 for theorems for consistency. EM algorithm and computation issues are in section 4. Section 5 is for simulation study, and section 6 is for applications. The technical details are put into appendix.
2

((2.3).1)

structure
((1.3).2)

((1.2).3)


0.0 0.2 0.4 0.6 0.8

q

1999

2000

2001

2002

2003

2004

2005

2006

2007

2008

Figure 1: LCP for Exchange Rates: structure (upper) and parameters (lower, 1(green) and 2)(blue) for Gumbel HAC. m0 = 40.

2 Model description

The hidden Markov model is regarded as a parameterized Markov random walk with the underlying

Markov chain viewed as missing data, as in Leroux (1992), Bickel et al. (1998). Specifically,

in our HMM HAC framework, let {Xt, t  0} be a stationary Markov chain on a finite state space D = {1, 2, . . . , M }, with transition probability matrix P v× = [pivj×]i,j=1,...,M and initial distribution v× = {iv×}i=1,...,M , where v ×   V ×   N  × Rq denotes an element in the parameter space V ×  which parametrize this model, and q as the number of parameters (note

that our parameter space is partially discrete (V ), and partially continuous ()). Suppose that

a real-valued additive component Bt,j =

t k=0

Yk,j

,

j



1, . . . , d

with

Bt

=

(Bt,1, Bt,2, . . . , Bt,d)

and Yk = (Yk,1, Yk,2, . . . , Yk,d) are r.v. taking values on Rd, is adjoined to the chain such that

{(Xn, Bt), t  0} is a Markov chain on D × Rd and

P{(Xt, Bt)  A × (B + b)|(Xt-1, Bt-1) = (i, b)} = P{(X1, B1)  A × B|(X0, B0) = (i, 0)}

(1)

= P(i, A × B) =

pvij×fj{b; sj(v × ), (j)(v × )}µ(db),

jA bB

where B, b  Rd, A  D, fj{b; s(j)(v × ), (j)(v × )} is the conditional density of Yt given Xt-1, Xt with respect to a -finite measure µ on Rd, (v × )  , s(v × )  S, j = 1, . . . , M
are the unknown parameters. That is, {Xt, t  0} is a Markov chain, given X0, X1, . . . , XT , with
Y1, . . . , YT being independent. We give a formal definition as follows. {Bt, t  0} is called a hidden
Markov model if there is a Markov chain {Xt, t  0} such that the process {(Xt, Bt), t  0} satisfies (1). Note that in (1), the usual parameterization (j)(v × ) = (j), and s(j)(v × ) = s(j).
Moreover,  = ((1), . . . , (M))  RdM are the unknown dependency parameters, s = (s(1), . . . , s(M)) are the unknown structure parameters, and its true value is denoted by  and s. For simplicity, we will use i for iv× and pij for pivj×. See Figure 2 for a graphical illustration of HMM.

3

Xt-1

Xt

Xt+1

Xt+2

Yt-1

Yt

Yt+1

Yt+2

Figure 1: Graphical representation of the dependence structure of HMM Figure 2: Graphical representation of the dependence structure of HMM, where Xt depends only on Xt-1 and Yt only on Xt.

For given d dimensional times series y1, · · · , yT ,  Rd (yt = (y1t, y2t, y3t, . . . , ydt) ) connected with unobservable (or missing) x1, . . . , xT from a hidden Markov model {Bt, t  0}, define xt as the i for x0 = i, i = 1, . . . , M , and pxt-1xt = pji for xt-1 = j and xt = i. The full likelihood function given one realization of {xt, yt}tT=1 is:

T
pT (y1, · · · , yT ; x1, . . . , xT ; v × ) = x0 pxt-1xtfxt(yt; (xt), s(xt)),
t=1

(2)

and the likelihood for only the observations {yt}tT=1 by marginalization :

MM

T

pT (y1, · · · , yT ; v × ) = · · · x0 pxt-1xt fxt (yt; (xt), s(xt)),

x0=1 xn=1

t=1

(3)

with the abbreviation of pT (y1, · · · , yT ; v × ) as pT (y1:T ; v × )

2.1 Parametrization of fxt(yt; (xt), s(xt))(xt = i) by HAC
The novelty of our approach lies in a special parametrization of fxt(yt; (xt), s(xt))(xt = i) (abbreviated as fi(.)), which helps to properly understand the dynamics of a multivariate distribution. Up to now, typical parameterizations are mixtures of log-concave or elliptical symmetric densities, like those from Gamma or Poisson families, which are not flexible enough to model high dimensional time series. The advantage of the copula is that it splits the multivariate distribution into the margins and a pure dependency component. In other words, it captures the dependency between variables eliminating the impact of the marginal distributions.
Usually, copula comes into play, when one is interested in a simple but informative representation of the joint distribution of a d dimension r.v., say Z1, . . . , Zd with continuous cumulative distribution function (cdf)F (·). The theorem which guarantees the existence and uniqueness of copula functions states that there exists a unique function C : [0, 1]d  [0, 1] satisfying
C(u1, . . . , ud) = F {F1-1,m(u1), . .1. , Fd-1,m(ud)}, u1, . . . , ud  [0, 1], where F1-1,m(u1), . . . , Fd-1,m(ud) are the quantile functions of the corresponding continuous marginal distributions F1m(Z1), . . . , Fdm(Zd).
4

1 2 u4 3 u3 u1 u2

1 2 3 u1 u2 u3 u4

FigureF3ig: uFruell1y: aFnudllpyaratniadllypanretsiatelldy cnoepsutelade coofpduilmaeenosfiodnimd e=ns4iownith =str4ucwtuitrhes sstr=uc(t(u(r1e2s)3)4=) on the lef(t((a1n2d)3s)4=) (o(n12t)h(e34le)f)toanndthe =rig(h(t12)(34)) on the right

We neceodpualafue.rtFhoer epxaarmampleet,ritzhaetisopnecoifalthceasceoopfuHlaAfCunfcutliloynn, ewstheidchcoapreulflaecxaibnlebeengoivuegnh btyo capture

the tail dependency and have an explicit form and are simple in estimation and estimation. One

candidate would be the family of Archimedean copulae, see Nelsen (2006).

( 1, . . . , ) =

1{ 2( 1, . . . ,

-1),

}=

1{

-1 1



2( 1, . . . ,

-1) + 1-1(

)}

C(u1, . . . , u=k)

=
1

{{-1 1-1(u12)(

+-2 1·(· ·

+3(

1-, 1.(.u. d,

)},
-2

)u) 1+, .

.

2-. ,1u( d

-1[)0),+1],

-1 1(

)}.

(4) (2)

where (.) is defined as the generator of the copula and most depends on the parameter . (.)  L = {(.) : [0; )  [0, 1] | (0) = 1, () = 0; (-1)j(j)  0; j = 1, . . . , }, simplified asTsuhme pctoiomnpsoosnitionmacaynbebefouapnpdliiendMrceNcuerisl iavneldyNuessilneghodviáffe(2re0n0t9)s.egAms eanntaetxiaomnsploef, tvhaeriGabulmesbel

generalteoardins ggivtoenmboyre(c.)om=pelxepx(-HxA1C/s). forFo0rnoxta<tion,al1 conve<nien.ce let the expression =

Howev{e(r.,.m. (u1lt.iv. a. ri1a)t.e.A. (r.c.h.i)m. e.d. )e}andceonpoutelaethaerestsrtuilcltruersetroicftiaveH, sAinCc,e wthheerreend ered{1d,e.p.e.n,de}ncisy is dsyempemndeatsrrioeconwrdaietshriinnrgeglsepofepcatthrateomintehdteeicrpeosefromtfhutethageteivnoaenrriaoatfbovlreasrf.uianbclteidsoenan.nodFteotshr etrhemefiunslettrdiuvsacttrruiuartceetuodrfeesp,uewbnecdoecpnoucnylsaiesdtewrruicHthtiuerrearchical A=rch.imFeudretahnerCloeptutlahe (H-dAiCm)enwshioicnhalarheietrhaercchoimcaploAsirtciohnims eodf esaimn pcloepAurlachbime eddeenaontecdopbuylae.
Conveni(en1t,ly.,. .w,e d;en,ot)e, twhheesrteructtuhreesoeft aofHcAoCpualas parameters. For example the fully nested

HAC (2) can be expressed sas= {(. . . (i1 . . . ij1) . . . (. . .) . . .)},

where i  subcopulae

w{1i(t,h.1.s,.d.,.d=.},

is s.

;Fau=rrethoredr, eler)itn=tgheof{d-td1h,iem. .ien.n,dsiicoe;ns(a(ol fh-ite1hr)ear)vc,ah(rici1aa,bl.l.Ae.sr,.chsi-mj1)dede}neaontecsotphuelastbreudcteunroeteodf

by C(u1, . . . ,=ud; s, -)1,, w-h1e(re--11,th-e1 set {of 1c,o.p. .u,la p-a1r; a((me-te2r)s(. -Fo1r))e,x(am1,p. l.e. ,the-2f)ull}y nested HAC

(see

Figure

3, +

left)-c1an
-1,

be (
-1

expressed )),

as

C(u1, . . . , ud; s = sd, ) = C{u1, . . . , ud; ((sd-1)d), (1, . . . , d-1) }

w=hered-1,=d-{1((..-d.-1(11,2d)-31). .C. ){u)1},.. .In. ,Fuidg-u1r;e((1sdw-e2)p(rde-sen1t))t,h(e1fu, .ll.y. ,neds-te2)d H}A+Cwd--1i1t,hds-t1r(uucdt)u),re

where s==((({1(2.).3.)(41)2a)3n)d. .p.a)rdt)ia}l.ly Fneigsuterde w3itphrese=nt(s(1t2h)e(3f4u)l)lyinndeismteednsHioAnC =wi4th. structure s =

(d(e(t1a2il)s3H)oA4f)C(HleaAftrC)e ,atnhsedoeropJuaogrethila(yl1ly9a9nn7a)el,ystsWeeddhweinliatnhJo(se20=(0149()9(,71)2S,)a(vW3u4h)a)e(lnardinghT(t2r)e0d0ine4)d,(2imS0a0ev6nu)s,ioaOnnkddhTr=irne,d4eO. k(F2ho0rri0n6m)a,onrde

SchmidEm(2b0r0e9cah)t.s, Lindskog and McNeil (2003).

The aforementioned tree structure with different generator functions would be too many to consider. NTootme athkaetthgeenperroabtolerms mowriethcionncareHtAe Cwitchaonuctolmoses eoifthgeernefrroamlitya, swinegcloengceennetrraattoerofnamonileysoinrgle
generaftroormfadmiffileyrewnitthgienneornaetoHr AfaCm, ialineds. thIfe di'sscubseslioonng istocotnhsetrsaaimneedfatmo iblyin, atrhyenstrtuhcetucorems,plie.et.e at

monotonicity of  +1 imposes some co5nstraints on the parameters 1, . . . , -1. Theorem 4.4 of McNeil (2008) provides sufficient conditions on the generator functions to

5

each level of the hierarchy only two variables are joined together. This makes our model very flexible and simultaneously parsimonious.
Note for each HAC not only the parameters are unknown, but also the structure has to be determined. We adopt the computation procedure as in Okhrin et al. (2009b) to estimate the HAC structure and parameters, which leads to efficient and unbiased estimators. In this procedure, one estimates the marginal distributions either parametrically or nonparametrically. Then assuming that the marginal distributions are known, one selects the couple of variables with the strongest fit and denote the respective estimator of the parameter at the first level by ^1 and the set of indices of the variables by I1 . The selected couple is joined together to define the pseudo-variables z1 = C{(I1); ^1, 1}. Next, one proceeds in the same way by considering the remaining variables and the new pseudo-variable. At every level, the copula parameter is estimated by assuming that the margins as well as the copula parameters at lower levels are known. The considered procedure allows us to determine the estimated structure of the copula recursively.
Further, we incorporate the above mentioned procedure into the HMM framework. We denote the underlying Markov variable Xt as a dependency type variable. If xt = i, the parameters (s(i), (i)) determined by state i = 1, . . . , M take values on S × , where S is discrete number of candidate states corresponding to different dependency structure of HAC, and  is a compact set in Rd-1 where the HAC parameters take values. Therefore,

fi(·) = c{F1m(y1), F2m(y2), . . . , Fdm(yd), s(i), (i)}f1m(y1)f2m(y2) · · · fdm(yd),

(5)

with fim(yi) are the marginal densities.
Let (i) = (i1, . . . , id-1) be the dependency parameters of copulae starting with the lowest up to the highest level connected a fixed state xt = i and the fi(.). The multistage maximum likelihood estimator s^(i), ^(i) solves the system

L1 i1

,

.

.

.

,

Ld-1 id-1

= 0,

T

where Lj =

witlij(Yt), for j = 1, . . . , d - 1,

t=1

lij(Yt) = log c {F^mm(ytm, m)}m{1,...,d}; s(j), {i } =1,...,d-1

f^mm(ytm, m)

m{1,...,d}

for j = 1, . . . , d - 1, t = 1, . . . , T.

(6)

wdmehanersrgieitnieFa^slmmfc^(mmd·)(f·i)Fs mamar(ne·)eessattniimdmaaiftteoedrsta(imecictaohtreedrdinnmgolanyrpgtaoirnatshmaeercte.rdipc.af.orsar,mapneadtrraiwmcaiteltisrtihtceh,nedFwe^pmemei(gn·h)dti=nagsFsoommnc(i·at,ht^eemdd)w.aittMah)asortgfaittnehaeil and time t, see (17). Chen and Fan (2006) and Okhrin et al. (2009b) provide asymptotic behavior
of the estimates.

2.2 Likelihood estimation
For the estimation of the HMM HAC model, we adopt the EM algorithm, Dempster, Laird and Rubin (1997). In the context of HMM, the EM algorithm is also known as the Baum-Welch algorithm. Let us recall the description in the setting of HMM on HAC.
6

Recall the definition of a Markov chain:

P(X0 = i) = i, P(Xt = j|Xt-1 = i) = pij
= P(Xt = j|Xt-1 = i, Xt-2 = xt-2, . . . , X1 = x1, X0 = x0), i, j = 1, . . . , M

(7) (8)

In addition, at time t, given Xt = i, the distribution of Yt is fixed. Namely, the following holds:

P(Xt|X1:(t-1), Y1:(t-1)) = P(Xt|Xt-1) P(Yt|Y1:(t-1), X(1:t)) = P(Yt|Xt),

(9) (10)

where Y1:(t-1) stands for {Y1, . . . , Yt-1}, t < T .
Recall the full likelihood pT (y1:T ; x1:T ; v × ) in (2) and the partial likelihood pT (y1, . . . , yT ; v × ) in (3), and the log likelihood :

MM T

log{pT (y1, . . . , yT ; v × )} = log{ · · ·

x0 pxt-1xt fxt (yt; s(xt), (xt), s(xt))}

x0=1 xn=1

t=1

(11)

The EM algorithm suggests to estimate a sequence of parameters g(i) d=ef (P(i), s(i), (i)) (for the ith
iteration) by iterative maximization of Q(g; g(i)) with Q(g; g(i)) d=ef Eg(i)(log pT (Y1:T ; X1:T ; v ×)|Y ), (Y stands for Y1:T ), namely, one conducts the following two steps:

· (a) E-step : compute Q(g; g(i)),
· (b) M-step : choose the update parameters g(i+1) = arg maxgQ(g; g(i)).
The essence of the EM algorithm is that Q(g; g(i)) can be used as a surrogate for log pT (y1, . . . , yT ;1 , . . . , xT ; ), see Cappé, Moulines and Rydén (2005).

7

In our setting, we may write Q(g; g(i)) as :

M

Q(g; g(i)) =

E g(i)[log{1{X0 = i}ifi(y0)}|Y ]

i=1

T MM

+ E g(i)[log{1{Xt = j}1{Xt-1 = i}pijfj(yt)}|Y ]

t=1 i=1 j=1

(12)

M
= E g(i)[1{X0 = i} log{ifi(y0)}|Y ]
i=1 T MM
+ E g(i)[1{Xt = j}1{Xt-1 = i} log{pij}|Y ]
t=1 i=1 j=1

(13)

TM

+ E g(i)[1{Xt = i} log fi(yt)|Y ]
t=1 i=1

(14)

M T MM

= Pg(i)(X0 = i|Y ) log{ifi(y0)} +

Pg(i)(Xt-1 = i, Xt = j|Y ) log{pij}

i=1 t=1 i=1 j=1

TM
+ Pg(i)(Xt = i|Y ) log fi(yt),
t=1 i=1

(15)

where fi(·) is as in (5) and margins may be estimated nonparametrically as

F^dm(x) = (T +1)-1

T i=1

1(Xi



x).

The

E-step,

in

which

Pg(i) (Xt

=

i|Y

), Pg(i) (Xt-1

=

i, Xt

=

j|Y

)

are evaluated, is carried out by forward-backward algorithm shown in the appendix, and the M -

step is explicit in pijs and is. Recall fi(·) is defined from last section as c{F1m(y1), F2m(y2), . . . , Fdm(yd), s(i), (i)}f1m(y1)f2m(y2) · · · fdm(yd). Adding constraints to (15) yields:

MM
L(g, ; g ) = Q(g; g ) + i(1 - pij)
i=1 j=1

(16)

For the M -step, we need to take the first order partial derivative, and plug into the (16). So dependency parameters  and structure parameters s needs to be estimated iteratively, for (i) :

L(g, ; g ) ij

=

T t=1

P(Xt

=

i|Y ) log fi(yt)/ij,

(17)

where, j = 1, . . . , d - 1. To simplify the procedure, we adopt the HAC estimation method (6) with weights in terms of wit d=ef P(Xt = i|Y ). To reduce the number of parameters to be estimated, we may fix i, i = 1, . . . , M as it influences only the first observation Xo which may be consider also as given and fixed. The estimation of the transition probabilities pij follows:

L(g, ; g ) pij

=

T t=1

P(Xt-1

= i, Xt pij

=

j|Y

)

-

i

L(g, ; g ) i

=

M
1 - pij.
j=1

8

(18) (19)

Equating expression in (18) and (19) yields:

p^i,j =

n t=1

P(Xt-1

=

i,

Xt

=

j|Y

)

n t=1

M j=1

P(Xt-1

=

i,

Xt

=

j|Y

)

(20)

3 Theoretical Results

Assumptions

A.1 {Xt} is stationary and irreducible
A.2 The family of mixture of at most M elements {f (y, j, sj) : j  , sj  S} is identifiable w.r.t. the parameters and structures:

MM

MM

jf (y, j, sj) = jf (y, j, sj)a.e. =  j j,s(j) = jj,sj ,

j=1 j=1

j=1 j=1

(21)

Define j,sj as the distribution function for a point mass in  × S, and it only make sense to say j = j when sj = sj. The property of identifiability is nothing else as the construction of the finite mixture model. For more details on mixture models we refer to McLanchlan and Peel (2000). As copula is a special form of the multivariate distribution, similar techniques may be applied to get identifiability also in the case of copulae. The family of copula mixtures has been thoroughly investigated in Caia, Chen, Fan and Wang (2006) during developing the estimation techniques. In that general case one should be careful as the general copula class is very wide and its mixture identification may cause some problems because of different densities forms. Construction of the HAC itself narrows the class. Imposing same generator functions on all levels of the HAC we restrict the family to the vector of parameters and the tree structure. Some discussion on this can been found in Okhrin et al. (2009b). Our numerical preliminary analysis shows that HAC fulfills identifiability property for all used in the study structures and parameters. To be more sure we assume throughout the paper that the copula model is identifiable.
A.3 {Xt}Tt=1 is a time homogeneous Markov chain that is ergodic A.4 E{| log fi(y, (i), s(i))|} < , for i = 1, . . . , M , s  S.
A.5 For every   , and any particular structure considered s  S,

E[ sup {fi(Y1,  , s)}+] < ,
 - <

for some  > 0. Define ^(i), s^(i) as ^(i)(v^ × ^) and s^(i)(v^ × ^) with (v^ × ^) as the point over the whole parameter space V ×  where p(y1:T ; v × ) achieve the maximum value.
It is known that HMM is not itself identifiable as with the permutation of states pT (y1:T ;v×) would take the same value. We assume (j)s and s(j)s are distinct in the sense that: for any s(i) = s(j), i = j we have (i) = (j).

Theorem 3.1 Assume A.1- A.5, and {Yt}tT=1 are i.i.d and generated from HAC HMM model with parameters {si , i, , [pij]i,j}. The parameter ^(i) satisfies:

lim P(^(i) = (i)) = 1, i, 1, . . . , M
n

(22)

9

given the selected structure s^(1), s^(2), . . . , s^(M).
Moreover, Theorem 3.2 Under A.1- A.5, we find the corresponding structure:
lim P(s^(i) = s(i)) = 1, i.
n
For the proof we refer to the appendix.

(23)

4 Simulation
The estimation performance of HMMHAC is evaluated in this section, Subsection I considers four states with very disjoined copulae parameters, while subsection II considers three states realistically calibrated from exchange rates data. We show that our algorithm converges after a few iterations with moderate estimation errors. Throughout the simulation study, we keep the marginal distribution fixed.

4.1 Simulation I

In this setup, a three dimensional generating process has fixed marginal distributions: Yt1  N(0, 1), Yt2  t(3), Yt3  N(0, 3). The dependence structure is modeled through HAC with Gumbel generators, and four different dependency parameters and structures correspond to four states
(M = 4).

C{u3, C(u1, u2; 1 = 4.00); 2 = 1.5} C{u1, C(u2, u3; 1 = 10.0); 2 = 4.0} C{u2, C(u1, u3; 1 = 30.0); 2 = 10.0} C{u1, C(u2, u3; 1 = 40.0); 2 = 20.0}

As can be seen, we consider quite different state parameters, which helps to easily visualize dependency states. The transition probability matrix is given by:

 0.985

P

=

{pij }i,j

=

  

0.005 0.005

0.005

0.001 0.990 0.005 0.004

0.003 0.003 0.991 0.003

0.006 

0.003 

0.001

 

0.990

of sample size T = 2000. With  = (0.25, 0.25, 0.25, 0.25) . Note that we set the diagonal elements of P close 1, since it is realistic to assume the states stay the same with a high probability. Figure 4 represents underlying states, and marginal plot of the generated three dimensional time series. A state switching pattern is not evident from the marginal plots. Figure 5 however clearly displays the switching of dependency patterns. The black, red, green, blue dots corresponding to the observations from different states.

10

-10 -5 0 5 10 -4 -2 0 2

-10 0 10 1.0 2.0 3.0 4.0

0 500

1500

0 500

1500

-30

0 500

1500

0 500

1500

Figure 4: The underlying sequence xt (upper left panel), marginal plots of (yt1, yt2, yt3).

Figure 6 displays the first 7 iterations a (The parameters stay constant after). Since starting values play an important role, a moving window estimation is proposed to decide the initial parameters. The blue and the red dotted line show respectively how the estimators behave with the initial values close to the true (red) and initial values obtained from our algorithm (blue). The upper panel of Figure 6 shows the number of wrongly estimated states at each iteration; the middle panel represents the (L1) difference of the true transition matrix from the estimated ones; the lower panel is the sum of estimated parameter errors of the four states with the correctly estimated states. One can see that our choice of initial values can perform as good as the true one.
4.2 Simulation II
Let us consider now a Monte Carlo setup where the setting employs parameters calibrated from data, see application I. The three states with M = 3 are taken as follows:
C{u1, C(u2, u3; 1 = 1.3); 2 = 1.05} C{u2, C(u3, u1; 1 = 2.0); 2 = 1.35} C{u3, C(u1, u2; 1 = 4.5); 2 = 2.85},
the transition matrix is chosen as: 0.72 0.15 0.13
P = 0.23 0.64 0.13 0.03 0.02 0.95
11

-10 0 5

-10 0 5

-10 0 5

-6 -4 -2 0 2 4 6
-6 -4 -2 0 2 4 6
-6 -4 -2 0 2 4 6 Figure 5: Snapshots of pairwise scatter plots of dependency structures (t = 500, . . . , 1000), the 1st against 2nd (upper), the 2nd against 3rd (middle), and the 1st against 3rd (lower).
12

Figure 6: The convergence of states (upper panel), transition matrix (middle panel), parameters (lower panel). Estimation starts from near true value (red); starts from values attained by our proposal (blue)
13

Figure 7: The convergence of states (upper panel), transition matrix (middle panel), parameters (lower panel). Estimation starts from near true value (red); starts from values attained by our proposal (blue)
sample size T = 2000. The iteration procedure stops after 12 steps. Figure 7 presents respectively the deviation of estimated states, transition matrix, and parameters from their true value . The estimation error is presented in the same fashion as Figure 6. To judge the estimation quality, a histogram of the estimation error from 100 samples is presented in Figure 8. It can be seen that on average only %15 of the states can not be correctly estimated.
5 Applications
To see how HMM HAC performs on a real data set, applications on financial and rainfall data are offered. A good model for the dynamics of exchange rates give insights into exogenous economic conditions, like the business cycle. It is also helpful for portfolio risk management and decisions on asset allocation. We demonstrate the forecast performance of the proposed technique by estimating VaR of the portfolio and compare it with multivariate Garch models like DCC, BEKK, etc. The backtesting results show that VaR calculated from HMMHAC performs significantly better. The second application is on modeling rainfall process. HMM is a conventional model for rainfall data, however, bringing HMM and HAC together for modeling the multivariate rainfall process is
14

Figure 8: The error of misidentification of states by 100 samples
totally new in our work. We illustrate the estimation procedure and evaluate its performance by checking how far the model is from the reality.

5.1 Application I

5.1.1 Data

The data set consists of the daily values for the exchange rates JPY/EUR, GBP/EUR and USD/EUR. The covered period is [4.1.1999; 14.8.2009], resulting in 2771 observations, Härdle et al. (2011).
To eliminate intertemporal conditional heteroscedasticity we fit to each marginal time series of log-returns a univariate GARCH(1,1) process

Yj,t = µj,t + j,tj,t with j2,t = j + j j2,t-1 + j (Yj,t-1 - µj,t-1)2

(24)

and  > 0, j  0, j  0, j + j < 1.
The residuals exhibit the typical behavior: they are not normally distributed, which motivates nonparametric estimation of the margins. From the results of the Box-Ljung test, whose p-values are 0.73, 0.01 and 0.87 for JPY/EUR, GBP/EUR and USD/EUR, we conclude that the autocorrelation of the residuals is strongly significant only for GBP/EUR rate. After this intertemporal correction we work only with the residuals.
The dependency variation is measured by Kendall and Pearson's correlation coefficients: Figure 9 shows the variation of both coefficients calculated in a rolling window of width r = 250. Their dynamic behavior is similar, but not identical. This motivates once more a time varying copula based model.

15

Pearson's corelation 0.0 0.2 0.4 0.6 0.8
Kendall's corelation 0.0 0.1 0.2 0.3 0.4 0.5 0.6

1999

2001

2003

2005

2007

2009

1999

2001

2003

2005

2007

2009

Figure 9: Rolling window estimators of Pearson's (left) and Kendall's (right) correlation coefficients between the GARCH(1,1) residuals of exchange rates: JPY and USD (solid line), JPY and GBP (dashed line), GBP and USD (dotted line). The width of the rolling window is set to 250 observations.

5.1.2 Fitting an HMM model

Figure 1, 10, and 11 summarize the analysis using three methods: moving window, LCP, HMMHAC. LCP uses moving windows, with varying sizes. To be more specific, LCP is a multiple testing scaling technique which determines a local homogeneous window at each time point Härdle et al. (2011). In contrast to LCP, HMMHAC is based on a global modeling concept rather than a local one. One observes, a relative smooth changes of parameters, see Figure 1 and 10 . HMMHAC is as flexible as LCP as can be seen from Figure 1, 10, and 11, since the structure estimated taken also three values and confirms with the variations of structures estimated from LCP. Moreover, the moving window analysis or LCP can serve as guidelines for choosing the initial values for our HMMHAC. Figure 12 displays the number of states for HMMHAC for rolling windows with a length of 500 observations.

A VaR estimation example is to show the good performance of HMMHAC. We generate N = 104

pathes with T = 2219 observations, and |W | = 1000 combinations of different portfolios, where

W = {(1/3, 1/3, 1/3) [w = (w1, w2, w3)]}, with wi = wi/

3 i=1

wi,

wi

 U (0, 1).

The

Profit

Loss

(P&L) function of a weighted portfolio based on assets ytd is Lt+1 d=ef

3 d=1

wi(yt+1d

-

ytd),

with

weights w = (w1, w2, w3)  W . The VaR of a particular portfolio at level 0 <  < 1 is defined as

V aR() d=ef FL-1(), where the ^w is estimated as a relative fraction of violations, see Table 1:

T
^w d=ef T -1 I{Lt < V aRt()},
t=1

and the distance between ^w and  is as:

ew d=ef (^w - )/.

If the portfolio distribution is i.i.d., and a well calibrated model is properly mimicking the true
underlying asset process, ^w is close to its nominal level . The performance is measured through an average of w over all |W | portfolios see Table 1.

16

structure
(JPY.(GBP.USD))


0.0 0.2 0.4 0.6 0.8

q

1999

2000

2001

2002

2003

2004

2005

2006

2007

2008

Figure 10: Rolling window for Exchange Rates: structure (upper) and dependency parameters (lower, 1 and 2) for Gumbel HAC. w = 250.

0.0 0.2 0.4 0.6 0.8 (V1.(V2.V3)) (V1.(V2.V3)) ((V1.V2).V3)

structure

q



1999

2000

2001

2002

2003

2004

2005

2006

2007

2008

Figure 11: HMM for Exchange Rates: structure (upper) and dependency parameters (lower, 1 and 2) for Gumbel HAC.

17

number of states 1.0 1.5 2.0 2.5 3.0

qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq qqqqqqqqqqqqqqqqqqqqq qqqqqqqqqqqqqqqqqqqqq qqqqqqqqqqqqqqqqqqqqq

qqqqqqqqqqqqq q qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq

qqqqqqqqqqqqqq qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq qqqqqqqqqqqq qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq

qq q

qqqqqq qqqqqqqqqqqqqqqqq qq

1999 2000 2001 2002 2003 2004 2005 2006 2007

Figure 12: Plot of estimated number of states

HMM, RGum
HMM, Gum
Rolwin, RGum
Rolwin, Gum LCP, m0 = 40 LCP, m0 = 20 DCC

Window\ 500 500 250 250 468 235 500

0.1 0.0980 0.0981 0.1037 0.1043 0.0973 0.1034 0.0743

0.05 0.0507 0.0512 0.0529 0.0539 0.0520 0.0537 0.0393

0.01 0.0128 0.0135 0.0151 0.0162 0.0146 0.0169 0.0163

Table 1: VaR backtesting results, ¯^, where "Gum" denotes the Gumbel copula and "RGum" the rotated Gumbel one.

We considered four main models: HMMHAC for 500 observation windows for Gumbel and rotated

Gumbel ; multiple rolling window with 250 observations windows; LCP with m0 = 20 and m0 = 40 with Gumbel Copulae; DCC based on 500 observation windows. For all the models we made an

out of sample forecast. To better evaluate the performance we calculated the average and SD of

eW as.

AW

=

1 |W |

ew,

wW

DW =

1/2

1 |W |

(ew - AW )2

.

wW

Table 1 and 2 show backtesting performance for the described models. One concludes that HMMHAC performs better than the concurring moving window, LCP, DCC, as Aw and Dw are typically smaller.

5.2 Application II
Our goal is to propose a realistic model for rainfall, which can be used to forecast or simulate rainfall. The difficulty for modeling precipitation data is the nonzero point mass at zero of the rainfall distribution. Another difficulties arises when one incorporates spatial relationships, see

18

HMM, RGum
HMM, Gum
Rolwin, RGum
Rolwin, Gum LCP, m0 = 40 LCP, m0 = 20 DCC

Window\ 500 500 250 250 468 235 500

0.1 -0.0204 (0.013) -0.0191 (0.008) 0.0375 (0.009) 0.0426 (0.009) -0.0270 (0.010) 0.0344 (0.009) -0.2573 (0.015)

0.05 0.0147 (0.012) 0.0233 (0.018) 0.0576 (0.012) 0.0772 (0.030) 0.0391 (0.018) 0.0735 (0.026) -0.2140 (0.015)

0.01 0.2827 (0.064) 0.3521 (0.029) 0.5076 (0.074) 0.6210 (0.043) 0.4553 (0.037) 0.6888 (0.050) 0.6346 (0.091)

Table 2: Robustness relative to AW (DW )

Ailliot, Thompson and Thomson (2009) for an HMM application. However, Ailliot et al. (2009) only consider Gaussian dependency among locations, and the method is computationally expensive.

We extend Ailliot et al. (2009) to a copula framework. Different from application I, the marginal distribution here will be varying over states. We propose two methods in modeling marginal distributions, one is considering ytk to be censored normal distributions, with the following equation:

fkm{ytk} =

1 - pkxt

ytk = 0

pkxt{(ytk - µxt(k))/(xt(k))}/xt(k) ytk > 0

with k = 1, · · · , d as the location, (·) as the standard normal density, pxkt as the rainfall occurrence probability for the location k and state xt, and µxt(k), xt(k) being mean and standard deviation parameters at time t, for location k.

A second proposal for the marginal distributions are gamma distributions:

fkm{ytk} =

1 - pkxt

ytk = 0

pkxt{ytk; (k)xt, (k)xt} ytk > 0

where again the (k)xt, (k)xt are the shape and scale parameter for state xt and location k. We take the joint distribution function to be a truncated version of a continuous copulae function, with the copulae density cd(·) denoted through:

cd(µ, ) =

cc(µ, )

, ytk > 0, k

Cc(µ, )/µk1 . . . µkB , ki  {ytki > 0}, i  1, . . . , E

(25)

where E is denoted as the number of wet places among the d locations, the Cc(·) as the continuous copulae function, and cc(.) as the continuous copulae density. Our formulation is simpler than Ailliot et al. (2009) since the copulae has closed form c.d.f., so we do not need additional effort to calculate integration. Representation in (25) is however more general, as we consider copulae to capture the dependency.
Assume that the daily rainfall observations from the same month are yearly independent realizations of a common underlying hidden Markov model, whose states represents different weather

19

Figure 13: Map of Guangxi, Guangdong, Fujian in China

types. So the likelihood is different. As an example, we take every June's daily rainfall.

log pT (y1:T , x1:T ; v × )

M T MM

= log{ 1{x0 = i}ifi(y0)} + log{

1{xt = j}1{xt-1 = i}pijfj(yt)}

i=1 t=1 i=1 j=1

M T MM

= 1{x0 = i} log{ifi(y0)} +

1{xt = j}1{xt-1 = i} log{pijfj(yt)}

i=1 t=1 i=1 j=1

MM

+ {1{xt = i}{log(i)} - 1{xt = j}1{xt-1 = i} log(pij)}.

tB i=1

j=1

where B is the set of days as the first day in June for each year. We use here 50 years of rainfall data from three locations in China, Guangxi, Guangdong, Fujian (Figure 13). The graphical correlation can naturally be captured by the fitting of different copulae state parameter.

Table 3 presents with a truncated Gumbel the estimated three states, the corresponding dif-
ferent marginal distributions and copula parameters, with estimated initial probability: ^Xt = (0.298, 0.660, 0.042) and estimated transition probability matrix:

 0.590 0.321 0.298   0.188 0.742 0.660  .
0.329 0.271 0.042

In our data situation, gamma distributions fit better as marginal. The states filtered out represents different weather types. The third states is the most humid state with a high rainfall occurrence probabilities, while the second states are drier, and the first are the driest. From the parameters of the gamma distributions, one sees the variance increases from the first to the third states, which indicates a higher chance for heavy rainfall for the humid states.
To validate our model, 1000 sample of artificial time series of 1500 observations are generated from the fitted model and compared with the original data. Table 4 presents the true Pearson

20

Xt Shape

Scale

Occur Prob

1 (0.442,0.429,0.552) (139.33,116.70,169.66) (0.252,0.256,0.439)

2 (0.671,0.618,0.561) (273.83,253.25,427.46) (0.806,0.786,0.683)

3 (0.636,1.125,0.774) (381.09,264.83,514.08) (0.667,1.000,0.944)

Table 3: Rainfall occurrence probability and shape, scale parameters estimated from HMM (data 1957 - 2006) .

Location
1-2 2-3 1-3

True 0.308 0.261 0.203

Corr(Yt,1, Yt,2) 0.300 (0.235, 0.373) 0.411 (0.256, 0.586) 0.130 (0.058, 0.215)

Table 4: True correlations, simulated averaged correlations from 1000 samples their 5%confidence intervals. 1 Fujian, 2 Guangdong, 3 Guangxi

correlation compared with the estimated ones from the generated time series. The 5% confidence intervals of the estimators cover the true correlation, which implies that the simulated rainfall can describe the real correlation of the data quite well. Figure 14 shows a marginal plot of the log survival function derived from the empirical cdf of the real data and generated data. The log survival function is a transformation of the marginal cdf F m(ytk):

log{1 - F m(ytk)}.

(26)

Again we show that the 95% confidence interval can cover the true curve fairly well.
Figure 15 are the autocorrelation and cross autocorrelation of the real data and the generated time series. Unfortunately, our generated time series do not show the similar auto correlation and cross auto correlation. Since there is usually more than one significant lag of auto correlation or cross correlation, but the simulated time series mostly only have one lag.

6 Conclusion
In this project, we propose a dynamic model for multivariate time series with non Gaussian dependency. The idea has an easy extension to HMM for general Copula models, and implies a rich class further work on dynamic models for dependency structures. This method is helpful in studying the financial contagion at extreme level over time, and naturally it can help to derive the conditional risk measures, such as CoVaR. As we have shown, dynamics copula models are good enough for mimicking financial markets as well as nature.

21

-8 -4

0 20 40 60 80 100

-8 -4

0 20 40 60 80 100

-8 -4

0 20 40 60 80 100
Figure 14: Log-survivor-function (red) and 95% prediction intervals (blue) of the simulated distribution for the fitted model with sample log-survivor-function superimposed (black)

7 Appendix

7.1 Proof of Theorem 3.1, 3.2

Recall the associated parameter space being V × , where V consists of a set of discrete finite
elements and  is associated with parameters , [pij]i,j. Defined s and  is associated with the point v0 × 0 in the parameter space, consider the following definitions:

qT (Y1:T

;

v0

×

0)

d=ef

max
j1,...,M

pT (y1:T |x1

=

j,

;

v0

×

0)

(27)

H(v0 × 0) d=ef E v0×0{- log p(Y0|Y-1, Y-2, . . . ; v0 × 0)}, where Y-1, . . . , Y-T are finite number of past values of the process.

H(v0 × 0, v × ) d=ef E v0×0{log pT (Y1:T ; v × )}

Theorem 7.1 (Leroux (1992)) Under A.1- A.5

lim
T 

T

-1

E

v0×0 {log

pT

(Y1:T

;

v0

×

0)}

=

-H(v0 × 0))

lim
T 

T

-1

log

pT

(Y1:T

;

v0

×

0))

=

-H(v0 × 0)),

with probability 1, under v0 × 0, and

lim
T 

T

-1

E

v0×0 {log

pT

(Y1:T

;

v

×

)}

=

H(v0 × 0, v × )

lim
T 

T

-1pT

(Y1:T

;

v

×

)

=

H(v0 × 0, v × ),

22

with probability 1, under v0 × 0.

To prove the consistency of our estimated parameter, we try to restate the theorems of consistency in Leroux (1992) for our parameter space. One needs to show that for V c × c which does not contain any point of the equivalent class of v0 × 0 (equivalent class of v0 × 0 is defined in Leroux
(1992)), we have with probability 1

lim
T 

max
vV c

log

sup
c

pT

(Y1:T

;

v

×

)

-

log

pT

(Y1:T

;

v0

×

0)



-,

(28)

which is implied from, for any closed subset C of c, exists a sequence of open subsets of Oh with h = 1, . . . , H with C  hH=1Oh, such that

lim
T 

max
vV c

max h

log

sup
Oh

pT

(Y1:T

;

v

×

)

-

log

pT

(Y1:T

;

v0

×

0)



-.

(29)

To prove (29), we have the modified definition:

H (v0

×

0, v

×

; Oh)

d=ef

lim log max sup T vV c  0

qT (Y1:T , v

×



)/T .

(30)

It can be derived that

H(v0 × 0, v × ) < H(v0 × 0, v0 × 0),

(31)

for v ×  and v0 × 0 does not lie in the same equivalent class. (31) is a consequence of the identifiability condition A.2, and it would lead to:  > 0, T and O, such that,

E log sup qT(v ×  )/T < E log qT(v × )/T +  < H(v0 × 0, v0 × 0) - ,  O

with

v d=ef argmaxvV cH(v0 × 0, v ×  , O).

Also because maxvV c log sup O pT (Y1:T , v ×  )/T and maxvV c log sup O qT (Y1:T , v ×  )/T have the same limit value, there exists a constant  > 0,

lim max log sup

T  vV c

 Oh

pT (y1:T , v

×



)/T

=

H (v0

×

0, v

×

; Oh)



H (v0

×

0, v0

×

0)

-

.

Then (29) follows.

7.2 Estimation and Algorithm
If original data has GARCH dependence structure, we deGARCH by taking the residuals of the GARCH model. The estimation procedure start with initializing the formal unknown parameters, specifically, we fix M and initialize parameters (0) = {s((i0)), ((0i)), (0), P(0)} by some preliminary analysis, typically a moving window analysis. 1) We estimate x1, x2, . . . , xT (the realization of the underlying Markov chain) which maximize P(Y |). To achieve this goal, we use the Viterbi Algorithm, see Rabiner (1989):
23

· Initialization : 1(i) = ifi(y1), 1  i  M , 1(i) = 0. However in the practice it is better to consider log 1(i) as in this case convergence is faster.
· Recursion :

t(i)

=

max
1jM

{t-1

(i)pij

}fi(yt),

2



t



T,

1



j



M,

t(j)

=

arg

max
1iM

t-1(i)pij

(32)

· Termination :

p

=

max
1iM

{T

(i)}

xT

=

arg

max
1iM

{T

(i)}

· Path (State Sequence) back tracking : xt = t+1(qt+1) , t = T - 1, T - 2, . . . , 1

We propose to estimate the marginal distribution function of the realizations of Yt nonparametrically, namely,
T
F^i(s) = (T + 1)-1 1{yti  s}
t=1
2) After estimating the optimal sequence x from 1), the next step would be to update parameters (0). Define :
t(i) = P(y1, y2, . . . , yt, xt = i|(0)) t(i) = P(yt+1, yt+2, . . . , T |xt = i, (0))
They can be estimated efficiently by the following algorithm:

· 1(i) = ifi(y), 1  i  M

· Induction : t+1(j) =

M i=1

t(i)pij

fj

(yt+1).

Following Rabiner (1989) we use a computa-

tionally more efficient by setting t+1(j) =

M i=1

t

(i)pij

fj

(yt+1)/

M i=1

t(i)

· Termination: P(Y |) =

M i=1

t(i)

· T (i) = 1, 1  i  M .

· t(i) =

M j=1

pij

fj

(yt+1

)t+1(j

),

t

=

T

-

1, T

-

2, . . . , 1,

1



i



M,

similarly

to

the

case

with , we define t(i) =

N j=1

pij

fj

(yt+1

)t+1

(j

)/

M j=1

t+1

(j

)

Updates of (0) and P(0), define:

t(i, j) d=ef P(xt = i, xt+1 = j|Y, ) rt(i) d=ef P(xt = i|Y, ),

24

which can be estimated by:

t(i, j) =

t (i)pij fj (yt+1 )t+1 (j )

N i=1

N j=1

t(i)pij

fj

(yt+1)t+1(j

)

N

rt(j) =

t(i, j).

j=1

Therefore, update equations for the step k are:

i,(k) = ri(k-1)(i)

pij,(k) =

T -1 t=1

t(k-1)(i,

j)

T -1 t=1

rt(k-1)(i)

Given the updates of i,(k), and pij,(k), the coefficients of copulae  can be reestimated by (20) with the weights rt for each observation. In this case structure s and parameters  are estimated jointly.

References
Ailliot, P., Thompson, C. and Thomson, P. (2009). Space-time modeling of precipitation by using a hidden markov model and censored gaussian distributions, Journal of the Royal Statistical Society 58: 405­426.
Bickel, P. J., Ritov, Y. and Rydén, T. (1998). Asymptotic normality of the maximum-likelihood estimator for general hidden markov models, Annals of Statistics 26(4): 1614­1635.
Caia, Z., Chen, X., Fan, Y. and Wang, X. (2006). Selection of copulas with applications in finance, Working Paper . available at http://www.economics.smu.edu.sg/femes/2008/papers/219.pdf.
Cappé, O., Moulines, E. and Rydén, T. (2005). Inference in Hidden Markov Models, Springer Verlag.
Chen, X. and Fan, Y. (2005). Estimation of copula-based semiparametric time series models, Journal of Econometrics 130(2): 307­335.
Chen, X. and Fan, Y. (2006). Estimation and model selection of semiparametric copula-based multivariate dynamic models under copula misspesification, Journal of Econometrics 135: 125­ 154.
Dempster, A., Laird, N. and Rubin, D. (1997). Maximum likelihood from incomplete data via the em algorithm (with discussion), J. Roy. Statistical Society B 39: 1­38.
Fuh, C.-D. (2003). SPRT and CUSUM in hidden Markov Models, Ann. Statist. 31(3): 942­977.
Giacomini, E., Härdle, W. K. and Spokoiny, V. (2009). Inhomogeneous dependence modeling with time-varying copulae, Journal of Business and Economic Statistics 27(2): 224­234.
Härdle, W. K., Okhrin, O. and Okhrin, Y. (2011). Time varying hierarchical archimedean copulae, Submitted for publication .
25

Joe, H. (1996). Families of m-variate distributions with given margins and m(m - 1)/2 bivariate dependence parameters, in L. Rüschendorf, B. Schweizer and M. Taylor (eds), Distribution with fixed marginals and related topics, IMS Lecture Notes ­ Monograph Series, Institute of Mathematical Statistics.
Joe, H. (1997). Multivariate Models and Dependence Concepts, Chapman & Hall, London. Leroux, B. G. (1992). Maximum-likelihood estimation for hidden markov models, Stochastic Pro-
cesses and their Applications 40: 127­143. McLanchlan, G. and Peel, D. (2000). Finite Mixture Models, Wiley. McNeil, A. J. and Neslehová, J. (2009). Multivariate Archimedean copulas, d-monotone functions
and l1 norm symmetric distributions, Annals of Statistics 37(5b): 3059­3097. Nelsen, R. B. (2006). An Introduction to Copulas, Springer Verlag, New York. Okhrin, O., Okhrin, Y. and Schmid, W. (2009a). On the structure and estimation of hierarchical
archimedean copulas, Under Revision of Journal of Econometrics . Okhrin, O., Okhrin, Y. and Schmid, W. (2009b). Properties of Hierarchical Archimedean Copulas,
SFB 649 Discussion Paper 2009-014, Sonderforschungsbereich 649, Humboldt-Universität zu Berlin, Germany. available at http://sfb649.wiwi.hu-berlin.de/papers/pdf/SFB649DP2009014.pdf. Patton, A. J. (2004). On the out-of-sample importance of skewness and asymmetric dependence for asset allocation, Journal of Financial Econometrics 2: 130­168. Rabiner, L. R. (1989). A tutorial on Hidden Markov Models and selected applications in speech recognition, Proceedings of IEEE 77(2). Rodriguez, J. C. (2007). Measuring financial contagion: a copula approach, Journal of Empirical Finance 14: 401­423. Savu, C. and Trede, M. (2006). Hierarchical Archimedean copulas, Discussion paper, University of Muenster. Sklar, A. (1959). Fonctions dé repartition á n dimension et leurs marges, Publ. Inst. Stat. Univ. Paris 8: 299­231. Whelan, N. (2004). Sampling from Archimedean copulas, Quantitative Finance 4: 339­352.
26

(a) the simulated rainfall time series.
(b) the original rainfall time series.
Figure 15: Autocorrelations and cross correlations of the simulated rainfall and original time series 27

SFB 649 Discussion Paper Series 2012
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "HMM in dynamic HAC models" by Wolfgang Karl Härdle, Ostap Okhrin and Weining Wang, January 2012.
SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

