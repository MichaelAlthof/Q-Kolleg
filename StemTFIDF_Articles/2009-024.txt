BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2009-024
Incorporating the Dynamics of Leverage into Default Prediction
Gunter Löffler* Alina Maurer*
* Universität Ulm, Germany
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universität zu Berlin Spandauer Straße 1, D-10178 Berlin

Incorporating the Dynamics of Leverage into Default Prediction

Gunter L¨offler

Alina Maurer

This Version: April 2009

Abstract: A firm's current leverage ratio is one of the core characteristics of credit quality used in statistical default prediction models. Based on the capital structure literature, which shows that leverage is mean-reverting to a target leverage, we forecast future leverage ratios and include them in the set of default risk drivers. The analysis is done with a discrete duration model. Out-of-sample analysis of default events two to five years ahead reveals that the discriminating power of the duration model increases substantially when leverage forecasts are included. We further document that credit ratings contain information beyond the one contained in standard variables but that this information is unrelated to forecasts of leverage ratios.
Keywords: default prediction, discrete duration model, leverage targeting, mean reversion, credit rating
JEL Classification: G32, G33

Acknowledgements: This research was supported by the Deutsche Forschungsgemeinschaft (DFG) through a grant and through the SFB 649 "Economic Risk". We thank Moody's Investors Service for providing rating and default data.
 Ulm University, Institute of Finance, Helmholtzstrasse 18, 89069 Ulm, Germany  Corresponding author. Tel.: +49-731-50-23591; Fax.: +49-731-50-23950; Ulm University, Institute of
Finance, Helmholtzstrasse 18, 89069 Ulm, Germany

1. Introduction
Many observations suggest that firms follow leverage targets. A survey of chief financial officers conducted by Graham and Harvey (2001) reveals that the majority of firms has a target debt-equity ratio. Among others, Fama and French (2002), Leary and Roberts (2005), Flannery and Rangan (2006) and most recently Lemmon et al. (2008) document that empirical leverage ratios are mean-reverting. Estimation is usually based on a partial adjustment model where the optimal capital structure depends on a set of firm characteristics. The results differ regarding the speed of adjustment and the relative importance of targeting behavior, but the finding that firms actively rebalance capital structure in order to close the gap between the current and the targeted leverage appears robust. The results are consistent with the trade-off theory of capital structure in which firms balance the costs and benefits of debt to determine an optimal leverage ratio (Kraus and Litzenberger, 1973). Rival theories include the pecking order theory (Myers, 1984) and the market timing theory (Baker and Wurgler, 2002).
If firms follow leverage targets then future leverage ratios should be predictable. In this paper, we examine whether such predictability can be exploited to improve the accuracy of statistical default prediction models. In such models, future defaults are explained through a set of variables including accounting ratios and stock market information. A variable that measures a firm's current leverage is usually included and found to have significant explanatory power. This suggests the following approach: in a first step, derive forecasts for future leverage ratios from a partial adjustment equation. Then extend a standard default prediction model by a new variable that incorporates these forecasts.
We find that this two-step approach significantly improves prediction accuracy. The added value from incorporating leverage dynamics increases if we extend the default prediction horizon from two to five years. This is consistent with the empirical finding that it takes several years to close the gap between the current and the target leverage ratio.1
Our results should help improve default prediction models, which are essential ingredients to risk management and pricing in many financial institutions. The results also add a new argument to the discussion of the empirical relevance of leverage-targeting behavior. It would be difficult to maintain the interpretation that targeting behavior is relevant if it were irrelevant in a setting such as default prediction where leverage plays a crucial role.
While statistical default prediction models are commonly used in practice, capital market participants also rely heavily on credit ratings issued by agencies such as Fitch, Moody's or Standard & Poor's. According to rating agencies, these ratings have a longterm horizon and are not only based on a firm's current situation but also on projections of its future situation. According to Moody's, for instance, "credit ratings are ordinal measures of through-the-cycle expected loss. As such, while they are certainly based
1 The half-life of deviations from optimal capital structure is approximately five years in Fama and French (2002) and two years in Flannery and Rangan (2006).
1

on the current financial strength of the issuer, they incorporate expectations of future performance as well." (Metz and Cantor, 2006, p.1). It therefore seems interesting to examine whether rating analysts incorporate information about mean-reverting leverage ratios. If we include the current rating as a predictive variable in our default prediction model we find that it is significant but does not affect the significance of the variable that captures leverage dynamics. Thus, while ratings contain valuable information for default prediction, this information is largely unrelated to the leverage predictions that can be derived from the targeting behavior of firms.
Our research combines approaches from two areas: the capital structure literature introduced above and the literature on default prediction. In the latter, a firm's forward default probability is modeled as a function of firm-specific covariates such as leverage, profitability or liquidity. Some studies additionally include industry or economy-wide factors. Most recent contributions employ discrete duration models or, equivalently, multi-period logit models. They include Shumway (2001), Hillegeist et al. (2004) and Campbell et al. (2008). Often, these studies choose a one-year horizon for default prediction but longer horizons are also used, e.g. Campbell et al. (2008).
The pricing implications of mean-reverting leverage ratios are explored in CollinDufresne and Goldstein (2001). The two papers which are closest to ours are Duffie et al. (2007) and Lo et al. (2008). Duffie et al. (2007) use a doubly-stochastic framework where the dynamics of all covariates, including a ratio closely related to leverage (distance to default), is modeled by a vector autoregressive time series. The authors report an improvement of predictive performance, which however cannot directly be ascribed to any of the covariates. In our approach, introducing the dynamics of only one variable (as we do in the two-step dynamic model for leverage) results in a long-term prediction accuracy similar to that reported by Duffie et al. (2007). Lo et al. (2008) incorporate targeting behavior in a structural model for one-year default probabilities, but take model parameters from the capital structure literature. The key difference to our approach is that we estimate target leverage through a set of firm-specific variables as suggested by the literature on capital structure. Unlike in our study, the model of Lo et al. (2008) does not outperform credit ratings.
The rest of the paper is organized as follows. In Section 2 we outline the statistical methodology for default analysis as well as the partial adjustment model and introduce two approaches for incorporating leverage dynamics into default prediction. Section 3 describes the data. Econometric issues relevant for the partial adjustment model are discussed in Section 4. The main results are reported in Section 5. Section 6 examines whether credit ratings incorporate information on mean-reverting leverage ratios. Section 7 concludes.
2. Methodology
We begin with an overview on the discrete duration model. This is followed by a short introduction to the partial adjustment model and its uses for forecasting leverage ratios.
2

2.1. Default Analysis
We use a discrete duration model. At time t, a firm's conditional probability of default within the next year given the firm's current condition and survival until the beginning of year t is expressed by a discrete hazard function h(t):

h(t) = P (Yt,t+1 = 1|Yt-1,t = 0, Xt),
where the vector Xt captures the firm's current condition and the binary variable Ys,t indicates default in the time interval (s, t], i.e.

1 if default occurs in (s, t] Ys,t = 0 else.

As has been pointed out by Shumway (2001), a discrete duration model is equivalent

to a multi-period logit model estimated on panel data if the hazard function is specified

as

h(t)

=

1

+

1 exp(-

-

. Xt)

(1)

In our analysis we adopt the above specification of the hazard function, since it has

widely been used in the literature, e.g. Shumway (2001), Chava and Jarrow (2004), Hillegeist et al. (2004) and Campbell et al. (2008).

For default events multiple periods ahead we consider what we will call discrete multi-

period default probabilities, addressing the question "What is the probability of default

between year t + k and t + k + 1 given today's covariates?" Again this question is only

reasonable for firms that did not default prior to t + k. Discrete multi-period default

probabilities are essentially lagged single-period default probabilities, i.e.

h(t + k) = P (Yt+k,t+k+1 = 1|Yt-1,t+k = 0, Xt)

=

1

+

1 exp(-k

-

. k Xt )

(2)

Hereby we explicitly allow the coefficients to vary with the prediction horizon.
We do not model the probability that a firm will default within the next k (k  2) years: P (Yt,t+k = 1|Yt-1,t = 0, Xt).2 This probability is no longer logistically distributed if discrete default probabilities follow a logistic distribution (cf. Campbell et al. (2008)).
Modeling the baseline hazard as constant over time (k(t) = k, t) is justified by the assumption of duration independence in the data, i.e. the probability of default does not depend on the length of time a firm did exist before default analysis. We test for
duration independence following the procedure described in Beck et al. (1998). For the
sample used in our analysis the likelihood ratio test indicates no duration dependence in the data.3

2 P (Yt,t+k = 1|Yt-1,t = 0, Xt) = 1 -

k-1 j=0

(1

-

h(t

+

j)).

3 Shumway (2001) controls for duration dependence by specifying (t) = ln(age), with age being the

number of years a firm has been listed on the particular stock exchange, and finds this variable

insignificant.

3

2.2. Mean-Reverting Leverage Ratios

The empirical literature on capital structure has widely analyzed the pecking order

theory versus the alternative trade-off model (for an overview see Frank and Goyal

(2007)). Although neither theory can fully explain observed capital structure decisions,

a large amount of studies support the trade-off theory by providing evidence for the

hypothesis that leverage is mean-reverting.

The standard approach is to describe the dynamics of leverage by a partial adjustment

equation:

Lt+1 - Lt = a0 + a1(Lt+1 - Lt) + t+1,

(3)

where Lt denotes the leverage ratio observed at time t and Lt+1 is the targeted leverage ratio for the next period. As implied by the trade-off theory, L is the optimal value
that sets off the benefits of interest tax shields against the costs of financial distress. According to the partial adjustment hypothesis, each year a firm closes a fraction of the
gap between its actual and desired future leverage level (measured by the adjustment
rate a1 in Eq. (3)). Often the adjustment rate is modeled constant over time and firms, representing an average firm's adjustment speed.4
We follow Flannery and Rangan (2006) who model the targeted leverage ratio, which
is not observable, as a linear combination of firm-specific observable covariates Ct, i.e.

Lt+1 = b0 + b1Ct.

(4)

Replacing the targeted leverage ratio in (3) by the assumed relation from (4) and rearranging results in an equation which relates the future leverage ratio to the current leverage and a set of leverage factors:

Lt+1 = c0 + c1Ct + c2Lt + t+1,

(5)

with c0 = a0 + a1b0, c1 = a1b1 and c2 = (1 - a1). For leverage levels multiple periods ahead, we consider the desired leverage ratio in
t + k given today's firm characteristics:

Lt+k = b0,k + b1,kCt. Future leverage ratios can then be estimated through:

(6)

Lt+k = c0,k + c1,kCt + c2,kLt + t+k,

(7)

for each horizon t + k (k  1).

2.3. Incorporating Leverage Dynamics into Default Prediction
The central question of this paper is whether results on the dynamics of capital structure are of benefit for long-term default prediction. Leverage is one of the key determinants
4 We will consider modifications of this assumption in Section 5.3.

4

of default risk and predictive knowledge about leverage should help improve default prediction. We consider two related models in order to analyze this question.
Future leverage ratios are related to the current leverage ratio Lt and a set of leverage factors Ct (cf. Eq. (7)). Consequently, the information on dynamics of leverage can be incorporated into default prediction by extending the vector of covariates in Eq. (2) (our base model) to
Ut = (Xt, Lt, Ct).
We will call this the reduced-form approach. Within an alternative two-step approach we first estimate future leverage ratios. In
particular, for default in (t + k, t + k + 1] we forecast leverage in t + k (k  1). Leverage ratios are by definition restricted to the unit interval. Hence we set all fitted values that are negative or larger than 1 to this theoretical bounds. In the second step, the covariates vector in the base regression model (Eq. (2)) is extended to
Zt+k = (Xt, dL^t+k).
The new variable dL^t+k = (L^t+k -Lt) captures the dynamics of leverage, since it predicts the change from the most recently observed to the estimated future leverage ratio.5 In this sense, we will refer to dL^t+k as to the dynamic variable.
The reduced-form approach nests the two-step approach. The latter imposes the restriction that the covariates vector Ct is weighted according to Eq. (4) as well as the restriction that predicted leverage ratios are bounded by 0 and 1. Imposing restrictions in a regression model automatically leads to a deterioration of the in-sample fit. The out-ofsample performance could be improved through the two-step approach if the restrictions turn out to be correct and thus increase the precision of parameter estimates. We therefore examine both approaches.
The two models differ in ease of interpretation. In the two-step approach the effect of leverage dynamics on creditworthiness is straightforward: a larger difference dL^t+k comes along with a higher future leverage ratio and should therefore increase the probability of default. In the reduced-form approach we have to interpret a set of coefficients and it is difficult to assess the extent to which estimated coefficients are in line with the partial adjustment hypothesis that is the basis of our work.
3. Data and Definition of Variables
We perform our analysis on a sample constructed by merging three sources: accounting information from the annual COMPUSTAT database; market variables from the Center for Research in Security Prices (CRSP) as well as credit rating and default information
5 One could also add L^t+k, the prediction of the leverage ratio. The difference dL^t+k is advantageous, since it contains the same information as L^t+k and is more easily accessible in terms of interpretation. Also, the estimate L^t+k is highly correlated with the current leverage ratio and by considering the difference instead of the absolute value we reduce the problem of multicollinearity. We do not consider dL^t+1, . . . , dL^t+k-1 as additional covariates (which is possible for k  2) because estimated leverage ratios at consecutive points in time are highly correlated.
5

from Moody's Investors Service. All accounting variables are lagged by six months to ensure availability at the start of the prediction horizon, i.e. time t is the fiscal year-end plus six months.
Moody's database covers ratings and default events for corporate bond issuers. The default indicator in our analysis is based on Moody's definition of default that includes missed or delayed payments, bankruptcy and distressed exchange (cf. Hamilton et al. (2006)). Observations for firms with multiple default events are included only if the credit rating prior to a recurrent default has been upgraded to at least "B3".
We restrict our analysis to U.S. companies excluding financial firms (CRSP SIC 60006999) and regulated utilities (CRSP SIC 4000-4999), whose capital decisions are subject to regulatory influence and hence might violate assumptions made in the partial adjustment model. The final sample comprises 17499 firm-years. During the whole observation period (1975 to 2005) a total of 269 default events were recorded.
In the following two subsections we detail the choice and definition of explanatory variables. A specification including COMPUSTAT items and descriptive statistics are provided in Table 5 in the Appendix.
3.1. Covariates for Default Analysis
In the literature there is no consensus on the right choice of covariates to be used for the estimation of default probabilities. Altman (1968) suggests a set of accounting ratios which is modified by Zmijewski (1984) and Ohlson (1980), among others. A more recent analysis by Shumway (2001) concludes that stock market variables (excess stock return, return volatility) improve prediction accuracy when added to accounting ratios.
Although being different in detail, the various accounting ratios can be grouped as proxies for either leverage, profitability, liquidity or coverage; four main characteristics that determine the quality of an obligor. For our analysis, we decided on the definition of each characteristic that shows best explanatory power in terms of significance when compared to alternatives.
Leverage is measured as the ratio of total debt to the market value of total assets (L=TD/MTA), with MTA being the sum of total debt and market capitalization, cf. Campbell et al. (2008). We proxy expected profitability by the ratio of earnings before interest and taxes to total assets (EBIT/TA), as has been suggested by Altman (1968) and Fama and French (2002). In general, more profitable firms are less likely to default. We observe that neither of the alternative measures for liquidity (e.g. working capital to total assets or current assets to current liabilities) is significant. For this reason, we do not include a proxy for liquidity in the analysis. Similar to Blume et al. (1998) we quantify coverage by the ratio of earnings before interest and taxes over interest expenses of the same period (EBIT/XINT). The lower the ratio, the higher the risk that the company will not satisfy its interest expenses and meet its debt obligations.
Accounting ratios are complemented by stock return and stock return volatility. Stock returns (RET) are compounded from monthly returns over the previous twelve months.6
6 Through the inclusion of returns instead of abnormal returns we also control for market wide fluctuations.
6

Falling stock prices are likely to capture an increase in a firm's distress potential. We

define volatility (VOLA) as the standard deviation of monthly stock returns over the

previous twelve months. We expect more volatile stocks to be associated with low credit

quality.

We include a measure of firm size along with a proxy for investment opportunities as

explanatory variables. Similar to Shumway (2001) firm size (SIZE) is measured as the

natural logarithm of the ratio of a firm's market capitalization to the capitalization of the

S&P500. Larger firms are suspected to be less exposed to default. We proxy investment

opportunities

by

growth

in

assets

(dTA

=

T

At-T At-1 T At

),

as

in

Fama

and

French

(2002).

The corresponding coefficient is presumed to be positive.

In order to mitigate the influence of outliers, we winsorize all observed covariates,

except SIZE and EBIT/XINT, at the 1% and 99% quantiles. Taking the logarithm

when measuring firm size already reduces the impact of outliers. Interest coverage is

truncated similar to the procedure suggested by Blume et al. (1998): all observations

with negative earnings are set to zero; all observations with negative interest expenses

are set to the maximum value of 5; all remaining values are cut of at the maximum value

of 5. The procedure results in a range of [0, 5] for transformed interest coverage.7

3.2. Covariates for Leverage Forecasts
In line with the specification for default analysis leverage is measured as a firm's market debt ratio. As leverage factors we consider a set of widely used firm characteristics (cf. Rajan and Zingales (1995), Howakimian et al. (2001), Fama and French (2002), Flannery and Rangan (2006)). These include profitability, firm size, non-debt tax shields and tangibility as well as product uniqueness along with growth and investment opportunities.
Firms with high profitability (EBIT/TA)8 have less leverage, since firms with higher retained earnings are more likely to use equity finance. On the other hand, the inverse relationship between profitability and bankruptcy costs implies better debt conditions. Firm size (SIZE) might have a positive relation to leverage due to less volatile earnings and better access to the debt market. Non-debt tax shields are proxied by the proportion of depreciation expense relative to total assets (XD/TA). Higher non-debt tax shields most likely increase the preference for equity relative to debt financing. Tangibility is measured by the ratio of fixed to total assets (FA/TA). Firms with a higher proportion of tangible assets tend to operate with higher leverage. Product uniqueness, measured by the proportion of research and development expenses to total assets (R&D/TA), should be negatively related to leverage. As in Flannery and Rangan (2006) we also include a dummy variable indicating whether a firm does report R&D expenses. We proxy growth opportunities by the market-to-book ratio (MB); firms with high expected

7 Blume et al. (1998) point out that coverage is likely to have non-linear effects. Consequently, in a logit model a change in values close to the mean of the distribution would have a larger impact on the dependent variable than the same change in values close to the tails of the distribution.
8 For consistency reasons, variables that approximate the same characteristics considered in the default analysis are not redefined. Outliers are again removed through winsorization at the 1% and 99% quantiles.

7

future growth tend to have more equity. Again growth in assets (dTA) is used as a proxy for investments opportunities.9
Following Flannery and Rangan (2006) we include the industry mean of leverage (INDMEAN) in order to control for industry wide characteristics not captured otherwise. For industry definitions we refer to Chava and Jarrow (2004).
Lemmon et al. (2008) stress the importance of initial leverage relative to time-varying leverage factors. We define initial leverage (L0) as a firm's first observable market debt ratio.
4. Partial Adjustment Model - Econometric Issues
The estimation of Eq. (7) entails a dynamic panel regression. Panel data is in general subject to two sources of dependence: correlation of residuals for a given year across firms and correlation of residuals for a given firm across years. The first source is usually controlled for using time dummies, whereas cross-sectional dependence is dealt with by including dummies for each firm (fixed effects or within estimation), cf. Petersen (2009). Further, the introduction of a lagged dependent variable comes along with the problem of endogeneity, since Lt will be correlated with the error term. A standard approach in this case is an instrumental variables regression.
Several estimation techniques have been suggested for dynamic panel data.10 The results differ with respect to estimated coefficients and standard errors. In our application, however, we primarily focus on accurate out-of-sample forecasts rather than on correct in-sample estimates. Within the two-step approach forecasts of future leverage ratios are added to the regressors in the default analysis in order to increase prediction accuracy. Thus, it is obvious that our findings are sensitive to the results from the first-step regression and poor forecasts should be avoided.
We compare several estimation techniques and use the one that performs best with respect to the out-of-sample forecasting ability quantified by the root mean squared error (RMSE). We consider within groups estimation as well as instrumental variables regression with and without fixed effects. Time dummies are included in each specification. For the instrumental variables regression we follow Flannery and Rangan (2006) who suggest book debt ratio (the ratio of total debt to the book value of total assets) as an instrument for Lt.
We test the out-of-sample forecasting performance for the years 1996 to 2000 with coefficients being estimated on a sample including the years 1985 to 1995. An average RMSE is computed over forecasting horizons of one to four years. For the instrumental variables regression without fixed effects we get the lowest value: 0.16. Allowing for fixed effects results in an average RMSE of 0.24 (IV regression) and 0.25 (within estimation).
Based on this results we use instrumental variables regression without fixed effects in the first step of the two-step dynamic model. All following inference is based on this
9 Fama and French (2002) include growth in assets to capture temporary movements in leverage away from its target rather than as a direct determinant of target leverage.
10 A detailed overview can be found in Baltagi (2003).
8

choice. Regression results for the partial adjustment equation for forecasting horizons of one to four years are presented in Table 6 in the Appendix (we do not list coefficient estimates for time dummies).
5. Empirical Results
We first report in-sample estimation results for the discrete duration model with the following covariates: Xt (the base model), Ut = (Xt, Lt, Ct) (the reduced-form dynamic model) and Zt+k = (Xt, dL^t+k) (the two-step dynamic model). The respective prediction accuracies are compared out-of-sample in Section 5.2.
5.1. In-Sample Estimation
Table 1 presents regression results for the base model for discrete default probabilities one to five years ahead, i.e. for default in (t, t + 1] to (t + 4, t + 5]. We report coefficient estimates, robust standard errors adjusted for clustering on firms and the McFadden Pseudo-R2 as an indicator for the overall fit of the model as well as the area under the Receiver Operating Characteristic (ROC) curve (AUC).11
For the one-year prediction horizon coefficient estimates for all risk factors carry the expected sign and show high significance, except for EBIT/TA, which is only marginally significant with a p-value of 0.1. For other horizons this covariate remains insignificant, whereas the accounting ratios L, EBIT/XINT and dTA keep their predictive power. Among the market variables only SIZE exhibits long-term explanatory power. Neither past returns, nor their volatility can explain defaults four or five years ahead. We find a rapid decline in the overall fit of the model, comparing the relatively high Pseudo-R2 for a one-year horizon (Pseudo-R2 = 0.3987) to the rather small overall fit for the five-year horizon (Pseudo-R2 = 0.0718). A similar trend is observed for prediction accuracy; the area under the ROC curve reduces from AUCB1 ase = 0.9460 to AUC5Base = 0.7502.
Table 2 presents coefficient estimates for the two-step dynamic model. The dynamic variable dL^ has the right sign and exhibits high statistical significance for any of the considered horizons. After the inclusion of the dynamic variable the covariate dTA becomes insignificant. This might be due to the fact that dTA is one of the leverage factors used in the first step to forecast future leverage ratios. The remaining covariates are only slightly affected. Further, values for the Pseudo-R2 and AUC of the two-step dynamic model exceed the respective values of the base model. The best in-sample gain in AUC is observed for a prediction horizon of four years, with an increase from AUCB4 ase = 0.7856 to AUC4Two-Step = 0.8161.
Regression results for the reduced-form dynamic model are reported in Table 3. Since time dummies are included in the partial adjustment model, they are also included in the reduced-form dynamic model. Yet, to keep results clearly presented, we do not
11 The area under the ROC curve measures the discriminating power of a model; a value close to the maximum of 1.0 corresponds to a perfect discrimination between defaulters and non-defaulters, whereas a random decision would lead to a value of about 0.5.
9

L
EBIT/TA
EBIT/XINT
RET
VOLA
dTA
SIZE
Constant
Firm-years Pseudo-R2 AUC

1 4.80*** (0.53 )
-1.76 (1.07) -0.31** (0.10) -1.64*** (0.31) 4.69*** (1.02) 1.14** (0.40) -0.18*** (0.05) -9.08*** (0.54) 17499 0.3987 0.9460

Prediction Horizon in Years

234

2.97*** 2.41*** 1.49**

(0.41) (0.39) (0.46)

0.95 -0.24 1.86

(1.16) (1.29) (1.48)

-0.33*** -0.19** -0.29**

(0.08) (0.07) (0.09)

-0.65*** -0.29

-0.24

(0.18) (0.16) (0.19)

4.39*** 3.43**

0.67

(1.12) (1.07) (1.36)

1.13*** 1.13** 1.17*

(0.34) (0.40) (0.50)

-0.20*** -0.19*** -0.22***

(0.05) (0.05) (0.05)

-7.53*** -7.08*** -6.47***

(0.49) (0.44) (0.50)

15566 14611 13719

0.2238 0.1398 0.0965

0.8810 0.8259 0.7856

5 0.99* (0.48) 2.23 (1.68) -0.31*** (0.09) -0.11 (0.20) 0.33 (1.39) 1.37** (0.45) -0.21*** (0.06) -6.12*** (0.53) 13230 0.0718 0.7502

Table 1: Regression results for the base model explaining discrete default probabilities one to five years ahead. Robust standard errors are in parentheses. Stars indicate a significance level: p < 0.05, p < 0.01, p < 0.001.

list coefficient estimates for time dummies. The model shows the best overall fit and discriminatory power which is what we expect because it imposes fewer restrictions than the base or two-step dynamic model. The improvement is pronounced. It is largest at the five-year horizon. Discriminatory power increases from AUC5Base = 0.7502 and AUCT5 wo-Step = 0.7761 to AUCR5 educed-Form = 0.8358.
The likelihood ratio test for the null hypothesis Ct = 0, i.e. leverage factors have no explanatory power (where we only consider covariates that are not part of the base model as well as time dummies), is rejected at the 0.1% significance level for all horizons. When inspecting the individual variables in Ct, however, only R&D/TA and the time dummies are significant. The low precision of the other variables as well as the importance of time dummies ­ which do not contribute to an out-of-sample prediction ­ already indicate that the good in-sample performance of the reduced-form model may not carry over to a good out-of-sample performance.
5.2. Out-of-Sample Prediction Accuracy
Through an out-of-sample validation we can assess the performance of the dynamic models in a realistic setting, where an analyst aims to predict future default probabilities using only current and past information.
We conduct the out-of-sample validation as follows. For each validation year, 1991 to 2000, we compute future default probabilities based on coefficient estimates from a sample consisting of observations of the previous n years. We vary the number of years in

10

L dL^1 dL^2 dL^3 dL^4 EBIT/TA EBIT/XINT RET VOLA dTA SIZE Constant
Firm-years Pseudo-R2 AUC

Prediction Horizon in Years

2 3 45

4.31*** 5.00*** 4.64*** 4.05***

(0.49)

(0.52)

(0.65)

(0.73)

12.57***

(2.23)

13.12***

(1.66)

11.47***

(1.57)

8.84***

(1.55)

0.55 -1.62 0.70 1.55

(1.18)

(1.35)

(1.62)

(1.82)

-0.33*** -0.18* -0.27*** -0.28***

(0.08)

(0.08)

(0.09)

(0.09)

-0.66*** -0.33

-0.29

-0.16

(0.19)

(0.17)

(0.21)

(0.21)

4.57*** 4.28***

2.08

2.04

(1.14)

(1.1)

(1.42)

(1.4)

0.28

-0.11

-0.04

0.49

(0.36)

(0.44)

(0.53)

(0.48)

-0.15*** -0.12* -0.15*** -0.17***

(0.05)

(0.05)

(0.05)

(0.06)

-7.52*** -7.38*** -7.05*** -6.95***

(0.48)

(0.45)

(0.52)

(0.58)

15566

14611

13719

13230

0.2362 0.1701 0.1275 0.0935

0.8883 0.8500 0.8161 0.7761

Table 2: Regression results for the two-step dynamic model explaining discrete default probabilities two to five years ahead. Robust standard errors are in parentheses. Stars indicate a significance level: p < 0.05; p < 0.01; p < 0.001.

11

L EBIT/TA EBIT/XINT RET VOLA dTA SIZE L0 MB XD/TA FA/TA R&D Dummy R&D/TA INDMEAN Constant Firm-years Pseudo-R2 AUC

Prediction Horizon in Years

2345

2.86*** 2.54*** 1.49*

1.28*

(0.5)

(0.47) (0.56) (0.57)

0.61 -0.78 2.23 2.52

(1.31) (1.44) (1.81) (1.87)

-0.3*** -0.14

-0.25* -0.26*

(0.08) (0.08)

(0.1)

(0.1)

-0.54*

-0.31

-0.49*

-0.14

(0.2)

(0.18) (0.22) (0.23)

5.42*** 5.22*** 4.16*

4.09*

(1.32) (1.31) (1.73) (1.71)

0.83*

0.71

0.85 1.18*

(0.35) (0.41) (0.51) (0.46)

-0.2*** -0.17*** -0.17*** -0.2***

(0.05) (0.05) (0.06) (0.06)

0.09 0.22 0.24 0.35

(0.34) (0.36) (0.38)

(0.4)

-0.1

-0.24

-0.32

-0.03

(0.25) (0.19) (0.23) (0.19)

2.76 -1.58 1.75 4.19

(3.51) (3.86)

(4.4)

(4.08)

0.16 -0.07 -0.51 -0.39

(0.43) (0.41) (0.43) (0.44)

-0.14

-0.23

-0.29

-0.43*

(0.16) (0.17) (0.17) (0.18)

-7.91* -6.4 -9.25* -7.64*

(3.6)

(3.64) (4.06)

(3.7)

0.38 0.22 0.03 -1.04

(1.2)

(1.33) (1.41) (1.63)

-9.24*** -7.84*** -6.15*** -7.58***

(1.34) (1.05) (0.97) (1.31)

15566 14611 13719 13230

0.2709 0.2051 0.1704 0.1457

0.9048 0.8769 0.8551 0.8358

Table 3: Regression results for the reduced-form dynamic model explaining discrete default probabilities two to five years ahead (coefficients for time dummies are omitted). Robust standard errors are in parentheses. Stars indicate a significance level: p < 0.05; p < 0.01; p < 0.001.

12

the estimation sample from n = 8 to n = 13 years. We compare the prediction accuracy of the two dynamic models to that of the base model by means of the AUC. The ROC curve is computed using the set of pooled probability estimates for all validation years. Additionally, we test the null hypothesis of equality of areas under two ROC curves using the algorithm suggested by DeLong et al. (1988).
The variable dL^ in the two-step dynamic model is obtained in a way which is consistent with the out-of-sample methodology. The partial adjustment equation is estimated only with data from the years that make up the estimation sample.
Table 7 in the Appendix documents the results in Panels A to D. We report p-values for the null hypothesis comparing each dynamic model to the base model. A graphical presentation of results is provided separately for each dynamic model in Fig. 1. The ordinate shows the increase in AUC (in percentage points) when compared to the base model; the abscissa marks the number of years in the estimation sample. Each value is labeled by stars or a circle. Stars indicate the significance level if the null hypotheses of equality is rejected. If the null cannot be rejected at a significance level of 5% the plot displays a circle.
Out-of-sample, the two dynamic models perform quite differently. The increase in prediction accuracy is on average higher for the two-step dynamic model. Moreover, the results mostly indicate no significant increase in the AUC for the reduced-form model.
For both dynamic models the out-of-sample performance depends on the number of years included in the estimation sample. This effect is even more pronounced for the two-step dynamic model. Here a significant increase only shows for estimation samples that cover less then twelve years. We observe best improvement for the nine and tenyear estimation samples, but no improvement for the twelve and thirteen-year estimation samples.
Consequently, when all years prior to the validation year are used for estimation the two-step dynamic model is not superior to the base model. We also find mostly no significant difference in the performance of the reduced-form and the base model.12
Why does the performance of the two-step dynamic model deteriorate for large estimation samples? In the partial adjustment model (the first-step regression) the adjustment speed as well as the linkage between firm characteristics and target leverage are modeled constant over time. In-sample, departures from this assumption are mitigated by time dummies. Out-of-sample, they are not, and a too long estimation history might therefore lead to a reduction in the precision of leverage forecasts. A comparison of root mean squared errors supports this conjecture; the values are lowest for an estimation sample covering ten years. This suggests that one limits the estimation sample for the first-step regression to around ten years even if a longer data history is available. Of course, there is no need to impose the same limit on the second-step regression. We checked whether the two-step dynamic model continues to be superior if the estimation samples are chosen to be ten years for the first-step regression and eleven to thirteen years for the second-step regression. We still find significant (5% or better) increases in AUC.
12 All unreported results are available upon request.
13

Increase in AUC (in pp.)

15 10
5*
0
**
-5 -10 -15
8
15 10
5*** ****
0

Reduced-Form Dynamic Model (with test against Base Model)
2-year pred. horizon 3-year pred. horizon 4-year pred. horizon
** 5-year pred. horizon
*

* * ***

9 10 11 12 Years in the estimation sample

***
13

Two-Step Dynamic Model (with test against Base Model)

2-year pred. horizon

3-year pred. horizon

4-year pred. horizon

****** ***

*** ******

5-year pred. horizon

*** *****

Increase in AUC (in pp.)

-5 ***
-10

-15 8

9 10 11 12 Years in the estimation sample

13

Figure 1: Out-of-sample performance of the reduced-form and two-step dynamic model relative to the base model for two to five-year prediction horizons. Estimation samples cover eight to thirteen years. Stars indicate a significance level: p < 0.05; p < 0.01; p < 0.001, circles indicate no rejection of the null hypotheses of equality of areas under two ROC curves.

14

The rather poor out-of-sample performance of the reduced-form model indicates that a simultaneous estimation of leverage dynamics and default probabilities cannot capture the dynamics of leverage sufficiently. The two-step procedure is clearly more favorable.
5.3. Variations of the Two-Step Dynamic Model
In the specification of the partial adjustment equation we already control for differences in industry characteristics through the covariate INDMEAN (mean industry leverage ratio). Alternatively, in the two-step dynamic model, we can take account of a heterogenous adjustment behavior by running the first-step regression on industry class subsamples. Industry classes are defined as in Chava and Jarrow (2004), resulting in eight classes.
Kisgen (2006) shows that ratings influence capital structure decisions. We therefore repeat the analysis for rating category subsamples. In order to ensure a sufficient sample size in each category, we aggregate Moody's ratings into four categories (high = Aaa to Aa3, medium = A1 to Baa3, speculative = Ba1 to B3, and poor = Caa1 to C). Unrated firms are assigned a separate category.
The evaluation of out-of-sample ROC curves shows no clear-cut improvement in prediction accuracy from using subsamples in the first-step regression. The separation based on rating classes increases the AUC significantly only for the four and five-year prediction horizons. Estimation on industry class subsamples improves out-of-sample prediction accuracy only if at least 12 years are included in the estimation sample.
Overall, the results show that refinements of the partial adjustment regression could help to further improve default prediction. Improvements are not clear-cut though, suggesting that the two-step dynamic model with its rather simplistic assumption of a homogeneous adjustment behavior is a good starting point for practical purposes.
One could surmise that it matters for default prediction whether the predicted change in leverage is positive or negative. Therefore, we include the variable dL^  DdL^<0, with DdL^<0 being a dummy variable set to one if dL^ < 0, in the two-step dynamic model. Comparing out-of-sample results to the performance of the two-step dynamic model we find no material increase in AUC. In the data, information about predicted reductions in leverage is as valuable as information about predicted increases in leverage.
6. Do Credit Ratings Capture the Dynamics of Leverage?
In the preceding section we have shown that additional information on the dynamics of capital structure can significantly improve long-term default prediction accuracy. Credit ratings assigned by rating agencies such as Moody's or Standard & Poor's also focus on the long-term quality of an obligor's debt. Fons et al. (2002) state on Moody's ratings: "[. . . ] credit ratings powerfully discriminate among relative long-term risks. They target multiple horizons, rather than a single, defined investment horizon." In other words, credit ratings are meant to be forward-looking with respect to credit quality and the question arises whether such a forward-looking ability covers leverage dynamics. If it
15

does, adding credit rating information to the default regression in the two-step dynamic model would make the dynamic leverage variable redundant or less important.
We address this question by considering the following covariates in the default prediction model:
(i) Xt, i.e. the base model,
(ii) Zt+k = (Xt, dL^t+k), i.e. the two-step dynamic model,
(iii) Vt = (Xt, RATt), i.e. the base model plus rating,
(iv) Wt+k = (Xt, dL^t+k, RATt), i.e. the two-step dynamic model plus rating,
where RATt denotes the credit rating assigned by Moody's at time t. Following Kisgen (2006) we convert each of the 21 rating categories to a numerical variable: 1 corresponds to rating class Aaa, 2 to rating class Aa1, . . . , 21 corresponds to rating class C. Such, a higher rating is associated with a higher probability of default.
Table 4 reports regression results when the two-step dynamic model is enlarged by the current rating. Comparing the coefficient estimates to those of the two-step dynamic model (Table 2), we find that the inclusion of RAT has no effect on the significance and magnitude of the dynamic variable. The rating variable itself is highly significant.
Mutual significance of leverage and rating information can further be validated by a comparison of the respective out-of-sample ROC areas. We compare the out-of-sample predictive performance as described in Section 5.2 with either Xt, Zt+k, Vt or Wt+k being the vector of explanatory variables. We let the estimation sample cover a history of ten years, due to the observation from Section 5.2. Results are presented in Fig. 2, where we plot the respective AUC value against the prediction horizon.
The highest AUC values result from the two-step dynamic model enlarged by credit rating. The values for the two-step dynamic model without rating information are slightly lower; the differences are significant for the four and five-year prediction horizon (p-values 0.018 and 0.005).
Similarly, the AUC values increase after adding the rating information to the base model. Yet, the resulting ROC curves differ statistically only for the five-year prediction horizon (p-value = 0.01). The inclusion of the dynamic variable, however, yields a significantly higher prediction accuracy for both the base model and the base model with rating. This is observed for any of the considered prediction horizons.
Summarizing, the in-sample coefficient estimates as well as the out-of-sample analysis of ROC curves suggest that ratings are forward-looking but that they do not capture the dynamics in leverage. The inclusion of the dynamic variable consistently increases outof-sample prediction accuracy even after controlling for the actual rating. Whereas the information on credit rating is only relevant for the five-year prediction horizon. Here, the dynamic variable and credit rating are complementary in the sense that neither one can be replaced by the other without loss of prediction accuracy.
16

L dL^1 dL^2 dL^3 dL^4 RAT EBIT/TA EBIT/XINT RET VOLA dTA SIZE Constant
Firm-years Pseudo-R2 AUC

Prediction Horizon in Years

2 3 45

3.96*** 4.35*** 4.45*** 3.93***

(0.53)

(0.53)

(0.65)

(0.74)

11.85***

(2.17)

12.75***

(1.61)

12.13***

(1.56)

9.39***

(1.61)

0.12*** 0.19*** 0.21*** 0.15***

(0.04)

(0.04)

(0.04)

(0.04)

-0.2

-2.12

-1.39

0.28

(1.21)

(1.33)

(1.57)

(1.78)

-0.25**

-0.08

-0.08

-0.17

(0.09)

(0.08)

(0.09)

(0.1)

-0.72*** -0.46** -0.48*

-0.38

(0.19)

(0.17)

(0.21)

(0.22)

3.51** 3.28**

0.44

0.37

(1.23)

(1.16)

(1.53)

(1.48)

0.5

-0.05

-0.17

0.29

(0.36)

(0.45)

(0.51)

(0.49)

-0.1

-0.01

-0.01

-0.06

(0.06)

(0.07)

(0.07)

(0.08)

-8.37*** -8.3*** -8.21*** -7.64***

(0.54)

(0.52)

(0.62)

(0.66)

13448

13223

13023

12852

0.2531 0.1918 0.1533 0.1099

0.8976 0.8680 0.8435 0.8013

Table 4: Regression results for the two-step dynamic model enlarged by credit rating explaining discrete default probabilities two to five years ahead. Robust standard errors are in parentheses. Stars indicate a significance level: p < 0.05; p < 0.01; p < 0.001.

17

Effect of credit rating on prediction accuracy of the Base and Two-Step Dynamic Model 0.9

0.85

0.8

AUC

0.75

0.7 0.65 2

Base Model Base Model with Rating Two-Step Dynamic Model Two-Step Dynamic Model with Rating
34 Prediction Horizon in Years

5

Figure 2: Out-of-sample prediction accuracies for two to five-year prediction horizons: base model, base model enlarged by the current rating, two-step dynamic model and two-step dynamic model enlarged by the current rating. The estimation sample covers 10 years.

7. Summary and Concluding Remarks
Empirical corporate finance research documents that firms actively rebalance their capital structure towards a target leverage ratio. The main question addressed in our paper is whether this insight can be used to improve the prediction of corporate defaults. We use two related econometric specifications. In both cases, a standard discrete hazard rate model (our base model) is enriched by variables that capture the dynamics of leverage. In the reduced-form approach, we just add the variables that the capital structure literature uses to model target leverage ratios. In the two-step approach, we augment the base model by the predicted change in the leverage ratio; the prediction is obtained from a first-step regression along the lines of a partial adjustment model used in the capital structure literature. The reduced-form approach nests the two-step approach.
In-sample, both approaches lead to significant improvements over the base model. The reduced-form model performs best because it imposes the fewest restrictions. To judge the usefulness of a default prediction model, however, it is crucial to conduct an out-of-sample analysis. For the reduced-form dynamic model, we find no material increase in predictive accuracy as measured by the area under the ROC curve and hence conclude that dynamics in leverage cannot be captured by solely adding covariates from the partial adjustment model to the set of risk drivers. For the two-step dynamic model, by contrast, a significant increase in prediction accuracy is observed. The restrictions imposed through the partial adjustment model increase the precision of coefficient estimates and thereby lead to better out-of-sample performance. The magnitude of this

18

improvement varies with the length of the sample used for estimating the partial adjustment equation. Restricting the estimation sample for leverage forecasts to at most ten preceding years results in the highest out-of-sample prediction accuracy.
Standard default prediction models do not use information contained in credit ratings but many market participants do. Given that rating agencies claim their ratings to be forward-looking we further ask whether credit ratings contain information about leverage dynamics. We address this question by adding credit ratings to our default prediction models. Including credit ratings improves predictive power, albeit only for the five-year prediction horizon. Further, the contribution of the leverage forecast is not affected. While rating analysts do appear to have a forward-looking ability, this ability is unrelated to the predictability of leverage ratios that has been documented in the corporate finance literature.
The paper could inspire other extensions of existing default prediction models. Until now, specification of such models is largely based on a search for covariates that perform better than the ones previously considered. The final regression equation is reducedform in the sense that it imposes no restrictions on variables (except for the commonly made linearity restriction). Our analysis has shown that default prediction models can benefit from imposing restrictions that are derived from other research areas, e.g. capital structure. Finally, the work contributes to the corporate finance literature, since it shows that it is important to model the leverage-targeting behavior of firms. If we had obtained that leverage forecasts from a partial adjustment equation are useless in default prediction, this would have cast doubts on the empirical relevance of the trade-off theory.
A. Appendix
19

L
L0 INDMEAN EBIT/TA EBIT/XINT dTA
SIZE RET
VOLA
MB XD/TA FA/TA R&D/TA R&D Dummy
Instrumental Variable

Description

Leverage = Total Debt/

Market Value of Total Assets

Initial Leverage

Mean Leverage by Industry

EBIT/Total Assets

EBIT/Interest Expense

Growth in Assets

(dTA

=

)T At-T At-1 T At

ln(MCAP/Cap. of S&P500)

Return over the

previous 12 months

Volatility of returns over the

previous 12 months

Market-to-Book ratio

Depreciation/Total Assets

Fixed Assets/Total Assets

R&D Expenses/Total Assets

Set to 1 if a firm

declares R&D expenses

Total Debt/

Book Value of Total Assets

COMPUSTAT Items (CS9+CS34)/ (CS9+CS34+MCAP)
(CS18+CS15+CS16)/CS6 (CS18+CS15+CS16)/CS15 CS6
(CS9+CS34+MCAP)/CS6 CS14/CS6 CS8/CS6 CS46/CS6 CS46 (CS9+CS34)/CS6

Mean 0.340
0.219 0.340 0.093 3.230 0.060
-8.414 0.150
0.110
1.263 0.046 0.350 0.02 0.384
0.317

Std. Dev. 0.231
0.206 0.064 0.088 1.843 0.167
1.902 0.444
0.057
0.883 0.025 0.205 0.035 0.486
0.179

Min 0.0002
0 0.178 -0.260
0 -0.616
-15.813 -0.732
0.035
0.372 0.005 0.019
0 0
0.0002

Max 0.921
0.983 0.716 0.307
5 0.560
-2.812 1.893
0.338
5.702 0.157 0.885 0.178
1
0.937

20

Table 5: Definition and descriptive statistics of covariates used in the default analysis and partial adjustment equation. Descriptive statistics are estimated based on 17499 firm-years. The CRSP item MCAP (market capitalization) is defined as MCAP = price per share*shares outstanding.

L L0 EBIT/TA MB XD/TA FA/TA R&D Dummy R&D/TA INDMEAN SIZE dTA Constant Firm-years R2

Forecast Horizon in Years

1234

0.889*** 0.795*** 0.722*** 0.652***

(0.009) (0.016) (0.021) (0.027)

0.018*** 0.038*** 0.053*** 0.060***

(0.005) (0.010) (0.013) (0.017)

0.031* 0.070** 0.091** 0.099**

(0.015) (0.022) (0.029) (0.035)

-0.006*** -0.009*** -0.011*** -0.013***

(0.001) (0.002) (0.003) (0.004)

-0.064

-0.173*

-0.148

-0.145

(0.049) (0.086) (0.121) (0.157)

0.021*** 0.038*** 0.040** 0.048*

(0.006) (0.011) (0.015) (0.019)

-0.001

-0.002

-0.001

-0.001

(0.002) (0.004) (0.005) (0.007)

-0.102*** -0.167*** -0.258*** -0.345***

(0.027) (0.049) (0.068) (0.084)

0.026

0.019

-0.012

-0.042

(0.020) (0.035) (0.048) (0.057)

-0.002** -0.002

-0.002

-0.001

(0.001) (0.001) (0.002) (0.003)

0.046*** 0.064*** 0.073*** 0.072***

(0.007) (0.010) (0.012) (0.014)

-0.009

0.030 0.111*** 0.107***

(0.011) (0.019) (0.025) (0.029)

14826

13290

11931

11045

0.8091

0.6618

0.5590

0.4799

Table 6: Regression results for the partial adjustment equation using IV regression without fixed effects. Lagged leverage ratio is instrumented by book debt ratio. Robust standard errors are in parentheses. Stars indicate a significance level: p < 0.05; p < 0.01; p < 0.001.

21

Base Two-Step Reduced-Form
Base Two-Step Reduced-Form
Base Two-Step Reduced-Form
Base Two-Step Reduced-Form

Years in the estimation sample

8 9 10 11 12

Panel A

Prediction Horizon 2 Years

0.8513 0.8563 0.8587 0.8643 0.8693

0.8575 0.8665 0.8856 0.8828 0.8734

(0.255) (0.057) (<0.001) (<0.001) (0.570)

0.8157 0.8461 0.8506

0.863 0.8377

(0.001) (0.255) (0.434) (0.875) (0.015)

Panel B

Prediction Horizon 3 Years

0.7703 0.7873 0.7987 0.8136 0.8184

0.7856 0.8303 0.8497 0.8407 0.8283

(0.009) (<0.001) (<0.001) (0.008) (0.234)

0.7407 0.8034 0.8089 0.8349 0.7961

(0.106) (0.284) (0.531) (0.069) (0.091)

Panel C

Prediction Horizon 4 Years

0.6232 0.6874 0.7195 0.7537 0.7647

0.6703 0.7618 0.7833

0.784

0.759

(<0.001) (<0.001) (<0.001) (0.093) (0.706)

0.6652 0.7342 0.7281 0.7682 0.7327

(0.029) (0.045) (0.711) (0.532) (0.168)

Panel D

Prediction Horizon 5 Years

0.5258 0.5748 0.6278 0.6796 0.6965

0.5480 0.6382 0.7101 0.7049 0.6603

(0.003) (<0.001) (<0.001) (0.234) (0.052)

0.5566 0.6599

0.672

0.6863 0.6325

(0.179) (0.001) (0.152) (0.823) (0.029)

13
0.8732 0.8808 (0.119) 0.868 (0.603)
0.8179 0.8019 (0.052) 0.7996 (0.087)
0.7650 0.7088 (<0.001) 0.6996 (<0.001)
0.6905 0.6347 (<0.001) 0.5536 (<0.001)

Table 7: Out-of-sample AUC values for the base, the two-step and the reduced-form dynamic model. Number of years in the estimation samples ranges from eight to thirteen. The dynamic models are compared to the base model; the respective p-values for to the null hypotheses of equality of areas under two ROC curves are in parenthesis.

22

References
Altman, E., 1968. Financial Ratios, Discriminant Analysis and the Prediction of Corporate Bankruptcy. The Journal of Finance 23, 589­609.
Baker, M., Wurgler, J., 2002. Market Timing and Capital Structure. The Journal of Finance 57, 1­32.
Baltagi, B., 2003. Econometric analysis of panel data. John Wiley & Sons, Ltd.
Beck, N., Katz, J., Tucker, R., 1998. Taking Time Seriously: Time-Series-Cross-Section Analysis with a Binary Dependent Variable. American Journal of Political Science 42, 1260­1288.
Blume M.E., Lim F., MacKinley A., 1998. The Declining Credit Quality of U.S. Corporate Debt: Myth or Reality? The Journal of Finance 53, 1389­1413.
Campbell, J., Hilscher, J., Szilagyi, J., 2008. In Search of Distress Risk. The Journal of Finance 63, 2899­2939.
Chava, S., Jarrow R., 2004. Bankruptcy Prediction with Industry Effects. Review of Finance 8, 537­569.
Collin-Dufresne, P., Goldstein, R., 2001. Do Credit Spreads Reflect Stationary Leverage Ratios? The Journal of Finance 56, 1929­1957.
Duffie, D., Saita, L., Wang, K., 2007. Multi-period corporate default prediction with stochastic covariates. Journal of Financial Economics 83, 635­665.
DeLong, E., DeLong, D., Clarke-Pearson, D., 1988. Comparing the areas under two or more correlated receiver operating curves: A nonparametric approach. Biometrics 44, 837­845.
Fama, E., French, K., 2002. Testing Trade-off and Pecking Order Predictions About Dividends and Debt. The Review of Financial Studies 15, 1­33.
Flannery, M., Rangan, K., 2006. Partial adjustment toward target capital structure. Journal of Financial Economics 79, 469­506.
Fons, J., Cantor, R., Mahoney C., 2002. Understanding Moody's Corporate Bond Ratings And Rating Process. Moody's Investors Service, Special Comment.
Frank, M., Goyal, V., 2007. Trade-Off and Pecking Order Theories of Debt. Working Paper.
Graham, J., Harvey, C., 2001. The theory and practice of corporate finance: evidence from the field. Journal of Financial Economics 60, 187­243.
Hamilton, D., Varma, P., Ou, S., and Cantor, R., 2006. Default and Recovery Rates of Corporate Bond Issuers, 1920-2005. Moody's Investors Service, Special Comment.
Hillegeist, S., Keating, E., Cram, D., Lundstedt, K., 2004. Assessing the Probability of Bankruptcy. Review of Accounting Studies 9, 5­34.
Howakimian, A. Opler, T., Titman, S., 2001. The Debt-Equity Choice. Journal of Financial and Quantitative Analysis 36, 1­24.
Kisgen, D., 2006. Credit Ratings and Capital Structure. The Journal of Finance 61, 1035­1072.
Kraus, A., Litzenberger, R., 1973. A State-Preference Model of Optimal Financial Leverage. The Journal of Finance 28, 911­922.
23

Leary, M., Roberts, M., 2005. Do Firms Rebalance Their Capital Structure? The Journal of Finance 60, 2575­2619.
Lemmon L., Roberts M., Zender J., 2008. Back to the Beginning: Persistence and the Cross-Section of Corporate Capital Structure. The Journal of Finance 63, 1575­1608.
Lo, C., Wong, T., Hui, C., Huang, M., 2008. Assessing Credit Risk of Companies with Mean-Reverting Leverage Ratios. HKIMR Working Paper No. 4/2008
Myers, S., 1984. The Capital Structure Puzzle. The Journal of Finance 39, 575­592. Metz, A., Cantor, R., 2006. Moody's Credit Rating Prediction Model. Moody's Investors Service, Special
Comment. Ohlson, J., 1980. Financial Ratios and the Probabilistic Prediction of Bankruptcy. Journal of Accounting
Research 19, 109­131. Petersen M., 2009. Estimating Standard Errors in Finance Panel Data Sets: Comparing Approaches.
The Review of Financial Studies 22, 435­480. Rajan, R., Zingales L., 1995. What Do We Know about Capital Structure? Some Evidence from Inter-
national Data. The Journal of Finance 50, 1421­1460. Shumway, T., 2001. Forecasting Bankruptcy More Accurately: A Simple Hazard Model. The Journal of
Business 74, 101­124. Zmijewski, M., 1984. Methodological Issues Related to the Estimation of Financial Distress Prediction
Models. Journal of Accounting Research 22, 59­82.
24

SFB 649 Discussion Paper Series 2009
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "Implied Market Price of Weather Risk" by Wolfgang Härdle and Brenda López Cabrera, January 2009.
002 "On the Systemic Nature of Weather Risk" by Guenther Filler, Martin Odening, Ostap Okhrin and Wei Xu, January 2009.
003 "Localized Realized Volatility Modelling" by Ying Chen, Wolfgang Karl Härdle and Uta Pigorsch, January 2009.
004 "New recipes for estimating default intensities" by Alexander Baranovski, Carsten von Lieres and André Wilch, January 2009.
005 "Panel Cointegration Testing in the Presence of a Time Trend" by Bernd Droge and Deniz Dilan Karaman Örsal, January 2009.
006 "Regulatory Risk under Optimal Incentive Regulation" by Roland Strausz, January 2009.
007 "Combination of multivariate volatility forecasts" by Alessandra Amendola and Giuseppe Storti, January 2009.
008 "Mortality modeling: Lee-Carter and the macroeconomy" by Katja Hanewald, January 2009.
009 "Stochastic Population Forecast for Germany and its Consequence for the German Pension System" by Wolfgang Härdle and Alena Mysickova, February 2009.
010 "A Microeconomic Explanation of the EPK Paradox" by Wolfgang Härdle, Volker Krätschmer and Rouslan Moro, February 2009.
011 "Defending Against Speculative Attacks" by Tijmen Daniëls, Henk Jager and Franc Klaassen, February 2009.
012 "On the Existence of the Moments of the Asymptotic Trace Statistic" by Deniz Dilan Karaman Örsal and Bernd Droge, February 2009.
013 "CDO Pricing with Copulae" by Barbara Choros, Wolfgang Härdle and Ostap Okhrin, March 2009.
014 "Properties of Hierarchical Archimedean Copulas" by Ostap Okhrin, Yarema Okhrin and Wolfgang Schmid, March 2009.
015 "Stochastic Mortality, Macroeconomic Risks, and Life Insurer Solvency" by Katja Hanewald, Thomas Post and Helmut Gründl, March 2009.
016 "Men, Women, and the Ballot Woman Suffrage in the United States" by Sebastian Braun and Michael Kvasnicka, March 2009.
017 "The Importance of Two-Sided Heterogeneity for the Cyclicality of Labour Market Dynamics" by Ronald Bachmann and Peggy David, March 2009.
018 "Transparency through Financial Claims with Fingerprints ­ A Free Market Mechanism for Preventing Mortgage Securitization Induced Financial Crises" by Helmut Gründl and Thomas Post, March 2009.
019 "A Joint Analysis of the KOSPI 200 Option and ODAX Option Markets Dynamics" by Ji Cao, Wolfgang Härdle and Julius Mungo, March 2009.
020 "Putting Up a Good Fight: The Galí-Monacelli Model versus `The Six Major Puzzles in International Macroeconomics'", by Stefan Ried, April 2009.
021 "Spectral estimation of the fractional order of a Lévy process" by Denis Belomestny, April 2009.
022 "Individual Welfare Gains from Deferred Life-Annuities under Stochastic Lee-Carter Mortality" by Thomas Post, April 2009.
SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

SFB 649 Discussion Paper Series 2009
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
023 "Pricing Bermudan options using regression: optimal rates of convergence for lower estimates" by Denis Belomestny, April 2009.
024 "Incorporating the Dynamics of Leverage into Default Prediction" by Gunter Löffler and Alina Maurer, April 2009.
SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

