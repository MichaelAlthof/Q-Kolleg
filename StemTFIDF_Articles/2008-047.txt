BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2008-047
Modelling High-Frequency Volatility and Liquidity
Using Multiplicative Error Models
Nikolaus Hautsch* Vahidin Jeleskovic*
* Humboldt-Universität zu Berlin, Germany
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universität zu Berlin Spandauer Straße 1, D-10178 Berlin

Modelling High-Frequency Volatility and Liquidity Using Multiplicative Error Models

Nikolaus Hautsch

Vahidin Jeleskovic

June 26, 2008

Abstract
In this paper, we study the dynamic interdependencies between high-frequency volatility, liquidity demand as well as trading costs in an electronic limit order book market. Using data from the Australian Stock Exchange we model 1-min squared mid-quote returns, average trade sizes, number of trades and average (excess) trading costs per time interval in terms of a four-dimensional multiplicative error model. The latter is augmented to account also for zero observations. We find evidence for significant contemporaneous relationships and dynamic interdependencies between the individual variables. Liquidity is causal for future volatility but not vice versa. Furthermore, trade sizes are negatively driven by past trading intensities and trading costs. Finally, excess trading costs mainly depend on their own history. Keywords: Multiplicative error models, volatility, liquidity, high-frequency data.
JEL Classification: C13, C32, C52
1 Introduction
Due to the permanently increasing availability of high-frequency financial data, the empirical analysis of trading behavior and the modelling of trading processes has become a major theme in modern financial econometrics. Key variables in empirical studies of high-frequency data are price volatilities, trading volume, trading intensities, bid-ask spreads and market depth as displayed by an open limit order book. A common characteristic of these variables is that they are positive-valued and persistently clustered over time.
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
Institute for Statistics and Econometrics and CASE - Center for Applied Statistics and Economics, Humboldt-Universita¨t zu Berlin, Quantitative Products Laboratory (QPL), Berlin, and Center for Financial Study (CFS), Frankfurt. Address: Spandauer Str. 1, D-10178 Berlin, Germany. Email: nikolaus.hautsch@wiwi.hu-berlin.de
Institute for Statistics and Econometrics, Humboldt-Universita¨t zu Berlin, and Quantitative Products Laboratory (QPL), Berlin. Address: Alexanderstrasse 5, 10178 Berlin, Germany. Email: vahidin.jeleskovic@db.com
1

To capture the stochastic properties of positive-valued autoregressive processes, so-called (MEMs) have become popular. The basic idea of modelling a positive-valued process in terms of the product of positive-valued (typically i.i.d.) innovation terms and an observation-driven and/or parameter driven dynamic function is well-known in financial econometrics and originates from the model structure of the autoregressive conditional heteroscedasticity (ARCH) model introduced by Engle (1982) or the stochastic volatility (SV) model proposed by Taylor (1982). Engle and Russell (1997, 1998) introduced the autoregressive conditional duration (ACD) model to model autoregressive (financial) duration processes in terms of a multiplicative error process and a GARCH-type parameterization of the conditional duration mean. The term 'MEM' is ultimately introduced by Engle (2002) who discusses this approach as a general framework to model any kind of positive-valued dynamic process. Manganelli (2005) proposes a multivariate MEM to jointly model high-frequency volatilities, trading volume and trading intensities. Hautsch (2008) generalizes this approach by introducing a common latent dynamic factor serving as a subordinated process driving the individual trading components. The resulting model combines features of a GARCH type model and an SV type model and is called stochastic MEM. Engle and Gallo (2006) apply MEM specifications to jointly model different volatility indicators including absolute returns, daily range, and realized volatility. Recently, Cipollini et al. (2006) extend the MEM by a copula specification in order to capture contemporaneous relationships between the variables.
Given the growing importance of MEMs for the modelling of high-frequency trading processes, liquidity dynamics and volatility processes, this paper gives an introduction to the topic and an overview of the current literature. Given that the ACD model is the most popular specification of a univariate MEM, we will strongly rely on this string of the literature. Finally, we will present an application of the MEM to jointly model the multivariate dynamics of volatilities, trade sizes, trading intensities, and trading costs based on limit order book data from the Australian Stock Exchange (ASX).
The paper is organized as follows: Section 2 presents the major principles and properties of univariate MEMS. In Section 3, we will introduce multivariate specifications of MEMs. Estimation and statistical inference is illustrated in Section 4. Finally, Section 5 gives an application of the MEM to model high-frequency trading processes using data from the ASX.
2 The Univariate MEM
Let {Yt}, t = 1, . . . , T , denote a non-negative (scalar) random variable. Then, the univariate MEM for Yt is given by
Yt = µt t , t |Ft-1  i.i.d. D(1,  2),
where Ft denotes the information set up to t, µt is a non-negative conditionally deterministic process given Ft-1, and t is a unit mean, i.i.d. variate process defined on
2

non-negative support with variance  2. Then, per construction we have

E [Yt |Ft-1] d=ef µt , Var [Yt |Ft-1] =  2µt2.

(1) (2)

The major principle of the MEM is to parameterize the conditional mean µt in terms of a function of the information set Ft-1 and parameters  . Then, the basic linear MEM(p,q) specification is given by

pq
 µt =  +  jYt- j +  jµt- j, j=1 j=1

(3)

where  > 0,  j  0,  j  0. This specification corresponds to a generalized ARCH model as proposed by Bollerslev (1986) as long as Yt is the squared (de-meaned) log return between t and t - 1 with µt corresponding to the conditional variance. Accordingly, the process (3) can be estimated by applying GARCH software based on Yt (without specifying a conditional mean function). Alternatively, if Yt corresponds to a (financial) duration, such as, e.g., the time between consecutive trades (so-called trade durations) or the time until a cumulative absolute price change is observed (so-called price durations), the model is referred to an ACD specification as introduced by Engle and Russell (1997, 1998).
The unconditional mean of Yt is straightforwardly computed as

pq
E[Yt] = /(1 -   j -   j). j=1 j=1

(4)

The derivation of the unconditional variance is more cumbersome since it requires the computation of E[µt2]. In the case of an MEM(1,1) process, the unconditional variance is given by (see, e.g., Hautsch (2004))

Var[Yt ] = E[Yt ]2 2(1 -  2 - 2 )/(1 - ( +  )2 - 2 2)

(5)

corresponding to

Var[Yt] = E[Yt]2(1 -  2 - 2 )/(1 -  2 - 2 - 22)

(6)

in case of  2 = 1 which is, e.g., associated with a standard exponential distribution. Correspondingly, the model implied autocorrelation function is given by

1 d=ef Corr[Yt ,Yt-1] = (1 -  2 -  )/(1 -  2 - 2 ),  j d=ef Corr[Yt ,Yt- j] = ( +  ) j-1 for j  2.

(7) (8)

Similarly to the GARCH model, the MEM can be represented in terms of an ARMA model for Yt. Let t d=ef Yt - µt denote a martingale difference, then the MEM(p,q) process can be written as

max( p,q)

q

 Yt =  +

( j +  j)Yt- j -  jt- j + t .

j=1 j=1

(9)

3

The weak stationarity condition of a MEM(1,1) process is given by ( + )2 -2 2 < 1 ensuring the existence of Var[Yt].
Relying on the GARCH literature, the linear MEM specification can be extended in various forms. A popular form is a logarithmic specification of a MEM ensuring the positivity of µt without imposing parameter constraints. This is particularly important whenever the model is augmented by explanatory variables or when the model has to accommodate negative (cross-) autocorrelations in a multivariate setting. Two versions of logarithmic MEM's have been introduced by Bauwens and Giot (2000) in the context of ACD models and are given (for simplicity for p = q = 1) by

log µt =  + g(t-1) +  log µt-1,

(10)

where g(·) is given either by g(t-1) = t-1 (type I) or g(t-1) = log t-1 (type II). The process is covariance stationary if  < 1, E[t exp{g(t)}] <  and E[exp{2g(t)}] < . For more details, see Bauwens and Giot (2000). Notice that due the logarithmic transformation, the news impact function, i.e., the relation between Yt and t-1 is not anymore linear but is convex in the type I case and is concave in the type II parameterization. I.e., in the latter case, the sensitivity of Yt to shocks in t-1 is higher if t-1 is small than in the case where it is large.
A more flexible way to capture nonlinear news responses is to allow for a kinked news response function

log µt =  + {|t-1 - b| + c(t-1 - b)} +  log µt-1,

(11)

where b gives the position of the kink while  determines the shape of the piecewise function around the kink. For  = 1, the model implies a linear news response function which is kinked at b resembling the EGARCH model proposed by Nelson (1991). For  > 1, the shape is convex while it is concave for  < 1. Such a specification allows to flexibly capture asymmetries in responses of Yt to small or large lagged innovation shocks, such as, e.g., shocks in liquidity demand, liquidity supply or volatility. A similar specification is considered by Cipollini et al. (2006) to capture leverage effects if Yt corresponds to a volatility variable. For more details on extended MEM specifications in the context of ACD models, see Hautsch (2004) or Bauwens and Hautsch (2008).
The error term distribution of t is chosen as a distribution defined on positive support and standardized by its mean. If Yt is the squared (de-meaned) log return, then
t  N(0, 1) yields the Gaussian GARCH model. If Yt denotes a liquidity variable (such as trade size, trading intensity, bid-ask spread or market depth), a natural choice is an exponential distribution. Though the exponential distribution is typically too restrictive to appropriately capture the distributional properties of trading variables, it allows for a quasi maximum likelihood (QML) estimation yielding consistent estimates irrespective of distributional misspecifications. For more details, see Section 4. More flexible distributions are, e.g., the Weibull distribution, the (generalized) gamma distribution, the Burr distribution or the generalized F distribution. The latter is proposed in an ACD context by Hautsch (2003) and is given in standardized form (i.e., with unit mean) by the p.d.f.
f (x) = [a{x/ (a, m, )}am-1[ + {x/ (a, m, )}](--m) ]/B(m, ), (12)

4

where a, m, and  are distribution parameters, B(m, ) = (m)()/(m + ), and

 (a, m, ) d=ef {1/a(m + 1/a)( - 1/a)}/{(m)()}.

(13)

The generalized F-distribution nests the generalized gamma distribution for   , the Weibull distribution for   , m = 1, the log-logistic distribution for m =  = 1, and the exponential distribution for   , m = a = 1. For more details, see Hautsch (2004).

3 The Vector MEM
Consider in the following a k-dimensional positive-valued time series, denoted by {Yt }, t = 1 . . . , T , with Yt d=ef (Yt(1), . . . ,Yt(k)). Then, the so-called vector MEM (VMEM) for Yt is defined by
Yt = µt t = diag(µt)t,

where denotes the Hadamard product (element-wise multiplication) and t is a kdimensional vector of mutually and serially i.i.d. innovation processes, where the j-th element is given by

(
t

j)|Ft-1



i.i.d.

D(1,  2j ),

j = 1, . . . , k.

A straightforward extension of the univariate linear MEM as proposed by Manganelli (2005) is given by

pq
 µt =  + A 0Yt + A jYt- j + B jµt- j, j=1 j=1

(14)

where  is a (k × 1) vector, and A 0, A j, and B j are (k × k) parameter matrices. The matrix A 0 captures contemporaneous relationships between the elements of Yt and

is specified as a matrix where only the upper triangular elements are non-zero. This triangular structure implies that Yt(i) is predetermined for all variables Yt( j) with j < i. Consequently, Yt(i) is conditionally i.i.d. given {Yt( j), Ft-1} for j < i.
The advantage of this specification is that contemporaneous relationships between

the variables are taken into account without requiring multivariate distributions for t.

This eases the estimation of the model. Furthermore, the theoretical properties of uni-

variate MEMs as discussed in the previous section can be straightforwardly extended

to the multivariate case. However, an obvious drawback is the requirement to impose

an explicit ordering of the variables in Yt which is typically chosen in accordance with

a specific research objective or following economic reasoning. An alternative way to

capture contemporaneous relationships between the elements of Yt is to allow for mu-

tual

correlations

between

the

innovation

terms

(
t

j).

Then,

the

innovation

term

vector

follows a density function which is defined over non-negative k-dimensional support

[0, +)k with unit mean  and covariance matrix , i.e.,

t |Ft-1  i.i.d. D(, )

5

implying

E [Yt |Ft-1] = µt , Var [Yt |Ft-1] = µt µt

 = diag(µt) diag(µt).

Finding an appropriate multivariate distribution defined on positive support is a diffi-
cult task. As discussed by Cipollini et al. (2006), a possible candidate is a multivariate
gamma distribution which however imposes severe restrictions on the contemporaneous correlations between the errors t(i). Alternatively, copula approaches can be used as, e.g., proposed by Heinen and Rengifo (2006) or Cipollini et al. (2006).
In correspondence to the univariate logarithmic MEM, we obtain a logarithmic
VMEM specification by

pq
 log µt =  + A 0 log Yt + A jg(t- j) + B j log µt- j, j=1 j=1

(15)

where g(t- j) = t- j or g(t- j) = log t- j, respectively. Generalized VMEMs can be specified accordingly to Section 2.
A further generalization of VMEM processes has been introduced by Hautsch (2008) and captures mutual (time-varying) dependencies by a subordinated common (latent) factor jointly driving the individual processes. The so-called stochastic MEM can be compactly represented as

Yt = µt  t t ,

(16)

where  t is a (k × 1) vector with elements {ti}, i = 1, . . . , k, log t = a log t-1 + t , t  i.i.d. N(0, 1),

(17)

and t is assumed to be independent of t. Hence, t serves as a common dynamic factor with process-specific impacts i. Then, the elements of µt represent 'genuine' (trade-driven) effects given the latent factor. They are assumed to follow (15) with g(t) = Yt µt-1. The model corresponds to a mixture model and nests important special cases, such as the SV model by Taylor (1982) or the stochastic conditional du-
ration model by Bauwens and Veredas (2004). Applying this approach to jointly model
high-frequency volatilities, trade sizes and trading intensities, Hautsch (2008) shows
that the latent component is a major driving force of cross-dependencies between the
individual processes.

4 Statistical Inference

Define f (Yt(1),Yt(2), . . . ,Yt(k)|Ft-1) as the joint conditional density given Ft-1. Without loss of generality the joint density can be decomposed into

f (Yt(1),Yt(2), . . . ,Yt(k)|Ft-1) = f (Yt(1)|Yt(2), . . . ,Yt(k); Ft-1) × f (Yt(2)|Yt(3), . . . ,Yt(k); Ft-1) × f (Ytk|Ft-1).

(18) (19) (20)

6

Then, the log likelihood function is defined by

Tk

 L ( ) d=ef

log f (Yt( j)|Yt( j+1), . . . ,Yt(k); Ft-1).

t=1 j=1

(21)

For instance, if Yt( j)|Yt( j+1), . . . ,Yt(k); Ft-1 follows a generalized F distribution with parameters a( j), m( j) and ( j), the corresponding log likelihood contribution is given
by

log f (Yt( j)|Yt( j+1), . . . ,Yt(k); Ft-1)

(22)

= log[(m( j) + ( j))/{(m( j))(( j))}] + log a( j) - a( j)m( j) log µ~t( j) (23)

+ (a( j)m( j) - 1) logYt( j) - (( j) + m( j)) log ( j) + Yt( j)/µ~t( j)

(24)

+ ( j) log(( j)),

(25)

where

µ~ t(

j)

=

(
µt

j)/

(a(

j),

m(

j),

(

j))

and



(·)

defined

as

above.

Constructing the likelihood based on an exponential distribution leads to the quasi

likelihood function with components

T

log f (Yt( j)|Yt( j+1), . . . ,Yt(k); Ft-1) = -

log

(
µt

j)

+

Yt(

j)/µt(

j)

,

t=1

where the score and Hessian are given by



log

f (Yt( j)|Yt( j+1), . . . ,Yt(k); Ft-1)   ( j)

=

T
-
t=1

( j)
 µt   ( j)

1
( j)
µt

Yt( j)
( j)

-

1

µt

 2 log f (Yt( j)|Yt( j+1), . . . ,Yt(k); Ft-1) = T



  ( j)  ( j)

t=1   ( j)

1

( j)
 µt

( j)
µt



 ( j)

-

1

( j) ( j)
 µt  µt

( j)
µt



 ( j)



 ( j)

Yt( j)
( j)2
µt

.

,

Yt( j)
( j)

-

1

µt

Building on the results by Bollerslev and Wooldridge (1992) and Lee and Hansen (1994), Engle (2000) shows the consistency and asymptotic normality of ^ , where the asymptotic covariance corresponds to the Bollerslev and Wooldridge (1992) QML covariance matrix.
Model evaluation can be straightforwardly performed by testing the dynamic and distributional properties of the model residuals

et( j) d=ef ^t( j) = Yt( j)/µ^t( j).

(26)

Under correct model specification, the series et( j) must be i.i.d. with distribution D(·). Portmanteau statistics such as the Ljung-Box statistic (Ljung and Box (1978)) based on (de-meaned) MEM residuals can be used to analyze whether the specification is able to capture the dynamic properties of the process. The distributional properties

7

can be checked based on QQ-plots. Engle and Russell (1998) propose a simple test for no excess dispersion implied by an exponential distribution using the statistic

 n

(^e2(j) - 1)/~ ( j)

,

where ^e2(j) is the sample variance of et( j) and ~ ( j) is the standard deviation of (t( j) -

1)2. Under the null hypothesis of an exponential totically normally distributed with e2(j) = 1 and

di~st(rji)bu2t=ion, t8h.e

test

statistic

is

asymp-

Alternatively, probability integral transforms can be used to evaluate the in-sample

goodness-of-fit, see, e.g., Bauwens et al. (2004). Building on the work by Rosenblatt

(1952), Diebold et al. (1998) show that

qt( j) d=ef


fe(j) (s)ds

-

must be i.i.d. U[0, 1]. Alternative ways to evaluate MEMs are Lagrange Multiplier tests as proposed by Meitz and Tera¨svirta (2006), (integrated) conditional moment tests as discussed by Hautsch (2006) or nonparametric tests as suggested by Fernandes and Grammig (2006).

5 High-Frequency Volatility and Liquidity Dynamics
In this section, we will illustrate an application of the VMEM to jointly model return volatilities, average trade sizes, the number of trades as well as average trading costs in intra-day trading. We use a data base extracted from the electronic trading of the Australian Stock Exchange (ASX) which is also used by Hall and Hautsch (2006, 2007). The ASX is a continuous double auction electronic market where the continuous trading period between 10:09 a.m. and 4:00 p.m. is preceded and followed by a call auction. During continuous trading, any buy (sell) order entered that has a price that is greater than (less than) or equal to existing queued buy (sell) orders, will execute immediately and will result in a transaction as long as there is no more buy (sell) order volume that has a price that is equal to or greater (less) than the entered buy (sell) order. In case of partial execution, the remaining volume enters the limit order queues. Limit orders are queued in the buy and sell queues according to a strict price-time priority order and may be entered, deleted and modified without restriction. For more details on ASX trading, see Hall and Hautsch (2007).
Here, we use data from completely reconstructed order books for the stocks of the National Australian Bank (NAB) and BHP Billiton Limited (BHP) during the trading period July and August 2002 covering 45 trading days. In order to reduce the impact of opening and closure effects, we delete all observations before 10:15 a.m. and after 3:45 p.m. To reduce the complexity of the model we restrict our analysis to equidistant observations based on one-minute aggregates. For applications of MEMs to irregularly spaced data, see Manganelli (2005) or Engle (2000).
Table 1 shows summary statistics for log returns, the average trade size, the number of trades, and the average (time-weighted) trading costs. The log returns correspond to the residuals of an MA(1) model for differences in log transaction prices. This preadjustment removes the effects of the well-known bid-ask bounce causing negative
8

first-order serial correlation, see Roll (1984). The trading costs are computed as the hypothetical trading costs of an order of the size of 10, 000 shares in excess to the trading costs which would prevail if investors could trade at the mid-quote. They are computed as a time-weighted average based on the average ask and bid volume pending in the queues and yield natural measures of transaction costs induced by a potentially lacking liquidity supply. Conversely, trade sizes and the number of trades per interval indicate the liquidity demand in the market.
We observe that high-frequency log returns reveal similar stochastic properties as daily log returns with significant overkurtosis and slight left-skewness. For the average trade size and the number of trades per interval we find a highly right-skewed distribution with a substantial proportion of observations being zero. These observations stem from tranquil trading periods, where market orders do not necessarily occur every minute. As illustrated below, these periods typically happen around noon causing the well-known 'lunch-time dip'. On the other hand, we also find evidence for very active trading periods resulting in a high speed of trading and large average trade sizes. On average, the number of trades per one-minute interval is around 2.5 and 3.5 for NAB and BHP, respectively, with average trade sizes of approximately 2, 300 and 5, 800 shares, respectively. The excess trading costs associated with the buy/sell transaction of 10, 000 shares are on average around 60 ASD for BHP and 188 ASD for NAB. Hence, on average, excess trading costs for NAB are significantly higher than for BHP which is caused by a higher average bid-ask spread and a lower liquidity supply in the book. The Ljung-Box statistics indicate the presence of a strong serial dependence in volatilities and all liquidity variables, and thus reveal the well-known clustering structures in trading processes. The significant Ljung-Box statistics for log returns are induced by the bid-ask bounce effect causing significantly negative first order autocorrelation. Obviously, the MA(1) filter does not work very well in the case of NAB data. Alternatively, one could use higher order MA-filter. The empirical autocorrelations (ACFs) shown in Figure 1 confirm a relatively high persistence in volatilities and liquidity variables indicated by the Ljung-Box statistics. A notable exception is the process of trade sizes for NAB revealing only weak serial dependencies. Figure 2 displays the cross-autocorrelation functions (CACFs) between the individual variables. It turns out that squared returns are significantly positively (cross-)autocorrelated with the number of trades and excess trading costs, and ­ to less extent ­ with the average trade size. This indicates strong dynamic interdependencies between volatility and liquidity demand as well as supply. Similarly, we also observe significantly positive CACFs between trade sizes and the speed of trading. Hence, periods of high liquidity demand are characterized by both high trade sizes and a high trading intensity. Conversely, the CACFS between trading costs and trade sizes as well as between trading costs and the trading intensity are significantly negative. Ceteris paribus this indicates that market participants tend to exploit periods of high liquidity supply, i.e. they trade fast and high volumes if the trading costs are low and thus liquidity supply is high.
Figure 1: Sample ACF of squared log returns (SR), trade size (TS), number of trades (NT), and trade costs (TC)(from top to bottom) for BHP (left) and NAB (right). The x-axis shows the lags. The broken line shows the asymptotic 95% confidence intervals.
A typical feature of high-frequency data is the strong influence of intra-day sea-
9

Obs. Mean S.D. Min Max q10 q90 Kurtosis LB20 LB20(SR)

LR 14520 6.81E-7 7.41E-2 -0.50
0.44 -0.10 0.10 5.23 29.61 2073.77

BHP TS
14520 5811.52 8378.09
0 250000
0 13475
1585.04
-

NT 14520
3.53 3.20
0 24
0 8 34907.77 -

TC 14520 60.20 18.47
2.99 231.38
5.00 8.80
22422.32
-

LR 14503 -3.19E-4 3.83E-2 -0.31
0.38 -0.04 0.04 9.85 939.05 2808.75

NAB

TS NT

14503 14503

2295.24

2.69

7228.38

2.72

00

757500.50

23

00

5150

6

--

95.94 22825.72

--

TC 14503 188.85 97.37 16.52 1043.35 84.48 317.48
23786.09
-

Table 1: Descriptive statistics of log returns (LR), trade sizes (TS), number of trades (NT), and trade costs (TC) for BHP and NAB. Evaluated statistics: mean value, standard deviation (S.D.), minimum and maximum, 10%- and 90%-quantile (q10 and q90, respectively), kurtosis, and the Ljung-Box statistic (associated with 20 lags). LB20(SR) represents the Ljung-Box statistic computed for the squared log returns (SR).

Figure 2: Sample CACF for BHP (top) and NAB (bottom). The solid, dash-dotted and dashed lines show the CACF between TC and SR, TC and TS, TC and NT, respectively, on the left side and between SR and TS, SR and NT, TS and NT, respectively, on the right side. The dotted line shows the asymptotic 95% confidence interval. The x-axis shows the lags.

sonalities which is well documented by a wide range of empirical studies. For detailed illustrations, see Bauwens and Giot (2001) or Hautsch (2004). One possibility to account for intra-day seasonalities is to augment the specification of µt by appropriate regressors. An alternative way is to adjust for seasonalities in a first step. Though the effect of a pre-adjustment on the final parameter estimates is controversially discussed in the literature (see e.g. Veredas et al. (2001)), most empirical studies prefer the two-stage method since it reduces model complexity and the number of parameters to be estimated in the final step. Here, we follow this proceeding and adjust the individual variables Yt(i) for deterministic intraday-seasonalities based on cubic spline regressions with 30-minute nodes between 10:30 and 15:30. Figure 3 shows the resulting estimated seasonality components. Confirming empirical findings from other markets, we observe that the liquidity demand follows a distinct U-shape pattern with a clear dip around lunch time. However, a clearly different picture is revealed for the trading costs. Obviously, the liquidity supply is lowest during the morning and around noon inducing high trading costs. Then, (excess) trading costs decline during the afternoon and reach a minimum before market closure. This indicates that not only liquidity demand but also liquidity supply is highest before the end of the trading period. For volatility, we observe a rather typical picture with the highest volatility after the opening of the market and (but to less extent) before closure. The high volatility at morning is clearly associated with information processing during the first minutes of trading.
Conceptual difficulties are caused by the relatively high number of zeros in the liquidity demand variables which cannot be captured by a standard MEM requiring

10

Figure 3: Deterministic intra-day seasonality patterns for SR, TS, NT and TC (from top to bottom) for BHP (left) and NAB (right). The seasonality components are estimated using cubic spline functions based on 30-minute nodes. The x-axis gives the time of the day.

positive random variables. In order to account for zeros, we augment a Log-VMEM by corresponding dummy variables:

log µt =  + A 0[(log Yt)

1{Yt

>0}]

+

A

0 0

1{Yt =0}

pp

 +

A j[g(t- j) 1{Yt-1>0}] +

A

0 j

1{Yt-1=0}

j=1 j=1

q
+ B j log µt- j, j=1

(27) (28)
(29)

where 1{Yt>0}} and 1Yt=0 denote k × 1 vectors of indicator variables indicating nonzeor and zero realizations, respectively, and A 0j, j = 0, . . . , p, are corresponding k × k parameter matrices.
Then, the log likelihood function is split up into two parts yielding

Tk

 L ( ) =

log f (Yt( j)|Yt( j+1), . . . ,Yt(k);Yt( j) > 0, Ft-1)

t=1 j=1

× log P[Yt( j) > 0|Yt( j+1), . . . ,Yt(k); Ft-1].

(30) (31)

If both likelihood components have no common parameters, the second part can be

maximized separately based on a binary choice model including past (and contempo-

raneous) variables as regressors. Then, the first log likelihood component is associated

only with positive values and corresponds to the log likelihood given by (27).

We estimate a four-dimensional Log-VMEM for squared log returns, trade sizes,

the number of trades and transaction costs standardized by their corresponding season-

ality components. For simplicity and to keep the model tractable, we restrict our analy-

sis to a specification of the order p = q = 1. The innovation terms are chosen as g(t) =

t . For the process of squared returns, Yt(1) = rt2, we assume Yt(1)|Yt(2), . . . ,Yt(4), Ft-1 

N(0,

(1)
µt

).

Accordingly,

for

Yt( j),

j



{2, 3, 4},

we

assume

Yt( j)|Yt( j+1), . . . ,Yt(4), Ft-1



Exp(µt( j)). Though it is well-known that both the normal and the exponential distribu-

tion are not flexible enough to capture the distributional properties of high-frequency

trading processes, they allow for a QML estimation of the model.

Hence, the adjustments for zero variables have to be done only in the liquidity

components but not in the return component. Moreover, note that there are no zeros

in the trading cost component. Furthermore, zero variables in the trade size and the

number of trades per construction always occur simultaneously. Consequently, we can

only

identify

the

(2, 3)-element

in

A

0 0

and

one

of

the

two

middle

columns

in

A

01,

where

all

other

parameters

in

A

0 0

and

A

0 1

are

set

to

zero.

For the sake of brevity we do not show the estimation results of the binary choice

component but restrict our analysis to the estimation of the MEM. Figure 2 shows the

estimation results for BHP and NAB based on a specification with fully parameterized

matrix A 1 and diagonal matrix B1.

11

Coeff.
1
2
3
4 A0,12 A0,13 A0,14 A0,23 A0,24 A0,34 A00,12 A1,11 A1,12 A1,13 A1,14 A1,21 A1,22 A1,23 A1,24 A1,31 A1,32 A1,33 A1,34 A1,41 A1,42 A1,43 A1,44 A01,21 A01,22 A10,23 A10,24 B1,11 B1,22 B1,33 B1,44 Log Likelihood
BIC

BHP Coeff. Std. err. -0.0673 0.0663 0.1921 0.0449 -0.4722 0.1009 -0.4914 0.1066 0.0549 0.0092 0.3142 0.0173 0.4685 0.0489 0.0673 0.0074 -0.1002 0.0289 -0.2181 0.0618 -3.8196 0.0402
0.1446 0.0080 0.0043 0.0090 -0.0939 0.0173 0.1487 0.0602 0.0004 0.0034 0.0488 0.0049 -0.0377 0.0115 -0.1911 0.0398 0.0100 0.0053 0.0095 0.0071 0.1088 0.0152 0.3420 0.0932 0.0064 0.0113 0.0091 0.0163 0.0524 0.0321 0.4256 0.0898 1.1467 0.0911
0.1497 0.0212
0.0946 0.0318
-0.0006 0.0755
0.4027 0.0252 0.7736 0.0179 0.9731 0.0074 0.5369 0.1024
-60211 -60378

NAB Coeff. Std. err. 0.0023 0.0302 0.1371 0.0254 -0.1226 0.0432 -0.5773 0.0485 0.1249 0.0056 0.6070 0.0122 0.7876 0.0094 0.0531 0.0070 0.0176 0.0093 -0.0235 0.0123 -1.5086 0.0176
0.0804 0.0038 0.0804 0.0041 0.2036 0.0125 -0.0833 0.0214 -0.0002 0.0015 0.0259 0.0025 -0.0116 0.0093 -0.1329 0.0226 -0.0022 0.0020 0.0045 0.0031 0.0894 0.0109 0.0341 0.0377 0.0044 0.0067 0.0081 0.0081 0.0537 0.0249 0.5105 0.0431 -0.5181 0.0204
0.0341 0.0134
0.0985 0.0132
0.0115 0.0579
0.2616 0.0078 0.9109 0.0081 0.9673 0.0070 0.7832 0.0374
-58622 -58790

Table 2: Quasi-maximum likelihood estimation results of a MEM for seasonally adjusted (i) squared (bid-ask bounce adjusted) log returns, (ii) average trade sizes, (iii) number of trades, and (iv) average trading costs per one-minute interval. Standard errors are computed based on the OPG covariance matrix.

12

Mean S.D. LB20
Mean S.D. LB20

SR 1.000 1.963 1159.456
SR 1.000 1.568 63.559

Descriptive statistics of seasonally adjusted data

BHP NAB

TS NT

TC SR TS

NT

1.001

1.000

1.000 1.002 1.001

1.000

1.528

0.834

0.300 3.152 2.644

0.991

202.001 8782.762 19210.412 800.808 124.806 3775.762

Descriptive statistics of MEM-residuals

BHP NAB

TS NT

TC SR TS

NT

1.000

1.000

1.000 1.000 0.999

1.001

1.348

0.629

0.228 2.595 2.280

0.675

61.388 519.348 1568.428 63.455 14.201 751.317

TC 0.999 0.507 19707.831
TC 1.000 0.386 163.426

Table 3: Summary statistics of the seasonality adjusted time series and the corresponding MEM residuals for BHP and NAB.

We can summarize the following major findings: First, we observe significant mu-

tual correlations between nearly all variables. Confirming the descriptive statistics

above, volatility is positively correlated with liquidity demand and liquidity supply.

Hence, active trading as driven by high volumes and high trading intensities is ac-

companied by high volatility. Simultaneously, as indicated by significantly negative

estimates

of

A

0 24

and

A

0 34

,

these

are

trading

periods

which

are

characterized

by

low

transaction costs.

Second, as indicated by the diagonal elements in A 1 and the elements in B1, all

trading components are strongly positively autocorrelated but are not very persistent.

As also revealed by the descriptive statistics, the strongest first order serial dependence

is observed for the process of trading costs. The persistence is highest for trade sizes

and trading intensities.

Third, we find Granger causalities from liquidity variables to future volatility. High

trade sizes predict high future return volatilities. However, the impact of trading in-

tensities and trading costs on future volatility is less clear. Here, we find contradictive

results for both stocks. Conversely, we do not observe any predictability of return

volatility for future liquidity demand and supply. For both stocks all corresponding

coefficients are insignificant.

Fourth, trade sizes are significantly negatively driven by past trading intensities

and past trading costs. This finding indicates that a high speed of trading tends to

reduce trade sizes over time. Similarly, increasing trading costs deplete the incentive

for high order sizes but on the other hand increase the speed of trading. Hence, market

participants observing a low liquidity supply reduce trade sizes but trade more often.

A possible explanation for this finding is that investors tend to break up large orders

into sequences of small orders.

Fifth, (excess) transaction costs depend only on their own history but not on the

lagged volatility or liquidity demand. This indicates that liquidity supply is difficult to

predict based on the history of the trading process.

Sixth, as shown by the summary statistics of the MEM residuals, the model cap-

tures a substantial part of the serial dependence in the data. This is indicated by a sig-

13

nificant reduction of the corresponding Ljung-Box statistics. Nevertheless, for some processes, there is still significant remaining serial dependence in the residuals. This is particularly true for the trading cost and trading intensity components for which obviously higher order dynamics have to be taken into account. For the sake of brevity we refrain from showing results of higher parameterized models. Allowing for more dynamic and distributional flexibility further improves the goodness-of-fit, however, makes the model less tractable and less stable for out-of-sample forecasts.
6 Conclusion
In summary, we find strong dynamic interdependencies and causalities between highfrequency volatility, liquidity demand, and liquidity supply. In particular, the high trade sizes are able to predict high future volatilities whereas the return volatility appears not to give rise to future liquidity demand and supply dynamic. The effects of the trading intensities and trading costs on future volatilities could not be uniformly concluded although these effects seem to be significant. An interesting finding is that the high trade costs, associated with low liquidity supply, lead to a decrease of the trade sizes and simultaneously to an increase of the trade intensities. However, the dynamic of the trade costs seems to be mostly driven by its own history. Last but not at least we find a higher persistence by liquidity variables than by return volatilities. Hence, these results might serve as valuable input for trading strategies and (automated) trading algorithms.
References
Bauwens, L. and N. Hautsch (2008). Modelling financial high frequency data with point processes. In: Handbook of Financial Time Series (T.G. Andersen, R.A. Davis, J.-P. Kreiss and T. Mikosch, Eds.). Springer Verlag.
Bauwens, L., P. Giot, J. Grammig and D. Veredas (2004). A comparison of financial duration models via density forecasts. International Journal of Forecasting 20, 589­609.
Bauwens, Luc and David Veredas (2004). The stochastic conditional duration model: A latent factor model for the analysis of financial durations. Journal of Econometrics 119, 381­412.
Bauwens, Luc and Pierre Giot (2000). The logarithmic ACD model: An application to the Bid/Ask quote process of two NYSE stocks. Annales d'Economie et de Statistique 60, 117­149.
Bauwens, Luc and Pierre Giot (2001). Econometric Modelling of Stock Market Intraday Activity. Kluwer.
Bollerslev, T. (1986). Generalized autoregressive conditional heteroskedasticity. Journal of Econometrics 31, 307­327.
14

Bollerslev, Tim and Jeffrey Wooldridge (1992). Quasi-maximum likelihood estimation and inference in dynamic models with time varying covariances. Econometric Reviews 11, 143­172.
Cipollini, F., R.F. Engle and G.M. Gallo (2006). Vector multiplicative error models: Representation and inference. Technical Report 2006/331. NBER.
Diebold, F. X., T. A. Gunther and A. S. Tay (1998). Evaluating density forecasts, with applications to financial risk management. International Economic Review 39, 863­883.
Engle, R.F. (1982). Autoregressive conditional heteroskedasticity with estimates of the variance of united kingdom inflation. Econometrica 50, 987­1008.
Engle, R.F. (2000). The econometrics of ultra-high frequency data. Econometrica 68, 1­22.
Engle, R.F. (2002). New frontiers for arch models. Journal of Applied Econometrics 17, 425­446.
Engle, R.F. and G.M. Gallo (2006). A multiple indicators model for volatility using intra-daily data. Journal of Econometrics 131, 3­27.
Engle, Robert F. and Jeffrey R. Russell (1997). Forecasting the frequency of changes in quoted foreign exchange prices with autoregressive conditional duration model. Journal of Empirical Finance 4, 187­212.
Engle, Robert F. and Jeffrey R. Russell (1998). Autoregressive conditional duration: A new model for irregularly spaced transaction data. Econometrica 66, 1127­1162.
Fernandes, M. and J. Grammig (2006). A family of autoregressive conditional duration models. Journal of Econometrics 130, 1­23.
Hall, A. D. and N. Hautsch (2006). Order aggressiveness and order book dynamics. Empirical Economics 30, 973­1005.
Hall, A. D. and N. Hautsch (2007). Modelling the buy and sell intensity in a limit order book market. Journal of Financial Markets 10(3), 249­286.
Hautsch, N. (2003). Assessing the risk of liquidity suppliers on the basis of excess demand intensities. Journal of Financial Econometrics 1(2), 189­215.
Hautsch, N. (2004). Modelling Irregularly Spaced Financial Data - Theory and Practice of Dynamic Duration Models. Springer, Berlin.
Hautsch, N. (2006). Testing the conditional mean function of autoregressive conditional duration models. Technical Report 2006-06. Finance Research Unit, Department of Economics, University of Copenhagen.
Hautsch, N. (2008). Capturing common components in high-frequency financial time series: A multivariate stochastic multiplicative error model. Journal of Economic Dynamics and Control, forthcoming.
15

Heinen, Andre´as and Erick Rengifo (2006). Multivariate autoregressive modelling of time series count data using copulas. Journal of Empirical Finance 14, 564­583.
Lee, S. and B. Hansen (1994). Asymptotic theory for the GARCH(1,1) quasimaximum likelihood estimator. Econometric Theory 10, 29­52.
Ljung, G. M. and G. E. P. Box (1978). On a measure of lack of fit in time series models. Biometrika 65, 297­303.
Manganelli, Simone (2005). Duration, volume and volatility impact of trades. Journal of Financial Markets 8, 377­399.
Meitz, M. and T. Tera¨svirta (2006). Evaluating models of autoregressive conditional duration. Journal of Business and Economic Statistics 24, 104­124.
Nelson, D.B. (1991). Conditional heteroskedasticity in asset returns: A new approach. Journal of Econometrics 43, 227­251.
Roll, Richard (1984). A simple implicit measure of the effective bid-ask spread in an efficient market. Journal of Finance 39, 1127­1139.
Rosenblatt, M. (1952). Remarks on a multivariate transformation. Annals of Mathematical Statistics 23, 470­472.
Taylor, S. J. (1982). Financial returns modelled by the product of two stochastic processes - a study of daily sugar prices. In: Time Series Analysis: Theory and Practice (O. D. Anderson, Ed.). North-Holland, Amsterdam.
Veredas, D., J. Rodriguez-Poo and A. Espasa (2001). On the (intradaily) seasonality, dynamics and durations zero of a financial point process. Technical Report WS013321. Universidad Carlos III, Departamento de Estad´istica y Econometr´ia.
16

SFB 649 Discussion Paper Series 2008
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.

001 "Testing Monotonicity of Pricing Kernels" by Yuri Golubev, Wolfgang

Härdle and Roman Timonfeev, January 2008.

002 "Adaptive pointwise estimation in time-inhomogeneous time-series

models" by Pavel Cizek, Wolfgang Härdle and Vladimir Spokoiny,

January 2008.

003 "The Bayesian Additive Classification Tree Applied to Credit Risk

Modelling" by Junni L. Zhang and Wolfgang Härdle, January 2008.

004 "Independent Component Analysis Via Copula Techniques" by Ray-Bing

Chen, Meihui Guo, Wolfgang Härdle and Shih-Feng

Huang, January

2008.

005 "The Default Risk of Firms Examined with Smooth Support Vector

Machines" by Wolfgang Härdle, Yuh-Jye Lee, Dorothea Schäfer

and Yi-Ren Yeh, January 2008.

006 "Value-at-Risk and Expected Shortfall when there is long range

dependence" by Wolfgang Härdle and Julius Mungo, Januray 2008.

007 "A Consistent Nonparametric Test for Causality in Quantile" by

Kiho Jeong and Wolfgang Härdle, January 2008.

008 "Do Legal Standards Affect Ethical Concerns of Consumers?" by Dirk

Engelmann and Dorothea Kübler, January 2008.

009 "Recursive Portfolio Selection with Decision Trees" by Anton Andriyashin,

Wolfgang Härdle and Roman Timofeev, January 2008.

010 "Do Public Banks have a Competitive Advantage?" by Astrid Matthey,

January 2008.

011 "Don't aim too high: the potential costs of high aspirations" by Astrid

Matthey and Nadja Dwenger, January 2008.

012 "Visualizing exploratory factor analysis models" by Sigbert Klinke and

Cornelia Wagner, January 2008.

013 "House Prices and Replacement Cost: A Micro-Level Analysis" by Rainer

Schulz and Axel Werwatz, January 2008.

014 "Support Vector Regression Based GARCH Model with Application to

Forecasting Volatility of Financial Returns" by Shiyi Chen, Kiho Jeong and

Wolfgang Härdle, January 2008.

015 "Structural Constant Conditional Correlation" by Enzo Weber, January

2008.

016 "Estimating Investment Equations in Imperfect Capital Markets" by Silke

Hüttel, Oliver Mußhoff, Martin Odening and Nataliya Zinych, January

2008.

017 "Adaptive Forecasting of the EURIBOR Swap Term Structure" by Oliver

Blaskowitz and Helmut Herwatz, January 2008.

018 "Solving, Estimating and Selecting Nonlinear Dynamic Models without

the Curse of Dimensionality" by Viktor Winschel and Markus Krätzig,

February 2008.

019 "The Accuracy of Long-term Real Estate Valuations" by Rainer Schulz,

Markus Staiber, Martin Wersing and Axel Werwatz, February 2008.

020 "The Impact of International Outsourcing on Labour Market Dynamics in

Germany" by Ronald Bachmann and Sebastian Braun, February 2008.

021 "Preferences for Collective versus Individualised Wage Setting" by Tito

Boeri and Michael C. Burda, February 2008.

SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

022 "Lumpy Labor Adjustment as a Propagation Mechanism of Business Cycles" by Fang Yao, February 2008.
023 "Family Management, Family Ownership and Downsizing: Evidence from S&P 500 Firms" by Jörn Hendrich Block, February 2008.
024 "Skill Specific Unemployment with Imperfect Substitution of Skills" by Runli Xie, March 2008.
025 "Price Adjustment to News with Uncertain Precision" by Nikolaus Hautsch, Dieter Hess and Christoph Müller, March 2008.
026 "Information and Beliefs in a Repeated Normal-form Game" by Dietmar Fehr, Dorothea Kübler and David Danz, March 2008.
027 "The Stochastic Fluctuation of the Quantile Regression Curve" by Wolfgang Härdle and Song Song, March 2008.
028 "Are stewardship and valuation usefulness compatible or alternative objectives of financial accounting?" by Joachim Gassen, March 2008.
029 "Genetic Codes of Mergers, Post Merger Technology Evolution and Why Mergers Fail" by Alexander Cuntz, April 2008.
030 "Using R, LaTeX and Wiki for an Arabic e-learning platform" by Taleb Ahmad, Wolfgang Härdle, Sigbert Klinke and Shafeeqah Al Awadhi, April 2008.
031 "Beyond the business cycle ­ factors driving aggregate mortality rates" by Katja Hanewald, April 2008.
032 "Against All Odds? National Sentiment and Wagering on European Football" by Sebastian Braun and Michael Kvasnicka, April 2008.
033 "Are CEOs in Family Firms Paid Like Bureaucrats? Evidence from Bayesian and Frequentist Analyses" by Jörn Hendrich Block, April 2008.
034 "JBendge: An Object-Oriented System for Solving, Estimating and Selecting Nonlinear Dynamic Models" by Viktor Winschel and Markus Krätzig, April 2008.
035 "Stock Picking via Nonsymmetrically Pruned Binary Decision Trees" by Anton Andriyashin, May 2008.
036 "Expected Inflation, Expected Stock Returns, and Money Illusion: What can we learn from Survey Expectations?" by Maik Schmeling and Andreas Schrimpf, May 2008.
037 "The Impact of Individual Investment Behavior for Retirement Welfare: Evidence from the United States and Germany" by Thomas Post, Helmut Gründl, Joan T. Schmit and Anja Zimmer, May 2008.
038 "Dynamic Semiparametric Factor Models in Risk Neutral Density Estimation" by Enzo Giacomini, Wolfgang Härdle and Volker Krätschmer, May 2008.
039 "Can Education Save Europe From High Unemployment?" by Nicole Walter and Runli Xie, June 2008.
042 "Gruppenvergleiche bei hypothetischen Konstrukten ­ Die Prüfung der Übereinstimmung von Messmodellen mit der Strukturgleichungsmethodik" by Dirk Temme and Lutz Hildebrandt, June 2008.
043 "Modeling Dependencies in Finance using Copulae" by Wolfgang Härdle, Ostap Okhrin and Yarema Okhrin, June 2008.
044 "Numerics of Implied Binomial Trees" by Wolfgang Härdle and Alena Mysickova, June 2008.
045 "Measuring and Modeling Risk Using High-Frequency Data" by Wolfgang Härdle, Nikolaus Hautsch and Uta Pigorsch, June 2008.
046 "Links between sustainability-related innovation and sustainability management" by Marcus Wagner, June 2008.
SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

047 "Modelling High-Frequency Volatility and Liquidity Using Multiplicative Error Models" by Nikolaus Hautsch and Vahidin Jeleskovic, July 2008.
SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

