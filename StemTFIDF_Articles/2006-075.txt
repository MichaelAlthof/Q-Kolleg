BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2006-075
Inhomogeneous Dependency Modelling
with Time Varying Copulae
Enzo Giacomini* Wolfgang K. Härdle* Ekaterina Ignatieva* Vladimir Spokoiny**
*CASE ­ Center for Applied Statistics and Economics Humboldt-Universität zu Berlin, Berlin, Germany
** Weierstrass Institute for Applied Analysis and Stochastics, Berlin, Germany
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universität zu Berlin Spandauer Straße 1, D-10178 Berlin

Inhomogeneous Dependency Modelling with Time Varying Copulae
Enzo Giacomini1, Wolfgang K. H¨ardle1, Ekaterina Ignatieva1 and Vladimir Spokoiny2
1 CASE ­ Center for Applied Statistics and Economics Humboldt-Universit¨at zu Berlin,
Spandauer Straße 1, 10178 Berlin, Germany 2 Weierstrass Institute for Applied Analysis and Stochastics
Mohrenstraße 39, 10117 Berlin, Germany
Abstract
Measuring dependence in a multivariate time series is tantamount to modelling its dynamic structure in space and time. In the context of a multivariate normally distributed time series, the evolution of the covariance (or correlation) matrix over time describes this dynamic. A wide variety of applications, though, requires a modelling framework different from the multivariate normal. In risk management the non-normal behaviour of most financial time series calls for nonlinear (i.e. non-gaussian) dependency. The correct modelling of non-gaussian dependencies is therefore a key issue in the analysis of multivariate time series. In this paper we use copulae functions with adaptively estimated time varying parameters for modelling the distribution of returns, free from the usual normality assumptions. Further, we apply copulae to estimation of Value-at-Risk (VaR) of a portfolio and show its better performance over the RiskMetrics approach, a widely used methodology for VaR estimation.
JEL classification: C 14 Keywords: Value-at-Risk, time varying copula, adaptive estimation, nonparametric estimation Financial support from Deutsche Forschungsgemeinschaft via SFB 649 "Economic Risk" is gratefully acknowledged.
1

1 Introduction

Time series of financial data are high dimensional and have typically a non-gaussian behavior. The classical linear modelling therefore fails to reproduce the stylized facts (i.e. fat tails, asymmetry), Granger (2003). A correct understanding of the time varying multivariate (conditional) distribution is vital to many standard applications in finance: portfolio selection, option pricing, asset pricing models, Value-at-Risk (VaR) etc.

The dependency (over time) of asset returns is especially important in risk management since

the profit and loss (P&L) function determines the Value-at-Risk. More precisely, Value-at-Risk

of a portfolio is determined by the multivariate distribution of risk factor increments. If w =

(w1, . . . , wd)  Rd denotes a portfolio of positions on d assets and St = (S1,t, . . . , Sd,t) a non-

negative random vector representing the prices of the assets at time t, the value Vt of the portfolio

w is given by

d
Vt = wj Sj,t.
j=1

The random variable

Lt = (Vt - Vt-1), Sj,0 = 0

(1.1)

called profit and loss (P&L) function, expresses the change in the portfolio value between two subsequent time points. Defining the log-returns Xt = log St - log St-1, (1.1) can be written as

d
Lt = wjSj,t-1 {exp(Xj,t) - 1} .
j=1

(1.2)

The distribution function of Lt is given by Ft,Lt(x) = Pt(Lt  x). The Value-at-Risk at level  from a portfolio w is defined as the -quantile from Ft,Lt:

V aRt() = Ft-,L1t ().

(1.3)

2

theta

4 3.5
3 2.5
2 1.5
1 0.5
0 2001

Copula parameter theta

2002

2003
time

2004

2005

Figure 1: Dependence over time for DaimlerChrysler, Volkswagen, Bayer, BASF, Allianz and Mu¨nchener Ru¨ckversicherung, 20000101-20041231.
It follows from (1.2) and (1.3) that Ft,Lt depends on the specification of the d-dimensional distribution of the risk factors Xt. Thus, modelling their distribution over time is essential to obtain the quantiles (1.3).
The RiskMetrics technique, a widely used methodology for VaR estimation assumes that the logreturns follow a multivariate normal distribution. Here L(Xt) = Nd(0, t) a d- dimensional multivariate distribution. A more general approach is based on copulae which avoids the procrustes bed of a normality assumptions resulting in better fits of the empirical characteristics (e.g. fat tails, tail dependency) of financial returns. Modelling the distribution of returns by copulae with time varying parameters, can therefore be expected to perform better. The question though is how to steer the time varying copulae parameters. This is exactly the focus of this paper.
Figure 1 shows the time varying copula parameter for DaimlerChrysler, Volkswagen, Bayer, BASF, Allianz and Mu¨nchener Ru¨ckversicherung from 1.Jan 2000 (20000101) to 31.Dec 2004 (20041231). In contrast the "global" copula parameter is shown by a constant horizontal line. The "local"
3

choice of copula is performed via an adaptive estimation method based on Spokoiny (2007). The adaptive estimation is based on the assumption of local homogeneity: for every time point there exists an interval of time homogeneity in which the copula parameter can be well approximated by a constant. This interval is recovered from the data using local change point analysis. For a stock portfolio, we estimate copulae with time varying parameters and simulate the VaR accordingly. Backtesting underlines the improved performance of the proposed adaptive time varying copulae fitting.
This paper is organized as follows: section 2 presents the basic copulae definitions and introduces modelling log-returns with copulae. Section 3 discusses the VaR and its estimation procedure and section 4 describes three possible copulae estimation procedures. The adaptive estimation and the moving window approach are presented in section 5 and in applied on simulated data in section 6. Using real data, the performance of the copula-based VaR estimation in comparison with RiskMetrics approach is evaluated by means of Backtesting in section 7.
2 A short introduction into copulae
Copula functions have a long history in probability theory and statistics: they are well known and can be found in a variety of the financial literature. The word copula first appears in Sklar (1959), although the ideas related to copulae originate in Hoeffding (1940). Since that, copula funcions have been studied in a variety of the statistics literature such as Nelsen (1998), Mari and Kotz (2001) and Franke et al. (2004). The application of copulae in finance is very recent: the idea first appears in Embrechts et al. (1999) in connection with correlation as a measure of dependence. Futher financial applications can be found in Embrechts et al. (2003b) and Embrechts et al. (2003a). Copulae constitute an essential part in quantitative finance, see H¨ardle et al. (2002), and as mentioned above are recognized as an important tool in VaR calculations.
Copulae represent an elegant concept of connecting marginals with joint cummulative distribution
4

functions. Copulae are functions that join or "couple" multivariate distribution functions to their 1-dimensional marginal distribution functions. They can preliminary be defined as multvariate distribution functions on the unit cube [0, 1]d with uniform-(0,1) marginals. Copulae provide a natural way for measuring the dependence structure between random variables. The most reasonable way to define copulae regarding their applications is obtained by using Sklar's theorem:

Definition 2.1. A d-dimensional copula is a function C : [0, 1]d  [0, 1] with uniform-(0,1)

marginals. If F is a d-dimensional distribution function with marginals F1 . . . , Fd, then there exists

a copula C with

F (x1, . . . , xd) = C{F1(x1), . . . , Fd(xd)}

(2.1)

for every x1, . . . , xd  R. If F1, . . . , Fd are continuous, then C is unique. Converserly, if C is a copula and F1, . . . , Fd are distribution functions, then the function F defined in (2.1) is a joint distribution function with marginals F1, . . . , Fd.

Sklar's theorem reveals that the multivariate dependence structure and the univariate marginals can be modelled separately and that the dependence structure is modelled by means of copulae. For all u = (u1, . . . , ud)  [0, 1]d, every copula C satisfies
W (u1, . . . , ud)  C(u1, . . . , ud)  M (u1, . . . , ud) where

M (u1, . . . , ud) = min(u1, . . . , ud) and

d

W (u1, . . . , ud) = max

ui - d + 1, 0 .

i=1

M (u1, . . . , ud) is called Fr´echet-Hoeffding upper bound and W (u1, . . . , ud) the Fr´echet-Hoeffding lower bound. They have been introduced in Fr´echet (1951). For d = 2, the lower and the upper Fr´echet-Hoeffding bounds are themselves copulae: they introduce the bivariate distribution functions of random vectors (U, 1 - U ) respectively (U, U ) , whereas U is the uniform-(0,1) random

5

variable. In this case, the perfect negative dependence is described by W whereas M describes perfect positive dependence. For d > 2 W is a copula while M is not, see Nelsen (1998) or Embrechts et al. (1999).
If X = (X1, . . . , Xd) is a random vector with distribution X  FX and continuous marginals Xj  FXj , the copula of X is the distribution function CX of u = (u1, . . . , ud) where uj = FXj (xj):

CX (u1, . . . , ud) = FX {FX-11(u1), . . . , FX-d1(ud)}. For an absolutely continuous copula C, the copula density is defined as

c(u1, . . . , ud)

=

dC(u1, . . . , ud) . u1 . . .ud

Some d-dimensional parametric copulae are presented below.

(2.2) (2.3)

2.1 Gaussian copula for Gaussian marginals

The Gaussian copula represents the dependence structure of the multivariate normal distribution. For Y = (Y1, . . . , Yd)  Nd(0, ),  a correlation matrix, the Gaussian copula is:

CGa(u1, . . . , ud) = FY {-1(u1), . . . , -1(ud)}

(2.4)

=

-1 (u1 )
...
-

-1

(ud

)

2

-

d 2

|



|-

1 2

exp

-

- 1 r -1r 2

dr1 . . . drd.

Defining j = -1(uj),  = (1, . . . , d) , the density of the Gaussian copula is

cGa(u1, . . . , ud)

=

|



|-

1 2

exp

-1 2

(-1 - Id)

.

6

The copula parameter is here .

2.2 Gumbel copula



-1 

d



C

(u1,

.

.

.

,

ud)

=

exp

- 

(- log uj)

 , 1    . 

j=1



For  > 1 this copula presents upper tail dependence while for  = 1 it reduces to the product

copula (independence):

d
C(u1, . . . , ud) = uj.
j=1

When  tends to infinity we obtain the Fr´echet-Hoeffding upper bound:

C(u1, . . . , ud) - min(u1, , . . . , ud).

The copula parameter is  and for    it indicates maximal dependence.

2.3 Clayton copula

 

--1

d

 C(u1, . . . , ud) = 

u-j 



-

d

+

 1

, >0

 j=1



where the density of the Clayton copula is:

 -(-1+d)
dd

c(u1, . . . , ud) = {1 + (j - 1)}uj-(+1)  uj- - d + 1

.

j=1 j=1

As the copula parameter  tends to infinity, dependence becomes maximal and as  tends to zero, we have independence. As  goes to 1, copula achieves the lower Fr´echet bound. The Clayton copula can mimic lower tail dependence but no upper tail dependence.

7

2.4 Kullback-Leibler Divergence and Copulae

For our further analysis of a jump in the copula parameter , the concept of Kullback-Leibler divergence will be required. Let X denote a random variable distributed as follows: X  C{FX1(x1), . . . , FXd(xd)}. The density function of X is given by
d
f(x1, . . . , xd) = c(u1, . . . , ud) fi(xi)
i=1
where ui = FXi(xi) and c is the corresponding copula density. The Kullback-Leibler divergence for copulae can be regarded as a distance between two copula densities. It follows from the definition of Kullback-Leibler divergence (for details refer to Spokoiny (2007)):

K(C0 , C1 )

=

E0 log

c0 (U1, . . . , Ud) c1 (U1, . . . , Ud)

where Ui = FXi(Xi)  U [0, 1] are i.i.d. random variables, i = 1, . . . , d. Moreover, for the indepen-

dence copula C(u1, . . . , ud) =

d i=1

ui

with

density

c(u1, . . . , ud)

=

1[0,1]d

it

holds:

K(C, C) = -E[log c(U1, . . . , Ud)] K(C, C) = E[log c(U1, . . . , Ud)].

3 Value-at-Risk and Copulae
The RiskMetrics VaR procedure assumes that the risk factor Xt have a conditional multivariate normal distribution. For the estimation of t the covariance matrix of Xt, RiskMetrics employs the exponentially weighted moving average model (EWMA). More precisely, the conditional distri-

8

bution of log-returns is estimated by N (0, t):
t = (e - 1) e-(t-s)XsXs .
s<t
The parameter  of the model (0 <  < 1) is the so-called decay factor, determined by an optimization procedure. The value 0.05, which according to Morgan/Reuters (1996) provides the best backtesting results, is used as the exponential moving average decay factor.
In the copulae based approach one first corrects the contemporaneous volatility in the log-returns process:
Xj,t = j,tj,t
where t = (1,t, . . . , d,t) are standardised innovations for j = 1, . . . , d and
j2,t = E[Xj2,t | Ft-1]
is the conditional variance given Ft-1. The innovations  = (1, . . . , d) have joint distribution F and j have continuous marginal distributions Fj, j = 1, . . . , d. The innovations  have a distribution function described by
F(1, . . . , d) = C{F1(1), . . . , Fd(d)}
where C is a copula belonging to a parametric family C = {C,   }. For details on the above model specification see Chen and Fan (2004), Chen and Fan (2006), Chen et al. (2006). For the Gaussian copula with Gaussian marginals we recover the conditional Gaussian RiskMetrics framework.
To obtain the Value-at-Risk in this set up, the dependence parameter and distribution function from residuals are estimated from a sample of log-returns and used to generate P&L Monte Carlo samples. Their quantiles at different levels are the estimators for the Value-at-Risk, see Embrechts
9

et al. (1999), Bouy´e et al. (1996). The whole procedure can be summarized as follows: For a portfolio w  Rd and a sample {xj,t}Tt=1, j = 1, . . . , d of log-returns, the Value-at-Risk at level  is estimated according to the following steps, see Giacomini and H¨ardle (2005), Ha¨rdle et al. (2002):
1. determination of innovations {^t}Tt=1 by e.g. deGARCHing 2. specification and estimation of marginal distributions Fj(^j) 3. specification of a parametric copula family C and estimation of the dependence parameter  4. generation of Monte Carlo sample of innovations  and losses L 5. estimation of V aRt(), the empirical -quantile of FL.

4 Copula Estimation

Consider a vector of random variables: X = (X1, ..., Xd) with parametric univariate marginal distributions FXj (xj, j), j = 1, ..., d. With (2.3) and  = (, 1, ..., d) the log-likelihood function is given by:

T Td

(; x1, . . . , xT ) = log c{FX1 (x1,t; 1), . . . , FXd (xd,t; d); } +

log fj (xj,t; j ).

t=1 t=1 j=1

(4.1)

The objective is to maximize this log-likelihood. The estimation can be done in three different ways, see Joe (1997), Durrleman et al. (2000). The full maximum likelihood (FML) method estimates parameter  in one step through
~F ML = arg max ().

The drawback of the FML method is that with an increasing scale of the problem the algorithm becomes computationally very burdensome.

10

In the inference for margins (IFM) method for maximizing (4.1) the parameters j are estimated
first:
^j = arg max j(j)


where

T
j(j) = ln fj(xj,t; j)
t=1

is the log-likelihood function for each of the marginal distributions. The pseudo log-likelihood

function

T
(, ^1, . . . , ^d) = ln c{FX1(x1,t; ^1), . . . , FXd(xd,t; ^d); }
t=1

is then maximized over  to get the dependence parameter estimate ^. The IFM is faster and

computationally easier to implement.

Canonical Maximum Likelihood (CML) maximizes the pseudo log-likelihood function with empirical marginal distributions:

T
() = log c{FX1 (x1,t), . . . , FXd (xd,t); }
t=1

CML = arg max ()


where

1T FXj (x) = T + 1 1{Xj,t  x}.
t=1

An advantage of the CML over both the other methods is that we do not need to make any

assumptions about the parametric form of the marginal distributions. Figure 2 shows that both

methods, IFM and CML provide nearly the same estimates for the estimated Clayton copula

dependence parameter .

11

theta

4 3.5
3 2.5
2 1.5
1 0.5
0 2001

Copula parameter theta

2002

2003
time

2004

2005

Figure 2: Copula dependence parameter  estimated using Clayton copula for DaimlerChrysler, Volkswagen, Bayer, BASF, Allianz and Mu¨nchener Ru¨ckversicherung, 20000101-20041231. Estimated using IFM approach (dashed line) and CML approach (solid line).
5 Inhomogeneous Dependence Modelling with Time Varying Cop-
ulae

Very similar to the Risk Metrics procedure, one can perform a moving window estimation of the copula parameter. This procedure though does not fine tune local changes in dependencies. In fact, the joint distribution Ft,Lt from (1.3) is modelled as Ft,Lt = Ct{Ft,1(L1), . . . , Ft,d(Ld)} with probability measure Pt. The moving window of fixed width will estimate a t for each t but will not provide precise estimates close to e.g. a change point in t.
In order to choose an interval of homogeneity we employ a local parametric fitting approach as introduced by Mercurio and Spokoiny (2004) and H¨ardle et al. (2003). The complete theory is given in Spokoiny (2007). The basic idea is to adaptively estimate an interval of homogeneity in which the hypothesis of a locally constant copula parameter is supported. Using Local Change

12

Point (LCP) detection procedure, see Spokoiny (2007), we sequentially test: t is constant (i.e. t = ) within some interval I (local parametric assumption). Thereby we define the "Oracle" choice as the largest interval I = [t0 - mk, t0], for which the small modelling bias condition (SMB):

where  is constant and

I () = K(P, Pt)  
tI

K(P,

P

)

=

E

log

p(y, ) p(y,  )

(5.1)

denotes the Kullback-Leibler divergence, is fulfilled. The "range point" t0 - mk indicates the largets interval fulfilling (5.1) and t0 is ideally estimated from I = [t0 - mk, t0]. The error and risk bounds are calculated in Spokoiny (2007). Other measures of differences between P and Pt may be employed. The Kulback-Leibler divergence though is most convenient in our setting since we base our adaptive choice of interval of homogeneity on likelihood ratio theory.

5.1 LCP procedure
The choice of the homogeneity interval is done by the local change point (LCP) detection procedure. LCP is based on the adaptive choice of the interval of homogeneity for the endpoint t0. Defining a family of intervals of the form I = {Ik, k = -1, 0, 1, ...} such that Ik = [t0 - mk, t0] with mk: m-1 < m0 < ...  t0, m-1 = 2m1, m0 = 1m1 and 1 > 2  (0, 1) and defining sets of internal points Tk  Ik of the form Tk = [t0 - mk-1, t0 - mk-2] for k = 1, 2, . . . we start the procedure with k = 1 and
1. test the H0,k hypothesis of homogeneity within Ik on Tk 2. if H0,k is not rejected, take the next larger interval Ik+1 and repeat the previous step until
homogeneity is rejected or the largest possible interval [0, t0] is reached 3. if H0,k is rejected within Ik, the estimated interval of homogeneity is the last accepted interval
13

I = Ik-2 4. if the largest possible interval is reached we take I = [0, t0].

t0 - m3

t0 - m2

t0 - m1

t0

t0 - 1m1 t0 - 2m1

T3 I3

I1 I2

We estimate the copula dependence parameter  from observations in I, assuming the homogeneous model within I, i.e. we define t0 = Ib. We now describe how to perform the local homogeneity test.

5.1.1 Test of homogeneity against a change point alternative

Let I = [t0 - m, t0] be an interval candidate and TI be a set of internal points within I. The null hypothesis H0 means that   TI , t = , i.e., the observations in I follow the model with dependence parameter . The alternative hypothesis H1 claims that   TI : t = 1 for t  J = [, t0] and t = 2 = 1 for t  Jc = [t0 - m,  [, i.e. the parameter  changes spontaneously in some internal point  of the interval I.
If I () and J (1)+ Jc(2) are the log-likelihood functions corresponding to H0 and H1 respectively, the likelihood ratio test for the single change point with known fixed location  can be written as:

TI, = max { J (1) + Jc (2)} - max I ()

1,2



= J (^J ) + Jc (^Jc ) - I (^I )

= ^J + ^Jc - ^I .

14

The test statistics for unknown change point location is defined as

TI

=

max
 TI

TI

,

and tests the homogeneity hypothesis in I against the change point alternative with unknown location  belonging to the set of considered locations TI . The change point test compares this test statistics with a critical value I which may depend on the interval I and the nominal first kind error probability . One rejects the hypothesis of homogeneity if TI > I . The estimator of the change point is then defined as
 = arg max TI, .
 TI

5.1.2 Parameters of the LCP procedure

To start the procedure, we have to specify some parameters. This includes: selection of interval candidates I and internal points TI for each of this intervals; choice of the critical values I , which may depend on the interval I and the nominal first kind error probability . One possible example of an implementation is presented below.
Selection of interval candidates I and internal points TI : It is usefull to take the set I of interval candidates in form of a geometric grid. We fix the length of the interval I1 to m1, define

1. m0 = 1m1 and m-1 = 2m1 for 1 > 2  (0, 1) 2. mk = [m1ck-1] for k = 1, 2, . . . , K and c > 1 where [x] means the integer part of x

We set Ik = [t0 - mk, t0] and Tk = [t0 - mk-1, t0 - mk-2] for k = 1, 2, . . . , K Choice of the critical values I : The event "accept homogeneity in Ik-1, reject in Ik" may be

15

represented by the set

k-1
Bk = {TIj  Ij }  {TIk > Ik }
j=1

and it holds BiBj =  for i = j, i, j = 1, 2, . . .. Thus, defining Ik = P (Bk) and Ik = P

we verify

k

Ik =

Ij

j=1

k j=1

Bj

The critical values Ik are sequentially selected by Monte Carlo simulation to provide, under the homogeneity hypothesis, probability of "false alarm" Ik for every interval Ik


k-1



PH0  {Tj  Ij }  {TIk > Ik } = Ik

j=1

and it follows that Ik is the probability of at least one false alarm until step k. The standard approach for choosing the critical values is to provide a prescribed first kind error probability K = . A reasonable proposal is to set


k

-1

IK-k+1 = m-k 1  m-j 1

j=1

where mk denotes the number of points in interval Ik.

6 Simulated Examples
6.1 Clayton Copula: sudden jump in dependence
The LCP procedure is applied to different sets of simulations from d-dimensional Clayton copula with parameter given by

16

3 2 1 0 0 150 100 50 0 0

50 100 150 200 250 300 50 100 150 200 250 300

Figure 3: Pointwise median (full), 0.25, 0.75 quantiles (dotted) of estimated parameter ^t, true parameter t (dashed), top. Median of estimated size of homogeneity intervals |I^t|, bottom. Based
on 200 simulations, Clayton copula,  = 3, d = 2, m1 = 20 and c = 1.25



 

0.1







t = 







 

0.1

if 1  t  100 if 101  t  200 if 201  t  300

For each pair of values  and d (for jumps to and from  = 1.5, 3 and 6 and 2-, 6- and 10- dimensional copulae), 200 distinct simulations are generated. The dependence parameter and homogeneity intervals are estimated and the detection delay to the jumps computed for each of the sets. Figures 3, 4 and 6 show the pointwise median and quantiles of the estimated parameter ^t and pointwise median of the size of estimated homogeneity intervals |I^t|.

The detection delay  at rule r  [0, 1] to jump of size  = t - t-1 and t  {101, 201} is expressed by
(t, , r) = 1{<100} + (100)1{100}

17

3 2 1 0 0 100
50
00

50 100 150 200 250 300 50 100 150 200 250 300

Figure 4: Pointwise median (full), 0.25, 0.75 quantiles (dotted) of estimated parameter ^t, true parameter t (dashed), top. Median of estimated size of homogeneity intervals |I^t|, bottom. Based
on 200 simulations, Clayton copula,  = 3, d = 6, m1 = 20 and c = 1.25

12 10
8 6 4 2 0 3 3.5 4 4.5 5 5.5 6 6.5 7
log of interval lenght
Figure 5: Critical values Ik for  = 0.05, m1 = 20, c = 1.25, d = 2 (dotted), 6 (dashed) and 10 (full)
18

2 1.5
1 0.5
0 50 100 150 200 250 300
2 1.5
1 0.5
0 50 100 150 200 250 300
2 1.5
1 0.5
0 50 100 150 200 250 300

4 3 2 1 0
50 100 150 200 250 300
4 3 2 1 0
50 100 150 200 250 300
4 3 2 1 0
50 100 150 200 250 300

8 6 4 2 0
50 100 150 200 250 300
8 6 4 2 0
50 100 150 200 250 300
8 6 4 2 0
50 100 150 200 250 300

Figure 6: Pointwise median (full), 0.25, 0.75 quantiles (dotted) from estimated parameter ^t and true parameter t (dashed), from left to right  = 1.5, 3, 6, from top to bottom d = 2, 6, 10. Based on 200 simulations from Clayton copula, m1 = 20 and c = 1.25

19

where

 = min{k  t : ^k = t-1 + r} - t

and ^t is the estimated parameter at t. It represents the number of steps necessary for the estimated parameter to reach the r-fraction of a jump in the real parameter (if the fraction is not reached in 100 steps, the delay is set to 100).

Detection delays are proportional to probability of error of type II, i.e., probability of accepting homogeneity in case of jump. Thus, tests with higher power correspond to lower detection delays. The Kullback-Leibler divergences for upward (Kd(0.1, )) and downward (Kd(, 0.1)) jumps for d-dimensional Clayton copulae are proportional to the power of the respective homogeneity tests and are displayed in table 1. We verify that for Clayton copulae the divergence is increasing in the size of jump and in dimension and is also higher for upward than for downward jumps (fig. 8)

The descriptive statistics for detection delays to jumps at t = 101 and 102 are in table 1. The mean detection delay decreases with  and dimension d. Moreover they are higher for downward jumps (at t = 101) than for upward (at t = 102). Figure 7 displays the logarithm of mean detection delay against jump size for r = 0.6 for upward and downward jumps and respective dimensions.

6.2 Clayton Copula: linear change in dependence
The procedure is applied on simulated data with linear increase and decrease in dependence. Similarly to the last section, different sets of simulations from d-dimensional Clayton copula with parameter given by

20

 = 1.5

=3

=6

dt

r mean std dev. max min mean std dev. max min mean std dev. max min

101 40% 35.64

16.49 93

1 23.05

9.41 62

6 14.31

6.39 38

4

50% 41.70

19.23 100

2 26.34

11.79 67

6 15.24

7.60 41

4

2 60% 50.04 201 40% 9.27 50% 14.70 60% 25.78

21.93
10.39 13.38 21.04

100
62 74 100

7 29.31
1 8.27 1 10.62 1 12.87

13.82
5.79 6.20 7.30

84
30 32 45

6 16.00
1 5.55 1 6.07 1 6.66

8.62 41
2.43 16 2.73 17 3.21 22

4
1 1 1

101 40% 50%

8.84 9.35

3.53 31 4.39 34

2 5.82 2 6.07

1.07 9 2 6.22 0.97 9 3 6.43

0.80 7 4 0.68 7 4

6 60% 10.00 201 40% 5.33 50% 5.87 60% 6.31

5.57 34
2.69 14 3.13 15 3.57 20

3 6.32
1 2.89 1 3.01 1 3.07

0.92 9 4 6.62
1.39 7 1 1.61 1.45 7 1 1.62 1.46 7 1 1.74

0.61 9 5
0.74 4 1 0.75 4 1 0.81 4 1

101 40% 50%

5.84 6.04

1.57 13 1.51 13

2 5.67 2 6.04

1.00 7 2 6.34 0.91 7 3 6.60

0.68 7 4 0.55 7 5

10 60% 201 40% 50% 60%

6.26
3.61 3.69 3.79

1.40 13
1.68 10 1.72 10 1.71 10

3 6.37
1 2.01 1 2.07 1 2.31

0.75 7 4 6.68
0.90 4 1 1.24 0.95 4 1 1.26 1.06 5 1 1.51

0.52 7 5
0.46 3 1 0.49 3 1 0.66 3 1

Table 1: Statistics for detection delay  to downward (t = 101) and upward (t = 201) jump of size  - 0.1 at rule r, based on 200 simulations from d-dimensional Clayton copula, m1 = 20, c = 1.25

 K2(0.1, ) K2(, 0.1) K6(0.1, ) K6(, 0.1) K10(0.1, ) K10(, 0.1)

1.5 0.41 0.26 3.52 1.57 7.30 2.89

3.0 1.28 0.56 11.49 3.25 24.69

5.89

6.0 3.51 1.01 31.52 5.56 68.35 10.00

Table 2: Kullback-Leibler divergence between d-dimensional Clayton copulae with parameters 0.1 and 

21

log() log()

4.5 4
3.5 3
2.5 2
1.5 1
0.5 1.5

3 4.5 

4.5 4
3.5 3
2.5 2
1.5 1
0.5 6 1.5

3 4.5 

6

Figure 7: Logarithm of mean detection delays at r = 0.6 for different upward (left) and downward (right) jump sizes, d-dimensional Clayton Copula, d = 2 (dashed), 6 (dotted) and 10 (full)

4 30 60 3
20 40 2
10 20 1 000 0 5 10 0 5 10 0 5 10
Figure 8: Kd(0.1, ) (dashed), Kd(, 0.1) (full), corresponding to upward and downward jumps, d-dimensional Clayton copula, d = 2 (left), 6 (middle) and 10 (right)
22

3.5 3
2.5 2
1.5 1
0.5 0 0 50 100 150 200 250 300 350 400

Figure 9: Pointwise median (full), 0.25, 0.75 quantiles (dotted) from estimated parameter ^t and true parameter t (dashed),  = 3, d = 6. Based on 200 simulations from Clayton copula, m1 = 20 and c = 1.25



 

0.1







    

0.1 +

1 50

(t

-

100)





t = 





    

-

1 50

(t

-

250)







 

0.1

if 1  t  100 if 101  t  150 if 151  t  250 if 251  t  300 if 301  t  400

and  =  - 0.1 are generated. Figures 9 and 10 depict the pointwise median and quantiles of the estimated parameter ^t and the true parameter t for  = 1.5, 3 and 6 and 2-, 6- and 10- dimensional copulae.

23

248

1.5 3 6

124

0.5 1 2

000

100 200 300 400

100 200 300 400

100 200 300 400

248

1.5 3 6

124

0.5 1 2

000

100 200 300 400

100 200 300 400

100 200 300 400

248

1.5 3 6

124

0.5 1 2

000

100 200 300 400

100 200 300 400

100 200 300 400

Figure 10: Pointwise median (full), 0.25, 0.75 quantiles (dotted) of estimated parameter ^t, true parameter t (dashed), from left to right  = 1.5, 3, 6, from top to bottom d = 2, 6, 10. Based on 200 simulations from Clayton copula, m1 = 20 and c = 1.25

24

t r mean std dev. max min

100 40% 18.11

7.15 43 6

50% 19.69

7.74 43 6

60% 22.24

9.42 46 8

200 40% 16.02

9.08 45 2

50% 20.42 13.19 63 2

60% 25.21 18.16 100 2

Table 3: Statistics for detection delay  to downward (t = 101) and upward (t = 201) jump of size 0.8 at rule r, based on 100 simulations from Gaussian copula, m1 = 20, c = 1.25
6.3 Gaussian Copula: sudden jump in correlation

The Gaussian copula is parametrized by its correlation matrix (2.4). In the 2 dimensional Gaussian copula the parameter is the correlation coefficient . As in previous sections, the LCP procedure is applied to sets of simulations from 2-dimensional Gaussian copula with parameter given by



 

0







t =







 

0

if 1  t  100 if 101  t  200 if 201  t  300

Figure 11 shows the pointwise median and quantiles of the estimated parameter ^t and the true parameter t for = 0.8. The Kullback-Leibler divergences corresponding to up and downward jumps in the 2-dimensional Gaussian copula are displayed in fig. 12 as a function of . For = 0.8 the divergences are K2(0, 0.8) = 1.78 and K2(0.8, 0) = 0.51. The detection delay statistics for sudden jump in correlation for Gaussian copula at rule 60% are depicted in table 3.
In the 3-dimensional case the parameter is the correlation matrix . The LCP procedure is applied to sets of simulations from a 3-dimensional Gaussian copula with correlation given by

25

0.8 0.6 0.4 0.2
0 -0.2
0

50 100 150 200 250 300

Figure 11: Pointwise median (full), 0.25, 0.75 quantiles (dotted) from estimated parameter ^t and true parameter t (dashed), = 0.8. Based on 100 simulations from Gaussian copula, m1 = 20 and c = 1.25

3.5 3
2.5 2
1.5 1
0.5 0 -1 -0.8 -0.6 -0.4 -0.2 0 0.2 0.4 0.6 0.8 1
Figure 12: K2(0, ) (dashed), K2( , 0) (full), corresponding to upward and downward jumps, 2dimensional Gaussian copula
26



 

I3







t = R







 

I3

if 1  t  100 if 101  t  200 if 201  t  300

where I3 is the identity matrix of size 3 and



1



R

=

 0.8



 0

0.8 1 -0.5


0 
 -0.5

 1

The distance between the estimated ^ and the true correlation matrix , d(^ , ) is given by

d(^ , ) = ||^ - ||2

(6.1)

where  = (12, 13, 23) and ij is the (i, j) element of matrix . This distance is motivated by
1
the Frobenius norm for a matrix A, ||A||F = i,j |aij|2 2 and we have d(R, I3) = 0.9434. Figure
13 depicts the pointwise median and quantiles of distance d(^ t, t) between estimated and true
correlation matrices.

7 Empirical Results
The estimation methods described in the preceeding section (RiskMetrics, moving window and adaptive estimation procedure) are applied to a portfolio composed of two different sets of DAX stocks. At first we apply the procedure to DaimlerChrysler (DCX), Volkswagen (VW), Allianz (ALV), Mu¨nchener Ru¨ckversicherung (MUV2), Bayer (BAY) and BASF (BAS) and afterwards to Siemens (SIE), ThyssenKrupp (THY), Schering (SCH), E.ON AG (EOA), Henkel (HEN) and Lufthansa (LHA). The observation period for both data sets covers January 1st to December 31st, 2004 (data available in http://sfb649.wiwi.hu-berlin.de/fedc). For the log-returns {Xj,t}
27

1 0.8 0.6 0.4 0.2
0 0 50 100 150 200 250 300

Figure 13: Pointwise median (full), 0.25, 0.75 quantiles (dotted) of distance d(^ t, t) between estimated and true correlation matrices. Based on 200 simulations from Gaussian copula, d = 3, m1 = 20 and c = 1.25

modelled as

Xj,t = j,tj,t

we estimate the parameters j2,t using exponential smoothing techniques for every time point t:

^j2,t = (e - 1) e-(t-s)Xs2,j
s<t
where Xj,s, j = 1, ..., 6 denotes log returns of DCX, VW, ALV, MUV, BAY and BAS (SIE, THY, SCH, EOA, HEN and LHA) at time point s (we set  = 1/20).

The chosen copula belongs to the Clayton family since it allows to capture the dependence in the lower tail which is essential for VaR calculation. For the moving window approach we fix w = 250; for the LCP procedure we set  = 0.05, c = 1.25 and m1 = 20. We have chosen these parameters from our experience in simulations. For details on robustness of the reported results with respect to the choice of the parameters c, 1, 2 and m1 refer to Spokoiny (2007).

28

The performance of VaR estimation is evaluated based on backtesting. The estimated values for the

VaR are compared with the true realizations {lt} of the P&L function, an exceedance occuring for

each lt smaller than V aRt(). The ratio of the number of exceedances to the number of observations

gives the exceedances ratio ^:

1T

^ = T - w

1{lt<V aRt()}

t=w

7.1 DCX, VW, ALV, MUV, BAY and BAS

At first, we analyze the performance of the procedure by applying it to the first portfolio of the DAX stocks: DCX, VW, ALV, MUV, BAY and BAS. Figures 14 and 15 represent the copula dependence parameter and the intervals of homogeneity estimated with the parameters m1 = 20 and m1 = 50, respectively. From the aforementioned Figures in combination with Figure 16 we can observe that with increasing m1 the estimated copula parameter  takes on smaller values and its peaks diminish. Accordingly, the intervals of homogeneity become smoother. Further, the analysis shows a September 11 effect: before the terror attack the copula parameter experienced small fluctuations below the value of the global parameter. At the same time, the lengths of the intervals of homogeneity reached high levels. After the attack, the dependence among the stocks becomes larger and the lengths of intervals of homogeneity increase.
The results of the VaR estimation are summarized in Table 4 for Riskmetrics, in Table 5 for the moving window and in Table 6 for the adaptive estimation procedure. They represent exceedance ratios at different levels  = 1% to  = 5%, at which the VaR has been calculated. Further, the absolute and the relative sum of squared deviations of the exceedance ^ from the actual level  are calculated. We can observe that Riskmetrics outperforms the moving window and the adaptive estimation procedures for higher quantiles: relative squared deviation wW (^ - )2/ for Riskmetrics accounts to 13.34, 17.01 and 26.55 at 5%, 4% and 3% levels respectively, whereas for the moving window and the LCP approach we observe values between 19.67 at 5% level and 30.5 at 3% level (see Table 7). However, Riskmetrics fails to capture the lower tail dependence while
29

theta

4 3 2 1 0 2001
200 150 100
50 0 2001

Copula parameter theta

2002

2003
time

2004

2002

2003
time

2004

2005 2005

length

Figure 14: Upper panel: estimated copula dependence parameter  for 6-dim data: DaimlerChrysler, Volkswagen, Bayer, BASF, Allianz and Mu¨nchener Ru¨ckversicherung and the global parameter. Lower panel: estimated intervals of time homogeneity; with parameters m1 = 20, c = 1.25 and  = 0.05.

30

theta

2.5 2
1.5 1
0.5 0 2001
350 300 250 200 150 100
50 0 2001

Copula parameter theta

2002

2003
time

2004

2002

2003
time

2004

2005 2005

length

Figure 15: Upper panel: estimated copula dependence parameter  for 6-dim data: DaimlerChrysler, Volkswagen, Bayer, BASF, Allianz and Mu¨nchener Ru¨ckversicherung and the global parameter. Lower panel: estimated intervals of time homogeneity; with parameters m1 = 50, c = 1.25 and  = 0.05.

31

Portfolio
(1, 1, 1, 1, 1, 1) (1, 2, 3, 2, 1, 3) (2, 1, 2, 3, 1, 3) (3, 2, 3, 2, 3, 1) (3, 1, 2, 1, 3, 2) (1, 3, 1, 2, 3, 1) (2, 1, 3, 2, 1, 3) (2, 3, 3, 2, 1, 1) (3, 1, 2, 2, 2, 3) (2, 3, 1, 1, 2, 3) (2, 3, 2, 3, 2, 3) (3, 2, 3, 2, 3, 3) (1, 1, 1, 1, 1, -1) (1, 2, 3, 2, 1, -3) (2, 1, 2, 3, 1, -3) (3, 2, 3, 2, 3, -1) (3, 1, 2, 1, 3, -2) (1, 3, 1, 2, 3, -1) (2, 1, 3, 2, 1, -3) (2, 3, 3, 2, 1, -1) (3, 1, 2, 2, 2, -3) (2, 3, 1, 1, 2, -3) (2, 3, 2, 3, 2, -3) (3, 2, 3, 2, 3, -3)
avg. std.dev. wW (^ - )2 wW (^ - )2/

Exceedances ratio (×102) 5.00 4.00 3.00 2.00 1.00 6.77 5.88 4.90 4.02 3.43 6.86 5.69 4.61 4.12 3.33 5.59 5.00 4.51 3.63 2.84 7.16 5.98 5.10 4.31 3.43 7.94 7.16 5.79 5.00 3.63 6.47 5.59 4.61 4.21 2.94 6.67 5.49 4.61 4.12 3.43 6.96 5.79 4.90 4.12 3.53 6.77 5.88 4.90 3.92 3.43 8.24 7.16 5.79 4.51 3.63 6.18 5.59 4.61 3.92 2.84 7.26 6.47 5.39 4.31 3.53 5.39 4.80 4.41 3.82 3.04 5.00 4.41 4.31 3.53 2.64 4.41 4.21 3.63 3.14 2.15 6.86 5.79 4.90 4.12 3.53 7.55 6.28 5.10 4.41 3.72 5.69 4.80 4.51 3.92 2.74 5.10 4.51 4.31 3.43 2.64 6.47 5.29 4.71 4.02 3.43 5.00 4.51 4.41 3.63 2.84 6.47 5.69 5.29 4.21 3.04 4.80 4.41 4.12 3.43 2.74 6.37 5.10 4.61 3.92 3.23 6.33 5.48 4.75 3.99 3.16 1.01 0.81 0.49 0.40 0.40 0.66 0.68 0.79 0.99 1.15 13.34 17.00 26.54 49.62 115.89

Table 4: Exceedances ratio ^ for different portfolios, estimated using RiskMetrics approach for 6-dim data: DCX, VW, ALV, MUV, BAY and BAS.

32

Portfolio
(1, 1, 1, 1, 1, 1) (1, 2, 3, 2, 1, 3) (2, 1, 2, 3, 1, 3) (3, 2, 3, 2, 3, 1) (3, 1, 2, 1, 3, 2) (1, 3, 1, 2, 3, 1) (2, 1, 3, 2, 1, 3) (2, 3, 3, 2, 1, 1) (3, 1, 2, 2, 2, 3) (2, 3, 1, 1, 2, 3) (2, 3, 2, 3, 2, 3) (3, 2, 3, 2, 3, 3) (1, 1, 1, 1, 1, -1) (1, 2, 3, 2, 1, -3) (2, 1, 2, 3, 1, -3) (3, 2, 3, 2, 3, -1) (3, 1, 2, 1, 3, -2) (1, 3, 1, 2, 3, -1) (2, 1, 3, 2, 1, -3) (2, 3, 3, 2, 1, -1) (3, 1, 2, 2, 2, -3) (2, 3, 1, 1, 2, -3) (2, 3, 2, 3, 2, -3) (3, 2, 3, 2, 3, -3)
avg. std.dev. wW (^ - )2 wW (^ - )2/

Exceedances ratio (×102) 5.00 4.00 3.00 2.00 1.00 7.06 6.08 4.80 3.43 1.76 7.36 6.28 4.80 3.72 1.76 7.45 6.37 4.80 3.63 1.37 7.45 6.28 4.80 3.53 1.96 6.67 5.69 4.71 3.33 1.86 6.47 5.59 4.12 3.04 1.66 7.36 6.28 4.80 3.82 1.76 7.55 6.28 5.00 3.63 1.96 6.96 6.08 4.90 3.82 1.86 6.47 5.39 4.31 3.04 1.76 7.06 6.08 4.61 3.43 1.57 7.06 6.08 4.80 3.33 1.86 7.06 6.18 5.59 3.72 1.66 7.75 6.67 5.29 4.21 1.86 7.65 6.67 5.49 4.41 1.57 7.16 6.37 4.80 3.82 1.66 7.36 6.08 4.90 4.02 1.96 6.86 5.98 4.31 3.14 1.37 7.85 6.67 5.39 4.02 1.86 7.65 6.08 5.10 4.02 1.76 7.65 6.37 5.39 3.92 1.57 6.86 5.88 4.90 3.04 1.37 7.06 6.28 5.10 3.92 1.66 7.55 6.28 5.20 4.02 1.57 7.22 6.17 4.91 3.67 1.71 0.38 0.31 0.36 0.38 0.18 1.22 1.15 0.91 0.70 0.12 24.55 28.83 30.50 35.23 12.96

Table 5: Exceedances ratio ^ for different portfolios, estimated with Clayton copula using moving window approach for 6-dim data: DCX, VW, ALV, MUV, BAY and BAS.

33

Portfolio
(1, 1, 1, 1, 1, 1) (1, 2, 3, 2, 1, 3) (2, 1, 2, 3, 1, 3) (3, 2, 3, 2, 3, 1) (3, 1, 2, 1, 3, 2) (1, 3, 1, 2, 3, 1) (2, 1, 3, 2, 1, 3) (2, 3, 3, 2, 1, 1) (3, 1, 2, 2, 2, 3) (2, 3, 1, 1, 2, 3) (2, 3, 2, 3, 2, 3) (3, 2, 3, 2, 3, 3) (1, 1, 1, 1, 1, -1) (1, 2, 3, 2, 1, -3) (2, 1, 2, 3, 1, -3) (3, 2, 3, 2, 3, -1) (3, 1, 2, 1, 3, -2) (1, 3, 1, 2, 3, -1) (2, 1, 3, 2, 1, -3) (2, 3, 3, 2, 1, -1) (3, 1, 2, 2, 2, -3) (2, 3, 1, 1, 2, -3) (2, 3, 2, 3, 2, -3) (3, 2, 3, 2, 3, -3)
avg. std.dev wW (^ - )2 wW (^ - )2/

Exceedances ratio (×102) 5.00 4.00 3.00 2.00 1.00 7.06 6.08 4.80 2.84 1.57 7.06 6.37 4.71 3.14 1.76 7.06 6.28 4.90 3.04 1.37 7.16 6.08 5.00 3.33 1.76 6.57 5.79 4.41 3.33 1.76 6.18 5.59 4.41 2.94 1.57 7.16 6.28 4.61 3.33 1.76 7.06 6.47 5.10 3.43 1.66 6.96 5.88 4.71 3.04 1.66 6.28 5.20 4.61 2.84 1.86 6.77 5.88 4.80 2.94 1.37 6.96 6.08 4.90 3.14 1.86 7.26 6.18 5.49 3.33 1.37 7.26 6.37 5.20 3.63 1.66 7.75 6.37 4.90 4.02 1.66 7.26 6.08 5.10 3.72 1.57 6.77 5.69 4.90 3.53 1.57 6.47 5.49 4.31 3.04 1.37 7.65 6.18 5.39 3.82 1.57 7.36 6.28 5.00 3.82 1.47 7.26 6.08 5.29 3.53 1.47 5.98 5.69 4.90 3.14 1.17 6.96 6.18 4.90 3.33 1.37 7.16 6.08 5.00 3.63 1.37 6.97 6.03 4.89 3.33 1.57 0.43 0.31 0.29 0.33 0.18 0.98 1.01 0.88 0.45 0.08 19.6 25.33 29.38 22.57 8.57

Table 6: Exceedances ratio ^ for different portfolios, estimated with Clayton copula using adaptive estimation procedure for 6-dim data: DCX, VW, ALV, MUV, BAY and BAS.

Method Riskmetrics Moving Window
LCP

Exceedances ratio (×102)

5432

1

13.34 17.00 26.54 49.62 115.89

24.55 28.83 30.50 35.23 12.96

19.66 25.33 29.38 22.57 8.57

Table 7: Relative squared deviation wW (^ - )2/ for Riskmetrics, Moving Window and LCP approach (DCX, VW, ALV, MUV, BAY and BAS).

34

theta

4 3.5
3 2.5
2 1.5
1 0.5
0 2001

Copula parameter theta

2002

2003
time

2004

2005

Figure 16: Estimated copula dependence parameter  for 6-dim data: DaimlerChrysler, Volkswagen, Bayer, BASF, Allianz and Mu¨nchener Ru¨ckversicherung estimated with parameter m1 = 20 (dashed line) and m1 = 50 (solid line).
copula-based approaches provide better results: for example, the relative squared deviation at the 1% level is in case of Riskmetrics is at least 10 times as high as for the adaptive procedure. Further, the exceedances ratios in Riskmetrics case are more volatile: the standard deviations account to 1.02 to 4.03 for Riskmetrics, whereas with a copula-based approch we obtain values between 0.18 and 0.43 .

7.2 SIE, THY, SCH, EOA, HEN and LHA
We consider now a portfolio consisting of the DAX stocks SIE, THY, SCH, EOA, HEN and LHA. The copula dependence parameter and the intervals of homogeneity estimated with parameters m1 = 20 and m1 = 50 are plotted in Figures 18 and 19 respectively. As in the case of DCX, VW, ALV, MUV, BAY and BAS, with increasing m1 we observe diminishing of peaks in the estimated values of copula dependence parameter (Figure 20) and smoother pattern for the length of the
35

100 0
-100 -200
2001
100 0
-100 -200
2001
100 0
-100 -200
2001

Riskmetrics

2002

2003 Moving window

2004

2002

2003 Adaptive estimation

2004

2002

2003

2004

2005 2005 2005

Figure 17: P&L (dots) and V aR() at level 1 = 0.01; w = (3, 2, 3, 2, 3, -1) , estimated using RiskMetrics approach (upper panel), moving window approach (middle panel) and adaptive estimation procedure (lower panel) for 6-dim data: DaimlerChrysler, Volkswagen, Bayer, BASF, Allianz and Mu¨nchener Ru¨ckversicherung.
36

theta

4 3 2 1 0 2001
200 150 100
50 0 2001

Copula parameter theta

2002

2003
time

2004

2002

2003
time

2004

2005 2005

length

Figure 18: Upper panel: estimated copula dependence parameter  for 6-dim data: Siemens, ThyssenKrupp, Schering, E.ON AG, Henkel, Lufthansa and the global parameter. Lower panel: estimated intervals of time homogeneity; with parameters m1 = 20, c = 1.25 and  = 0.05.
intervals of homogeneity.
The results of the VaR estimation are summarized in Table 8 for Riskmetrics, in Table 9 for the moving window and in Table 10 for the adaptive estimation procedure. We can observe that at the 5% level Riskmetrics performs better than moving window. However, the adaptive procedure produces even better results: the relative squared deviations acount to 6.96, 7.38 and 3.59 for Riskmetrics, moving window and LCP procedure, respectively (Table 11). For the quantiles at levels  = 4% to  = 1% copula-based approaches outperform Riskmetrics, whereas the adaptive procedure leads to the smallest values of the relative squared deviations: taking on values between 3.53 and 7.42, it produces results twice as good as moving window and Riskmetrics approaches.
37

theta

1.5
1
0.5
0 2001
350 300 250 200 150 100
50 0 2001

Copula parameter theta

2002

2003
time

2004

2002

2003
time

2004

2005 2005

length

Figure 19: Upper panel: estimated copula dependence parameter  for 6-dim data: Siemens, ThyssenKrupp, Schering, E.ON AG, Henkel, Lufthansa and the global parameter. Lower panel: estimated intervals of time homogeneity; with parameters m1 = 50, c = 1.25 and  = 0.05.

38

Portfolio
(1, 1, 1, 1, 1, 1) (1, 2, 3, 2, 1, 3) (2, 1, 2, 3, 1, 3) (3, 2, 3, 2, 3, 1) (3, 1, 2, 1, 3, 2) (1, 3, 1, 2, 3, 1) (2, 1, 3, 2, 1, 3) (2, 3, 3, 2, 1, 1) (3, 1, 2, 2, 2, 3) (2, 3, 1, 1, 2, 3) (2, 3, 2, 3, 2, 3) (3, 2, 3, 2, 3, 3) (1, 1, 1, 1, 1, -1) (1, 2, 3, 2, 1, -3) (2, 1, 2, 3, 1, -3) (3, 2, 3, 2, 3, -1) (3, 1, 2, 1, 3, -2) (1, 3, 1, 2, 3, -1) (2, 1, 3, 2, 1, -3) (2, 3, 3, 2, 1, -1) (3, 1, 2, 2, 2, -3) (2, 3, 1, 1, 2, -3) (2, 3, 2, 3, 2, -3) (3, 2, 3, 2, 3, -3)
avg. std.dev. wW (^ - )2 wW (^ - )2/

Exceedances ratio (×102) 5.00 4.00 3.00 2.00 1.00 6.28 5.39 4.61 3.72 1.86 6.47 5.69 4.41 3.33 1.76 6.28 5.69 4.80 3.33 2.15 6.47 4.90 4.41 3.72 1.86 6.18 5.49 4.41 3.14 1.57 6.18 5.49 4.71 3.04 1.96 6.47 5.59 4.31 3.33 1.86 6.37 5.69 4.21 3.43 2.06 6.18 5.49 4.61 3.23 1.86 6.37 5.39 4.90 3.92 1.86 6.28 5.69 4.61 3.92 2.15 6.18 5.49 4.51 3.63 1.86 5.88 5.39 4.21 3.72 1.57 5.79 5.10 4.51 2.94 1.66 6.37 5.20 4.31 3.23 1.76 6.47 5.29 4.41 3.63 1.76 6.08 5.10 4.41 3.14 1.66 5.98 5.39 4.31 2.74 1.86 5.88 5.29 4.61 3.04 1.76 6.28 5.29 4.31 3.23 1.86 5.69 4.90 4.31 3.72 1.76 5.98 5.10 4.31 3.53 1.96 5.88 5.49 4.12 3.82 1.76 6.28 5.20 4.51 3.43 1.47 6.18 5.36 4.45 3.41 1.82 0.23 0.23 0.19 0.32 0.16 0.34 0.46 0.51 0.50 0.16 6.96 11.55 17.26 25.34 16.93

Table 8: Exceedances ratio ^ for different portfolios, estimated using RiskMetrics approach for 6-dim data: SIE, THY, SCH, EOA, HEN and LHA.

39

Portfolio
(1, 1, 1, 1, 1, 1) (1, 2, 3, 2, 1, 3) (2, 1, 2, 3, 1, 3) (3, 2, 3, 2, 3, 1) (3, 1, 2, 1, 3, 2) (1, 3, 1, 2, 3, 1) (2, 1, 3, 2, 1, 3) (2, 3, 3, 2, 1, 1) (3, 1, 2, 2, 2, 3) (2, 3, 1, 1, 2, 3) (2, 3, 2, 3, 2, 3) (3, 2, 3, 2, 3, 3) (1, 1, 1, 1, 1, -1) (1, 2, 3, 2, 1, -3) (2, 1, 2, 3, 1, -3) (3, 2, 3, 2, 3, -1) (3, 1, 2, 1, 3, -2) (1, 3, 1, 2, 3, -1) (2, 1, 3, 2, 1, -3) (2, 3, 3, 2, 1, -1) (3, 1, 2, 2, 2, -3) (2, 3, 1, 1, 2, -3) (2, 3, 2, 3, 2, -3) (3, 2, 3, 2, 3, -3)
avg. std.dev. wW (^ - )2 wW (^ - )2/

Exceedances ratio (×102) 5.00 4.00 3.00 2.00 1.00 5.98 5.39 4.61 3.72 1.66 5.88 5.10 3.63 2.35 1.37 7.26 6.47 5.49 3.92 2.25 5.59 5.00 4.31 3.33 1.66 6.08 5.20 4.31 3.33 1.47 5.10 4.02 3.14 2.84 1.57 6.96 5.59 4.51 3.33 2.06 6.57 5.29 4.61 3.63 1.96 7.16 6.18 5.39 4.41 2.15 7.06 5.98 5.10 3.82 1.96 6.86 5.59 4.71 3.33 2.06 5.98 5.20 4.41 3.43 1.57 5.59 5.00 4.21 2.94 1.57 4.71 4.12 3.23 2.15 1.37 6.47 5.59 4.21 3.43 1.96 5.69 4.80 4.21 3.14 1.66 5.39 4.80 4.21 2.94 1.37 4.31 3.53 2.94 2.45 1.66 5.88 5.10 3.92 2.84 1.76 6.18 5.29 4.41 3.23 1.96 6.28 5.29 5.10 3.43 2.15 5.69 5.00 4.31 2.74 1.66 5.59 4.80 4.02 3.14 1.66 5.59 4.90 3.63 2.64 1.66 5.99 5.13 4.28 3.19 1.76 0.75 0.64 0.65 0.52 0.26 0.36 0.40 0.49 0.40 0.15 7.38 10.21 16.39 20.27 15.55

Table 9: Exceedances ratio ^ for different portfolios, estimated with Clayton copula using moving window approach for 6-dim data: SIE, THY, SCH, EOA, HEN and LHA.

40

Portfolio
(1, 1, 1, 1, 1, 1) (1, 2, 3, 2, 1, 3) (2, 1, 2, 3, 1, 3) (3, 2, 3, 2, 3, 1) (3, 1, 2, 1, 3, 2) (1, 3, 1, 2, 3, 1) (2, 1, 3, 2, 1, 3) (2, 3, 3, 2, 1, 1) (3, 1, 2, 2, 2, 3) (2, 3, 1, 1, 2, 3) (2, 3, 2, 3, 2, 3) (3, 2, 3, 2, 3, 3) (1, 1, 1, 1, 1, -1) (1, 2, 3, 2, 1, -3) (2, 1, 2, 3, 1, -3) (3, 2, 3, 2, 3, -1) (3, 1, 2, 1, 3, -2) (1, 3, 1, 2, 3, -1) (2, 1, 3, 2, 1, -3) (2, 3, 3, 2, 1, -1) (3, 1, 2, 2, 2, -3) (2, 3, 1, 1, 2, -3) (2, 3, 2, 3, 2, -3) (3, 2, 3, 2, 3, -3)
avg. std.dev wW (^ - )2 wW (^ - )2/

Exceedances ratio (×102) 5.00 4.00 3.00 2.00 1.00 5.49 4.61 3.82 2.84 1.37 5.10 3.92 3.23 2.55 1.37 6.77 5.49 4.61 3.23 2.25 5.20 4.21 3.43 2.45 1.37 5.29 4.61 3.43 2.25 1.37 4.02 3.23 2.64 2.45 1.17 5.98 5.10 4.12 2.94 1.57 5.88 5.00 4.12 3.23 1.66 6.77 5.49 4.71 3.14 1.66 6.57 5.49 4.41 2.94 1.37 6.37 4.71 3.82 2.94 1.57 5.29 4.31 3.72 2.74 1.37 5.10 4.12 3.33 2.35 1.47 4.51 3.82 2.74 2.06 1.37 5.79 5.20 3.92 3.14 1.86 5.10 4.21 3.23 2.45 1.37 5.29 4.21 3.33 2.15 1.17 3.72 2.94 2.55 2.15 1.37 5.29 4.61 3.53 2.84 1.57 5.29 4.90 4.02 3.23 1.57 5.88 4.90 4.31 2.74 1.66 5.39 4.80 3.63 2.45 1.57 5.29 4.12 3.43 2.35 1.66 5.00 4.12 2.94 2.15 1.37 5.43 4.51 3.63 2.66 1.50 0.75 0.66 0.59 0.38 0.22 0.17 0.16 0.17 0.13 0.07 3.53 4.08 5.85 6.97 7.42

Table 10: Exceedances ratio ^ for different portfolios, estimated with Clayton copula using adaptive estimation procedure for 6-dim data: SIE, THY, SCH, EOA, HEN and LHA.

Method Riskmetrics Moving Window
LCP

Exceedances ratio (×102) 5.00 4.00 3.00 2.00 1.00 6.96 11.55 17.26 25.34 16.93 7.38 10.21 16.39 20.27 15.55 3.52 4.08 5.85 6.97 7.42

Table 11: Relative squared deviation wW (^ - )2/ for Riskmetrics, Moving Window and LCP approach (SIE, THY, SCH, EOA, HEN and LHA).

41

theta

4 3.5
3 2.5
2 1.5
1 0.5
0 2001

Copula parameter theta

2002

2003
time

2004

2005

Figure 20: Estimated copula dependence parameter  for 6-dim data: Siemens, ThyssenKrupp, Schering, E.ON AG, Henkel, Lufthansa estimated with parameter m1 = 20 (dashed line) and m1 = 50 (solid line).
However, we can observe higher standard deviations in the LCP case than in the moving window and Riskmetrics case.
We conclude by summarizing the main findings. The Clayton copula was used to estimate the Value-at-Risk from the 6-dimensional portfolio: at first, DCX, VW, ALV, MUV, BAY and BAS and then, SIE, THY, SCH, EOA, HEN and LHA with adaptive estimation and moving window approach. Backtesting was used to compare the performance of the copula-based Value-at-Risk estimation with the RiskMetrics approach. All three methods overestimate the Value-at-Risk in average. In terms of capital requirement, a financial institution would be requested to keep more capital aside than necessary to guarantee the desired confidence level. In the case of the portfolio consisting of DCX, VW, ALV, MUV, BAY and BAS, the Riskmetrics approach performed well, providing the relative squared deviation smaller than in the case of the moving window and the LCP procedure. However, one observes higher standard deviations in the case of Riskmetrics. For the second portfolio consisting of SIE, THY, SCH, EOA, HEN and LHA, Riskmetrics lead to
42

50
0
-50 2001
50
0
-50 2001
50
0
-50 2001

Riskmetrics

2002

2003 Moving window

2004

2002

2003 Adaptive estimation

2004

2002

2003

2004

2005 2005 2005

Figure 21: P&L (dots) and V aR() at level 1 = 0.01; w = (3, 2, 3, 2, 3, -1) , estimated using RiskMetrics approach (upper panel), moving window approach (middle panel) and adaptive estimation procedure (lower panel) for 6-dim data: Siemens, ThyssenKrupp, Schering, E.ON AG, Henkel, Lufthansa.
43

smaller standard deviations fitting well only at the 5% level. It failed to capture the dependence at lower quantiles: the correlation structure contains nonlinearities that can not be captured by the multivariate normal distribution. Further, the adaptive estimation procedure allows for dynamic selection of the interval for dependence structure estimation and thus produces smaller relative squared deviations which leads to better backtesting results.
44

References
E. Bouy´e, V. Durrleman, A. Nikeghbali, G. Riboulet, and T. Roncalli. Copulas for Finance. Groupe de Recherche Op´erationnelle Cr´edit Lyonnais, 1996.
X. Chen and Y. Fan. Estimation and Model Selection of Semiparametric Copula-Based Multivariate Dynamic Models under Copula Misspecification. Journal of Econometrics, forthcoming, 2004.
X. Chen and Y. Fan. Estimation of Copula-Based Semiparametric Time Series Models. Journal of Econometrics, 130:307­335, 2006.
X. Chen, Y. Fan, and V Tsyrennikov. Efficient Estimation of Semiparametric Multivariate Copula Models. Journal of the American Statistical Association, forthcoming, 2006.
V. Durrleman, A. Nikeghbali, and T. Roncalli. Which Copula is the Right One? Groupe de Recherche Op´erationnelle Cr´edit Lyonnais, 2000.
P. Embrechts, A. McNeil, and D. Straumann. Correlation and Dependence in Risk Management: Properties and Pitfalls. Correlation, Risk Management: Value at Risk and Beyond, 1999.
P. Embrechts, A. Hoeing, and A. Juri. Using Copulae to Bound the Value-at-Risk for Functions of Dependent Risks. Finance and Stochastics, 7(2):145­167, 2003a.
P. Embrechts, F. Lindskog, and A McNeil. Modelling Dependence with Copulas and Applications to Risk Management. Handbook of Heavy Tailed Distributions in Finance, 8:329­384, 2003b.
J. Franke, W. H¨ardle, and C. Hafner. Statistics of Financial Markets. Springer-Verlag, Heidelberg, 2004.
M. Fr´echet. Sur les Tableaux de Corr´elation Dont les Marges sont Donn´ees. Annales de l'Universit´e de Lyon, Sciences., 14:53­77, 1951.
E. Giacomini and W. Ha¨rdle. Value-at-Risk Calculations with Time Varying Copulae. Bulletin of the International Statistical Institute, 55th Session Sydney Vol. 55., 2005. 45

C.W.J. Granger. Time Series Concept for Conditional Distributions. Oxford Bulletin of Economics and Statistics, 65:689­701, 2003.
W. Ha¨rdle, T. Kleinow, and G. Stahl. Applied Quantitative Finance. Springer-Verlag, Heidelberg, 2002.
W. Ha¨rdle, H. Herwatz, and V. Spokoiny. Time Inhomogeneous Multiple Volatility Modelling. Journal of Financial Econometrics, 1:55­95, 2003.
W. Hoeffding. Massstabinvariante Korrelationstheorie. Schriften des mathematischen Seminars und des Instituts fu¨r angewandte Mathematik der Universit¨at Berlin, 5:181­233, 1940.
W. H¨ardle, T. Kleinow, and G. Stahl. Applied Quantitative Finance. Springer-Verlag, Heidelberg, 2002.
H. Joe. Multivariate Models and Dependence Concepts. Chapman & Hall, London, 1997. D.D. Mari and S. Kotz. Correlation and Dependence. Imperial College Press, London, 2001. D. Mercurio and V. Spokoiny. Estimation of Time Dependent Volatility via Local Change Point
Analysis with Applications to Value-at-Risk. Annals of Statistics, 32:577­602, 2004. J.P. Morgan/Reuters. RiskMetrics Technical Document. http://www.riskmetrics.com/rmcovv.
html, New York, 1996. R. Nelsen. An Introduction to Copulas. Springer-Verlag, New York, 1998. A. Sklar. Fonctions de R´epartition a` n Dimensions et Leures Marges. Fonctions de r´epartition `a n
dimensions et leures marges, 8:229­231, 1959. V. Spokoiny. Local Parametric Methods in Nonparametric Estimation. Springer-Verlag, Berlin,
Heidelberg, NY., 2007.
46

SFB 649 Discussion Paper Series 2006
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "Calibration Risk for Exotic Options" by Kai Detlefsen and Wolfgang K. Härdle, January 2006.
002 "Calibration Design of Implied Volatility Surfaces" by Kai Detlefsen and Wolfgang K. Härdle, January 2006.
003 "On the Appropriateness of Inappropriate VaR Models" by Wolfgang Härdle, Zdenk Hlávka and Gerhard Stahl, January 2006.
004 "Regional Labor Markets, Network Externalities and Migration: The Case of German Reunification" by Harald Uhlig, January/February 2006.
005 "British Interest Rate Convergence between the US and Europe: A Recursive Cointegration Analysis" by Enzo Weber, January 2006.
006 "A Combined Approach for Segment-Specific Analysis of Market Basket Data" by Yasemin Boztu and Thomas Reutterer, January 2006.
007 "Robust utility maximization in a stochastic factor model" by Daniel Hernández­Hernández and Alexander Schied, January 2006.
008 "Economic Growth of Agglomerations and Geographic Concentration of Industries - Evidence for Germany" by Kurt Geppert, Martin Gornig and Axel Werwatz, January 2006.
009 "Institutions, Bargaining Power and Labor Shares" by Benjamin Bental and Dominique Demougin, January 2006.
010 "Common Functional Principal Components" by Michal Benko, Wolfgang Härdle and Alois Kneip, Jauary 2006.
011 "VAR Modeling for Dynamic Semiparametric Factors of Volatility Strings" by Ralf Brüggemann, Wolfgang Härdle, Julius Mungo and Carsten Trenkler, February 2006.
012 "Bootstrapping Systems Cointegration Tests with a Prior Adjustment for Deterministic Terms" by Carsten Trenkler, February 2006.
013 "Penalties and Optimality in Financial Contracts: Taking Stock" by Michel A. Robe, Eva-Maria Steiger and Pierre-Armand Michel, February 2006.
014 "Core Labour Standards and FDI: Friends or Foes? The Case of Child Labour" by Sebastian Braun, February 2006.
015 "Graphical Data Representation in Bankruptcy Analysis" by Wolfgang Härdle, Rouslan Moro and Dorothea Schäfer, February 2006.
016 "Fiscal Policy Effects in the European Union" by Andreas Thams, February 2006.
017 "Estimation with the Nested Logit Model: Specifications and Software Particularities" by Nadja Silberhorn, Yasemin Boztu and Lutz Hildebrandt, March 2006.
018 "The Bologna Process: How student mobility affects multi-cultural skills and educational quality" by Lydia Mechtenberg and Roland Strausz, March 2006.
019 "Cheap Talk in the Classroom" by Lydia Mechtenberg, March 2006. 020 "Time Dependent Relative Risk Aversion" by Enzo Giacomini, Michael
Handel and Wolfgang Härdle, March 2006. 021 "Finite Sample Properties of Impulse Response Intervals in SVECMs with
Long-Run Identifying Restrictions" by Ralf Brüggemann, March 2006. 022 "Barrier Option Hedging under Constraints: A Viscosity Approach" by
Imen Bentahar and Bruno Bouchard, March 2006.
SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

023 "How Far Are We From The Slippery Slope? The Laffer Curve Revisited" by Mathias Trabandt and Harald Uhlig, April 2006.
024 "e-Learning Statistics ­ A Selective Review" by Wolfgang Härdle, Sigbert Klinke and Uwe Ziegenhagen, April 2006.
025 "Macroeconomic Regime Switches and Speculative Attacks" by Bartosz Makowiak, April 2006.
026 "External Shocks, U.S. Monetary Policy and Macroeconomic Fluctuations in Emerging Markets" by Bartosz Makowiak, April 2006.
027 "Institutional Competition, Political Process and Holdup" by Bruno Deffains and Dominique Demougin, April 2006.
028 "Technological Choice under Organizational Diseconomies of Scale" by Dominique Demougin and Anja Schöttner, April 2006.
029 "Tail Conditional Expectation for vector-valued Risks" by Imen Bentahar, April 2006.
030 "Approximate Solutions to Dynamic Models ­ Linear Methods" by Harald Uhlig, April 2006.
031 "Exploratory Graphics of a Financial Dataset" by Antony Unwin, Martin Theus and Wolfgang Härdle, April 2006.
032 "When did the 2001 recession really start?" by Jörg Polzehl, Vladimir Spokoiny and Ctlin Stric, April 2006.
033 "Varying coefficient GARCH versus local constant volatility modeling. Comparison of the predictive power" by Jörg Polzehl and Vladimir Spokoiny, April 2006.
034 "Spectral calibration of exponential Lévy Models [1]" by Denis Belomestny and Markus Reiß, April 2006.
035 "Spectral calibration of exponential Lévy Models [2]" by Denis Belomestny and Markus Reiß, April 2006.
036 "Spatial aggregation of local likelihood estimates with applications to classification" by Denis Belomestny and Vladimir Spokoiny, April 2006.
037 "A jump-diffusion Libor model and its robust calibration" by Denis Belomestny and John Schoenmakers, April 2006.
038 "Adaptive Simulation Algorithms for Pricing American and Bermudan Options by Local Analysis of Financial Market" by Denis Belomestny and Grigori N. Milstein, April 2006.
039 "Macroeconomic Integration in Asia Pacific: Common Stochastic Trends and Business Cycle Coherence" by Enzo Weber, May 2006.
040 "In Search of Non-Gaussian Components of a High-Dimensional Distribution" by Gilles Blanchard, Motoaki Kawanabe, Masashi Sugiyama, Vladimir Spokoiny and Klaus-Robert Müller, May 2006.
041 "Forward and reverse representations for Markov chains" by Grigori N. Milstein, John G. M. Schoenmakers and Vladimir Spokoiny, May 2006.
042 "Discussion of 'The Source of Historical Economic Fluctuations: An Analysis using Long-Run Restrictions' by Neville Francis and Valerie A. Ramey" by Harald Uhlig, May 2006.
043 "An Iteration Procedure for Solving Integral Equations Related to Optimal Stopping Problems" by Denis Belomestny and Pavel V. Gapeev, May 2006.
044 "East Germany's Wage Gap: A non-parametric decomposition based on establishment characteristics" by Bernd Görzig, Martin Gornig and Axel Werwatz, May 2006.
045 "Firm Specific Wage Spread in Germany - Decomposition of regional differences in inter firm wage dispersion" by Bernd Görzig, Martin Gornig and Axel Werwatz, May 2006.
SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

046 "Produktdiversifizierung: Haben die ostdeutschen Unternehmen den Anschluss an den Westen geschafft? ­ Eine vergleichende Analyse mit Mikrodaten der amtlichen Statistik" by Bernd Görzig, Martin Gornig and Axel Werwatz, May 2006.
047 "The Division of Ownership in New Ventures" by Dominique Demougin and Oliver Fabel, June 2006.
048 "The Anglo-German Industrial Productivity Paradox, 1895-1938: A Restatement and a Possible Resolution" by Albrecht Ritschl, May 2006.
049 "The Influence of Information Costs on the Integration of Financial Markets: Northern Europe, 1350-1560" by Oliver Volckart, May 2006.
050 "Robust Econometrics" by Pavel Cízek and Wolfgang Härdle, June 2006. 051 "Regression methods in pricing American and Bermudan options using
consumption processes" by Denis Belomestny, Grigori N. Milstein and Vladimir Spokoiny, July 2006. 052 "Forecasting the Term Structure of Variance Swaps" by Kai Detlefsen and Wolfgang Härdle, July 2006. 053 "Governance: Who Controls Matters" by Bruno Deffains and Dominique Demougin, July 2006. 054 "On the Coexistence of Banks and Markets" by Hans Gersbach and Harald Uhlig, August 2006. 055 "Reassessing Intergenerational Mobility in Germany and the United States: The Impact of Differences in Lifecycle Earnings Patterns" by Thorsten Vogel, September 2006. 056 "The Euro and the Transatlantic Capital Market Leadership: A Recursive Cointegration Analysis" by Enzo Weber, September 2006. 057 "Discounted Optimal Stopping for Maxima in Diffusion Models with Finite Horizon" by Pavel V. Gapeev, September 2006. 058 "Perpetual Barrier Options in Jump-Diffusion Models" by Pavel V. Gapeev, September 2006. 059 "Discounted Optimal Stopping for Maxima of some Jump-Diffusion Processes" by Pavel V. Gapeev, September 2006. 060 "On Maximal Inequalities for some Jump Processes" by Pavel V. Gapeev, September 2006. 061 "A Control Approach to Robust Utility Maximization with Logarithmic Utility and Time-Consistent Penalties" by Daniel Hernández­Hernández and Alexander Schied, September 2006. 062 "On the Difficulty to Design Arabic E-learning System in Statistics" by Taleb Ahmad, Wolfgang Härdle and Julius Mungo, September 2006. 063 "Robust Optimization of Consumption with Random Endowment" by Wiebke Wittmüß, September 2006. 064 "Common and Uncommon Sources of Growth in Asia Pacific" by Enzo Weber, September 2006. 065 "Forecasting Euro-Area Variables with German Pre-EMU Data" by Ralf Brüggemann, Helmut Lütkepohl and Massimiliano Marcellino, September 2006. 066 "Pension Systems and the Allocation of Macroeconomic Risk" by Lans Bovenberg and Harald Uhlig, September 2006. 067 "Testing for the Cointegrating Rank of a VAR Process with Level Shift and Trend Break" by Carsten Trenkler, Pentti Saikkonen and Helmut Lütkepohl, September 2006. 068 "Integral Options in Models with Jumps" by Pavel V. Gapeev, September 2006. 069 "Constrained General Regression in Pseudo-Sobolev Spaces with Application to Option Pricing" by Zdenk Hlávka and Michal Pesta, September 2006.
SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

070 "The Welfare Enhancing Effects of a Selfish Government in the Presence of Uninsurable, Idiosyncratic Risk" by R. Anton Braun and Harald Uhlig, September 2006.
071 "Color Harmonization in Car Manufacturing Process" by Anton Andriyashin, Michal Benko, Wolfgang Härdle, Roman Timofeev and Uwe Ziegenhagen, October 2006.
072 "Optimal Interest Rate Stabilization in a Basic Sticky-Price Model" by Matthias Paustian and Christian Stoltenberg, October 2006.
073 "Real Balance Effects, Timing and Equilibrium Determination" by Christian Stoltenberg, October 2006.
074 "Multiple Disorder Problems for Wiener and Compound Poisson Processes With Exponential Jumps" by Pavel V. Gapeev, October 2006.
075 "Inhomogeneous Dependency Modelling with Time Varying Copulae" by Enzo Giacomini, Wolfgang K. Härdle, Ekaterina Ignatieva and Vladimir Spokoiny, November 2006.
SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

