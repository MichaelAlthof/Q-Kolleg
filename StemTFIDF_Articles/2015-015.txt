BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2015-015
Structural Vector Autoregressions with Heteroskedasticity:
A Comparison of Different Volatility Models
Helmut Lütkepohl* Aleksei Netsunajev**
*DIW Berlin and Freie Universität Berlin, Germany **Freie Universität Berlin, Germany
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universität zu Berlin Spandauer Straße 1, D-10178 Berlin

Structural Vector Autoregressions with Heteroskedasticity
A Comparison of Different Volatility Models
Helmut Lu¨tkepohl
DIW Berlin and Freie Universit¨at Berlin, Mohrenstr. 58, 10117 Berlin, Germany
email: hluetkepohl@diw.de
Aleksei Netsunajev
Freie Universit¨at Berlin, Fachbereich Wirtschaftswissenschaft Boltzmannstr. 20, 14195 Berlin, Germany email: Aleksei.Netsunajev@fu-berlin.de
March 30, 2015
Abstract. A growing literature uses changes in residual volatility for identifying structural shocks in vector autoregressive (VAR) analysis. A number of different models for heteroskedasticity or conditional heteroskedasticity are proposed and used in applications in this context. This study reviews the different volatility models and points out their advantages and drawbacks. It thereby enables researchers wishing to use identification of structural VAR models via heteroskedasticity to make a more informed choice of a suitable model for a specific empirical analysis. An application investigating the interaction between U.S. monetary policy and the stock market is used to illustrate the related issues.
Key Words: Structural vector autoregression, identification via heteroskedasticity, conditional heteroskedasticity, smooth transition, Markov switching, GARCH
JEL classification: C32
 The paper was written while the first author was a Bundesbank Professor at the Freie Universit¨at Berlin. Financial support was provided by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

1 Introduction
Structural vector autoregressive (SVAR) models are typically identified by exclusion restrictions on the impact effects of the structural shocks (e.g., Sims (1980), Bernanke and Mihov (1998), Kilian (2009)), by restrictions on the long-run effects of the shocks (e.g, Blanchard and Quah (1989), King, Plosser, Stock and Watson (1991)) or by restrictions on the signs of the responses of specific variables to a shock (e.g., Faust (1998), Canova and De Nicolo´ (2002), Uhlig (2005)). Recently, a number of articles uses changes in the volatility of the variables for identification of SVAR models (e.g., Rigobon (2003)). A number of alternative approaches have been proposed for modelling the changes in volatility. For example, exogenous changes in the variances of the residuals are considered by Rigobon (2003), Rigobon and Sack (2003) and Lanne and Lu¨tkepohl (2008). In contrast, Lanne, Lu¨tkepohl and Maciejowska (2010) and Herwartz and Lu¨tkepohl (2014), for example, model the changes in volatility by a Markov regime switching (MS) mechanism whereas Lu¨tkepohl and Netsunajev (2014b) consider smooth transition of the residual volatility from one regime to another. Yet another approach is based on a generalized autoregressive conditional heteroskedastic (GARCH) error structure (e.g., Normandin and Phaneuf (2004), Bouakez and Normandin (2010), Weber (2010), Strohsal and Weber (2012)). Typically in this literature there is not much discussion why a particular volatility model is used.
The objective of this study is to compare the alternative approaches and discuss their advantages and drawbacks. Thereby we hope to provide a basis for making a rational decision which model to use for a particular application. Specifically we discuss the model setup, identification conditions for the shocks, estimation and inference methods related to the alternative models. As far as estimation and inference is concerned, we focus on frequentist procedures because Bayesian procedures have not been applied much so far in this context (see, however, Kulikov and Netsunajev (2013)). Hence, there is not much experience with Bayesian methods. For some of the models they are not yet fully developed.
We illustrate the different approaches in the SVAR analysis based on the study by Bjørnland and Leitemo (2009). These authors use conventional exclusion restrictions on the impact and long-run effects of the shocks in studying the interaction between monetary policy and the stock market in the U.S.. We demonstrate how the different volatility models can be used for generating additional identifying information and we discuss the advantages and drawbacks of the alternative models for the example system.
Earlier related reviews of some of the models discussed in the following are given by Lu¨tkepohl (2013) and Lu¨tkepohl and Velinov (2015). They
1

discuss a more limited set of volatility models and different, more limited examples. In particular, they do not compare the full range of volatility models in the context of a specific example. The latter of the two articles focuses specifically on combining restrictions on the long-run effects of the shocks with identifying information from changes in volatility. That topic is part of our general setup and, hence, it is included in the present study as a special case.
The remainder of this study is organized as follows. In the next section the basic SVAR model is introduced and the different volatility models are discussed in Section 3. The illustrative example is considered in Section 4 and concluding remarks are given in the final section.

2 The Baseline Model

The baseline model is a VAR of order p (VAR(p)) of the form

yt =  + A1yt-1 + · · · + Apyt-p + ut,

(1)

where yt = (y1t, . . . , yKt) is a vector of observable variables, the Ai are (K × K) coefficient matrices,  is a (K × 1) constant term and the ut are K-dimensional serially uncorrelated reduced form residuals with mean zero
and nonsingular covariance matrix u. The structural residuals are denoted by t. They have zero mean and are
serially uncorrelated. Typically they are also assumed to be instantaneously uncorrelated, that is, t  (0, ), where  is a diagonal matrix. Sometimes it is convenient to assume that the variances of the structural shocks are
normalized to one so that  is an identity matrix. The structural residuals are typically obtained from the reduced form
residuals by a linear transformation:

t = B-1ut or ut = Bt.

(2)

The matrix B contains the instantaneous effects of the structural shocks on the observed variables. Given the relation between the reduced form residuals and the structural residuals, the matrix B has to satisfy u = BB . In other words, in principle B can be any matrix satisfying u = BB . The relation between the reduced form and structural residuals does not uniquely determine the matrix B and, hence, the structural innovations are not uniquely determined without further assumptions.
The conventional approach is to impose further restrictions on B or its inverse directly to make it unique. These restrictions may be zero restrictions

2

indicating that a certain shock does not have an instantaneous impact on one of the variables (Sims (1980)) or it may be implied by a restriction on the long-run effects of a structural shock as in Blanchard and Quah (1989). In the latter approach the matrix of long-run effects of structural shocks is given by
 = (IK - A1 - · · · - Ap)-1B,
assuming that the inverse exists. That condition is satisfied for stable, stationary processes without unit roots. For integrated and cointegrated processes the long-run effects matrix is related to the cointegration structure of the model (see, e.g., Lu¨tkepohl (2005) or Lu¨tkepohl and Velinov (2015)). For our purposes it is sufficient to know that the matrix of long-run effects can be computed from the reduced form and structural parameters. Imposing restrictions on the matrix of long-run effects implies restrictions on B for a given data generation process (DGP) and, hence, a given reduced form.
Typically the restrictions on B just-identify the structural model and, hence, the structural shocks. In other words, there are just enough restrictions for uniqueness of B and no more. If there are two competing sets of just-identifying assumptions or theories implying just-identifying restrictions, they lead to identical reduced forms and cannot be tested against the data. Hence, the conventional setup is often uninformative regarding the validity of specific economic theories. In the next section it is discussed how heteroskedasticity can be used to improve the situation in this case.

3 SVAR Models with Time-Varying Volatility

Suppose now that ut is a heteroskedastic or conditionally heteroskedastic error term. This means that the variances or conditional variances of the reduced form and, hence, also the structural innovations change over time. In the macroeconomic literature such behaviour is well documented. Allowing for this feature means that there is more than one volatility regime present during the sample period and each regime is characterized by a covariance matrix u(m), say. Suppose that there are M such regimes. If the corresponding covariance matrices can be decomposed as

u(1) = BB , u(m) = BmB , m = 2, . . . , M,

(3)

with m = diag(m1, . . . , mK), then the structural shocks obtained as in (2) satisfy the basic condition that they are instantaneously uncorrelated in all

3

volatility regimes. The diagonal matrices m are the matrices of variances of structural shocks in regime m relative to regime 1. For convenience 1 is chosen to be the identity matrix. In other words, the structural shocks are normalized to have unit variances in the first volatility regime.
In this setup the matrix of impact effects of the shocks, B, is (locally) uniquely determined by the decomposition in (3) if for any subscripts k, l  {1, . . . , K}, k = l, there is a j  {2, . . . , M } such that jk = jl (Lanne et al., 2010, Proposition 1). In other words, for any two subscripts k and l there must be at least one regime, where the corresponding relative variances are different. For example, for the case of just two different volatility states with covariance matrices

u(1) = BB , u(2) = B2B all diagonal elements of 2 have to be distinct. For more than two states,

2k = 2l, . . . , Mk = Ml

(4)

must not hold for any combination k, l with k = l. In other words, local uniqueness is ensured if there is sufficient heterogeneity in the volatility changes. For instance, it is not enough that all variances change in proportion.
Here local uniqueness refers to the fact that the matrix B is unique only up to changes in the signs of its columns and up to permutations of its columns. In other words, the matrix B is unique if the structural shocks are chosen as t = B-1ut and the signs and ordering of the shocks are fixed. Thus, allowing for multiple volatility regimes the assumption of regime invariant impact effects of the structural shocks, i.e., choosing t = B-1ut with a time-invariant transformation matrix implies uniqueness or identification without imposing additional economic restrictions. In the context of SVARs with heteroskedasticity the identification is shifted from imposing the just-identifying exclusion or long-run restrictions on B towards restrictions implied by the statistical model setup. These conditions have to be met in order to obtain exact (local) identification via changes in volatility. Once the statistical identification is achieved, additional economic restrictions can be imposed and can be tested formally as over-identifying restrictions.
There are several ways to model the change in volatility. Initially the change points were just specified exogenously by the analyst, possibly based on some prior statistical analysis (e.g., Rigobon (2003), Lanne and Lu¨tkepohl (2008), Bacchiocchi and Fanelli (2012)). Other approaches let the data decide endogenously on the change points and possibly also the number of volatility regimes. This approach is used when modelling the changes in volatility

4

with a smooth transition specification (Lu¨tkepohl and Netsunajev (2014b)), via a Markov switching process (e.g., Lanne et al. (2010)), or based on a generalized autoregressive conditional heteroskedasticity (GARCH) process (Normandin and Phaneuf (2004)). These approaches allow even for infinitly many volatility regimes. They are presented and discussed in more detail in the following sections.

3.1 Exogenously Specified Volatility Changes
A simple model for volatility changes is based on the assumption that the change points are exogenously given, that is,

E(utut) = u,t = u(m) for t  Tm, m = 1, . . . , M,

(5)

where Tm = {Tm-1 + 1, . . . , Tm} (m = 1, . . . , M ) are M given volatility regimes usually consisting of consecutive time periods. The Tm, for m = 1, . . . , M - 1, represent the time periods of volatility changes. The initial T0 = 0 and TM = T . The Tm are assumed to be known to the analyst and are, hence, taken as given in the analysis. In practice, they may be obtained with some prior statistical procedure, for instance, a testing procedure for changes in the residual covariance matrix.
Estimation of the model is straightforward. Under normality assumptions, the likelihood function can be set up and ML estimation can be used (see, e.g., Lu¨tkepohl (2013)). If the data are not normally distributed, the estimators are quasi ML estimators with standard asymptotic properties. Since the likelihood function is nonlinear one may also want to consider a generalized least squares procedure instead of full ML.
To estimate the structural parameters, u(1) has to be replaced by BB and BmB replaces u(m) (m = 2, . . . , M ) in the likelihood function. Note, however, that for M > 2 this imposes a restriction on the model that can be tested by a likelihood ratio (LR) test. Under Gaussian assumptions and the null hypothesis of the restriction being correct, the LR statistic has an asymptotic 2 distribution with

1 M K(K

+

1)

-

K2

-

(M

-

1)K

2

degrees of freedom (see Lanne et al. (2010)). If the null hypothesis is rejected, the assumption of a time-invariant initial effects matrix B across all volatility regimes is not in line with the data. In that case, one could consider the possibility of a time-invariant initial effects matrix across some of the regimes.

5

If the decomposition of the covariance matrices is supported by the data, then the conditions for local uniqueness of B can be tested. In other words, using (4), null hypotheses

H0 : 2k = 2l, . . . , Mk = Ml

(6)

have to be tested for all pairs k, l  {1, . . . , K} with k = l. These are conditions on the diagonal elements of the m matrices. They are identified if they are ordered uniquely even if B is not identified. For example, one may order the diagonal elements of 2 from smallest to largest, if all elements are distinct. If some of the elements are equal, the ordering can be based on 3 etc.. In any case, their asymptotic distribution can be used for testing the identifying conditions. Wald tests based on the asymptotic distribution of the mk can be used for that purpose (see Herwartz and Lu¨tkepohl (2014)). Alternatively, under Gaussian assumptions, LR tests can be considered (Lu¨tkepohl and Netsunajev (2014a)).
Another issue is the determination of the volatility change points. As mentioned previously, in practice this is often done by prior statistical procedures (e.g., Ehrmann, Fratzscher and Rigobon (2011)). Again standard procedures, e.g., Chow tests can be used for this purpose. Thus, overall the statistical procedures related to the model are straightforward and computationally feasible.
Applications of the model are due to Rigobon (2003), Rigobon and Sack (2003, 2004), Lanne and Lu¨tkepohl (2008) and Ehrmann et al. (2011), for example. While the straightforward estimation and inference procedures associated with the model make it attractive for use in practice, the fact that the volatility change points have to be prespecified is a disadvantage. Clearly, it is often plausible to assume that the volatility changes are endogenously generated. Therefore letting the data determine the volatility process including its possible change points is more appealing.

3.2 SVAR with Smooth Transition in Variances
One possible model with endogenously changing volatility assumes a smooth change in the residual covariance matrix. It was proposed in this context by Lu¨tkepohl and Netsunajev (2014b). More precisely, the change in the covariance structure is modelled as a smooth transition from a volatility regime characterized by a positive definite covariance matrix u(1) to a regime with a different positive definite covariance matrix u(2). The transition is described by a smooth transition function G(, c, st) that depends on parameters  and c as well as a transition variable st. Lu¨tkepohl and Netsunajev

6

(2014b) use a logistic function with transition variable st = t, that is, G(, c, st) = (1 + exp[- exp()(t - c)])-1.

(7)

Because exp() > 0 for positive and negative values of , G(, c, st) > 0 is close to zero when t is much smaller than c and G(, c, st)  1 for t  . Formally, the reduced form residual covariance is described as

E(utut) = u,t = (1 - G(, c, st))u(1) + G(, c, st)u(2).

(8)

This setup ensures a positive definite matrix u,t because this matrix is a convex combination of two positive definite matrices. Notice that due to the covariance change during the transition period there are in fact infinitely many different covariance regimes.
The transition from the residual covariance matrix u(1) to u(2) can be used for identification purposes, using the decomposition

u(1) = BB and u(2) = B2B ,

(9)

where 2 = diag(21, . . . , 2K) is a diagonal matrix with positive diagonal elements as before. Apart from changing the signs of the columns of B this decomposition is unique for a given ordering of the diagonal elements of 2 if the diagonal elements are all pairwise distinct (Lanne and Lu¨tkepohl (2008)). Thus, if the B matrix from (9) is used to transform the reduced form residuals, the covariance matrices of the structural shocks are IK and 2 for the initial and final regimes, respectively. The diagonal elements of the 2 matrix can thus be interpreted as variances of structural shocks in the final regime relative to the initial regime.
Under the assumption of normality the likelihood function of the model can be set up and ML estimation can be performed using standard numerical non-linear optimization algorithms. An iterative procedure for estimation is discussed in detail by Lu¨tkepohl and Netsunajev (2014b). Since the range of the smoothness and threshold parameters {, c} can be bounded, a grid search can be performed over the space of these two parameters. Thus, estimation is technically straightforward and the asymptotic properties of the parameter estimators are standard under usual assumptions for the DGP.
An important advantage of using this setup is that the identification condition based on the diagonal elements of 2 becomes testable. Lu¨tkepohl and Netsunajev (2014b) use Wald tests for this purpose. In a related context Lu¨tkepohl and Netsunajev (2014a) use likelihood ratio tests. If the diagonal elements of 2 are all distinct, any restrictions imposed on B in a conventional SVAR framework become over-identifying and can be tested against the data.

7

Apart from the straightforward estimation and inference procedures of the model it has also the advantage of transparency of the mechanism of volatility change. This, however, may turn out to be a disadvantage because it may not be very realistic in many macroeconomic applications. A simple move from one volatility regime to another during the sample period is clearly a very special situation. Of course, the model can be extended by including further transition terms so that the volatility can move between more states. Also one could consider other transition variables or transition functions that allow for more movement between two volatility states. If such volatility changes are suspected it is a question, however, whether alternative specifications may be more suitable for capturing them. One such alternative specification is a Markov switching mechanism that drives the volatility changes. It is presented next.

3.3 SVARs with Markov Switching in Variances
Lanne et al. (2010) propose to use a Markov regime switching mechanisms in the VAR residuals for modelling the volatility changes and identifying structural shocks. The related statistical methodology for using it in the SVAR framework is partly developed by Herwartz and Lu¨tkepohl (2014). In this approach the distribution of the error term ut is assumed to depend on a discrete Markov process st (t = 0, ±1, ±2, . . . ) with states 1, . . . , M , and transition probabilities

pij = Pr(st = j|st-1 = i), i, j = 1, . . . , M.

The conditional distribution of ut given st is assumed to have a covariance matrix that is different across states,

ut|st  (0, u(st)).

(10)

The model allows for Markov switching in the residual covariances only and not in the VAR parameters. It captures conditional heteroskedasticity. Notice that there are finitely many Markov states only. Since the model assigns probabilities to these states in each period, there are actually infinitely many possible conditional covariance matrices. Thus, the model can also capture smooth transitions from one state to another because a particular state does not necessarily come up with probability one but the system may be in between states. In other words, the actual volatility may be described by a mixture of different states, each state being weighted by a certain probability in each period.

8

Structural identification is obtained in this setting by using the covariance decomposition

u(1) = BB , u(m) = BmB , m = 2, . . . , M,

(11)

as in the model with exogenously determined changes in volatility. The conditions are the same as those discussed in Section 3.1.
Estimation of the model can be done by ML if distributional assumptions are made. Lanne et al. (2010) and Herwartz and Lu¨tkepohl (2014) assume a normal conditional distribution of ut, i.e., ut|st  N (0, u(st)), set up the likelihood function accordingly and present a suitable optimization algorithm. The actual optimization task is difficult for larger models. There are several obstacles that make estimation difficult. First, the likelihood function is actually unbounded so that strictly speaking there is no maximum. The problem can be overcome by ensuring that all covariance matrices are positive definite and their eigenvalues are bounded away from zero. Second, the likelihood function is highly nonlinear and has local optima. This problem can be alleviated by using a large number of different starting values for the optimization algorithm. Third, there is the well-known label-switching problem which arises if the ordering of the regimes changes in the course of the optimization. These obstacles make it difficult to compute ML estimates for models with many parameters, that is, for models with many volatility regimes, many variables or large lag orders. It may be noteworthy that overcoming these problems is also not straightforward in a Bayesian approach.
If ML estimates can be obtained they have standard asymptotic properties under suitable assumptions. In fact, the normality assumption may be relaxed. Asymptotic properties can also be derived if the true distribution is different so that ML based on the conditionally Gaussian distribution is actually a quasi ML procedure. Note however, that assuming a Gaussian conditional distribution implies a nonnormal unconditional distribution of the data. Hence, the assumption may make sense even for financial data, for example.
In any case, the difficult numerical computation of the ML estimates is a drawback of the model when systems with larger numbers of variables are of interest. It also makes it difficult to use bootstrap techniques that require estimation of a large number of models. Herwartz and Lu¨tkepohl (2014) propose a fixed design wild bootstrap method that conditions on some of the estimated parameters. Little is known about the actual properties of the method.
Applications of the MS-SVAR model are available in a number of studies. Examples are Lanne et al. (2010), Herwartz and Lu¨tkepohl (2014), Lu¨tkepohl

9

and Netsunajev (2014a), Netsunajev (2013), Lu¨tkepohl and Velinov (2015), Velinov (2013).
The model has appeal because it lets the data assign the observations to the different volatility regimes. The regimes obtained in this way often have a clear interpretation. For example, they may be linked to the business cycle or other economically relevant features or periods of particular interest from the point of view of economics. Identification conditions are available that can be checked easily. If the model is small enough to compute Gaussian ML estimates easily, then standard procedures for inference can be used straightforwardly. The drawback of the model is, however, that for larger models with long lag orders, a larger set of variables or many different volatility regimes estimation is difficult and potentially unreliable. Moreover, even for small models that can be estimated easily, little is known about the properties of the proposed methods for constructing confidence bands around impulse responses, for example.

3.4 SVARs with GARCH

Suppose now that the reduced form errors ut follow a multivariate GARCH process. The information available up to and including period t is contained in the set Ft and the conditional covariance matrix of ut given Ft-1 is assumed to be of the form

E(utut|Ft-1) = B,t|t-1B ,

(12)

where ,t|t-1 = diag(12,t|t-1, . . . , K2 ,t|t-1) is a diagonal matrix. The individual variances of structural shocks are assumed to have a GARCH(1,1)

structure:

k2,t|t-1 = (1 - k - gk) + kk2,t-j + gkk2,t-j|t-j-1, k = 1, . . . , K. (13)

In other words, the structural shocks are assumed to be orthogonal and their variances are modelled by individual GARCH(1, 1) processes. Of course, in principle one could consider higher order GARCH processes. Because this is not done in practice, we also focus on GARCH(1,1) processes to avoid unnecessarily clumsy notation. Notice also that the individual GARCH processes imply an unconditional variance of 1. Hence, the unconditional covariance matrix of the structural errors is the identity and

E(utut) = u = BB .
The setup of our model very much resembles the GO-GARCH specification proposed by van der Weide (2002) and the model considered by Normandin and Phaneuf (2004).

10

Sentana and Fiorentini (2001) and Milunovich and Yang (2013) provide general results on the identification of B and, hence, the structural shocks. Specifically, B is (locally) identified if at least K - 1 of the GARCH(1,1) processes are nontrivial, that is, k = 0 for at least K - 1 of the K processes in (13). In essence, there has to be enough heterogeneity in the conditional variances to identify the shocks. At most one shock may be homoskedastic.
In the empirical literature using GARCH for identifying structural shocks in an SVAR analysis, formal tests of the identification condition are typically not applied. Such tests are desirable in particular in macroeconometric studies because they often involve variables for which one would not expect conditional heteroskedasticity a priori, especially when data of relatively low frequency, such as quarterly data are used. Lu¨tkepohl and Milunovich (2015) propose and explore the properties of tests for identification in SVARGARCH models that were originally suggested by Lanne and Saikkonen (2007) in a related context. It tests the null hypothesis that there are K - 2 nontrivial GARCH components against the alternative that there are more such components. Rejecting the null hypothesis implies identification. The test proceeds as follows.
To emphasize the fact that there may only be h < K nontrivial GARCH(1,1) components, the process generating the reduced-form errors is written as

ut = B

1t|/t-2 1

0

0 IK-h

t,

(14)

where t  iid(0, IK) and

 12,t|t-1

0

t|t-1

=

 

...

 

0 h2,t|t-1

(15)

is an (h × h) diagonal matrix with univariate GARCH(1,1) processes on the diagonal. In other words,

ut|t-1  0, t|t-1 = B

t|t-1 0 0 IK-h

B

.

Partitioning the transformation matrix B such that B = [B1 : B2], where B1 is (K × h) and B2 is (K × (K - h)), the first part, B1 is identified and, hence, can be estimated consistently. Lanne and Saikkonen (2007) propose
to choose B2 as an orthogonal complement of the estimated B1. Denoting by B^ the estimated B matrix obtained in this way, they propose to test the

11

last K - h components of B^-1u^t, say e^2t, for remaining GARCH components using GARCH tests based on portmanteau type statistics (see Lu¨tkepohl and Milunovich (2015) for details). More precisely, they consider test statistics based on autocorrelations of the quantities

T
t = e^2te^2t - T -1 e^2te^2t
t=1
and

t =vech(e^2te^2t) - T -1 Tt=1vech(e^2te^2t), where vech denotes the half-vectorization operator. The test statistics are

H
Q1(H) = T [~(h)/~(0)]2,
j=1

(16)

where

T

~(j) = T -1

t t-j ,

t=j+1

and
H
Q2(H) = T tr[~(j) ~(0)-1~(j)~(0)-1],
j=1

(17)

where

T

~(j) = T -1

tt-j for j = 0, 1, . . . ,

t=j+1

and ~(j) = ~(-j) for j < 0. Under the null hypothesis of only h GARCH components, the statistics Q1(H) and Q2(H) have asymptotic 2 distributions with H and H(K - h)2(K - h + 1)2/4 degrees of freedom, respectively. The number H of autocorrelations to be included has to be fixed by the analyst. A value H = 1 is considered by Lanne and Saikkonen (2007) and Lu¨tkepohl and Milunovich (2015).
For a third possible test, Lu¨tkepohl and Milunovich (2015) consider the regression

t = 0 + D1t-1 + · · · + DH t-H + wt,

(18)

12

where

t

=

vech(e^2te^2t),

0

is

a

1 2

(K

- h)(K

- h + 1)-dimensional

fixed

vector,

the

Di,

i

=

1, . . . , H

are

1 2

(K

-

h)(K

-

h

+

1)

×

1 2

(K

-

h)(K

-

h

+

1)

parameter

matrices and wt is an error term. The LM test statistic for testing the null

H0 : D1 = · · · = DH

is

Q3 (H )

=

1 2

T

(K

-

h)(K

-

h

+

1)

-

T tr[~ w~(0)-1]

(19)

where ~ w is the estimated residual covariance matrix of (18). The criti-

cal

values

are

obtained

from

the

2(

1 2

H

(K

-

h)2(K

-

h

+

1)2)

distribution.

Lu¨tkepohl and Milunovich (2015) also choose H = 1 for implementing this

test.

The estimation of the parameters of the SVAR-GARCH model may be

done by ML under Gaussian assumptions, that is, t is assumed to be normally distributed. Lanne and Saikkonen (2007) derive a form of the likelihood

that does not depend on unidentified parameters for given h. Thus, estima-

tion is feasible. The actual optimization of the log-likelihood can still be

numerically challenging for large models. Therefore designing useful boot-

strap methods, for example, for estimating impulse responses leaves room for

further research.

In some studies using the SVAR-GARCH approach, other GARCH mod-

els are considered (e.g., Weber (2010), Strohsal and Weber (2012)). In fact,

given the additional identifying information in the GARCH structure, it is

not even necessary to insist on instantaneously uncorrelated shocks and this

assumption is given up in some related literature. The shocks can be identi-

fied by some other assumption such as constant conditional correlations (see

Weber (2010)). In any case, this does not make the treatment of the model

simpler. A drawback is the challenging likelihood function that is difficult

to maximize for larger models with many variables although the procedure

described in the foregoing may alleviate the task. Another drawback is that

the periods of different volatility, such as low volatility and high volatility

periods, may not be obvious from the model. On the other hand, the con-

ditional heteroskedastic structure has been applied extensively for financial

data and, hence, it has some appeal for such data.

13

4 The Relation Between U.S. Monetary Policy and the Stock Market
4.1 The Data and the Structural Model
In this section the different heteroskedastic and conditionally heteroskedastic SVARs are illustrated in the context of an investigation of the interaction between U.S. monetary policy and the stock market. We use all three models that allow for endogenously changing volatility and reconsider a study reported by Bjørnland and Leitemo (2009). These authors use short-run and long-run restrictions in a conventional SVAR setting to identify the shocks of interest. The study by Bjørnland and Leitemo (2009) is chosen as point of departure for several reasons. First, these authors propose a novel identification scheme that is not testable in a conventional setting while the SVARs with heteroskedasticity allow to test the restrictions. Second, the model of Bjørnland and Leitemo (2009) is at monthly frequency and we use the extended sample period 1970M1 - 2007M6 and, hence, we have 450 observations for each variable making, for instance, GARCH model estimation feasible. The end of the sample is determined to avoid distortions from the crisis that started around the middle of 2007. Typical macro-VARs on quarterly frequency would not contain more than 250 observations. The data is collected as close as possible to Bjørnland and Leitemo (2009). We consider a five dimensional VAR with the vector of variables being yt = (qt, t, ct, spt, rt) , where:
· qt is the linearly detrended log of an industrial production index;
· t is the scaled (×100) annual change in the log of consumer prices (CPI);
· ct represents the scaled (×100) annual change in the log of the World Bank (non energy) commodity price index;
· spt is the log of the S&P 500 stock price index deflated by the CPI to measure the real stock prices. The series is first differenced to represent monthly returns (spt);
· rt denotes the Federal Funds rate.
The data (with the exception of the commodity price index obtained from the World Bank) is downloaded from the Federal Reserve Bank of St. Louis database FRED.
14

From the point of view of our analysis it is of particular interest to test the restrictions specified by Bjørnland and Leitemo (2009) using different models and, hence, to check whether they are in line with the data. Bjørnland and Leitemo (2009) criticize the recursive identification of monetary policy and stock price shocks. They suggest that monetary policy shocks may have an impact on the stock market within the month. To overcome this problem combining short-run and long-run restrictions is proposed. The identification scheme can be visualized as follows:

 0 0 0 0

    

  0 0 0

    

B

=

 







0

0

 

and



=

 











 

,

 











 

 









0

 





(20)

where the asterisks indicate unrestricted elements and zeros denote elements restricted to zero and B and  denote the matrices of impact and longrun effects, respectively, of the shocks, as before. The shocks of particular interest are the shocks ordered fourth and fifth, corresponding to the last two columns of the matrices. This identification suggests that the last shock is the monetary policy shock and it has no immediate impact on industrial production, inflation and commodity prices as well as no long-run effect on stock prices. The shock ordered fourth is viewed as the stock price shock and it has no contemporaneous effect on the real side of the economy. Note that the first three shocks are not of interest for the current analysis. They can be identified arbitrarily in a conventional SVAR analysis.
In the following we consider alternative sets of restrictions for the initial effects matrix B and the long-run effects matrix  and explore their compatibility with the data.

R1: B and  are restricted as in (20) (Bjørnland-Leitemo identification).
R2: Only the two last columns of B and  are restricted as in (20).
R3: Only B is restricted as in (20) and no restrictions are imposed on .
The first set of restrictions constrains the impact effects and long-run responses just as in the Bjørnland-Leitemo setup. The second set imposes only the restrictions used for the shocks of interest, i.e., the stock market shock and the monetary policy shock. Finally, R3 represents the full set of restrictions from Bjørnland-Leitemo except for the long-run restriction. Thus, imposing only those restrictions does not fully identify the shocks of interest. All these sets of restrictions are either under-identifying or just-identifying

15

in a conventional framework. Hence, testing them requires additional identifying restrictions that we get from the changes in volatility in the variables.
4.2 The Volatility Model
We estimate the standard VAR and three (conditional) heteroskedastic VARs with different assumptions on the evolution of volatility. The VAR order is chosen to be three as suggested by the Akaike information criterion (AIC) in a conventional model that does not allow for heteroskedasticity. Bjørnland and Leitemo (2009) use four lags based on lag reduction tests for their shorter data range.
In practice, if changes in volatility are suspected, it is useful to think about the most suitable volatility model for a particular application. For the system of interest here, volatility changes are likely, for example, because a financial variable such as spt is included. It is not easy to link the volatility changes to specific exogenous events and, hence, to specific parts of the sample period. Therefore a model that assigns the volatility states endogenously makes more sense than a model with exogenous volatility changes. Given the stock returns in the system one may think of a GARCH model. However, also the MS model can capture similar conditional heteroskedastic structures. Therefore it is a priori equally suitable if enough volatility states are allowed for. If the volatility change is sufficiently smooth, also the ST model is a possibility. It is used, in fact, by Lu¨tkepohl and Netsunajev (2014b) for the presently considered system and we draw on the results from that study for the ST-SVAR model in the following. In deciding on the volatility model it may be useful to inspect the residuals from a standard VAR analysis. They are presented in Figure 5 and show that there are indeed considerable changes in volatility throughout the sample and capturing them with a model with exogenously assigned volatility regimes may not be easy. Therefore we consider all three models with endogenous assignment of volatility states in the following.
Clearly, a visual inspection of the residuals is not enough for making a good decision on the most suitable volatility model. Such visual tools have to be complemented with statistical criteria such as information criteria. Therefore we show values of the Akaike information criterion and the Schwarz criterion (SC) for different models in Table 1. Notice that in all the volatility models a state-invariant initial effects matrix B is assumed and the VAR order is 3 for all models. The GARCH model is estimated with 5 univariate GARCH(1,1) components. It turns out that all (conditionally) heteroskedastic SVARs perform much better than the standard VAR according to AIC and SC. In fact, both criteria are minimized for the MS-SVAR
16

model with 3 volatility states. We did not try to estimate MS models with more volatility states because for a 5-dimensional model that would have been a major computational challenge and the estimates cannot be expected to be reliable.
The ultimate objective is, of course, to capture the volatility well with our models. Therefore it is instructive to look at the standardized residuals
u^kt/^kk,t
obtained for the different models. Here ^k2k,t is the kth diagonal element of the estimated residual covariance matrix or conditional covariance matrix for period t, depending on the model considered. These quantities are plotted in Figure 2 for the models with time-varying volatility. Notice that these are not the structural residuals obtained from these models but reduced-form residuals. The graphs are just meant to give a visual impression of possible remaining volatility changes or the ability of the different models to actually capture the volatility changes in the reduced-form residuals.
Comparing to the residuals in Figure 5, all models appear to improve on a model without allowance for volatility changes. However, the volatility models differ in their ability to capture the volatility in the data well. The visual impression is that the ST-SVAR model leaves quite some unexplained volatility in the residuals. Also, the MS(2) model appears to be inferior to the MS(3) model. For example, it leaves more heterogeneity in the commodity price residual series than the MS(3) model. Moreover, the GARCH residuals are somewhat disappointing and clearly inferior to the MS(3) residuals. Note, for example, large outliers in the utr series that are not captured by the GARCH model. Also some of the other residual series leave room for improvement relative to the corresponding quantities from the MS(3) model. For example, the volatility changes in the residuals of the output equation, uqt , are not well captured by the GARCH model. Thus, it is no accident that the AIC and SC criteria prefer the MS(3) model as well.
These results are perhaps better understood when looking at the transition function of the ST-SVAR model and the smoothed state probabilities of the MS(2)-SVAR and MS(3)-SVAR models in Figure 3. The MS models indicate that the change in volatility is more complex than what is captured by the ST-SVAR model. There does not appear to be a smooth transition from one volatility regime to another if the data are allowed to assign different regimes in a different way as in the MS models. Also allowing for a third state leads to a quite different separation of the sample period than a two state model. This explains why the MS(3) model is preferred over the ST and the MS(2) models. Despite the fact that we favor the MS(3)-SVAR for the
17

present dataset, we continue looking also at the other models for illustrative purposes.
4.3 Identification Analysis
The first question we have to address is the identification issue. For all three models statistical identification conditions are linked to the changes in volatility. For the ST and MS models they are linked to the relative variances. Estimates of these quantities are shown in Table 2. For the ST and MS(2) models the relative variances in the second state are all less than one. Hence, the ST model moves the volatility from a high volatility state to a lower volatility state. This corresponds well to the fact that the MS(2) model assigns the second, hence, lower volatility state to the latter part of the sample (see Figure 3). In contrast, the first state dominates the second half of the sample in the MS(3) model. Therefore it is plausible that the relative variances of the second and third states assigned by the MS(3) model are all larger than one, that is, the variances are larger than in the first state.
Recall that we have a fully identified ST-SVAR model if all the relative variances are distinct. Taking into account also the standard errors in Table 2, the estimates suggest that at least the first four relative variances are distinct. Formal tests that they are all distinct are presented in Table 3. Note that we have to test K(K - 1)/2 = 10 pairs for a system of dimension K = 5. For the smooth transition model, the null hypotheses of pairwise equality is rejected at a 10% significance level for all pairs but the last. Thus, we conclude that we have some statistically identified shocks but perhaps not a fully identified ST-SVAR model. In particular, the first three shocks are identified via heteroskedasticity. For a fully identified set of structural shocks we need additional restrictions such as those or some of those used by Bjørnland and Leitemo (2009).
The standard errors of the estimated relative variances for the MS models in Table 2 tend to be larger than for the ST model and also the estimated relative variances are not clearly distinct in a number of cases. Therefore it is not surprising that the corresponding tests for full identification shown in Tables 3 and 4 do not reject some of the relevant hypotheses. However, they do indicate that the volatility models contain at least some additional identifying information because some of the relevant hypotheses are clearly rejected with p-values much smaller than 5% or even 1%. Interestingly, in the MS(2)-SVAR model the tests indicate that the first relative variance is clearly distinct from the others and, hence, the first shock is identified while in the MS(3)-SVAR model the last shock is identified. Note, however, that we are using Wald tests for checking the identification restrictions and these
18

tests may not be very reliable (see Lu¨tkepohl and Netsunajev (2014a)). Thus, there may be more identified shocks. Our current statistical procedures do not provide much evidence for them, however.
The identification issue in the context of the SVAR-GARCH model is a somewhat different one. We have to check the number of univariate GARCH components underlying the GARCH structure. Ignoring the problem and estimating a model with five GARCH components as we have done in the foregoing, some of the GARCH parameters may actually not be identified. Thus, the analysis of the SVAR-GARCH model should ideally start with a thorough investigation of the number of underlying univariate GARCH components. This is of particular importance in analyses such as the present one where it is not clear whether the GARCH structure captures changes in volatility well enough in all variables. Notably variables such as industrial production are not necessarily well modelled by GARCH. Therefore we use the tests presented in Section 3.4 to investigate the issue. The results are shown in Table 5. Since the tests reject fewer than five GARCH components (r < 5), it makes sense to use the GARCH model with five components which also fully identifies all five shocks. As discussed earlier, this does not necessarily mean that the GARCH-SVAR model is the best one. In fact, we have seen earlier that it may be inferior to the MS(3)-SVAR model in some respects. What our tests show, however, is that the GARCH specification has a likelihood with curvature against restrictions on the B and  matrices if these restrictions are not in line with the data in the framework of the SVAR-GARCH model.
The overall conclusion of our identification analysis is that all models may present some power against restrictions on the short-run and long-run effects matrices B and . Therefore it makes sense to use all four models to test the restrictions discussed earlier. The test results are presented in Table 7. Obviously, all the null hypotheses can be rejected against models with fewer restrictions in all the four volatility setups. Thus there is strong evidence against any set of the restrictions. Rejecting R1 means, of course, that the Bjørnland-Leitemo restrictions are rejected. Such a rejection may be due to only one or a small subset of restrictions being false. To make sure that they are not rejected because the restrictions used to identify the shocks of no interest for an analysis of the stock market and monetary shocks, we also test R2 against a model without zero restrictions on B and . Again, these restrictions are clearly rejected regardless of the volatility model used. Moreover, the impact restrictions R3 are rejected in the absence of the longrun restriction. Similarly, the zero restriction on  is individually rejected in a test of R1 against R3. These results support findings in Lu¨tkepohl and Netsunajev (2014b) where also other ST-SVAR models are considered.
19

Of course, one could argue that it is not clear whether the BjørnlandLeitemo restrictions or the volatility models are rejected by the tests. However, given that all the volatility models agree in their rejections, this sheds some doubt on the restrictions. After all, in the conventional approach the changes in volatility are ignored and the restrictions are just identifying so that the data have no opportunity to speak up against them.
4.4 Impulse Response Analysis
Having rejected the Bjørnland-Leitemo restrictions one wonders what can be said about their main issue of interest namely the interaction between monetary policy and the stock market. The volatility analysis so far has not provided a full set of economic shocks. Even in the GARCH model where full identification is found, the shocks delivered by the SVAR-GARCH approach are just statistically identified and may not have economic meaning. For example, they may be mixtures of economic shocks. For the other models there is not even a full set of properly identified shocks. So the question arises whether we can learn something from our analysis regarding the economic questions of interest. To answer that question we can take a look at the identified shocks and see whether they can be interpreted as economically meaningful shocks. This can best be assessed by looking at the corresponding impulse responses.
Because we favor the MS(3)-SVAR model on the basis of our statistical analysis and because in this model we found only one clearly identified shock we present impulse responses for this shock in Figure 5 together with 68% confidence intervals. On impact the shock moves up the interest rate and, hence, qualifies as a contractionary monetary policy shock. On the other hand, there is a pronounced initial increase in output and inflation which would not be expected for responses to a monetary policy shock. Therefore we follow Lu¨tkepohl and Netsunajev (2014b) and interpret the shock identified via heteroskedasticity as a demand side monetary shock rather than a supply side shock of the money market. This is also in line with the money demand shock studied in Kulikov and Netsunajev (2013) and Favara and Giordani (2009). Hence, in our system and in the system we do not find a shock that qualifies as a supply side shock of the money market. Hence, the restrictions may be rejected because they do not identify the desired shock.
Turning now to the response of stock prices (spt), it is seen in Figure 5 that there is a significant decline for a few months after which the stock prices return to insignificant territory. Such a response is in fact quite plausible as one would expect the stock market to absorb monetary shocks quickly. Note that the impulse responses in Figure 5 are the accumulated responses of spt
20

and, thus, they are the responses of spt rather than the returns. For the other models we have also plotted impulse responses to the clearly
identified shocks and checked whether any one of them increases the interest rate significantly on impact. It turns out that for each of the models only one shock really qualifies as a monetary shock. We present the impulse responses of these shocks in Figure 5. As can be seen in the figure, the responses look very similar in all the models. In particular, they qualitatively tell the same story regarding the stock market response. The stock returns decline initially but move back up after a few months. Thus, we can conclude that there is some evidence of a short-term stock market response to activities in the money market. It is striking how little the volatility model affects the results. The important point seems to be that volatility changes are taken into account at all. The specific model for describing them is of secondary importance even if it is not an ideal description of the volatility changes. Of course, this latter conclusion may be specific to this example and cannot be generalized based on the available evidence.
5 Conclusions
In this study we have reviewed the volatility models in current use for identifying structural shocks in VAR analysis. The great advantage of this tool is that it offers potentially additional identifying information that can be used to investigate assumptions that are just-identifying in a conventional SVAR framework and thereby opens up the possibility to confront the data with such assumptions. We have pointed out the advantages and drawbacks of exogenously specified changes in volatility, smoothly changing volatility and volatility changes modelled by Markov switching and GARCH processes. Understanding the specific features of these models can help in making more informed decisions which model to use in a particular application.
Given that little about the actual volatility changes is typically known in practice for a specific set of variables of interest, exogenously specified volatility changes usually require considerable pretesting or preliminary analysis of possible changes. On one hand, they are very rigid in representing the break in volatility and assume that there is no transition for an extended period after some change has occurred. On the other hand, estimation is relatively easy.
Models that allow for endogenously determined volatility changes such as ST-SVAR, MS-SVAR and SVAR-GARCH models remove the burden of specifying the change points. Also the changes as such can be very flexible. The greatest flexibility in this respect is offered by MS-SVAR and SVAR-GARCH
21

models. On the other hand, these models are also the ones most difficult to estimate. In fact, estimation still poses considerable computational problems for models of larger size, that is, for models with many variables, large lag orders or, in the case of MS models, large numbers of different volatility states. For these models not only estimation of the model parameters is difficult but they also pose considerable problems for constructing bootstrap confidence intervals for impulse responses, for example.
On the positive side, for all model types precise conditions are known for full identification of all shocks. Moreover, statistical tests are available for checking the identification conditions formally.
We have illustrated the use of the models and some of the statistical issues involved by a detailed analysis of a monthly U.S. model for investigating the relation between monetary policy and the stock market. We find that previously used restrictions for identifying the shocks that are just-identifying in a conventional framework can be formally tested against the data and are in fact rejected by all volatility models. We find a Markov switching model with three regimes to be the most suitable model. Unfortunately, we do not find a full set of economically interpretable shocks using our preferred volatility model. Only a potential monetary shock and its responses can be clearly identified. It indicates that money market activities have some impact on stock returns. The effects are absorbed by the stock market quickly, however, as one might expect. This result is quite robust with respect to the volatility model used in this application. Whether or not this is a more general result is pure speculation. It shows, however, the importance of allowing for volatility changes in a system of variables where such changes actually occur.
References
Bacchiocchi, E. and Fanelli, L. (2012). Identification in structural vector autoregressive models with structural changes, Departmental Working Papers 2012-16, Department of Economics, Management and Quantitative Methods at Universita` degli Studi di Milano.
Bernanke, B. S. and Mihov, I. (1998). Measuring monetary policy, Quarterly Journal of Economics 113: 869­902.
Bjørnland, H. C. and Leitemo, K. (2009). Identifying the interdependence between US monetary policy and the stock market, Journal of Monetary Economics 56: 275 ­ 282.
22

Blanchard, O. and Quah, D. (1989). The dynamic effects of aggregate demand and supply disturbances, American Economic Review 79: 655­ 673.
Bouakez, H. and Normandin, M. (2010). Fluctuations in the foreign exchange market: How important are monetary policy shocks?, Journal of International Economics 81: 139­153.
Canova, F. and De Nicol´o, G. (2002). Monetary disturbances matter for business fluctuations in the G-7, Journal of Monetary Economics 49: 1131­ 1159.
Ehrmann, M., Fratzscher, M. and Rigobon, R. (2011). Stocks, bonds, money markets and exchange rates: Measuring international financial transmission, Journal of Applied Econometrics 26: 948­974.
Faust, J. (1998). The robustness of identified VAR conclusions about money, Carnegie-Rochester Conference Series in Public Policy 49: 207­244.
Favara, G. and Giordani, P. (2009). Reconsidering the role of money for output, prices and interest rates, Journal of Monetary Economics 56: 419­ 430.
Herwartz, H. and Lu¨tkepohl, H. (2014). Structural vector autoregressions with Markov switching: Combining conventional with statistical identification of shocks, Journal of Econometrics .
Kilian, L. (2009). Not all oil price shocks are alike: Disentangling demand and supply shocks in the crude oil market, American Economic Review 99: 1053­1069.
King, R. G., Plosser, C. I., Stock, J. H. and Watson, M. W. (1991). Stochastic trends and economic fluctuations, American Economic Review 81: 819­ 840.
Kulikov, D. and Netsunajev, A. (2013). Identifying monetary policy shocks via heteroskedasticity: A Bayesian approach, Bank of Estonia Working Papers WP2013-9, Bank of Estonia.
Lanne, M. and Lu¨tkepohl, H. (2008). Identifying monetary policy shocks via changes in volatility, Journal of Money, Credit and Banking 40: 1131­ 1149.
23

Lanne, M., Lu¨tkepohl, H. and Maciejowska, K. (2010). Structural vector autoregressions with Markov switching, Journal of Economic Dynamics and Control 34: 121­131.
Lanne, M. and Saikkonen, P. (2007). A multivariate generalized orthogonal factor GARCH model, Journal of Business & Economic Statistics 25: 61­75.
Lu¨tkepohl, H. (2005). New Introduction to Multiple Time Series Analysis, Springer-Verlag, Berlin.
Lu¨tkepohl, H. (2013). Identifying structural vector autoregressions via changes in volatility, Advances in Econometrics 32: 169­203.
Lu¨tkepohl, H. and Milunovich, G. (2015). Testing for identification in SVARGARCH models - reconsidering the impact of monetary shocks on exchange rates, Discussion Paper 1455, DIW Berlin.
Lu¨tkepohl, H. and Netsunajev, A. (2014a). Disentangling demand and supply shocks in the crude oil market: How to check sign restrictions in structural VARs, Journal of Applied Econometrics 29: 479­496.
Lu¨tkepohl, H. and Netsunajev, A. (2014b). Structural vector autoregressions with smooth transition in variances: The interaction between u.s. monetary policy and the stock market, Discussion Papers of DIW Berlin 1388, DIW Berlin, German Institute for Economic Research.
Lu¨tkepohl, H. and Velinov, A. (2015). Structural vector autoregressions: Checking identifying long-run restrictions via heteroskedasticity, Journal of Economic Surveys .
Milunovich, G. and Yang, M. (2013). On identifying structural VAR models via ARCH effects, Journal of Time Series Econometrics 5: 117­131.
Netsunajev, A. (2013). Reaction to technology shocks in Markov-switching structural VARs: Identification via heteroskedasticity, Journal of Macroeconomics 36: 51­62.
Normandin, M. and Phaneuf, L. (2004). Monetary policy shocks: Testing identification conditions under time-varying conditional volatility, Journal of Monetary Economics 51: 1217­1243.
Rigobon, R. (2003). Identification through heteroskedasticity, Review of Economics and Statistics 85: 777­792.
24

Rigobon, R. and Sack, B. (2003). Measuring the reaction of monetary policy to the stock market, Quarterly Journal of Economics 118: 639­669.
Rigobon, R. and Sack, B. (2004). The impact of monetary policy on asset prices, Journal of Monetary Economics 51: 1553­1575.
Sentana, E. and Fiorentini, G. (2001). Identification, estimation and testing of conditionally heteroskedastic factor models, Journal of Econometrics 102: 143­164.
Sims, C. A. (1980). Macroeconomics and reality, Econometrica 48: 1­48. Strohsal, T. and Weber, E. (2012). The signal of volatility, Discussion Paper
2012-043, Humboldt University Berlin, SFB 649. Uhlig, H. (2005). What are the effects of monetary policy on output? Re-
sults from an agnostic identification procedure, Journal of Monetary Economics 52: 381­419. van der Weide, R. (2002). GO-GARCH: A multivariate generalized orthogonal GARCH model, Journal of Applied Econometrics 17: 549­564. Velinov, A. S. (2013). Can stock price fundamentals really be captured? Using Markov switching in heteroskedasticity models to test identification restrictions, Discussion Paper 1350, DIW Berlin. Weber, E. (2010). Structural conditional correlation, Journal of Financial Econometrics 8: 392­407.
25

Table 1: Comparison of SVAR(3) Models with State Invariant B

Model SVAR(3) ST-SVAR(3) MS(2)-SVAR(3) MS(3)-SVAR(3) SVAR(3)-GARCH(1,1)

log LT -3159.344 -2878.255 -2826.742 -2774.614 -2891.971

AIC 6508.689 5976.510 5877.484 5791.230 6013.942

SC 6899.067 6428.527 6337.719 6288.448 6486.505

Note: LT ­ likelihood function, AIC = -2 log LT + 2×no of free parameters, SC = -2 log LT + log T ×no of free parameters.

Table 2: Estimates of Relative Variances for Smooth Transition and Markov Switching Models

parameter
21 22 23 24 25 31 32 33 34 35

ST-SVAR estimate std.dev.
0.019 0.002 0.315 0.057 0.548 0.088 0.867 0.154 0.927 0.172

MS(2)-SVAR estimate std.dev.
0.019 0.003 0.271 0.097 0.371 0.125 0.428 0.135 0.682 0.356

MS(3)-SVAR

3.724 2.741 5.243 3.544 2.568 1.859 2.554 2.693 3.981 82.265

0.849 0.626 1.309 0.761 0.608 0.593 0.747 0.863 1.153 16.065

26

Table 3: Tests for Equality of 2k for Unrestricted ST-SVAR and MS(2) Model

ST-SVAR

MS(2)-SVAR

H0 21 = 22 21 = 23 21 = 24 21 = 25

Wald statistic 26.463 35.720 29.806 27.498

p-value 2.686 × 10-7 2.277 × 10-9 4.673 × 10-8 1.572 × 10-7

Wald statistic 6.6233 7.9320 9.0093 3.4660

p-value 0.0101 0.0049 0.0027 0.0626

22 = 23 22 = 24 22 = 25 23 = 24

4.729 10.731 10.583 2.814

0.029 0.001 0.001 0.093

0.7049 1.3050 0.9135 0.1255

0.4012 0.2533 0.3392 0.7232

23 = 25 24 = 25

3.687 0.054 0.061 0.805

0.4901 0.4839 0.3201 0.5715

Table 4: Tests for Pairwise Equality of 2k and 3k for MS(3)-SVAR Model

MS(3)-SVAR

H0 Wald statistic p-value

21 = 22, 31 = 32 21 = 23, 31 = 33 21 = 24, 31 = 34

2.011 1.138 2.921

0.356 0.565 0.232

21 = 25, 31 = 35 22 = 23, 32 = 33 22 = 24, 32 = 34 22 = 25, 32 = 35

29.753 2.993 1.193 26.424

0.000 0.223 0.551 0.000

23 = 24, 33 = 34 23 = 25, 33 = 35 24 = 25, 34 = 35

2.758 34.043 28.324

0.251 0.000 0.000

Table 5: Tests for Identification in GARCH-SVAR Model

r under H0 Q1(1) df

p-value Q2(1) df

p-value

Q3(1) df

p-value

1 24.026 1 9.5 × 10-7 251.520 100 4.8 × 10-15 4036.911 100

0

2 20.446 1 6.1 × 10-6 148.644 36 1.2 × 10-15 2252.564 36

0

3 12.712 1 3.6 × 10-4 31.256 9 2.6 × 10-4 899.776 9

0

4 15.127 1 1.1 × 10-4 15.127 1 1.1 × 10-4 12.421 1 4.2 × 10-4

27

Table 6: Estimates of GARCH Parameters for Model with Unrestricted B and 
k gk k estimate std.dev. estimate std.dev. 1 0.349 0.078 0.089 0.182 2 0.342 0.021 0.614 0.039 3 0.245 0.233 0.234 0.223 4 0.125 0.005 0.819 0.037 5 0.095 0.004 0.832 0.036

Table 7: Tests for Identifying Restrictions in Heteroskedastic SVAR Models

H0 H1 R1 ST-SVAR with unrestricted B,  R2 ST-SVAR with unrestricted B,  R3 ST-SVAR with unrestricted B,  R1 R3

LR statistic df p-value

35.845

10 8.9 × 10-5

30.909

7 6.4 × 10-5

22.491

9 0.0074

13.354

1 2.5 × 10-4

R1 MS(2)-SVAR with unrestricted B,  R2 MS(2)-SVAR with unrestricted B,  R3 MS(2)-SVAR with unrestricted B,  R1 R3

52.505 54.586 19.097 33.408

10 9.1 × 10-8 7 1.4 × 10-13
9 0.024 1 7.4 × 10-9

R1 MS(3)-SVAR with unrestricted B,  R2 MS(3)-SVAR with unrestricted B,  R3 MS(3)-SVAR with unrestricted B,  R1 R3

54.134 49.350 27.921 26.212

10 4.5 × 10-8 7 1.93 × 10-8 9 9.8 × 10-4 1 3.5 × 10-7

R2 SVAR-GARCH with unrestricted B,  90.047

R2 SVAR-GARCH with unrestricted B,  92.229

R3 SVAR-GARCH with unrestricted B,  56.052

R1 R3

33.995

10 3.7 × 10-15
7 0.000 9 6.7 × 10-9 1 4.5 × 10-9

28

utq 8

ut 8

uct 8

ut sp 8

urt 8

66666

44444

22222

00000

-2 -2 -2 -2 -2

-4 -4 -4 -4 -4

-6 -6 -6 -6 -6

-8 1970

-8 2007 1970

-8 2007 1970

-8 2007 1970

-8 2007 1970

2007

Figure 1: Residuals obtained from VAR(3) model without allowance for heteroskedasticity.

29

utq 5

ut 5

utc 5

utsp 5

urt 5

00000

-5 -5 -5 -5 -5

1970

2007 1970

2007 1970

2007 1970

2007 1970

(a) Standardized residuals obtained from ST-SVAR model

2007

uqt 5

ut 5

uct 5

utsp 5

urt 5

00000

-5 -5 -5 -5 -5

1970

2007 1970

2007 1970

2007 1970

2007 1970

(b) Standardized residuals obtained from MS(2)-SVAR model

2007

5 0 -5 1970

uqt 8 6 4 2 0 -2 -4 -6 -8
2007 1970

ut 5 0 -5
2007 1970

uct utsp 8

6 5
4

2

00

-2

-4 -5
-6

-8 2007 1970

2007 1970

urt 2007

(c) Standardized residuals obtained from MS(3)-SVAR model

utq 8

ut 8

uct 8

ut sp 8

urt 8

66666

44444

22222

00000

-2 -2 -2 -2 -2

-4 -4 -4 -4 -4

-6 -6 -6 -6 -6

-8 1970

-8 2007 1970

-8 2007 1970

-8 2007 1970

-8 2007 1970

2007

(d) Standardized residuals obtained from SVAR-GARCH model

Figure 2: Standardized residuals obtained from different models allowing for time-varying volatility.
30

1 0.8 0.6 0.4 0.2
0 1970
1 0.5
0 1970
1 0.5
0 1970

1975

1980

1984

1990

1995

2000

(a) Transition function of ST-SVAR model

State 1

2005

1975

1980

1985

1990 State 2

1995

2000

2005

1975

1980

1985

1990

1995

2000

(b) Smoothed regime probabilities of MS(2)-SVAR model

2005

1 0.5
0 1970
1 0.5
0 1970
1 0.5
0 1970

1975 1975 1975

1980 1980 1980

State 1

1985

1990 State 2

1985

1990 State 3

1985

1990

1995 1995 1995

2000 2000 2000

2005 2005 2005

(c) Smoothed regime probabilities of MS(3)-SVAR model
Figure 3: Volatility regimes obtained from different models.

31

1 0.5
0 -0.5
-1 0

20

40 qt

60

0.6 0.4 0.2
0 -0.2 -0.4 -0.6 -0.8
0

20

40 t

60

2 0 -2 -4 -6
0

20

40 ct

60

10 8 6 4 2 0
-2 0

20

40 spt

60

2 1.5
1 0.5
0 -0.5
-1 0

20

40 rt

60

Figure 4: Impulse responses to monetary shock obtained from MS(3)-SVAR model.

ST-SVAR

MS(2)-SVAR

SVAR-GARCH

1 0.5 2 5 2

01

0

0 -2

0 0

-4

-1 -0.5

-5 -1

0 20 40 60

0 20 40 60

0 20 40 60

0 20 40 60

0 20 40 60

1 0.5

00

-1 -0.5

0 20 40 60

0 20 40 60

2 0 -2 -4
0 20 40 60

10 2

51

00

0

20 40 60

-1 0

20 40 60

1 0.5

00

-1 0

20

40

60

-0.5 0

20 40 60

qt t

5
0
-5 0 20 40 60 ct

5
0
-5 0 20 40 60 spt

2
1
0
-1 0 20 40 60 rt

Figure 5: Impulse responses to monetary shock obtained from models.

32

SFB 649 Discussion Paper Series 2015

For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.

001 002
003
004 005
006 007 008 009 010 011 012 013 014 015

"Pricing Kernel Modeling" by Denis Belomestny, Shujie Ma and Wolfgang Karl Härdle, January 2015. "Estimating the Value of Urban Green Space: A hedonic Pricing Analysis of the Housing Market in Cologne, Germany" by Jens Kolbe and Henry Wüstemann, January 2015. "Identifying Berlin's land value map using Adaptive Weights Smoothing" by Jens Kolbe, Rainer Schulz, Martin Wersing and Axel Werwatz, January 2015. "Efficiency of Wind Power Production and its Determinants" by Simone Pieralli, Matthias Ritter and Martin Odening, January 2015. "Distillation of News Flow into Analysis of Stock Reactions" by Junni L. Zhang, Wolfgang K. Härdle, Cathy Y. Chen and Elisabeth Bommes, January 2015. "Cognitive Bubbles" by Ciril Bosch-Rosay, Thomas Meissnerz and Antoni Bosch-Domènech, February 2015. "Stochastic Population Analysis: A Functional Data Approach" by Lei Fang and Wolfgang K. Härdle, February 2015. "Nonparametric change-point analysis of volatility" by Markus Bibinger, Moritz Jirak and Mathias Vetter, February 2015. "From Galloping Inflation to Price Stability in Steps: Israel 1985­2013" by Rafi Melnick and till Strohsal, February 2015. "Estimation of NAIRU with Inflation Expectation Data" by Wei Cui, Wolfgang K. Härdle and Weining Wang, February 2015. "Competitors In Merger Control: Shall They Be Merely Heard Or Also Listened To?" by Thomas Giebe and Miyu Lee, February 2015. "The Impact of Credit Default Swap Trading on Loan Syndication" by Daniel Streitz, March 2015. "Pitfalls and Perils of Financial Innovation: The Use of CDS by Corporate Bond Funds" by Tim Adam and Andre Guettler, March 2015. "Generalized Exogenous Processes in DSGE: A Bayesian Approach" by Alexander Meyer-Gohde and Daniel Neuhoff, March 2015. " Structural Vector Autoregressions with Heteroskedasticy" by Helmut Lütkepohl and Aleksei Netsunajev, March 2015.

SFSBF6B4694, 9S,pSapnadnaduaeureSrtrSatßraeß1e, 1D,-D10-1107187B8eBrleinrlin htthpt:t/p/:/s/fbs6fb4694.w9.iwwiiw.hiu.h-bue-brleinrl.idne.de
ThTishrisesreasrecahrcwhawsassupsuppoprtoerdtebdybtyhethDeeDuetsucthseche ForFsocrhsuchnugnsgesgmeeminesicnhsachftatfht rtohuroguhgthhethSeFSBF6B4694"9Ec"oEnconmoimc RicisRki"s.k".

