BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2007-023
Time Series Modelling with Semiparametric
Factor Dynamics
Szymon Borak* Wolfgang H‰rdle* Enno Mammen** Byeong U. Park***
* Humboldt-Universit‰t zu Berlin, Germany ** University of Mannheim, Germany *** Seoul National University, Korea
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universit‰t zu Berlin Spandauer Straﬂe 1, D-10178 Berlin

Time Series Modelling with Semiparametric Factor Dynamics 
Szymon Borak
CASE ≠ Center for Applied Statistics and Economics Humboldt-Universita®t zu Berlin,
Spandauer Straﬂe 1, 10178 Berlin, Germany
Wolfgang Ha®rdle
CASE ≠ Center for Applied Statistics and Economics Humboldt-Universita®t zu Berlin,
Spandauer Straﬂe 1, 10178 Berlin, Germany
Enno Mammen
Department of Economics, University of Mannheim L 7, 3≠5, 68131 Mannheim, Germany
Byeong U. Park
Department of Statistics, Seoul National University Seoul 151-747, Korea
April 25, 2007
We gratefully acknowledge financial support by the Deutsche Forschungsgemeinschaft and the Sonderforschungsbereich 649 "O® konomisches Risiko". Byeong U. Park's research was supported by the Korea Research Foundation Grant funded by the Korean Government (MOEHRD) (KRF-2005-070-C00021).
1

Time Series Modelling with Semiparametric Factor Dynamics
Abstract
High-dimensional regression problems which reveal dynamic behavior are typically analyzed by time propagation of a few number of factors. The inference on the whole system is then based on the low-dimensional time series analysis. Such highdimensional problems occur frequently in many different fields of science. In this paper we address the problem of inference when the factors and factor loadings are estimated by semiparametric methods. This more flexible modelling approach poses an important question: Is it justified, from inferential point of view, to base statistical inference on the estimated times series factors? We show that the difference of the inference based on the estimated time series and `true' unobserved time series is asymptotically negligible. Our results justify fitting vector autoregressive processes to the estimated factors, which allows one to study the dynamics of the whole high-dimensional system with a low-dimensional representation. We illustrate the theory with a simulation study. Also, we apply the method to a study of the dynamic behavior of implied volatilities and discuss other possible applications in finance and economics.
AMS 2000 subject classification: 62G08, 62G20, 62M10 JEL classification codes: C14, C32, G12
Keywords: semiparametric models, factor models, implied volatility surface, vector autoregressive process, asymptotic inference
2

1 Introduction

Modelling for high-dimensional data is a challenging task in statistics especially when the data comes in a dynamic context and is observed at changing locations with different sample size. Such modelling challenges appear in many different fields. In empirical macroeconomics one is interested in analyzing the dynamics of the plethora of economic indicators that reflect the state of the economy, see Stock and Watson (2005). In mortality analysis one builds a model for forecasting death rate or life expectancy, as is done in Lee and Carter (1992). The statistical analysis of financial term structure dynamics is crucial for bond portfolio risk management or derivative pricing, see Nelson and Siegel (1987) and Diebold and Li (2006). In bio-medical research the interest can be focussed on time improvement of the patients' treatment, as in the children growth history analysis by Martinussen and Scheike (2000). Other examples include the studies of radiation treatment of prostate cancer by Kauermann (2000) and evoked potentials in EEG analysis by Gasser et al. (1983). In financial engineering, it is common to analyze the dynamics of implied volatility surface for pricing exotic options.

A successful modelling approach utilizes factor type models, which allow low-dimensional representation of the data. In an orthogonal L-factor model an observable J-dimensional random vector Yt = (Yt,1, . . . , Yt,J ) can be represented as

Yt,j = m0,j + Zt,1m1,j + ∑ ∑ ∑ + Zt,LmL,j + t,j,

(1)

where Zt,l are common factors, t,j are errors or specific factors and the coefficients ml,j are factor loadings. In most applications, the index t = 1, . . . , T reflects the time evolution of the whole system, and Yt can be considered as a multi-dimensional time series. For a method to identify common factors in this model we refer to Pen~a and Box (1987). The study of high-dimensional Yt is then simplified to the modelling of Zt = (Zt,1, . . . , Zt,L) , which is a more feasible task when L J.

In a variety of applications, one has explanatory variables Xt,j at hand that may influence the factor loadings ml. An important refinement of the model (1) is to incorporate the existence of observable covariates Xt,j. The factor loadings are now generalized to functions

3

implied volatility implied volatility

0.5 0.45
0.4 0.35
0.3 0.25
0.2 0.15
0.1 0.8

1 1.2
moneyness

1.4 0

0.5 0.4 0.3 0.2 0.1 time to maturity

0.5 0.45
0.4 0.35
0.3 0.25
0.2 0.15
0.1 0.8

1 1.2
moneyness

1.4 0

0.5 0.4 0.3 0.2 0.1 time to maturity

Figure 1: The typical IV data design on two different days. In the maturity direction observations appear in the discrete points for each particular day. Bottom solid lines indicate the observed maturities, which move towards the expiry. Left panel: observations on 20040701, Jt = 5606. Right panel: observations on 20040819, Jt = 8152.

of Xt,j, so that the model (1) is generalized to

L
Yt,j = m0(Xt,j) + Zt,l ml(Xt,j) + t,j.
l=1

(2)

The model (2) can be regarded as a regression model with embedded time evolution. In par-

ticular, lagged observations of the component series (Yt-1,j, . . . , Yt-p,j) may be the regressor Xt,j, but we allow here any external variable Xt = (Xt,1, . . . , Xt,J ) . Additionally, the regularity of the multi-dimensional time series may be omitted by allowing J depending on t, say

Jt. The model (2) is different from varying-coefficient models, such as in Fan et al. (2003) and Yang et al. (2006), since Zt is unobservable. Our model also has some similarities to the one considered in Connor and Linton (2007) and Connor et al. (2007) which generalized the

study of Fama and French (1992) on the common movements of stock price returns. There,

the covariates, denoted by Xl,j, are time-invariant and are different for different ml, which allows a direct application of backfitting procedures and makes the problem quite different

from our setting. Some linear models which allow time-varying coefficients, as considered in

Hansen et al. (2004) and Brumback and Rice (1998), may be recognized as a special case of

(2).

In this paper we consider the model (2) with nonparametric functions ml. We call this

4

model a dynamic semiparametric factor model (DSFM). The evolution of complex highdimensional objects may be described by (2), so that their analysis can be reduced to the study of a low-dimensional vector of factors Zt. In the present paper, we consider an efficient nonparametric method of fitting the model. We provide relevant theory for the method as well as illustrate its empirical aspects through a simulation and a real data application.
One of the main motivations for the model (2) comes from a special structure of the implied volatility (IV) data. The IV is a volatility parameter that matches the observed plain vanilla option prices with the theoretical ones given by the formula of Black and Scholes (1973). Enforcing relatively simple assumptions their model and pricing formula have achieved enormous popularity, and it is now a common market standard to communicate in terms of IV. Due to the trading regulation one may observe, on a particular day, only those options with certain times-to-maturity. This feature causes a typical `string' structure in the IV data, which can be clearly observed in Figure 1. The data were obtained from the European option prices on the German stock index DAX (ODAX). The plots represent the values of IV calculated from option trades with maturities and moneyness≠a monotone transformation of strike price. While the observations lie relatively dense in the moneyness direction, they appear only at a few discrete points in the maturity direction. Moreover, the volatility strings shift towards expiry. This is indicated by the bottom lines in the figure, where one may also observe that the maturities of the options on the two different days are different. The latter means that the observed design points changes each day.
These IV dynamics may be represented well through the model (2). In this particular example, Yt,j are the values of IV or those of its transformation on the day t, and Xt,j are the two-dimensional vectors of the moneyness and time-to-maturity. For the analysis of IV data, Hafner (2004) considered a stochastic implied volatility model which assumes a parametric form for the functions ml. This method, however, may incur a significant model-bias when the actual model is far from the assumed parametric one. Cont and da Fonseca (2002) applied the Karhunen-Lo¥eve decomposition in functional principal component analysis to the daily variations of IV surfaces that are estimated on the whole design space by a kernel method. This approach depends crucially on the initial estimation of IV surfaces, which may fail due to the design-sparseness that we discussed in the previous paragraph. DSFM is a flexible semiparametric model which neither assumes any parametric form for the functions
5

ml nor requires the initial smoothing as in Cont and da Fonseca (2002). The model has been used by Fengler et al. (2007) to study the dynamic behavior of implied volatility surfaces obtained from the ODAX data.
DSFM, fitted to the IV data, has numerous applications. First, the model can be seen as a low dimensional projection of the IV risk factors. Certain exotic options, whose prices strongly depend on the whole IV surface, have to be hedged additionally against undesirable surface movements. This, so called `vega hedging', can be refined by adjusting the hedging portfolio according to the new hedging ratios, defined as the derivatives of the option price with respect to Zt. Second, the model provides a useful tool for distributional forecasting of future IV, which is essential in risk management of large options' portfolios. It also serves for pricing certain exotic options as an extension of the Monte Carlo pricing methodology.
Our methods produce estimates of the true unobservable Zt, say Zt, as well as estimates of the unknown functions ml. In practice, one operates on these estimated values of Zt for further statistical analysis of the data. In particular, for the applications that we discuss in the above paragraph, one needs to fit an econometric model to the estimated factors Zt. For example, Hafner (2004) and Cont and da Fonseca (2002) fitted an AR(1) process to each factor, and Fengler et al. (2007) considered a multivariate VAR(2) model. The main question that arises from these applications is whether the inference based on Zt is equivalent to the one based on Zt. Attempting to give an answer to this question forms the core of this paper.
It is worthwhile to note here that Zt is not identifiable in the model (2). There are many versions of (Zt, m), where m = (m0, . . . , mL) , that give the same distribution of Yt. This means that estimates of Zt and ml are not uniquely defined. We show that for any version of {Zt} there exists a version of {Zt} whose lagged covariances are asymptotically the same as those of {Zt}. This justifies the inference based on {Zt} when {Zt} is a VAR process, in particular. We confirm this theoretical result by a Monte Carlo simulation study. We also discuss fitting the model to the real ODAX IV data.
Although DSFM has been motivated from analyzing IV surfaces, it may be applied to many other problems. A prominent example is modelling of yield curve evolution. Here, the standard approach is to use the parametric factor model proposed by Nelson and Siegel (1987), where the empirical form of the yield curve is fitted with some pre-specified functions
6

of the bonds' maturities. A possible refinement is the penalized spline smoothing, employed simultaneously in time and maturity dimensions, adopted by Krivobokova et al. (2006). Apart from this, other modelling strategies based on principal component analysis or factor models are commonly used, see Rebonato (1998), Bliss (1997) and Molgedey and Galic (2001) among others. Clearly, DSFM enhances flexibility of these approaches for modelling the term structure of interest rates. In a similar manner, DSFM may be employed to analyze the term structure of the variance swaps as in Detlefsen and Ha®rdle (2006), and to study future prices of CO2 emission allowances as in Tru®ck et al. (2006). Other examples include mortality trend fitting, where the current standard is to use the model proposed by Lee and Carter (1992). In that model the age-specific death rates are regressed additively on a time-invariant agespecific component and another age-specific component multiplied by a time-varying factor. Here, one can let the age specific components be nonparametric functions of some particular covariates and extend the model to the reduced DSFM with L = 1. The mortality forecast is then obtained by a standard statistical method applied to the estimated factor time series.
For each t, the set of observations Yt = {Yt,j : 1  j  Jt} may be viewed as representing discretized values of a smooth surface St. Therefore interest may be similarly put on the functional objects St, which has a direct linkage to the functional data analysis (Ramsay and Silverman, 1997). The standard practice is to obtain an estimate of St from Yt and proceed to build up a factor model as in Cont and da Fonseca (2002). However this procedure requires an initial fit for St, which may suffer from the design-sparseness problem as we mentioned earlier. DSFM avoids this preliminary estimation and shifts the discrete representation directly to the functions ml.
The paper is organized as follows. In the next section we propose a new method of fitting DSFM and an iterative algorithm that converges at a geometric rate. In Section 3 we present the results of a simulation study that illustrate the theoretical findings given in Section 5. In Section 4 we apply the model to the ODAX IV data and discuss some further applications. Section 5 is devoted to the asymptotic analysis of the method. Technical details are provided in the Appendix.
7

2 Methodology

We observe (Xt,j, Yt,j) for j = 1, . . . , Jt and t = 1, . . . , T such that

Yt,j = Zt m(Xt,j) + t,j.

(3)

Here Zt = (Zt,0, . . . , Zt,L) is an unobservable L + 1-dimensional process with Zt,0  1. The function m is a tuple (m0, . . . , mL) of unknown real-valued functions mj defined on a subset of IRd. The variables X1,1, . . . , XT,JT , 1,1, . . . , T,JT are independent. The errors t,j have zero means and finite second moments. For simplicity of notation, we will assume that the covariates Xt,j have support [0, 1]d, and also that Jt  J do not depend on t.

For the estimation of m, we use a series estimator. For an integer K  1, we choose functions 1, . . . , K : [0, 1]d  IR which are normed so that [0,1]d k2(x) dx = 1. For example, one may take {k : 1  k  K} to be a tensor B-spline basis, see e.g. de Boor (2001). Then, a tuple of functions m = (m0, . . . , mL) may be approximated by A, where A = (l,k) is a (L + 1) ◊ K matrix and  = (1, . . . , K) . We define the least squares estimators Zt = (Zt,0, . . . , Zt,L) and A = (l,k):

TJ

S(A, Z) 

Yt,j - Zt

A(Xt,j )

2 = min!
A,Z

t=1 j=1

(4)

where Z = Z1 , . . . , ZT . The minimization runs over all values of Zt with

Zt,0 = 1.

(5)

With A at hand, we estimate m by m = A.

We note that, given Z or A, the function S in (4) is quadratic with respect to the other variables, and thus has an explicit unique minimizer. However, minimization of L with respect to A and Z simultaneously is a fourth-order problem. The solution is neither unique nor explicit. It is unique only up to the values of Z1 A, . . . , ZT A. We will come back to this identifiability issue later in this section.

To find a solution (A, Z) of the minimization problem (4), one might adopt the following iterative algorithm: (i) Given an initial choice Z(0), minimize S(A, Z(0)) with respect to A,

8

which is an ordinary least squares problem and thus has an explicit unique solution. Call it A(1). (ii) Minimize S(A(1), Z) with respect to Z now, which is also an ordinary least squares problem. (iii) iterate (i) and (ii) until convergence. This is the approach taken by Fengler et al. (2007). However, the procedure is not guaranteed to converge to a solution of the original problem.

We propose to use a Newton-Raphson algorithm. Let   (A) denote the stack form of A = (l,k), i.e.,

 = (0,1, . . . , L,1, 0,2, . . . , L,2, . . . , 0,K , . . . , L,K ) .

In a slight abuse of notation we write S(, Z) for S(A, Z). Define

F10(, Z)

=

 

S(,

Z

),

F01(, Z)

=

 Z

S(,

Z ),

F20(, Z)

=

2 2

S

(,

Z

),

F11(, Z)

=

2 Z

S

(,

Z

),

F02(, Z)

=

2 Z2

S

(,

Z

).

Let t = (Xt,1), . . . , (Xt,J ) be a K ◊ J matrix. Then, it can be shown that

TT

F10(, Z) = 2 (tt )  (ZtZt )  - 2 (tYt)  Zt,

t=1 t=1

T

F20(, Z) = 2 (tt )  (ZtZt ) ,

t=1 

F01(, Z)

=

2 

A11 A Z1 - A1Y1 A22 A Z2 - A2Y2
...

 ,

 AT T A ZT - AT YT

F02(, Z)

=

2 

A11 A
0 ...

0 A22 A
...

∑∑∑
∑∑∑ ...



0

0 0

 .

0 0 ∑ ∑ ∑ AT T A

Here and below,  denotes the Kronecker product operator. Also, by some algebraic manipulations it can be shown that

(tt )  (ZtZt )  = (tt A Zt)  Zt. 9

Thus, we get

F11(, Z) = 2 (F11,1(, Z), F11,2(, Z), . . . , F11,T (, Z)) ,

where

F11,t(, Z) = (tt A )  Zt + (tt A Zt)  IL+1 - (tYt)  IL+1

and Iq denotes the identity matrix of dimension q. Let

F (, Z) =

F10(, Z) , F (, Z) = F01(, Z)

F20(, Z) F11(, Z) . F11(, Z) F02(, Z)

We need to solve the equation F (, Z) = 0 simultaneously for  and Z. Given (OLD, ZOLD), the Newton-Raphson algorithm gives the updating equation for (NEW, ZNEW):

NEW Z NEW

=

OLD Z OLD

- F (OLD, ZOLD)-1F (OLD, ZOLD).

(6)

The algorithm (6) is shown to converge to a solution of (4) at a geometric rate under some week conditions on the initial choice ((0), Z(0)), as is demonstrated by Theorem 2.1 below. We collect the conditions for the theorem.

(C1) F ((0), Z(0)) is invertible.
(C2) There exists a solution (, Z) of the equation F (, Z) = 0 such that t=1 ZtZt and t=1 ZtZt(0) are invertible, and l = (l1, . . . , lK) for l = 0, . . . , L are linearly
independent, i.e., the matrix A that corresponds to  has full rank.

Let (k) and Z(k) denote the kth updated vectors in the iteration with the algorithm (6). Also, we write A(k) for the matrix that corresponds to (k).

Theorem 2.1. Suppose that the initial choice ((0), Z(0)) satisfies (C1) and (C2). Then, for

any 0 <  < 1 there exists r > 0 and C > 0 such that, if

T t=1

Zt(0)

A(0) - Zt A^ 2  r, then

T
Zt(k) A(k) - Zt A^ 2  C2-(k-1)2k-1.
t=1

10

The minimization problem (4) has no unique solution. If (Zt, A) or (Zt, m = A) is a

minimizer, then also (B Zt, B-1m) is a minimizer. Here B is an arbitrary matrix of the

form

B= 1 0 0B

(7)

for an invertible matrix B. The special structure of B assures that the first component of B Zt equals 1. In Section 5, we will show that, for any solution Zt and for any version of true Zt, there exists a random matrix B such that Zt = B Zt has asymptotically the same covariance structure as Zt. This means that the difference of the inferences based on Zt and Zt is asymptotically negligible.

We also note that one can always choose m = A such that the components m1, . . . , mL

are orthonormal in L2([0, 1]d) or in other L2, e.g. in L2(T -1

T t=1

ft

)

where

ft

is

a

kernel

estimate of the density of Xt,j. If one selects m in this way, then the matrix B should be an

orthogonal matrix and the underlying time series Zt is estimated up to such transformations.

The following proposition will be used to prove Theorem 2.1, but it has an important implication in its own right. Let (OLD, ZOLD) be the `old' value to be updated by (6) and (NEW, ZNEW) be the updated value as defined there. For an (L + 1) ◊ (L + 1) nonsingular square matrix B, define

AOLD = B-1AOLD, ZtOLD = B ZtOLD. The stack form of AOLD can be written as

OLD = (IK  B-1)OLD.

(8)

Also, we have

ZOLD = (Z1OLD , . . . , ZTOLD ) = (IT  B )ZOLD.

(9)

The proposition demonstrates that updating OLD and ZOLD directly by the formula (6) is equivalent to first updating OLD and ZOLD by (6) and then transforming the updated vectors NEW and ZNEW according to (8) and (9), respectively.

Proposition 2.2. Let NEW and ZNEW be obtained from OLD and ZOLD by the updating equation (6). Then NEW = (IK  B-1)NEW and ZNEW = (IT  B )ZNEW.

11

Proof. Given (, Z), let  = (IK  B-1) and Z = (IT  B )Z. We prove

F (, Z)-1F (, Z) =

IK  B-1

O

O IT  B

F (, Z)-1F (, Z).

(10)

First, we collect several useful algebraic identities. Let M be an arbitrary u ◊ v matrix. For

matrices P, Q, R where P QR is defined,

M  (P QR) = (Iu  P )(M  Q)(Iv  R).

(11)

In particular, for a vector q where P q is defined, we have from (11) by taking R = 1 that

M  (P q) = (Iu  P )(M  q). On the other hand, for a vector q and a matrix P where M P is defined, we obtain

(12)

(M P )  q = (M  q)P.

(13)

Finally, for an r ◊ r invertible square matrix Q M  Ir = (Iu  Q)(M  Ir)(Iv  Q-1).

(14)

For simplicity, write Fij = Fij(, Z) and Fij = F (, Z) for (i, j) = (1, 0), (0, 1), (2, 0), (1, 1) and (0, 2). Using the facts (10)≠(14), it can be shown that

F20 = (IK  B )F20(IK  B), F02 = (IT  B-1)F02(IT  (B )-1), F11 = (IK  B )F11(IT  (B )-1).

(15)

From (15) it can be also seen that

F02 - F11F2-01F11 = (IT  B-1) F02 - F11F2-01F11 (IT  (B )-1).

(16)

For each of (i, j) = (2, 0), (1, 1), (0, 2), let Gij denote the block matrix of F (, Z)-1 whose the dimension equals that of Fij. Likewise, define Gij with F (, Z)-1. Then, from (15), (16) and the inversion formula for a partitioned matrix, we obtain

G20 = (IK  B-1)G20(IK  (B )-1), G02 = (IT  B )G02(IT  B), G11 = (IK  B-1)G11(IT  B).

(17)

The proposition follows immediately from (17) and the facts F10 = (IK  B )F10 and F01 = (IT  B-1)F01.

12

3 Simulation Study

In Section 5 we will argue that the inference based on the covariances of the unobserved factors Zt is asymptotically equivalent to the one based on B Zt for some invertible B, see Eq. (34). In this section we illustrates the equivalence by a simulation study. For this, we compare the covariances of Zt and Zt  B Zt.

We took T = 500, 1000, 2000, J = 100, 250, 1000 and K = 36, 49, 64. We considered

d = 2, L = 3 and the following tuple of 2-dimensional functions:



m0 m1 m2

 (x1, x2)

=



9.45

1

3.46(x1

-

1 2

)

(x1

-

1 2

)2

+

(x2

-

1 2

)2

m3 1.41 sin(2x2)

 - 1.6  .

(18)

m1 m2 m3

2
1
0
-1
-2 1 0.5 x2

00

4
2
0
-2 1
1 0.5 0.5 x1 x2 0 0

2
1
0
-1
-2 1
1 0.5 0.5 x1 x2 0 0

1 0.5 x1

Figure 2: True functions m1, m2, m3 from which the data were generated.

The coefficients in (18) were chosen so that m1, m2, m3 are close to orthogonal. The factor loading functions are displayed in Figure 2. We generated Zt from a centered VAR(1) process Zt = AZt-1 + Ut, where Ut is N3(0, U ) random vector and

 0.95
A =  0 0.1

-0.2 0.8 0

 0 0.1  , 0.6

 10-4
U =  0 0

0 10-4
0

 0 0  . 10-4

13

The design points Xt,j were independently generated from a uniform distribution on the unit square, t,j were i.i.d. N (0, 2) with  = 0.05, and Yt,j were obtained according to the model (3). The simulation experiment was repeated 250 times for each combination of (T, J, K).

1

0.5

0 0
0.2 0.4 0.6 0.8

10

1 0.8 0.6 0.4 0.2

Figure 3: Tensor linear B-spline basis used in the estimation. Left panel: one particular basis function k. Right panel: the whole set of basis functions for K = 36.

For the estimation we employed, for j, the tensor products of linear B-splines. The onedimensional linear B-splines k are defined on a consecutive equidistant knots xk, xk+1, xk+2 by k(x) = (x - xk)/(xk+1 - xk) for x  (xk, xk+1], k(x) = (xk+2 - x)/(xk+2 - xk+1) for x  (xk+1, xk+2], and k(x) = 0 otherwise. The tensor spline basis functions in the case K = 36 are plotted in Figure 3. In the simulation we increased the number of the basis
functions K to 49 and 64, which correspond to more dense layouts in the right panel of
Figure 3.

We plotted in Figure 4 the entries of the scaled difference of the covariance matrices

D = 1 T

T
Zt - Z
t=1

Zt - Z

T
- Zt - Z
t=1

Zt - Z

.

(19)

Each panel of Figure 4 corresponds to one entry of the matrix D, and the three boxplots

in each panel represent the distributions of the 250 values of the corresponding entry for

T = 500, 1000, 2000. In the figure we also depicted, by thick lines, the 95% and 5% quantiles

of

D = 1 T

T
Zt - Z
t=1

Zt - Z

- ,

(20)

14

0.02 0.015 0.01 0.005
0 -0.005 -0.01 -0.015 -0.02

T=500

T=1000

T=2000

0.01 0.008 0.006 0.004 0.002
0 -0.002 -0.004 -0.006 -0.008 -0.01

T=500

T=1000

T=2000

0.01 0.008 0.006 0.004 0.002
0 -0.002 -0.004 -0.006 -0.008 -0.01

T=500

T=1000

T=2000

0.01 0.008 0.006 0.004 0.002
0 -0.002 -0.004 -0.006 -0.008 -0.01

T=500

T=1000

T=2000

0.01 0.008 0.006 0.004 0.002
0 -0.002 -0.004 -0.006 -0.008 -0.01

T=500

T=1000

T=2000

0.01 0.008 0.006 0.004 0.002
0 -0.002 -0.004 -0.006 -0.008 -0.01

T=500

T=1000

T=2000

Figure 4: The boxplots based on 250 values of the entries of the scaled difference of the covariance matrices given at (19). The lengths of the series Zt and Zt were 500, 1000, 2000. The thick lines represent the 95% and 5% quantiles of (20).

15

where  is the true covariance matrix of the simulated VAR process. It is known that  can be represented as  = (IL2 - A  A)-1U , where  and U are the stack forms of  and U respectively. We refer to Lu®tkepohl (1993) for more details.
Our theory in Section 5 tells that the size of D is of smaller order than the normalized error D of the covariance estimator based on Zt. It is known that the latter converges to a non-degenerate law as T  . This is well supported by the plots in Figure 4 showing that the distance between the two thick lines in each panel is invariant as T increases. The fact that the additional error incurred by using Zt instead of Zt is negligible for large T is also confirmed. In particular, the long stretches at tails of the distributions of D as well as their interquartile ranges get shorter as T increases.
4 Applications
This section presents an application of DSFM. We fit the model to the intra-day IV based on ODAX prices and discuss related issues. We also give a brief overview for other possible applications.
For our analysis we chose the the data observed from July 1st 2004 to June 29th 2005. The one year period corresponds to the financial regulatory requirements. The data were taken from Financial and Economic Data Center of Humboldt-Universita®t zu Berlin. The IV data were regressed on the two-dimensional space of future moneyness and time-to- maturity, denoted by (t, t) . The future moneyness t is a monotone function of the strike price K: t = K/(Ste-rtt), where St is the spot price at time t and rt is the interest rate. We chose rt as a daily EURIBOR rate taken from Ecowin Reuters database. The time-to-maturity of the option were measured in years. We took all trades with 10/365 <  < 0.5. We limit also the moneyness range to   [0.7, 1.2].
The structure of the IV data, described already in Section 1, requires a careful treatment. Apart from the dynamic degeneration, one may also observe nonuniform frequency of the trades with significantly greater market activities for the options closer to expiry or atthe-money. Here, `at-the-money' means a condition in which the strike price of an option
16

equals the spot price of the underlying security, i.e., K = St. To avoid the problems with the highly skewed empirical distribution of Xt = (t, t), we transformed the initial space [0.7, 1.2] ◊ [0.03, 0.5] to [0, 1]2 by using the marginal empirical distribution functions. We applied the estimation algorithm to the transformed space, and then transformed back the results to the original space.

Since the model is not nested, the number of the dynamic functions needs to be determined in advance. Based on computed values

RV (L) =

T t

Jt j

{Yt,j

T

t

-

L l=0

Zt,l

ml(Xt,j

)}2

Jt j

(Yt,j

-

YØ

)2

,

(21)

which are given in Table 1 for various L, we chose L = 2. The quantity 1 - RV (L) can be interpreted as a proportion of the variation explained by the model among the total variation. Table 1 indicates that the third, fourth and fifth factor make only a small improvement in the fit.

No. Factors L=1 L=2 L=3 L=4 L=5

1 - RV (L) 0.848 0.969 0.976 0.978 0.980

Table 1: Proportion of the explained variation by the models with L = 1, . . . , 5 dynamic factors.

For the series estimators of ml we used tensor B-splines that are cubic in the moneyness and quadratic in the maturity direction. In the transformed space we placed 10 ◊ 5 knots

≠ 10 in the moneyness and 5 in the maturity direction. We found that the results were not

sensitive to the choice of the number of knots and the orders of splines, see Table 2. Since

the model is identifiable only up to the transformation (7), one has a freedom for the choice

of factors. Here, we chose m1 and m2 that are orthogonal to each other in L2[0, 1]2 in such

a way that

T t=1

Zt2,1

is

maximized,

as

is

described

in

Fengler

et

al.

(2007).

17

knots moneyness maturity
15 10 10 10 10 5 55 15 10 10 10 10 5 55 15 10 10 10 10 5 55

order moneyness maturity
32 32 32 32 22 22 22 22 21 21 21 21

1 - RV (2)
0.974 0.972 0.969 0.961 0.972 0.969 0.965 0.951 0.971 0.968 0.967 0.949

Table 2: Proportion of the explained variation by the models when L = 2 for different numbers of knots and different orders of splines.

The estimated functions m1 and m2 are plotted in Figure 5 in the transformed estimation space. The intercept function m0 is almost flat around zero, thus is not given. By construction, m0 + Zt,1m1 explain the principal movements of the surface. It was observed by Cont and da Fonseca (2002) Fengler et al. (2007) that most dominant innovations of the entire surface are parallel level shifts. Note that VDAX is an estimated at-the-money IV for an option with 45 days to maturity, and thus indicates up-and-down shifts. The left panel of Figure 6 shows the values of VDAX together with m0(Xt,0) + Zt,1m1(Xt,0), where Xt,0 is the moneyness and maturity corresponding to an option at-the-money with 45 days to maturity. The right panel of Figure 6 depicts the factor Zt, where one can find that Zt shows almost the same dynamic behavior as the index VDAX. This similarity supports that DSFM catches leading dynamic effects successfully. Obviously the model in its full setting explains other effects, such as skew or term structure changes, which are not explicitly stated here.
Statistical analysis on the evolution of a high-dimensional system ruling the option prices can be simplified to a low-dimensional analysis of the Zt. In particular, as our theory in
18

m1 m2

2
0
-2
0 0.2 0.4 0.6 0.8 moneyness

10

0.5 time to maturity

1

2
0
-2
0 0.2 0.4 0.6 0.8 moneyness

10

0.5 time to maturity

1

Figure 5: The estimated factor functions for the ODAX IV data from 20040701 to 20050629.

0.24 0.22
0.2 0.18 0.16 0.14 0.12
0.1 Jul04

0.17 0.16 0.15
Nov04

Dec04

Oct04

Jan05

Apr05

Jul05

0.04 0.02
0 -0.02 -0.04 -0.06 -0.08
-0.1 -0.12 -0.14 -0.16
Jul04

Oct04

z

Jan05

Apr05

Jul05

Figure 6: Left panel: VDAX from 20040701 to 20050629 (solid) and the dynamics of the corresponding IV given by the sub-model m0 + Zt,1m1 (dashed). Right panel: The obtained time series Zt on the ODAX IV data from 20040701 to 20050629. The solid line represents Zt,1, the dashed line Zt,2.

Section 5 and the simulation results in Section 3 assert, the inference based on the Zt is well justified in the VAR context. To select a VAR model we computed the Schwarz (SC), the Hannan-Quinn (HQ) and the Akaike criterion, as given in Table 3. One can find that SC and HQ suggest a VAR(1) process, while AIC selects VAR(2). The parameter estimates for each selected model are given in Table 4. The roots of the characteristic polynomial lie
19

order 1 2 3 4 5

AIC -14.06 -14.07* -14.06 -14.06 -14.07

SC -13.98* -13.93 -13.86 -13.81 -13.76

HQ -14.03* -14.02 -13.98 -13.96 -13.95

Table 3: The VAR model selection criteria. The smallest value for each criterion is marked by (*).

VAR(1)

VAR(2)

Zt-1,1 Zt-1,2 const. Zt-1,1 Zt-1,2 Zt-2,1 Zt-2,2 const. Zt,1 0.984 -0.029 -0.001 0.913 -0.025 0.071 -0.004 -0.001 Zt,2 0.055 0.739 0.005 0.124 0.880 -0.065 -0.187 0.006

Table 4: The estimated parameters for VAR(1) and VAR(2) models.

inside the unit circle, so the specified models satisfy the stationarity condition. For each of VAR(1) and VAR(2) models, we conducted a portmanteau test for the hypothesis that the autocorrelations of the error term at lags up to 12 are all zero, and also a series of LM tests, each of which tests whether the autocorrelation at a particular lag up to 5 equals zero. Some details on selection of lags for these tests can be found in Hosking (1980, 1981) and Bru®ggemann et al. (2006). We found that in any test the null hypothesis was not rejected at 5% level. A closer inspection on the autocorrelations of the residuals, however, revealed that the autocorrelation of Zt,2 residuals at lag one is slightly significant in the VAR(1) model, see Figure 7. But, this effect disappears in the VAR(2) case, see Figure 8. Similar analyses of characteristic polynomials, portmanteau and LM tests supported VAR(2) as a successful model for Zt.
Although DSFM is motivated from modelling IV data, it can be applied to many other problems. A number of possible applications have been already discussed in Section 1. We close this section by adding two other applications of DSFM. One is to analyze some
20

Cor(U1,U1(-i))
.2
.1
.0
-.1
-.2 1 2 3 4 5 6 7 8 9 10 11 12
Cor(U2,U1(-i))
.2
.1
.0
-.1
-.2 1 2 3 4 5 6 7 8 9 10 11 12

Cor(U1,U2(-i))
.2
.1
.0
-.1
-.2 1 2 3 4 5 6 7 8 9 10 11 12
Cor(U2,U2(-i))
.2
.1
.0
-.1
-.2 1 2 3 4 5 6 7 8 9 10 11 12

Figure 7: Cross-autocorrelogram for the VAR(1) residuals. The dashed line-bounds indicate ± 2 ◊ (standard deviations), which correspond to an approximate 95% confidence bound.

Cor(U1,U1(-i))
.3 .2 .1 .0 -.1 -.2 -.3
1 2 3 4 5 6 7 8 9 10 11 12
Cor(U2,U1(-i))
.3 .2 .1 .0 -.1 -.2 -.3
1 2 3 4 5 6 7 8 9 10 11 12

Cor(U1,U2(-i))
.3 .2 .1 .0 -.1 -.2 -.3
1 2 3 4 5 6 7 8 9 10 11 12
Cor(U2,U2(-i))
.3 .2 .1 .0 -.1 -.2 -.3
1 2 3 4 5 6 7 8 9 10 11 12

Figure 8: Cross-autocorrelogram for the VAR(2) residuals. The dashed line-bounds indicate ± 2 ◊ (standard deviations), which correspond to an approximate 95% confidence bound.

important characteristics of state price density (SPD). SPD describes the distribution of the risk-neutral price of an underlying asset at some future date. The knowledge of SPD
21

can be beneficial for an objective interpretation of market expectations. The SPD dynamics may also be modelled via (3), where the functions ml are one-dimensional nonparametric functions of the future underlying states. They can be described in terms of a symmetric or asymmetric contribution of the probability to reflect the changes in skewness and kurtosis over time. The other application is the analysis of book orders. It allows to recover at any time the supply and demand structure, usually given as bid and ask curves. These curves may serve to construct a measure of liquidity. A tradable asset is called `liquid' if it is possible to exchange a big volume `rapidly' without too much damage to the price of the asset. In practical term this means that the difference between the bid and ask prices (as a function of volume) is not too large. One can obtain for every day a surface of bid-ask differences as a function of time and volume. DSFM may help here in quantifying the dynamics of this liquidity measure.
5 Asymptotic analysis
In the simulation study and the real data application in Sections 3 and 4, we considered the case where Zt is a VAR-process. Here, we only make some weak assumptions on the average behavior of the process. For the asymptotic analysis, we let K, J, T  . Our first result relies on the following assumptions.
(A1) The variables X1,1, . . . , XT,J , 1,1, . . . , T,J are independent.
(A2) For t = 1, . . . , T the variables Xt,1, . . . , Xt,J are identically distributed, have support [0, 1]d and a density ft that is bounded from below and above on [0, 1]d, uniformly over t = 1, . . . , T .
(A3) We assume that
E[t,j] = 0 for t = 1, . . . , T, j = 1, . . . , J, sup E[2t,j] < .
t=1,...,T ,j =1,...,J
(A4) The functions k may depend on the increasing indices T and J, but are normed so that [0,1]d k2(x) dx = 1 for k = 1, . . . , K.
22

(A5) The components m0, . . . , mL can be approximated by 1, . . . , K, i.e.

K = sup inf |m(x) - A(x)|  0
x[0,1]d AIR(L+1)◊K
as K  . We denote a matrix that fulfills supx[0,1]d |m(x) - A(x)|  2K by A. We assume that K = O(K1/2J -1/2) for K, J  .

(A6) There exist constants 0 < CL < CU <  such that all eigenvalues of the random

matrix T -1

T t=1

ZtZt

lie in the interval [CL, CU ] with probability tending to one.

(A7) It holds that (K log K)/J  0 and log T /J  0.

(A8) The minimization (4) runs over all values of (A, z) with zt,0 = 1 and with

sup max
x[0,1] 1tT

zt A(x)

 MT ,

where the constant MT fulfils max1tT Zt  MT /Cm for a constant Cm such that supx[0,1] m(x) < Cm, and MT2 (K log K/J )  0, MT2 (log T /J )  0.

Condition (A8) and the additional bound MT in the minimization is introduced for purely technical reasons.

Our first result gives rates of convergence for the least squares estimators Zt and A.

Theorem 5.1. Suppose that model (3) holds and that (Zt, A) is defined by the minimization problem (4) under the constraint (5). Make the assumptions (A1)≠(A8). Then it holds that

1 T

Zt A - Zt A 2 = OP (KJ -1).

1tT

(22)

The proof of Theorem 5.1 is given in Section A.2.
At this point we have made no assumptions on the sequence Zt : 1  t  T , besides the bound in (A8). Up to now it is allowed to be a deterministic or a random sequence. We now assume that it is a random process. We discuss how a statistical analysis differs if inference on Zt is based on Zt instead of using (the unobserved) process Zt. We will show that the differences are asymptotically negligible (except an orthogonal transformation). This is
23

the content of the following theorem, where we consider estimators of autocovariances and show that these estimators differ only by second order terms. This asymptotic equivalence carries over to classical estimation and testing procedures in the framework of fitting a vector autoregresssive model. For the statement of the theorem we need the following assumptions:

(A9) The bound max1tT Zt  MT holds with probability tending to one, and it holds that MT2{(K log K)/J}  0 and MT2(log T /J)  0.

(A10) Zt is strictly stationary with E(Zt) = 0 and E Zt  <  for some  > 2. It is

strongly mixing with

 i=1

(i)(-2)/

<

.

The matrix EZtZt

has full rank.

The

process Zt is independent of X11, . . . , XT J , 11, . . . , T J .

(A11) The functions m0, . . . , mL are linearly independent. In particular, no function is equal to 0. Furthermore, it holds that supx[0,1] (x) = O(K1/2).
(A12) It holds that K/J + K = O(T -1/2), log T = O(K), K5J -4(log K)2 = O(T -1), and K7J -5(log K)2 = O(T -1).

Condition (A10) implies that T -1

T t=1

Zt

has

a

bounded

second

moment,

see

e.g.

Corollary

1.1 in Bosq (1998).

Theorem 5.2. Suppose that model (3) holds and that (Zt, A) is defined by the minimization problem (4) under the constraint (5). Make the assumptions (A1)≠(A12). Then there exists a random matrix B, which is of the form (7), such that for h  0

1T T

Zt - Z

t=h+1

Zt-h - Z

-

1 T

T

Zt - Z

t=h+1

Zt-h - Z

= OP (T -1/2),

Z - Z = OP (T -1/2),

where Zt = B Zt, Z = T -1

T t=1

Zt

and

Z

=

T -1

T t=1

Zt.

To illustrate an implication of Theorem 5.2, suppose that the factor loading process Zt in (3) is a stationary VAR(p) process in a mean adjusted form:

Zt - µ = 1(Zt-1 - µ) + ∑ ∑ ∑ + p(Zt-p - µ) + Ut,

(23)

24

where µ = E(Zt), j is a L ◊ L matrix of coefficients and Ut is a white noise with some nonsingular covariance matrix U . Here, we take the L components of Zt, omitting the first Zt,0  1. In a slight abuse of notation, we continue to refer to the resulting vector as Zt.
Let h be the autocovariance matrix of the process Zt with the lag h  0, which is estimated by h = T -1 Tt=h+1(Zt - Z)(Zt-h - Z) . Let Y = (Zp+1 - µ, . . . , ZT - µ),  = (1, . . . , p) and U = (Up+1, . . . , UT ). Define Wt = (Zt - µ) , . . . , (Zt-p+1 - µ) and W = (Wp, . . . , WT -1). Then, the model (23) can be rewritten as Y = W + U and the least squares estimator of  is given by  = Y W (W W )-1, where Y and W are the same as Y and W , respectively, except that µ is replaced by Z. Likewise, fitting a VAR(p) model with the estimated factor loading process Zt yields  = Y W (W W )-1, where Y and W are defined as Y and W with Zt being replaced by Zt. Both Y and W are matrices composed of h for various h. The matrices Y and W have the same forms as Y and W , respectively, but with h being replaced by h = T -1 Tt=h+1(Zt - Z)(Zt-h - Z) . It is well known that
T ( - ) = OP (1), see Lu®tkepohl (1993). By Theorem 5.2, we have T ( - ) = OP (1).

A Appendix

A.1 Proof of Theorem 2.1.

We use the following lemma to prove the theorem.

Lemma A.1. (Newton-Kantorovich) Let X and Y be Banach spaces and F : D  X  Y . Suppose that on an open convex set D0  D, F is Fr¥echet differentiable and

F (x) - F (y)   x - y , x, y  D0.

Let x0  D0 be the initial point. Assume that F (x0)-1 is defined on all of Y and

F (x0)-1  , F (x0)-1F (x0)  

for some constants  and  such that q  2  1. Define

t

=

1 

(1

-

1 - q),

t

=

1 

(1

+

1 - q),

25

and assume that S  {x x - x0  t}  D0. Then, the Newton iterates xk+1 = xk - F (xk)-1F (xk), k = 0, 1, . . .
are well defined, lie in S and converge to a solution x of F (x) = 0 at a geometric rate: xk - x   2-(k-1)q2k-1.
When q < 1, the solution x is unique in D0  {x x - x0 < t}. When q = 1 (in this case t = t), the solution x is unique in D0  {x x - x0  t}.

The proof of the lemma can be found in Kantorovich and Akilov (1982), for example.

We now prove the theorem. Suppose that

T t=1

Zt(0)

A(0) - Zt A 2  r for some r > 0

which will be chosen later. Define

B0 =

T
ZtZt(0)
t=1

-1 T
ZtZt .
t=1

Also, define A(0) = B0-1A(0) and Zt(0) = B0 Zt(0). Let (0) be the stack form of A(0), i.e.,

(0) = (IK  B0-1)(0). Note that

T t=1

ZtZt

=

T t=1

ZtZt(0)

.

With the Frobenius norm

M for a matrix M , we get

(0) -  2 = A(0) - A 2



T -1 2

ZtZt

∑

T ZtZt (A(0) - A) 2

t=1 t=1

=

T -1 2

ZtZt

∑

T

ZtZt(0)

A(0) -

T

2
ZtZt A)

t=1 t=1 t=1



T -1 2
ZtZt

T
ZtZt(0) A(0) - ZtZt A)

2

t=1 t=1

r

T -1 2
ZtZt

T
Zt 2

t=1
 r c1.

t=1

(24)

Now, for a matrix M , define M 2 = sup M x . It is known that M 2  M . We
x =1
26

get

A (Zt(0) - Zt)



A

-1 2

∑

AA

(Zt(0) - Zt)



A

-1 2

∑

(AA

)-1 -1 ∑

Zt(0) - Zt .

(25)

On the other hand,

(Zt(0) - Zt) A  Zt(0) (A - A(0)) + Zt(0) A(0) - Zt A  Zt(0) ∑ A - A(0) + Zt(0) A(0) - Zt A .

(26)

The two inequalities (25) and (26) together with (24) give

T

Z(0) - Z 2 =

Zt(0) - Zt 2



2r

A

2 2

∑

(AA )-1 2

t=1

◊ 1+

T
Zt(0) 2

T
Zt 2

 r c2.

t=1

t=1

(27)

T
ZtZt
t=1

-1 2

Since F (, Z) is quadratic in (, Z), there exists 0 < c3 <  for any compact set D in R(K+T )(L+1) such that F ( , Z ) - F (, Z) 2  c3 ( , Z ) - ( , Z ) for all ( , Z ) , ( , Z )  D. Let c4 = F ((0), Z(0))-1 2 < . Since F is continuous and F (, Z) = 0, there exists r > 0 such that, if (0) -  2 + Z(0) - Z 2  r , then

F ((0), Z(0))-1F ((0), Z(0))

 . 2c3c4

By Lemma A.1, the Newton iterates ((k), Z(k)) based on the algorithm (6) starting from ((0), Z(0)) converges to (, Z) at a geometric rate:

(k) -  2 + Z(k) - Z 2  C12-(k-1)2k-1

(28)

for some C1 > 0. By Proposition 2.2,

(k) = (IK  B0-1)(k), Z(k) = (IT  B0 )Z(k),

or equivalently

A(k) = B0-1A(k), Zt(k) = B0 Zt(k)

27

for k  1. This and (28) give that, if (0) -  2 + Z(0) - Z 2  r , then

TT

Zt(k) A(k) - Zt A 2 =

Zt(k) A(k) - Zt A 2

t=1 t=1

 C2 (k) -  2 + Z(k) - Z 2

 C2-(k-1)2k-1

for some C, C2 > 0. We take r = (c1 + c2)-1r . Then, by (24) and (27), (0) -  2 + Z(0) -

Z 2  r if

T t=1

Zt(0)

A(0) - Zt A 2  r. This completes the proof of the theorem.

A.2 Proof of Theorem 5.1.

We write dt = Zt A - Zt A. We have to show that

1 T

dt 2 = OP (KJ -1 + K2 ).

1tT

(29)

For the proof of this claim we first note that by definition of our estimator it holds that

TJ t=1 j=1

2 TJ
Yt,j - Zt A(Xt,j) 
t=1 j=1

Yt,j - Zt A(Xt,j) 2 .

(30)

This implies that

TJ

TJ

dt (Xt,j) 2  2

dt (Xt,j)t,j

t=1 j=1

t=1 j=1

(31)

TJ
+2 dt (Xt,j) Zt m(Xt,j) - Zt A(Xt,j) . (32)
t=1 j=1

With

d

2 J,T

= T -1J -1

with (A5)

1jJ,1tT dt (Xt,j ) 2 and d 2 = T -1

1tT dt 2 this gives



d

2 J,T

2

d

1 T

T

t=1

1 J

J

21/2 (Xt,j)t,j  + 4 d J,T K .

j=1

(33)

28

We now argue that with c, C > 0 small enough it holds for all vectors e  E(MT ) with E(C) = {e  IRK : e = 1 and supx[0,1] |e (x)|  C} and for 1  t  T

P J -1

e (Xt,j) 2  c  exp(-CJ/MT2 ).

1jJ

This follows by application of Bernstein`s inequality, see also (A4). Now we use that for all C > 0 the unit sphere in IRK can be covered by o{(C )-KKK} balls with radius C K-1. Furthermore, it holds almost surely with a constant C (not depending on C ):

sup J -1 e (Xt,j) 2 - J -1 f (Xt,j) 2  C C .

e = f =1, e-f C K-1

1jJ

1jJ

This implies that with a constant C

P

min inf J -1

1tT eE(MT )

1jJ

e (Xt,j) 2  c/2

 C (C )-KKKT exp(-CJ/MT2 ).

The right hand side converges to 0 because of (A8). This shows that

d

2 J,T



c 2

d

2

with probability tending to one. Therefore we get from (33) that with probability tending

to one



c 2

d



d

J,T



c

 

1 T

T

t=1

1 J

J

21/2 (Xt,j)t,j  + 4K .

j=1

The right hand side is of order OP (K1/2J-1/2). This concludes the proof of Theorem 5.1.

A.3 Proof of Theorem 5.2.

We choose B as

B=

T

T -1

ZtZt

t=1

-1 T
T -1 ZtZt .
t=1

(34)

For this definition we have to check that the matrix T -1

T t=1

ZtZt

is invertible. We suppose

that this is not the case and we define a random vector e (depending on T ) with e = 1

29

and e

T t=1

ZtZt

= 0. We now use that

TT
T -1 ZtZt A - T -1 ZtZt A

t=1 t=1

T

 T -1

ZtZt A - ZtZt A

t=1

T

= T -1

Zt Zt A - Zt A

t=1

T

 T -1

Zt Zt A - Zt A

t=1

T
 T -1

1/2 T

Zt 2

T -1

Zt A - Zt A 2

t=1 t=1

= OP (K1/2/J 1/2),

1/2

because of (A6) and Theorem 5.1. This gives with f = T -1

T t=1

ZtZt

e,

f m = f (A) + O(K) = OP (K1/2/J 1/2)

(35)

and this would imply that m0, . . . , md are linearly dependent, in contrast to assumption

(A11). Note also that T -1

T t=1

ZtZt

- EZtZt

= OP (T -1/2) = OP (1), because of (A6).

We now define Zt = B Zt and A = B-1A. Then Zt A = Zt A and T -1

T t=1

ZtZt

=

T -1

T t=1

ZtZt

.

This

gives

with

(35)

A - A

T
= T -1 ZtZt (A - A) OP (1)
t=1
TT
= T -1 ZtZt A - T -1 ZtZt A OP (1)
t=1 t=1
= OP (K1/2/J 1/2).

(36)

30

Furthermore, from (A11), (A5),(36) and Theorem 5.1 one gets that

T
T -1

2
Zt - Zt

(37)

t=1

T
= T -1

2
Zt m - Zt m OP (1)

t=1

T
= T -1

Zt A - Zt A 2 OP (1) + OP (K2 )

t=1

T
= T -1

Zt A - Zt A 2 OP (1) + T -1 T

2
Zt A - Zt A OP (1) + OP (K2 )

t=1 t=1

T
= T -1

Zt

2

A - A

2
OP (1) + OP (K/J)

t=1

T
= T -1

Zt - Zt

2

A - A

2
OP (1) +

A - A

2
OP (1) + OP (K/J)

t=1

= OP (K/J).

We will show that for h  0

T

T -1

Zt - Zt Zt-h = OP (T -1/2).

t=h+1

Because of Zt,0  1, the equation (38) with the choice h = 0 implies that

T
T -1
t=1

Zt - Zt

= OP (T -1/2).

These two equations imply the statement of Theorem 5.2, because of

T
T -1
t=h

Zt - Zt

Zt-h - Zt-h = OP (K/J ) = OP (T -1/2),

see (A12).

(38)

For the proof of (38) we use the representation Zt A(Xt,j) = {(Xt,j)  Zt} , where  is the stack form of A. Similarly, Zt A(Xt,j) = {(Xt,j)  Zt} , where  is the stack

31

form of A. Now, by definition

J

Zt = St-,Z1J -1

Yt,j A(Xt,j ),

j=1

TJ

 = S-1T -1J -1

{(Xt,j)  Zt}Yt,j,

t=1 j=1

where

J
St,Z = J -1 A(Xt,j)(Xt,j) A ,

j=1

TJ

S = T -1J -1

{(Xt,j)  Zt}{(Xt,j)  Zt} .

t=1 j=1

We now argue that

(39) (40)

St,Z - St,Z S - S

= OP (J 1/2K-1/2T -1/2), = OP (J 1/2K-1/2T -1/2),

(41) (42)

where

St,Z = AE (Xt,j)(Xt,j) A ,
T
S = T -1 E {(Xt,j)  Zt}{(Xt,j)  Zt} Zt .
t=1
We show (41). Claim (42) can be shown similarly. For the proof of (41) it suffices to show

32

that

J
J -1 A (Xt,j)(Xt,j) - E (Xt,j)(Xt,j)

A - A

j=1

= OP (J 1/2K-1/2T -1/2),

J
J -1 A - A (Xt,j)(Xt,j) - E (Xt,j)(Xt,j)

A - A

j=1

= OP (J 1/2K-1/2T -1/2),

J
J -1 A (Xt,j)(Xt,j) - E (Xt,j)(Xt,j)

A

j=1

= OP (J 1/2K-1/2T -1/2),

J
J -1 AE (Xt,j)(Xt,j)

A - A

j=1

= OP (J 1/2K-1/2T -1/2),

J
J -1 A - A E (Xt,j)(Xt,j)T A - A

j=1

= OP (J 1/2K-1/2T -1/2).

(43) (44) (45) (46) (47)

The proof of (45)≠(47) follows by simple arguments, note also that because of (A12) it holds that K1/2J -1/2 = O(J 1/2K-1/2T -1/2) by assumption. We now show (43). Claim (44) can be shown similarly. For the proof of (43) we use Bernstein`s inequality for the following sum:

P

J
| Wj| > x

 2 exp

1 x2 2 V + M x/3

.

j=1

(48)

Here for a value of t with 1  t  T and for a vector e  IRK with e = 1 the random variable Wj is a row of the vector

J -1A (Xt,j)(Xt,j) - E (Xtj)(Xtj) e.

In (48), V is an upper bound for the variance of

J j=1

Wj

and

M

is

a

bound

for

the

absolute

values of Wj, i.e. |Wj|  M for 1  j  J, a.s. With some constants C1 and C2 that do not

33

depend on t, e and the row number we get V  C1J-1 and M  C2K1/2J-1. One can check that for x with x/[JK-1T -1/2]  0 slowly enough, it holds that

KKT exp

1 x2 2 V + M x/3

 0.

Using similar arguments as in the proof of Theorem 5.1 this implies claim (43).

From (36), (37), (39), (40), (41) and (42) we get the following expansions (uniformly for 1  t  T ):

Zt - Zt = St-,Z1

JJ
J -1 t,jA(Xtj) + J -1 t,j(A - A)(Xt,j)
j=1 j=1

J
+J -1 Zt (A - A)(Xt,j)(A - A)(Xt,j)
j=1

JJ
+J -1 (Xt,j)A(Xt,j) + Zt (A - A)(Xt,j)A(Xt,j)
j=1 j=1

JJ

= St-,Z1J -1

t,j A(Xt,j ) + St-,Z1J -1

t,j(A - A)(Xt,j)

j=1 j=1

J
+St-,Z1J -1 Zt (A - A)(Xt,j)A(Xt,j) + OP (T -1/2)
j=1

= t,1,Z + t,2,Z + t,3,Z + OP (T -1/2),

(49) + OP (T -1/2)

34

TJ

 -  = S-1T -1J -1

{(Xt,j)  Zt}t,j

t=1 j=1

(50)

TJ

+S-1T -1J -1

{(Xt,j)  (Zt - Zt)}t,j

t=1 j=1

TJ

+S-1T -1J -1

{(Xt,j)  Zt}{(Xt,j)  (Zt - Zt)} 

t=1 j=1

TJ

+S-1T -1J -1

{(Xt,j)  (Zt - Zt)}{(Xt,j)  (Zt - Zt)} 

t=1 j=1

TJ

+S-1T -1J -1

{(Xt,j)  Zt}(Xt,j)

t=1 j=1

TJ

+S-1T -1J -1

{(Xt,j)  (Zt - Zt)}(Xt,j) + R,

t=1 j=1

where (x) = m(x) - A(x) and R is a vector with R = OP (T -1/2).

For the proof of the theorem it remains to show that for 1  j  3

T

T -1

t,j,Z Zt-h = OP (T -1/2).

t=h+1

This can be easily checked for j = 1. For j = 2 it follows from

(51)

J

E J -1

t,jSt-,Z1(Xt,j) 2 = O(KJ -1T -1)

j=1

and A - A 2 = O(KJ-1). For the proof of (51) for j = 3 we note first that for 0  l  L

T TJ

T -1

t,3,Z Zt-h,l = T -1J -1

St-,Z1A(Xt,j)Zt-h,l{(Xt,j)  Zt} ( - )

t=h+1

t=h+1 j=1

= QT ( - ) +  -  OP (K1/2J -1/2T -1/2)

= QT ( - ) + OP (T -1/2),

where

T

QT = E T -1

St-,Z1A(Xt,j)Zt-h,l{(Xt,j)  Zt}

t=h+1

.

35

Thus claim (51) for j = 3 follows from QT ( - ) = OP (T -1/2).
This claim can be checked by noting that QT = O(1) and by applying the expansion (50). Note that under our assumptions it does not hold in general that  -  = OP (T -1/2). For this reason a careful treatment that we have just described above is needed. This concludes the proof of Theorem 5.2.
References
Black, F. and Scholes, M. (1973). The pricing of options and corporate liabilities. Journal of Political Economy, 81:637≠654.
Bliss, R. (1997). Movements in the term structure of interest rates. Economic Review Q IV, Federal Reserve Bank of Atlanta.
Bosq, D. (1998). Nonparametric Statistics for Stochastic Processes. Springer, New York.
Bru®ggemann, R., Lu®tkepohl, H., and Saikkonen, P. (2006). Residual autocorrelation testing for vector error correction models. Journal of Econometrics, 134:579≠604.
Brumback, B. and Rice, J. A. (1998). Smooting spline models for the analysis of nested and crossed samples of curves. Journal of the American Statistical Association, 93:961≠994.
Connor, G., Hagmann, M., and Linton, O. (2007). Efficient semiparametric estimation of the Fama-French model and extensions. Preprint.
Connor, G. and Linton, O. (2007). Semiparametric estimation of a characteristic-based factor model of stock returns. Journal of Empirical Finance, forthcoming.
Cont, R. and da Fonseca, J. (2002). The dynamics of implied volatility surfaces. Quantitative Finance, 2(1):45≠60.
de Boor, C. (2001). A Practical Guide to Splines. Springer-Verlag, Berlin, Heidelberg.
Detlefsen, K. and Ha®rdle, W. (2006). Forecasting the term structure for variance swaps. Discussion Paper 2006-052, SfB 649, Humboldt-Universita®t zu Berlin.
36

Diebold, F. X. and Li, C. (2006). Forecasting the term structure of government bond yields. Journal of Econometrics, 130:337≠364.
Fama, E. F. and French, K. R. (1992). The cross-section of expected stock returns. Journal of Finance, 47:427≠465.
Fan, J., Yao, Q., and Cai, Z. (2003). Adaptive varying-coefficient linear models. Journal of the Royal Statistical Society B, 65:57≠80.
Fengler, M. R., Ha®rdle, W., and Mammen, E. (2007). A semiparametric factor model for implied volatility surface dynamics. Journal of Financial Econometrics, 5(2):189≠218.
Gasser, T., Mo®cks, R., and Verleger, R. (1983). Selavco: A method to deal with trial-totrial variability of evoked potential. Electroencephalography and Clinical Neurophysiology, 55:717≠723.
Hafner, R. (2004). Stochastic Implied Volatility. Springer, Berlin.
Hansen, L. H., Nielsen, B., and Nielsen, J. P. (2004). Two sided analysis of the variance with a latent time series. Nuffield Colledge Economic Working Paper 2004-W25, University of Oxford.
Hosking, J. R. M. (1980). The multivariate portmanteau statistic. Journal of the American Statistical Association, 75:602≠608.
Hosking, J. R. M. (1981). Lagrange-multiplier tests of multivariate time-series models. Journal of the Royal Statistical Society B, 43(2):219≠230.
Kantorovich, L. V. and Akilov, G. P. (1982). Functional Analysis. Pergamon Press, Oxford, 2nd edition.
Kauermann, G. (2000). Modeling longitudinal data with ordinal response by varying coefficients. Biometrics, 56(3):1692≠698.
Krivobokova, T., Kauermann, G., and Archontakis, T. (2006). Estimating the term structure of interest rates using penalized splines. Statistical Papers, 47(3):443≠459.
Lee, R. D. and Carter, L. (1992). Modeling and forecasting the time series of u.s. mortality. Journal of the American Statistical Association, 87(419):659≠671.
37

Lu®tkepohl, H. (1993). Intorduction to Multiple Time Series Analysis. Springer-Verlag, Berlin, Heidelberg.
Martinussen, T. and Scheike, T. (2000). A nonparametric dynamic additive regression model for longitudinal data. Annals of Statistics, 28(4):1000≠1025.
Molgedey, L. and Galic, E. (2001). Extracting factors for interest rate scenarios. European Physical Journal B, 20(4):517≠522.
Nelson, C. R. and Siegel, A. F. (1987). Parsimonious modeling of yield curves. Journal of Business, 60:473≠489.
Pen~a, D. and Box, E. P. (1987). Identifying a simplifying structure in time series. Journal of the American Statistical Association, 82:836≠843.
Rebonato, R. (1998). Interest-Rate Option Models: Understanding, Analyzing and Using Models for Exotic Interest-Rate Options. Wiley Series in Financial Engineering. John Wiley & Son Ltd., 2nd edition.
Stock, J. H. and Watson, M. W. (2005). Implications of dynamic factor models for var analysis. NBER Working Papers 11467, National Bureau of Economic Research, Inc. available at http://ideas.repec.org/p/nbr/nberwo/11467.html.
Tru®ck, S., Borak, S., Ha®rdle, W., and Weron, R. (2006). Convenience yields for co2 emission allowance futures contracts. Discussion Paper 2006-076, SfB 649, Humboldt-Universita®t zu Berlin.
Yang, L., Park, B. U., Xue, L., and Ha®rdle, W. (2006). Estimation and testing for varying coefficients in additive models with marginal integration. Journal of the American Statistical Association, 101:1212≠1227.
38

SFB 649 Discussion Paper Series 2007
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "Trade Liberalisation, Process and Product Innovation, and Relative Skill Demand" by Sebastian Braun, January 2007.
002 "Robust Risk Management. Accounting for Nonstationarity and Heavy Tails" by Ying Chen and Vladimir Spokoiny, January 2007.
003 "Explaining Asset Prices with External Habits and Wage Rigidities in a DSGE Model." by Harald Uhlig, January 2007.
004 "Volatility and Causality in Asia Pacific Financial Markets" by Enzo Weber, January 2007.
005 "Quantile Sieve Estimates For Time Series" by J¸rgen Franke, JeanPierre Stockis and Joseph Tadjuidje, February 2007.
006 "Real Origins of the Great Depression: Monopolistic Competition, Union Power, and the American Business Cycle in the 1920s" by Monique Ebell and Albrecht Ritschl, February 2007.
007 "Rules, Discretion or Reputation? Monetary Policies and the Efficiency of Financial Markets in Germany, 14th to 16th Centuries" by Oliver Volckart, February 2007.
008 "Sectoral Transformation, Turbulence, and Labour Market Dynamics in Germany" by Ronald Bachmann and Michael C. Burda, February 2007.
009 "Union Wage Compression in a Right-to-Manage Model" by Thorsten Vogel, February 2007.
010 "On -additive robust representation of convex risk measures for unbounded financial positions in the presence of uncertainty about the market model" by Volker Kr‰tschmer, March 2007.
011 "Media Coverage and Macroeconomic Information Processing" by Alexandra Niessen, March 2007.
012 "Are Correlations Constant Over Time? Application of the CC-TRIGt-test to Return Series from Different Asset Classes." by Matthias Fischer, March 2007.
013 "Uncertain Paternity, Mating Market Failure, and the Institution of Marriage" by Dirk Bethmann and Michael Kvasnicka, March 2007.
014 "What Happened to the Transatlantic Capital Market Relations?" by Enzo Weber, March 2007.
015 "Who Leads Financial Markets?" by Enzo Weber, April 2007. 016 "Fiscal Policy Rules in Practice" by Andreas Thams, April 2007. 017 "Empirical Pricing Kernels and Investor Preferences" by Kai Detlefsen,
Wolfgang H‰rdle and Rouslan Moro, April 2007. 018 "Simultaneous Causality in International Trade" by Enzo Weber, April
2007. 019 "Regional and Outward Economic Integration in South-East Asia" by
Enzo Weber, April 2007. 020 "Computational Statistics and Data Visualization" by Antony Unwin,
Chun-houh Chen and Wolfgang H‰rdle, April 2007. 021 "Ideology Without Ideologists" by Lydia Mechtenberg, April 2007. 022 "A Generalized ARFIMA Process with Markov-Switching Fractional
Differencing Parameter" by Wen-Jen Tsay and Wolfgang H‰rdle, April 2007.
SFB 649, Spandauer Straﬂe 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

023 "Time Series Modelling with Semiparametric Factor Dynamics" by Szymon Borak, Wolfgang H‰rdle, Enno Mammen and Byeong U. Park, April 2007.
SFB 649, Spandauer Straﬂe 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

