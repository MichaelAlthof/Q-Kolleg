BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2008-019
The Accuracy of Long-term Real Estate
Valuations
Rainer Schulz1 Markus Staiber2 Martin Wersing3 Axel Werwatz4
1University of Aberdeen, United Kingdom 2Allianz Lebensversicherungs-AG Leipzig, Germany
3Humboldt-Universit‰t zu Berlin, Germany 4Technische Universit‰t Berlin, Germany
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universit‰t zu Berlin Spandauer Straﬂe 1, D-10178 Berlin

The Accuracy of Long-term Real Estate Valuations
Rainer Schulz, Markus Staiber, Martin Wersing and Axel Werwatz January 2008
Schulz: University of Aberdeen Business School, Edward Wright Building, Dunbar Street, Aberdeen AB24 3QY, United Kingdom. Staiber: Allianz Lebensversicherungs-AG, Baufinanzierung/Gutachter, Eilenburger Straﬂe 4, 04317 Leipzig, Germany. Wersing: SFB 649 Economic Risk, Humboldt-Universita®t zu Berlin, Ziegelstraﬂe 13a, 10117 Berlin, Germany. Werwatz: Technische Universita®t Berlin, Institut fu®r Volkswirtschaftslehre und Wirtschaftsrecht, Straﬂe des 17. Juni 135, 10623 Berlin, Germany and SFB 649. Financial support from the Deutsche Forschungsgemeinschaft, SFB 649 Economic Risk, is gratefully acknowledged.
1

Abstract By using a unique data set of single-family house transactions, we examine the accuracy of the cost and sales comparison approach over different forecast horizons. We find that sales comparison values provide better long-term forecasts than cost values if the economic loss function is symmetric. A weighted average of both sales comparison value and cost value can reduce this loss even further. If the economic loss function is asymmetric, however, cost values might provide better long-term forecasts. Keywords: prediction accuracy, mortgage underwriting, risk management JEL classification: C52, C53
2

1 Introduction
Real estate valuations are important for financial institutions, especially banks, for at least two reasons. First, valuations are often needed during the underwriting or refinancing of mortgage loans, where valuations should provide a fair assessment of the (future) market value of the property that will serve as collateral for the loan. Second, valuations are needed if the institution or bank wants an updated assessment of collateral values for outstanding loans it holds on its balance sheet. Such reassessments might be necessary and required by Basel II if new information arrives or market sentiments change.
The two most common approaches for the valuation of single-family houses are the sales comparison approach and the cost approach. Focussing on a short-term horizon, the studies of Dotzour (1990) and Schulz and Werwatz (2008) have shown that sales comparison values are more accurate than cost values when used as forecasts of current house prices. Further, the latter study finds that a weighted average of sales comparison values and cost values performs best.
In this study, we complement the above results by focussing on a long-term horizon and examine the accuracy of single-family house valuations when used as forecasts of future house prices. Here, the future could refer to the date when the borrower is most likely to default. The long-term valuation would then be a forecast of collateral recovery value given default. Informal evidence indicates that the default probabilities are highest in the early years of a mortgage loan, so that a long-term horizon of up to five years seems to be a reasonable choice.
It should be noted that mortgage banks in several countries are required to compute so-called mortgage lending values for the underwriting process. The rules for the computation of mortgage lending values are binding and defined in detail by the financial market supervisory authorities. This applies to Germany, the country our data comes from. According to the German rules, sales and cost values form the basis for the computation of single-family house mortgage lending values, but further adjustments and deductions are required. Deductions are reasonable if the economic loss function of valuation errors is asymmetric. The long-term valuations we examine and the mortgage lending values are thus not identical, but related. Evaluating the accuracy of long-term valuations might thus also be useful for an understanding of the accuracy of mortgage lending values.
3

The results of our study show that the sales comparison values provide better long-term forecasts than cost values if the economic loss function is symmetric, but a weighted average of sales comparison and cost values performs best. If the economic loss function is asymmetric, however, then--as kernel density estimates of the valuation error distributions reveal--cost values might provide better long-term forecasts. In summary, the study proves that it is possible and useful to assess the long-term performance of different valuation approaches empirically. Future work has to provide better understanding of the economic loss function. Moreover, a discussion of the accuracy of the different valuation approaches in a portfolio context seems to be worthwhile (Shiller and Weiss, 1999).
The study is organized as follows. Section 2 discusses the sales comparison and the cost approach in detail and explains our data set and how we compute the different valuations. Section 3 presents the empirical results. Section 4 concludes.
2 Implementation
In this study, the accuracy of long-term valuations is explored with single-family house data from Berlin. Our data set allows the computation of sales comparison and cost values over a period of 30 quarters. These valuations are computed for different forecast horizons and are then compared to actual transaction prices. More precisely, we compute valuations for every transaction backdated up to five years, taking into account only the information that was available that time. These valuations are adjusted for the expected future levels of house prices and replacement cost, respectively, and also for depreciation when necessary. In addition to a direct comparison of sales comparison and cost values, we also compute an equally-weighted combination of both. In practice, appraisers sometimes compute such weighted combinations if two or more valuations of the same property are available.
2.1 Computation of the valuations
Sales comparison approach: This approach uses transaction prices of comparable houses to estimate the value of the subject house. Several adjustments might be necessary when this approach is applied, either because the recent transactions
4

are not completely comparable to the subject house or because house prices in the aggregate have changed.

We use hedonic regression techniques to compute sales comparison values. According to the technique, the observed transaction price of a house is a function of an aggregate price level, the house's characteristics and an unexplained part, assumed to be random. In particular, we employ the following specification

CD

pt = 0t +

c1Tc(xct) + c2Tc(xct)2 + dxdt + t .

c=1 d=1

(1)

The dependent variable pt is the log price for a house transacted in period t. 0t captures the price level in period t. Tc(∑) is a Box-Cox type transformation function for the cth continuous characteristic. Examples of continuous characteristics xc are size of the lot, amount of floor space, and age of the building. c1 and c2 are the implicit prices for the respective--possibly transformed--characteristic. xd is an indicator for the dth discrete characteristic, which could be a location indicator

or the type of cellar. d is the implicit price of the discrete characteristic. t is a random noise term.

Fitting equation (1) to transaction data requires the choice of a specific transformation function Tc(∑) for each of the continuous characteristics. In principle, these transformations might depend on the sample period used to fit the model. To simplify our analysis, we choose the transformations based on the entire sample and use these transformations throughout. As a by-product of our hedonic regressions, we also obtain constant-quality house price indices, which we use later for forecasting the expected future house price level. We start with a regression using the data over the period 1980Q1-1991Q2 to obtain estimates of the price levels 0t. The second regression covers the period 1991Q2-1995Q1 and is used to make valuations based on information up to 1995Q1. The estimated coefficients of the price levels are used to construct the price index series from 1980Q1-1995Q1, which is used to forecast the future trend of the price level. The procedure continues by shifting the sample by one quarter and fitting a new regression. The last regression is for the period 2002Q3-2006Q2 and we fit 47 regressions in total. For further details on the hedonic regression model and, in particular, the choice of functional form, see Schulz and Werwatz (2004).

The individual long-term sales comparison value of a house transacted in t + h is

5

computed in two steps. In the first step, we use hedonic regression fitted with data up to quarter t to compute the market value of the subject house in the valuation period t. Since the dependent variable in our hedonic regression is measured in logs, a re-transformation of the computed value is necessary. The re-transformation also corrects for any potential bias by using an `optimal linear correction' factor (Theil, 1966, pp. 34). In the second step, we adjust the computed period t sales comparison value for the expected future price level over the forecast horizon h, see Section 3.1.
As stated above, the hedonic regression technique is only one of many possible ways of implementing the sales comparison approach. A great advantage of the hedonic regression technique is that it copes easily with large data sets and is suitable for mass appraisals (automated valuation). Once the regression is fitted, the value of a house--its expected price--is readily computed. The disadvantage of the hedonic regression technique is that it cannot take into account information that is not systematically recorded in the data set being used to fit the model. Such missing information is often of `soft' nature, i.e., hard to quantify exactly. Examples are the style of decoration or the appearance of the immediate neighborhood. A valuer visiting the subject house would take such soft factors into account when forming his appraisal. The results presented below on the performance of the sales comparison values might thus be seen as conservative, because the performance could be improved if soft factors were taken into account.
Cost approach: This approach uses the replacement cost of the subject house as valuation, i.e., the sum of building cost and land cost. In case where the building of the subject property is not new, building cost needs to be adjusted for depreciation. The cost value C for a property is given by
C = L + {1 - (a)}B ,
where L is land cost, B is the construction cost of a new building, and (a) is the depreciation due to age a. Obviously, (0) = 0 and (a) approaches 1 as age a becomes large. Both building cost and land cost are computed by our data provider for the transaction period t + h, for details see Section 2.2.
We compute the cost values in two steps. First, we discount the land cost of the subject house to the valuation period t by using a land cost index. This land cost index is derived from estimating a hedonic regression over the full sample period.
6

The land cost in period t is then adjusted for the expected future growth of land cost over the forecast horizon h by using a time series model fitted to the land cost index estimated with information up to period t. In the second step, the observed building cost in period t + h is discounted to the valuation period t by using the official construction cost index, see Section 3.1. The building cost is then adjusted for the expected future growth over the forecast horizon h by using a time series model fitted to the construction cost index up to period t. The building cost for the subject house is finally adjusted for depreciation accrued in period t + h. We employ the following depreciation function



(a) = 1 -

1 - a 0.65

with

98 l=

if a 66

l 98 + (a - 66) if a > 66 ,

(2)

where l is the conditional life span of a new building and a is the age of the building. A simpler version of this function was first introduced by Cannaday and Sunderman (1986). Observe that for a 66 the depreciation accelerates with age. Once a building has reached the age of 66, however, depreciation slows, reflecting superior quality of long-lived buildings.

The building cost adjusted for depreciation and the land cost are then added together to form replacement cost, i.e., the cost value C. If a valuation is for the short term, it might be advisable to further adjust C for current deviations of prices from cost. Such an adjustment is not necessary for long-term valuations, however, if prices and replacement cost realign quickly over time, as it is the case for the test market (Schulz and Werwatz, 2008).

2.2 Data
The data used in the study consists of transactions of single-family houses in Berlin between 1980Q1 and 2007Q2. Data are provided by Berlin's local real estate surveyor commission (Gutachterausschuss fu®r Grundstu®ckswerte, GAA) out of its transaction database (Automatisierte Kaufpreissammlung, AKS). This transaction database covers information on all real estate transactions in Berlin. All observations in our data set have information on the price, appraised land cost, and many different characteristics of the house. Only transactions from 2000Q1 onwards, however, have current information on new building cost. Between 2000Q1 and 2007Q2, we have
7

9088 observations, with at least 135, at most 628, and on average 303 transactions per quarter. Table 1 reports summary statistics for the main characteristics of the houses. Obviously, all the characteristics that a valuer would use for computing a sales comparison value are observed.
[Table 1 about here.]
The building cost in our data set were computed by GAA surveyors based on information gathered and published by the German government Bundesministerium fu®r Raumordnung, Bauwesen und St®adtebau (1997); Bundesministerium fu®r Verkehr, Bau- und Wohnungswesen (2001). The published information gives the average building cost for many different house specifications in Germany. The land cost in our data set are the value of land if the site of the subject house were undeveloped. GAA surveyors appraised these land cost using the sales comparison approach and their database of all land transactions.
3 Empirical results
3.1 Characterization of the test market
Figure 1 shows the trend of house price, land cost, and construction cost for a constant-quality single-family house in Berlin over the period 1980Q1 to 2007Q2. The index values are computed as
100 exp{0t - 0.5t2} ,
which corrects for small-sample bias (Kennedy, 1998, p. 37). 0t is the estimated coefficient of the period-t dummy variable in a hedonic regression with either house price or land cost as the dependent variable and t2 is the corresponding estimated robust variance of the coefficient estimator. The quarterly construction cost index is provided by the Statistical Office Berlin in its Statistical Report M I 4. It measures the change of the construction cost for a new single-family building.
[Figure 1 about here.]
8

The movement of prices for existing houses and the cost of constructing new houses are closely related. This is in line with economic reasoning because if house prices are above replacement cost (i.e., the sum of land cost and building cost) then it is profitable for developers to construct new houses. The additional supply will increase the housing stock and, given unchanged demand, dampen house price growth. Developers will provide additional supply until prices of existing houses are realigned with replacement cost and no extra profits can be made. In the case that house prices fall below replacement cost, developers will provide no new supply at all and the housing stock will shrink until equilibrium is reached again. This reasoning motivates the use of the cost approach for forecasting long-term house values, because even if prices and replacement cost deviate at the date of valuation, they ought to move closer to each other in the near future. If replacement cost is a better predictor of the future price of a home than any function of past prices, then this could put the cost approach at advantage even if the sales comparison approach has been found in previous studies to perform better with respect to short-term valuations.
[Table 2 about here.]
For the forecast experiment, all three series are treated as difference-stationary time series and ARMA models are fitted to their growth rates. Table 2 presents the ARMA specifications for the three different series, the volatility of the growth rates over the full sample and the respective regression fit. In the case of the two estimated constant-quality series we take the log indices directly from the hedonic regressions (instead of re-transforming the indices again). The regression constant ct of the specifications in Table 2 allows for a shift in the respective growth rate after the introduction of the European single market in 1993. The specifications have a parsimonious parametrization and the fitted models have uncorrelated residuals according to the standard tests for autocorrelation (Q-Statistic and LM test). To simplify the forecast experiment, we fit the same specifications to all sample periods, regardless of their length. In most cases the residuals of the specifications fitted over shorter sample periods rather than the full sample period are uncorrelated and all coefficients are statistically significant.
It follows from the specification for the house price growth rate in Table 2 that the house price index follows a random walk. If we were to assume that the required
9

return rate for a housing investment is constant and the unobserved imputed rent is proportional to the house price, then a random walk would indicate that prices are set in an informational efficient manner. Without the lagged MA terms, the land cost index would follow a random walk, too. It seems reasonable to attribute the moving average terms to the valuation process with which land cost are computed (appraisal smoothing). The growth of construction cost exhibits a strong seasonal component.
As is obvious from Figure 1, the construction cost series has a much smaller volatility than the other two series. Moreover, because of the strong seasonal component, the in-sample predictability of construction cost growth is higher than for the other two series as indicated by the R2s. Thus, it might be possible to forecast construction cost with greater accuracy. Compared to the price regression, the land cost regression provides a much better fit of the data, which might indicate that land cost can be forecasted more accurately as well, making a combination of construction cost and land cost superior to direct forecasting of the house price index.
Figure 2 compares two different price forecasts for the last five years of the full sample period with the full sample house price index. The first forecast is based on the house price specification fitted to the data up to 2002Q2. This is a forecast of the house price index itself and corresponds to the very idea of the sales comparison approach. The second forecast is based on a weighted average of the land and construction cost indices, both forecasted in 2002Q2 based on the information available at that time. We assume that building cost account for 55% of replacement cost while land cost account for the remaining 45%. Using the replacement cost index as a forecast of the future level of house prices corresponds to the very idea of cost approach.
[Figure 2 about here.]
Figure 2 reveals that both forecasts seem to perform well.
Although the house price index estimated with the data up to 2002Q2 and the index estimated with the full data sample show a very similar behavior before 2002Q3, they are not identical. This is the results of the rolling window estimation technique we apply. New information due to the extension of the estimation sample can influence the estimated index coefficients in preceding quarters. The difference of the
10

two house price indices in Figure 2 before 2002Q2 are not statistically significant, but the point estimates differ. The index revision problem is not specific to the constant-quality indices, but applies also to official indices like the construction cost index. Consequently, the forecaster often has to work with provisional time series and there is no solution to this problem.
There are two additional aspects that have to be considered. First, the full sample house price index itself might not be the best benchmark for assessing forecast accuracy. Second, and closely related, because the time series are normalized indices, the seemingly good forecasting behavior of the replacement cost in Figure 2 should not be misinterpreted: the near equality of the full sample house price index and the replacement cost index in period 2002Q2 might simply be the result of the arbitrary index normalization. House prices in that period might be larger than replacement cost, in which case forecasted long-term cost values will be below prices during the whole forecasting horizon. If, on the other hand, replacement cost are slightly above house prices in period 2002Q2, then the forecasted long-term cost values might be even closer to prices over the forecasting horizon than Figure 2 indicates.
Because of these possible estimation and normalization effects, a pure comparison of index series is no substitute for the evaluation of individual house-specific forecast errors. Only a direct comparison of valuations and transaction prices can reveal the accuracy of a valuation technique. The results of such a direct comparison are presented in the next section.

3.2 Horse race

To measure forecasting accuracy at the individual level we use the valuation error

defined as

et+h = log Pt+h - log Vt ,

where Pt+h is the observed transaction price of a house in period t + h and Vt is the valuation made for this house based on information in period t. We focus on the five

quarterly forecast horizons h  {4, 8, 12, 16, 20}, which correspond to 1, 2, 3, 4, and 5

years, respectively. We use log errors, because they treat over- and undervaluations

symmetrically. If the errors are small, then et+h is a close approximation of the error

relative to the valuation

Pt+h - Vt Vt

11

and -et+h is a close approximation of the valuation error relative to the price Vt - Pt+h . Pt+h

Clearly, a valuation technique is the better the smaller the valuation errors are on average and the less dispersed they are. To save on notation, we use Nh to denote the number of transactions for which we make valuations with a horizon of h and we use eh,n to denote the valuation error for house n. The mean error of a valuation technique for forecast horizon h is then

1 Nh

MEh

=

Nh

eh,n
n=1

,

i.e., the arithmetic average over all errors with the same forecast horizon h. The mean error does not take the dispersion of the errors into account. A valuation technique might have a small mean error while individual valuations are never on the mark but either far too large or far too small. The following two measures take the dispersion into account. The first is the mean absolute error

1 Nh

MAEh

=

Nh

|eh,n|
n=1

and the second is the mean squared error

MSEh

=

1 Nh

Nh
e2h,n
n=1

.

[Table 3 about here.]
Both measures are symmetric and give the same weight to positive and negative errors of equal absolute magnitude. In many situations where the economic loss due to under- or overvaluations is unknown, this might be a good compromise. A negative valuation error corresponds to a forecasted value above the realized transaction price. In the context of the mortgage underwriting process, such overestimation could lead to underwriting based on a false perception of collateral value in the case of default. Overestimation does not necessarily need to lead to an actual loss in the case of default, because the loss also depends on the outstanding loan balance. The
12

sale of the collateral may still be enough to cover borrower's outstanding liabilities. However, from a risk management perspective, it is desirable that loan underwriting is based on a correct assessment of the recovery value of the collateral. Moreover, the initial loan might be directly related to the collateral value and overestimation could lead to larger and more risky loans than are perceived during the underwriting process. A positive valuation error corresponds to a forecasted value below the realized price. In this case the collateral will always be sufficient to cover any outstanding loan balance. The economic loss due to underestimated collateral values stems from the fact that loan applications may get declined during the underwriting process. This is foregone business for the mortgage underwriter, because the true value of the collateral could have been more than sufficient to fulfill the underwriting criteria. Using the MSE and the MAE as accuracy measures thus corresponds to the assumption that the economic loss of over- and undervaluation is the same.
Table 3 presents the forecast evaluation measures for cost and sales comparison values and an equally-weighted combination of both. In addition to the measures already discussed above, Table 3 also reports the median valuation error and the percentage of observations for which the valuation lies within ±25% of the observed transaction price. The first two panels of Table 3 show that the sales comparison values perform better than the cost values for each of the five forecast horizons. Although the cost values have smaller mean errors than the sales comparison values for all but the five year horizon, the variation of these errors is larger, as the MSE and the MAE clearly indicate. Moreover, the percentage of valuations that lie within ±25% of the transaction price is larger for the sales comparison approach than for the cost approach.
One may object that the above comparison is based on a sample of transaction prices only and that transaction prices in general may deviate from unobserved market values, i.e., the expected price. It could be that cost values forecast market values perfectly well, but this goes undetected, because observed prices can and will deviate from market values. Diebold and Mariano (1995) proposed several tests for the comparison of different forecast methods that take such uncertainty into account. The test on the MSE uses the N = 9088 differences of the squared errors
eC2 ,h,n - e2S,h,n ,
where C stands for the cost valuation error and S for the sales comparison valuation
13

error, and tests if the difference is equal to zero on average (same MSE) or if the difference is at most as large as zero (cost values are at least as good as sales comparison values, possibly even better). The test on the MAE uses
|eC,h,n| - |eS,h,n| ,
but is otherwise identical to the test on the MSE. Applied to our data, we can reject the hypothesis that the cost values have a MSE at most as large as the sales comparison values at the 1% significance level, i.e., we reject MSEC MSES. We can reject the equivalent hypothesis for the MAE at the same level of significance, i.e., we reject MAEC MAES. Another important test is the Sign test, which counts the number of observations where the cost value is closer to the price than the respective sales comparison value, i.e., how often it is true that
|eC,h,n| |eS,h,n| .
If both valuation approaches were of equal accuracy, then the probability of one being better than the other would be 0.5. If we have N pairwise observations of valuation errors, then we expect under the assumption of equal accuracy that the cost values are better in 50% of the observations and the sales comparison values in the remaining 50%. For our data, however, the cost values are better for only 44.2% of the pairwise observations over all forecast horizons, whereas the sales comparison values are better for 55.8% of the observations. Given the total number of observations, N = 9088, these frequencies are unlikely to have been generated by valuation approaches with equal accuracy. We can reject the hypothesis that the cost values are at least as accurate as the sales comparison values for each of the forecast horizons at the 1% significance level.
Taking the first two panels of Table 3 and the test results together, we conclude that the sales comparison approach performs better than the cost approach based on the MSE and MAE criteria. The third panel of Table 3 shows that an equallyweighted average of both approaches delivers an even better performance than standalone sales comparison values. Other than equal weights for the two values are possible, which might enhance the performance even further. The performance results on the long-term valuation accuracy of sale comparison and cost values are thus identical to the results obtained in previous studies for valuations with a shortterm horizon.
14

Both the MSE and the MAE weigh positive and negative valuation errors symmetrically. In the context of mortgage underwriting, however, it is open to debate if the cost of foregone business due to underestimating the collateral value is the same as the cost of a loan that is collateralized with a property that has a much lower market value than indicated by the forecasted long-term valuation. One could therefore argue that positive valuation errors are less costly than negative valuation errors. The true economic loss function would be then asymmetric, putting more weight on negative valuation errors. The main problem with this reasoning is that the true economic loss function is unknown and might be complicated to establish. Because of this, Shiller and Weiss (1999) have proposed to investigate the asymmetry issue by looking at estimates of the distributions of the valuation errors.
Figures 3 and 4 show kernel density estimates for the valuation error distributions with a horizon of two and five years. We select the bandwidth according to Silverman's rule of thumb; asymptotic confidence bands are estimated at the 95% level, see Ha®rdle et al. (2004, Chapter 3).
[Figure 3 about here.]
The density estimates for the horizons of one, three, and four years are very similar in shape to the density for the two year horizon in Figure 3. It emerges from these density estimates that the valuation error distribution of the sales comparison values is quite symmetric around its mean error, which is -3.3%, but shifted to the right if an expected error of zero is taken as reference. The distribution of the valuation errors of the cost values, on the other hand, is less symmetric around its mean error of -0.3%. Furthermore, the cost values have a larger probability (51.3%) for producing non-negative errors than the sales comparison values (45.6%). Compared to the sales comparison values, it is more likely that a cost value underestimates the future price. Severe underestimations, where the valuation is only 20-40% of the transaction price, are much more likely to occur with cost values compared than with sales comparison values. This is shown by the dent in the density function on the right side. If underestimation leads to a lower economic loss than overestimation, then this might indicate an advantage of the cost approach. Without an explicitly specified asymmetric economic loss function, however, it is not possible to compute the magnitude of this possible advantage.
15

A different picture emerges for the distribution of the valuation errors at the five year forecast horizon. Both distributions are shifted to the left and only 35.6% of the cost values produce a positive valuation error compared to 38.5% of the sales comparison values. The dent in the density function for large underestimations of the transaction price is visible again.
[Figure 4 about here.]
Figures 3 and 4 are also useful to assess the effect of proportional deductions on valuation errors. Such deductions are required for the computation of mortgage lending values. Let  denote the proportional deduction, say 20%, then the resulting mortgage lending value is (1 - )V . The corresponding lending valuation error distribution would then simply correspond to the plotted valuation error distributions shifted to the right by approximately .
4 Conclusion
The direct comparison has shown that sales comparison values perform better than cost values if the economic loss function is symmetric. If both values are available, however, then an equally-weighted average of both cost and sales comparison values produces smaller losses on average than each of the values alone. Pooling the valuations is thus advisable and the cost value, although inferior to the sales comparison values in a direct comparison, still provides information for better valuations. If the loss function is asymmetric, penalizing overvaluations more than undervaluations, then it might be possible that cost values are better in a direct comparison than the sales comparison values. It is more likely for a cost value to underestimate the transaction price of a house than it is for a sales comparison value.
Without further knowledge on the proper economic loss function to be applied to valuation errors it is not possible to arrive at a final assessment. Further work needs to explore and incorporate a specific form of the economic loss function. Given the deductions required for the computation of mortgage lending values, it seems plausible that losses from overestimation are more problematic in practice than losses from underestimation.
16

A shortcoming of our study is that from the first quarter of 2000 onwards prices were steadily falling; only in the last quarter do prices seem to have gained some upward momentum. This may explain why the mean valuation errors are negative in all but one case. Moreover, our data are for only one region with a large number of comparable sales. The performance of the sales comparison approach might be worse in regions with less active markets. Future studies have to make use of longer time periods and should also extend the horizons over which forecasts are being made.
17

References
Bundesministerium fu®r Raumordnung, Bauwesen und St®adtebau (1997). Normalherstellungskosten 1995. NHK 95, Bonn.
Bundesministerium fu®r Verkehr, Bau- und Wohnungswesen (2001). Normalherstellungskosten 2000. NHK 2000, Berlin.
Cannaday, R. E. and Sunderman, M. A. (1986). Estimation of depreciation for single-family appraisals, AREUEA Journal 14: 255≠273.
Diebold, F. X. and Mariano, R. S. (1995). Comparing predictive accuracy, Journal of Business & Economic Statistics 13: 253≠263.
Dotzour, M. G. (1990). An empirical analysis of the reliability and precision of the cost approach in residential appraisal, Journal of Real Estate Research 5: 67≠74.
Ha®rdle, W., Mu®ller, M., Sperlich, S. and Werwatz, A. (2004). Nonparametric and Semiparametric Models, Springer Series in Statistics, Springer, Berlin, New York.
Kennedy, P. (1998). A Guide to Econometrics, fourth edn, Blackwell, Oxford. Schulz, R. and Werwatz, A. (2004). A state space model for Berlin house prices:
Estimation and economic interpretation, Journal of Real Estate Finance and Economics 28: 37≠57. Schulz, R. and Werwatz, A. (2008). House prices and replacement cost: A microlevel analysis, SFB 649 Discussion Paper 2008-013, Sonderforschungsbereich 649, Humboldt-Universit®at zu Berlin, Germany. Shiller, R. J. and Weiss, A. N. (1999). Evaluating real estate valuation systems, Journal of Real Estate Finance and Economics 18: 147≠161. Theil, H. (1966). Applied Economic Forecasting, North-Holland, Amsterdam. Assisted by G.A.C. Beerens and C.G. De Leeuw and C.B. Tilanus.
18

List of Figures
1 House price, land cost, and construction cost indices . . . . . . . . . 20 2 House price index and forecasts . . . . . . . . . . . . . . . . . . . . . 21 3 Valuation error distribution, two years horizon . . . . . . . . . . . . 22 4 Valuation error distribution, five years horizon . . . . . . . . . . . . 23
19

Price and Cost Indices

280 240 200 Construction 160 House
Land 120
80 80 82 84 86 88 90 92 94 96 98 00 02 04 06 Year
Figure 1: Constant-quality house price and land cost indices, and construction cost indices for single-family houses in Berlin, 1980Q1-2007Q2. Series are normalized to 100 in 1980Q1.
20

Price Index and Forecasts

200 190 180 170 160
Price Index
150
FS FC
140 98 99 00 01 02 03 04 05 06 Year
Figure 2: Full sample house price index and forecasts for the period 2002Q3-2007Q2 (right from vertical line) based on information up to 2002Q2. The sales comparison approach forecast (FS) is based on the time series model for the price index, the cost approach forecast (FC) is a weighted average of the forecasted land cost and construction cost indices.
21

2.0 Cost Sales comparison
1.6

1.2

Density

0.8

0.4

0.0 -1.2

-0.8 -0.4 0.0 0.4 Valuation error (horizon 2 years)

0.8

1.2

Figure 3: Kernel density estimates for the valuation error distributions of the cost and the sales comparison values. The forecast horizon is two years. The dashed lines are 95% confidence intervals.

22

2.0 Cost Sales comparison
1.6

1.2

Density

0.8

0.4

0.0 -1.2

-0.8 -0.4 0.0 0.4 Valuation error (horizon 5 years)

0.8

1.2

Figure 4: Kernel density estimates for the valuation error distributions of the cost and the sales comparison values. The forecast horizon is five years. The dashed lines are 95% confidence intervals.

23

List of Tables
1 Summary statistics for transacted houses 2000Q1 to 2007Q2 . . . . . 25 2 Fitted time series models . . . . . . . . . . . . . . . . . . . . . . . . 26 3 Performance of valuations . . . . . . . . . . . . . . . . . . . . . . . . 27
24

Table 1: Summary statistics for transacted single-family houses in Berlin between 2000Q1 to 2007Q2.

Panel A: Continuous Characteristics, Prices, and Cost

Mean Median Std. Dev. Units

Lot size

566.8 514.0

308.3

Floor space

147.7 137.0

53.3

Gross volume

657.2 599.0

253.1

Gross base

247.4 232.0

90.0

Year of construction 1961 1962

29.0

Price

228.7 198.5

14.0

Building cost

185.8 173.4

82.4

Land cost

120.7 91.1

117.2

Panel B: House Type

Detached

52.7% Semi-detached

End-row

16.9% Mid-row

Panel C: Location and Lake Side

Simple

32.1% Average

Good

18.9% Excellent

Lake side

0.9%

Sqm Sqm Cm Sqm Year (000) (000) (000)
22.2% 15.8%
46.5% 2.0%

Panel D: Number of Storeys and Attic

One Three

54.3% Two 2.1% Attic

43.6% 55.0%

Panel E: Cellar

Full

77.4% Part

11.6%

No 10.9%

Notes: 9088 observations. Gross base is the sum of all base areas in all storeys, gross volume is the corresponding volume. 4017 objects have information on the gross volume and 9063 on the gross base. Prices and cost are in year 2000 Euros. Building cost are cost of constructing a new building. Attic in Panel D means that the attic is upgraded for living.

25

Table 2: Time series model specifications fitted to the three different index series. Volatility and coefficient of determination are for the full sample fit with data from 1980Q1 to 2007Q2.

Variable y House price Land cost Construction cost

Model specification
 ln yt = ct + t  ln yt = ct + 2t-2 + 3t-3 + 4t-4 + t  ln yt = ct + 4 ln yt-4 + 3t-3 + t

 ln y 2.6 2.8 0.9

R2 13.2 44.1 50.6

Notes: The constant is ct = c0 + c1I1993Q2(t), where I1993Q2(t) is an indicator
function, which is 1 if t 1993Q2 and 0 otherwise. t is the residual. The estimated volatility  ln y and the coefficient of determination R2 are expressed in percent.

26

Table 3: Performance of sales comparison and cost values over different yearly forecast horizons. Summary statistics of valuation errors for transactions between 2000:1 to 2007:2.

Valuation approach Cost value Sales comparison value Combination

Horizon 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5

ME 0.9 -0.3 -2.2 -5.6 -11.4 -3.3 -3.3 -4.6 -6.6 -7.9 -1.9 -2.5 -4.1 -6.9 -10.6

MDE 1.8 0.8 -0.9 -4.3
-10.3 -2.3 -2.4 -4.3 -5.7 -7.3 -0.6 -1.4 -3.0 -5.8 -9.4

MSE 8.8 8.8 9.1 9.5 11.0 6.2 6.7 7.2 7.9 8.6 6.2 6.4 6.7 7.3 8.2

MAE 22.6 22.6 22.8 23.4 25.5 18.7 19.5 20.2 21.3 22.5 18.7 19.1 19.5 20.5 21.8

PE25 65.0 65.2 64.7 63.4 59.5 73.4 71.6 69.7 67.2 64.3 72.9 72.0 71.2 69.3 66.2

Notes: All reported measures are in percent. Number of observations is 9088 per valuation method and forecast horizon. ME is the mean error, MDE the median error, MSE the mean squared error, MAE the mean absolute error, and PE25 is the relative frequency of valuation errors within the ±25% range. Combination is an equally-weighted average of the cost and the sales comparison values.

27

SFB 649 Discussion Paper Series 2008

For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.

001 "Testing Monotonicity of Pricing Kernels" by Yuri Golubev, Wolfgang

H‰rdle and Roman Timonfeev, January 2008.

002 "Adaptive pointwise estimation in time-inhomogeneous time-series

models" by Pavel Cizek, Wolfgang H‰rdle and Vladimir Spokoiny,

January 2008.

003 "The Bayesian Additive Classification Tree Applied to Credit Risk

Modelling" by Junni L. Zhang and Wolfgang H‰rdle, January 2008.

004 "Independent Component Analysis Via Copula Techniques" by Ray-Bing

Chen, Meihui Guo, Wolfgang H‰rdle and Shih-Feng

Huang, January

2008.

005 "The Default Risk of Firms Examined with Smooth Support Vector

Machines" by Wolfgang H‰rdle, Yuh-Jye Lee, Dorothea Sch‰fer

and Yi-Ren Yeh, January 2008.

006 "Value-at-Risk and Expected Shortfall when there is long range

dependence" by Wolfgang H‰rdle and Julius Mungo, Januray 2008.

007 "A Consistent Nonparametric Test for Causality in Quantile" by

Kiho Jeong and Wolfgang H‰rdle, January 2008.

008 "Do Legal Standards Affect Ethical Concerns of Consumers?" by Dirk

Engelmann and Dorothea K¸bler, January 2008.

009 "Recursive Portfolio Selection with Decision Trees" by Anton Andriyashin,

Wolfgang H‰rdle and Roman Timofeev, January 2008.

010 "Do Public Banks have a Competitive Advantage?" by Astrid Matthey,

January 2008.

011 "Don't aim too high: the potential costs of high aspirations" by Astrid

Matthey and Nadja Dwenger, January 2008.

012 "Visualizing exploratory factor analysis models" by Sigbert Klinke and

Cornelia Wagner, January 2008.

013 "House Prices and Replacement Cost: A Micro-Level Analysis" by Rainer

Schulz and Axel Werwatz, January 2008.

014 "Support Vector Regression Based GARCH Model with Application to

Forecasting Volatility of Financial Returns" by Shiyi Chen, Kiho Jeong and

Wolfgang H‰rdle, January 2008.

015 "Structural Constant Conditional Correlation" by Enzo Weber, January

2008.

016 "Estimating Investment Equations in Imperfect Capital Markets" by Silke

H¸ttel, Oliver Muﬂhoff, Martin Odening and Nataliya Zinych, January

2008.

017 "Adaptive Forecasting of the EURIBOR Swap Term Structure" by Oliver

Blaskowitz and Helmut Herwatz, January 2008.

018 "Solving, Estimating and Selecting Nonlinear Dynamic Models without

the Curse of Dimensionality" by Viktor Winschel and Markus Kr‰tzig,

February 2008.

019 "The Accuracy of Long-term Real Estate Valuations" by Rainer Schulz,

Markus Staiber, Martin Wersing and Axel Werwatz, February 2008.

SFB 649, Spandauer Straﬂe 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

