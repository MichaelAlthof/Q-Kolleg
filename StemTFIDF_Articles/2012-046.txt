BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2012-046
A uniform central limit theorem and efficiency
for deconvolution estimators
Jakob Söhl* Mathias Trabs*
* Humboldt-Universität zu Berlin, Germany
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universität zu Berlin Spandauer Straße 1, D-10178 Berlin

A uniform central limit theorem and efficiency for deconvolution estimators

Jakob So¨hl

Mathias Trabs

Humboldt-Universita¨t zu Berlin

August 3, 2012

Abstract
We estimate linear functionals in the classical deconvolution problem by kernel estimators. We obtain a uniform central limit theorem with n­rate on the assumption that the smoothness of the functionals is larger than the ill­posedness of the problem, which is given by the polynomial decay rate of the characteristic function of the error. The limit distribution is a generalized Brownian bridge with a covariance structure that depends on the characteristic function of the error and on the functionals. The proposed estimators are optimal in the sense of semiparametric efficiency. The class of linear functionals is wide enough to incorporate the estimation of distribution functions. The proofs are based on smoothed empirical processes and mapping properties of the deconvolution operator.
Keywords: Deconvolution · Donsker theorem · Efficiency · Distribution function · Smoothed empirical processes · Fourier multiplier
MSC (2000): 62G05 · 60F05
JEL Classification: C14

1 Introduction

Our observations are given by n  N independent and identically distributed random variables

Yj = Xj + j, j = 1, . . . , n,

(1)

where Xj and j are independent of each other, the distribution of the errors j is supposed to be known and the aim is statistical inference on the distribution of Xj. Let us denote the densities of Xj and j by fX and f, respectively. We consider the case of ordinary smooth errors, which means that the characteristic function  of the errors j decays with polynomial
The authors thank Richard Nickl and Markus Reiß for helpful comments and discussions. The first author thanks the Statistical Laboratory in Cambridge for the hospitality during a stay in which part of the project was started. This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
E-mail address: soehl@math.hu-berlin.de E-mail address: trabs@math.hu-berlin.de

1

rate, determining the ill­posedness of the inverse problem. The contribution of this article to the well studied problem of deconvolution is twofold. First, we prove a uniform central limit theorem for kernel estimators of the distribution function of Xj in the setting of n convergence rates. More precisely, the theorem does not only include the estimation of the distribution function but covers translation classes of linear functionals of the density fX whenever the ill­posedness is smaller than the smoothness of the functionals. Second, we obtain more exact results than the minimax rates of convergence by showing that the used estimators are optimal in the sense of semiparametric efficiency.
The classical Donsker theorem plays a central role in statistics and states that the empirical distribution function of an independent, identically distributed sample converges uniformly to the distribution function. In the deconvolution model (1) our Donsker theorem states uniform convergence for an asymptotically unbiased estimator of translated function-
als t  t := (x - t)fX (x) dx, where the special case  := 1(-,0] leads to the estimation
of the distribution function. This generalization allows to consider functionals t as long as the smoothness of  in an L2­Sobolev sense compensates the ill­posedness of the problem. The limiting process G in the uniform central limit theorem is a generalized Brownian bridge, whose covariance depends on the functional  and through the deconvolution operator F -1[1/] also on the distribution of the errors. The used kernel estimators t are minimax optimal since they converge with a n­rate. So investigating optimality further leads naturally to the question whether the asymptotic variance of the estimators is minimal, as in the case of the empirical distribution function in the classical Donsker theorem. We prove that the estimator · is efficient in the sense of a Ha´jek­Le Cam convolution theorem. In particular, the asymptotic covariance matrices of the finite dimensional distributions achieve the Cram´er­Rao information bound. By uniform convergence and efficiency the kernel estimator of fX fulfills the `plug-in' property of Bickel and Ritov [2] in the deconvolution model (1).
The deconvolution problem has attracted much attention so we mention here only closely related works and refer the interested reader to the references therein. The classical works by Fan [11, 12] contain asymptotic normality of kernel density estimators as well as minimax convergence rates for estimating the density and the distribution function. Butucea and Comte [5] have treated the data­driven choice of the bandwidth for estimating functionals of fX but assumed some minimal smoothness and integrability conditions on the functional t, which
exclude, for example,  := 1(-,0] since it is not integrable. Dattner et al. [6] have studied
minimax­optimal and adaptive estimation of the distribution function. Asymptotic normality of estimators for the distribution function has been shown by van Es and Uh [31] in the case of supersmooth errors an by Hall and Lahiri [18] for ordinary smooth errors. In contrast we consider the estimation of general linear functionals and are interested in uniform convergence. Uniform results have been studied for the density but not for the distribution function by Bissantz et al. [3] and by Lounici and Nickl [21]. Recently, Nickl and Reiß [24] have proved a Donsker theorem for estimators of the distribution function of a L´evy measure. Their situation is related but more involved than ours, owing to the nonlinearity and the auto-deconvolution of the L´evy measure. In a deconvolution context we consider the more general problem of estimating linear functionals efficiently, which contains estimating of the distribution function as a special case and provides clear insight in the interplay between smoothness of  and the ill­posedness of the problem. While efficiency has been investigated in various semiparametric models, e.g., see Bickel et al. [1], to the best of the authors knowledge there are no results in this direction in the deconvolution framework. However, in the L´evy setting Nickl and Reiß [24] have shown heuristically that their estimator achieves the lower bound of the variance
2

while a rigorous proof remained open.

In order to show the uniform central limit theorem in the deconvolution problem, we prove that the empirical process n(Pn - P) is tight in the space of bounded functions acting on
the class
G := {F -1[1/(-·)]  t| t  R}, t := (· - t),

where

P

and

Pn

=

1 n

n j=1

Yj

denote

the

true

and

the

empirical

probability

measure

of

the

observations Yj, respectively. Since G may consist of translates of an unbounded function, this

is in general not a Donsker class. Nevertheless, Radulovi´c and Wegkamp [26] have observed

that a smoothed empirical processes might converge even when the unsmoothed process does

not. Gin´e and Nickl [14] have further developed these ideas and have shown uniform central

limit theorems for kernel density estimators. Nickl and Reiß [24] used smoothed empirical

processes in the inverse problem of estimating the distribution function of L´evy measures. In

order to show semiparametric efficiency in the deconvolution problem, the main problem is

to show that the efficient influence function is indeed an element of the tangent space. If the

regularity of  is small, the standard methods given in the monograph of Bickel et al. [1] do not

apply in this ill­posed problem. Instead, we approximate  by a sequence of smooth (n) and show the convergence of the information bounds. Interestingly, this reveals a relation between

the intrinsic metric of the limit G and the metric which is induced by the inverse Fisher information. Additionally to techniques of smoothed empirical processes and the calculus

of information bounds, our proofs rely on the Fourier multiplier property of the underlying deconvolution operator F -1[1/], which is related to pseudo-differential operators as noted in
the L´evy process setting by Nickl and Reiß [24] and in the deconvolution context by Schmidt­ Hieber et al. [27]. Important for our proofs are the mapping properties of F -1[1/] on Besov
spaces.

This paper is organized as follows: In Section 2 we formulate the Donsker theorem and

discuss its consequences. Efficiency is then considered in Section 3. All proofs are deferred to

Sections 4 and 5. In the Appendix we summarize definitions and properties of the function

spaces used in the paper.

2 Uniform central limit theorem

2.1 The estimator

According to the observation scheme (1), Yj are distributed with density fY = fX  f de-

termining the probability measure P. The characteristic function  of P can be estimated by

its

empirical

version

n(u)

=

1 n

n j=1

eiuYj

,

u



R.

For



to

be

specified

later

and

recalling

t = (· - t), our aim is to estimate functionals of the form

t := t, fX = t(x)fX (x) dx.

(2)

Defining the Fourier transform by F f (u) := eiuxf (x) dx, u  R, the natural estimator of
the functional t is given by

t :=

t(x) F -1

F

Kh

n 

(x) dx,

(3)

3

where K is a kernel, h > 0 the bandwidth and we have written as usual Kh(x) = h-1K(x/h).
Choosing F K = 1[-,] for some  > 0 leads to the estimator proposed by Butucea and
Comte [5]. Throughout, we suppose that
(i) K  L1(R)  L(R) is symmetric and band­limited with supp(F K)  [-1, 1],

(ii) for l = 1, . . . , L

K = 1, xlK(x) dx = 0, |xL+1K(x)| dx <  and

(4)

(iii) K  C1(R) satisfies, denoting x := (1 + x2)1/2,
|K(x)| + |K (x)| x -2.

(5)

Throughout, we write Ap Bp if there exists a constant C > 0 independent of the parameter p such that Ap CBp. If Ap Bp and Bp Ap, we write Ap  Bp. Examples of such kernels
can be obtained by taking F K to be a symmetric function in C(R) which is supported in
[-1, 1] and constant to one in a neighborhood of zero. The resulting kernels are called flat
top kernels and were used in deconvolution problems, for example, by Bissantz et al. [3].

2.2 Statement of the theorem

Given a function  specified later, our aim is to show a Donsker theorem for the estimator over
the class of translations t, t  R. In view of the classical Donsker theorem in a model without
additive errors, where no assumptions on the smoothness of the distribution are needed, we want to assume as less smoothness of fX as possible still guaranteeing n-rates. For some  > 0 the following assumptions on the density fX will be needed:

Assumption 1.

(i) Let fX be bounded and assume the moment condition |x|2+fX (x) dx < .

(ii) Assume fX  H(R) that is the density has Sobolev smoothness of order  0.
We refer to the appendix for an exact definition of the Sobolev space H(R). Boundedness
of the observation density fY follows immediately from (i) since fY  fX  f L1 < . In addition to the smoothness of fX , the smoothness of  will be crucial. We assume for s, c > 0

  Zs,c :=  =c + s s  Hs(R) is compactly supported as well

as x  c(x) - a(x)  Hc(R) for some  > 0 and

(6)

some a  C(R) such that a is compactly supported

and write for   Zs,c with a given decomposition  = s + c

 Zs,c :=

s Hs +

1 ix+1



c

(x)

Hc ,

which is finite since

1 ix+1



c

(x)

H c

is

bounded

by

a(x) ix+1

Hc +

1 (ix+1) x  Cs

x  (c(x) -

a(x)) Hc <  for any s > c. Several examples for  and corresponding s, c will be given

in Examples 1-3 below. In particular, 1(-,0]  Zs,c for s < 1/2. The ill­posedness of the

problem is determined by the decay of the characteristic function of the errors. More precisely,

we suppose

4

Assumption 2. Let the error distribution satisfy

(i) |x|2+f(x) dx <  thus  is twice continuously differentiable and
(ii) |(- 1) (u)| u -1 for some  > 0, in particular |-1(u)| u , u  R.
Throughout, we write -1 = 1/. The Assumption (ii) on the distribution of the errors is similar to the classical decay assumption by Fan [11] and it is fulfilled for many ordinary smooth error laws such as gamma or Laplace distributions as discussed below. Assumption 2(ii) implies that -1 is a Fourier multiplier on Besov spaces so that
Bps,q(R) f  F -1[- 1(-·) F f ]  Bps,-q(R)
for p, q  [1, ], s  R, is a continuous linear map, which is essential in our proofs, com-
pare Lemma 5. In the same spirit Schmidt­Hieber et al. [27] discuss the behavior of the deconvolution operator as pseudo­differential operator. We define

gt := F -1[- 1(-·)]  t and G = {gt|t  R}.

(7)

Note that in general gt may only exist in a distributional sense, but on Assumption 2 and for   Zs,c it can be rigorously interpreted by (see (19))

g0(x) = F -1[-1(-u) F s(u)](x)

+

(1

+

ix)

F

-1[- 1

(-u)

F

[

1 iy+1



c

(y)](u)](x)

+

F

-1[(- 1)

(-u)

F

[

1 iy+1



c(y)](u)](x),

which indicates why we have imposed an assumption on (- 1) and have defined · Zs,c as above.
It will turn out that G is P­pregaussian, but not Donsker in general. Denoting by  the
largest integer smaller or equal to  and defining convergence in law on (R) as Dudley [9,
p. 94], we state our main result

Theorem 1. Grant Assumptions 1 and 2 as well as   Zs,c with s > , c > (1/2)+s and  + 3s > 2 + 1. Furthermore, let the kernel K satisfy (4) with L =  + s . Let h2n+2sn  0 and if s  + 1/2 let in addition hn n   for some  > 4 - 4s + 2, then

 n(t

-

t)tR

-L

G

in (R)

as n  , where G is a centered Gaussian Borel random variable in (R) with covariance
function given by
s,t := gs(x)gt(x) P( dx) - st

for gs, gt defined in (7) and s, t  R.

We illustrate the range of this theorem by the following examples.
Example 1. We consider the indicator function 1(-,0](x), x  R. Let a be a monotone decreasing C(R) function, which is for some M > 0 equal to zero for all x M and equal to one for all x -M . We define s := 1(-,0] - a and c := a. From the bounded variation of s follows s  B11,(R)  Hs(R) for any s < 1/2 by Besov smoothness of

5

bounded variation functions (51) as well as by the Besov space embeddings (46) and (47).
Since a  C(R) and a is compactly supported, the condition on c is satisfied for any c > 0. Hence, 1(-,t]  Zs,c if s < 1/2. On the other hand, this cannot hold for s > 1/2 since Hs(R)  C0(R) by Sobolev's embedding theorem or by (45), (46) and (47). Owing to
the condition s > , Assumption 2 needs to be fulfilled for some  < 1/2 which is done, for
example, by the gamma distribution (, ) with   (0, 1/2) and   (0, ), that is

f(x)

:=

 , (x)

:=

1 ()

x -1 e-x/ 1[0,) (x),

x  R,

and (u) = (1 - iu)-, u  R.
Example 2. Let t(x) := ts(x) := max(K - |x - t|, 0) and tc(x) := 0 with K > 0. The payoff of the butterfly spread is described by such a function [13]. Then F (u) = 4 sin2(u/2)/u2 and
s  Hs(R) for any s < 3/2. So, Assumption 2 is required for some  < 3/2, which holds,
for example, for the chi­squared distribution with one or two degrees of freedom or for the
exponential distribution. 
Example 3. Butucea and Comte [5] studied the case  > 1 and derived n-rates for s >  in our notation. In particular, they considered supersmooth , that is F  decays exponentially.
In this case   Hs(R) for any s  N. Requiring the slightly stronger assumption that x  (x)  Hs(R) for some arbitrary small  > 0 and for all s  N we can choose c :=  and
s := 0. Then  can be taken arbitrary large such that all gamma distributions, the Laplace
distributions and convolutions of them can be chosen as error distributions.

2.3 Discussion
 To have n­rates we suppose s >  in Theorem 1, which means that the smoothness of the
functionals compensates the ill­posedness of the problem. This condition is natural in view
of the abstract analysis in terms of Hilbert scales by Goldenshluger and Pereverzev [17], who obtain the minimax rate n-(+s)/(2+2)  n-1/2 in our notation. As a consequence of the
condition on s and c we can bound the stochastic error term of the estimator t uniformly in h  (0, 1). The bias term is of order h+s.
For s >  + 1/2 the class G is a Donsker class. In this case the only condition on the bandwidth is that the bias tends faster than n-1/2 to zero. In the interesting but involved
case s  (,  + 1/2], the class G will in general not be a Donsker class. Estimating the distribution function as in Example 1 belongs to this case. In order to see that G is in general
not a Donsker class, let the error distribution be given by f = ,(-·) and  = , with   (s +1/2,  +1). Then gt equals -, t. For the shape parameter holds  -  (1/2, 1)
and thus gt is an L2(R)­function unbounded at t. The Lebesgue density of P is bounded by
Assumption 1(i). Hence, G consists of all translates of an unbounded function and thus cannot
be Donsker, cf. Theorem 7 by Nickl [22].
Therefore, for s  (,  + 1/2] smoothed empirical processes are necessary, especially
we need to ensure enough smoothing to be able to obtain a uniform central limit theorem. The bandwidth cannot tend too fast to zero, more precisely we require hn n   as n   for some  with  > 4 - 4s + 2. In combination with the bias condition hn2+2sn  0 as n   we obtain necessarily  + s > 2 - 2s + 1 leading to the assumption in the theorem. Since 2 + 2s >  + 2 - s + 1 > 4 - 4s + 2 we can always choose hn  n-1/(+2-s+1). In contrast to Butucea and Comte [5], Dattner et al. [6], Fan [12] our

6

choice of the bandwidth hn is not determined by the bias­variance trade­off, but rather by
the amount of smoothing necessary to obtain a uniform central limit theorem. The classical bandwidth hn  n-1/(2+2) is optimal for estimating the density in the sense that it achieves

the minimax rate with respect to the mean integrated squared error (MISE), compare Fan [12]

who assumes Ho¨lder smoothness of fX instead of L2­Sobolev smoothness. For this choice the bias condition hn2+2sn  0 is satisfied. If s  + 1/2 the classical bandwidth satisfies the

additional minimal smoothness condition in the case of estimating the distribution function

with mild conditions on fX . It suffices for example that fX is of bounded variation. Then 
and s can be chosen large enough in (0, 1/2) such that 2+2 > 4 -4s +2 and the classical
bandwidth satisfies the conditions of the theorem. Whenever the classical bandwidth hn  n-1/(2+2) satisfies the conditions of Theorem 1, then the corresponding density estimator is

a `plug­in' estimator in the sense of Bickel and Ritov [2] meaning that the density is estimated

rate optimal for the MISE, the functionals are estimated efficiently (see Section 3) and the
estimators of the functionals converge uniformly over t  R.

The smoothness condition on the density fX is then a consequence of the given choice of hn
together with the classical bias estimate for kernel estimators. As we have seen in Example 1
for estimating the distribution function we have  = 1(-,0]  Zs,c with s < 1/2 arbitrary
close to 1/2. In the classical Donsker theorem which corresponds to the case   0 the

condition  + 3s > 2 + 1 would simplify to  > -1/2. However, we suppose fX to be
bounded, which leads to much clearer proofs, and thus fX  H0(R) is automatically satisfied.

Assumption 1 allows to focus on the interplay between the functional  and the deconvolution
operator F -1[-1]. Nickl and Reiß [24] have studied the case of unbounded densities, which
is necessary in the L´evy process setup, but considered t = 1(-,t] only. The class Zs,c
is defined by L2­Sobolev conditions so that bounded variation arguments for  have to be

avoided in the proofs.

An interesting aspect is the following: If we restrict the uniform convergence to (t)tT

for

some

compact

set

T



R,

it

is

sufficient

to

assume

1 ix+1



c



H c (R)

instead

of

requiring

(1  |x| )(c(x) - a(x))  Hc(R) for some  > 0 and a function a  C(R) such that a is

compactly supported as done in Zs,c. In particular, slowly growing  would be allowed. The

stronger condition in the definition of Zs,c is only needed to ensure polynomial covering
numbers of {gt|t  T } for T  R unbounded (cf. Theorem 7 below).
As a corollary of Theorem 1 we can weaken Assumption 2(ii). If the characteristic function

of the errors  is given by ~ =  where  satisfies Assumption 2(ii) and there is a Schwartz
distribution   S (R) such that F  = -1 and     Zs,c for   Zs,c, then for t  R

F -1[~- 1]  (· - t) = F -1[- 1]  (  )(· - t)

and thus we can proceed as before. For instance, for translated errors f  µ with µ = 0, the distribution  would be given by -µ.
As for the classical Donsker theorem the Donsker theorem for deconvolution estimators has many different applications, the most obvious being the construction of confidence bands. Further Donsker theorems may be obtained by applying the functional delta method to Hadamard differentiable maps. Let us illustrate the construction of confidence bands. By the continuous mapping theorem we infer

stuRp

 n|t

-

t|

-L

stuRp

|G(t)|.

7

The construction of confidence bands reduces now to knowledge about the distribution of the
supremum of G. Suprema of Gaussian processes are well studied and information about their distribution can be either obtained from theoretical considerations as in van der Vaart and Wellner [30, App. A.2] or from Monte Carlo simulations. Let q1- be the (1 - )­quantile of
suptR |G(t)| that is P(suptR |G(t)| q1-) = 1 - . Then

lim P
n

t  [t - q1-n-1/2, t + q1-n-1/2] for all t  R

=1-

and thus the intervals [t - q1-n-1/2, t + q1-n-1/2] define a confidence band.

3 Efficiency
Having established the asymptotic normality of our estimator, the natural question is whether it is optimal in the sense of the convolution Theorem 5.2.1 by Bickel et al. [1]. Typically, efficiency is investigated for estimators Tn which are (locally) regular, that is for any parametric submodel   fX, and n1/2|n - | 1 the law of n1/2(Tn - , fX, ) under n converges for n   to a distribution independent of (n). In Lemma 9 we show that the estimator t from (3) is asymptotically linear with influence function x  F -1[-1(-·)]  (y)(x - P)( dy) and thus t is Gaussian regular.
In general, semiparametric lower bounds are constructed as the supremum of the information bounds over all regular parametric submodels. As it turns out, it suffices to apply the Cram´er­Rao bound to the least favorable one-dimensional submodel Pg of the form
fY,g = fX,g  f with fX,g := fX + g, for all   (-,  ),
with some  > 0 and a perturbation g satisfying

fX ±  g 0 and g = 0.

(8)

Note that all laws Pg are absolutely continuous with respect to P assuming supp(fX ) = R.
Moreover, the submodels are regular with score function gf/fY , since for all   (-,  )\{0} we have the L2­differentiability

fY,g - fY - g  f fY

2
fY = 0.

Similarly to van der Vaart [29, Chap. 25.5], we define the score operator Sg := (g  f)fY-1/2 and thus the information operator of fX is given by I := S S, where S denotes the adjoint
of the linear operator S. This yields the Fisher information in direction g

I g, g = Sg, Sg =

g  f fY

2
fY

(9)

and we obtain the information bound

I := sup
g

g,  2 Sg, Sg

,

(10)

8

where the supremum is taken over all g satisfying (8). In the notation of [1, Def. 3.3.2], we consider the tangent space Q := {(g  f)/fY |g satisfies (8)}, representing the submodel {Pg},
and the efficient influence function of the parameter  : Q  R, h  h,  needs to be
determined.
Since we perturb the density additively with the restriction (8), the quotient |g/fX | needs
to be bounded and thus it is natural to assume a lower bound for the decay behavior of fX .
We state with some  > 0 and M  N

Assumption 3. Let the following be satisfied
(i) fX is bounded and fulfills the moment condition |x|2+fX (x) dx < ,
(ii) fX  W12(R) that is fX has L1-Sobolev regularity two, (iii) fX (x) x -M for x  R.
A precise definition of the L1-Sobolev space W12(R) can be found in the appendix. Due to the Sobolev embedding W12(R)  H(R) with  < 3/2 (cf. (44) and (46)), Assumption 3
implies the Assumption 1 in the previous section. The conditions on  need to be strengthened, too.

Assumption 4. We suppose
(i) |x|2+f(x) dx < ,
(ii) for some   (0, ) \ Z and M from above let   C(  M)+1(R) satisfy for all
k = 0, . . . , (   M ) + 1

1{k=0} u --k |(k)(u)| u --k.

Since M + 1 2, easy calculus shows that Assumption 2(ii) on - 1 follows from As-
sumption 4 on . We supposed  / Z mainly to simplify our proofs. Let us first show an
information bound for smooth .
Theorem 2. Grant Assumptions 3 and 4 and let   S (R) be a Schwartz function. For any
regular estimator T of 0 = , fX with asymptotic variance 2 we obtain

2 F -1[-1(-·)]   2fY - 20.

(11)

In particular, the supremum in (10) is attained at g := g() := I-1  - , fX fX , where the inverses of S and I are given by
(S )-1 = (F -1[-1(-·)]  ) fY and I-1  = S-1(S-1)  = F -1[-1]  F -1[- 1(-·)]   fY .
Therefore, the score function corresponding to g() which is given by

F -1[-1(-·)]   - (F -1[-1(-·)]  )fY

(compare (37) below) is the efficient influence function and, moreover, equals the influence function of . This equality shows that the estimator is efficient for smooth functionals .

9

Moreover, we found already the efficient influence function in the larger tangent set of all
regular submodels. Unfortunately, less smooth  might be only in the domain of (S )-1 while I-1  is not
in L2(R) and thus the formal maximizer g() cannot be applied rigorously as the following
example shows.
Example 4. Let j be gamma distributed with density ,1 for   (1/4, 1/2) and consider
(x) = ex1(-,0](x) = 1,1(-x) which is contained in Zs,c for all s < 1/2 and c arbitrary
large. We obtain

(S )-1 = 1-,1(-·) fY and I-1  = F -1 (1 - iu)((1 + iu)-1+  ) .

While first term behaves nicely the Fourier transform of I-1  is of order |u|-1+2 > |u|-1/2
for |u|   and thus I-1  / L2(R).
Therefore, we choose an approximating sequence n   with (n)nN  S (R). For
n  N let gn := g(n) = I-1 n - , fX fX be the least favorable direction in the estimation problem with respect to fX , n . We obtain for every n  N

I

gn ,  2 Sgn , Sgn

=

gn ,  - n + gn , n Sgn , Sgn

2
.

This inequality suggests two possibilities to understand our strategy for obtaining the efficiency bound. First, the sequence (gn) approximates the formal maximizer g() and thus plugging gn into the bound (10) might converge to the supremum. Second, any unbiased estimator of n = fX , n is at the same time a possibly biased estimator of  with bias tending to zero. Therefore, the bound for the smooth problems should converge to the nonsmooth one.
The following lemma provides a sufficient condition for the convergence of the Cram´er­Rao
bounds.

Lemma 3. Let  and (n) satisfy (S )-1  L2(R) and n, I-1 n  L2(R) for all n  N.

Then n   and

gn , 2 Sgn ,Sgn



(S )-1, (S )-1

-

, fX 2 hold as n   if

(S )-1(n - ) L2  0, as n  .

Using mapping properties on Besov spaces, we will show that the underlying Fourier multiplier F -1[-1] and thus the inverse adjoint score operator (S )-1 are well-defined on the set Zs,c. This allows the extension of Theorem 2 to all   Zs,c with s >  and
c >  + 1/2.
Since t does not only estimate t pointwise but also as a process in (R), we want to
generalize Theorem 2 in this direction, too. In view of Theorem 25.48 of van der Vaart [29]
the remaining ingredient is the tightness of the limiting object, which is already a necessary
condition for the Donsker theorem. A regular estimator Tn of (t)tR in (R) is efficient if
the limiting distribution of n(Tn -) is a tight zero mean Gaussian process whose covariance
structure is given by the information bound for the finite dimensional distributions (cf. the
convolution Theorem 5.2.1 of [1]). Interestingly, the class of efficient influence functions for
t  R is not Donsker as discussed above and thus there exists no efficient estimator which is asymptotically linear in (R) [cf. 20, Thm. 18.8].

Theorem 4. Let Assumptions 3 and 4 be satisfied as well as   Zs,c with s >  and
c >  + 1/2. Then the estimator (t)tR defined in (3) is (uniformly) efficient.

10

Additionally, the proof of Theorem 4 reveals the relation between the intrinsic metric d(s, t)2 = E[(Gs - Gt)2] of the limit G, which is essential to show tightness, and the metric dI-1(s, t)2 = (S )-1(t - s), (S )-1(t - s) which is induced by the inverse Fisher information, namely
dI-1 (s, t)2 = d(s, t)2 + t - s, fX 2
(cf. equations (25) and (43) below) such that both metrics are equal up to some centering
term which is another way of interpreting the efficiency of ·.

4 Proof of the Donsker theorem

First, we provide an auxiliary lemma, which describes the properties of the deconvolution operator F -1[- 1]. Lemma 5. Grant Assumption 2.
(i) For all s  R, p, q  [1, ] the deconvolution operator F -1[-1(-·)] is a Fourier multiplier from Bps,q(R) to Bps,-q(R), that is the linear map
Bps,q(R)  Bps,-q(R), f  F -1[-1(-·) F f ]
is bounded.
(ii) For any integer m strictly larger then  we have F -1[(1 + iu)-m-1]  L1(R) and if m >  + 1/2 we also have F -1[(1 + iu)-m-1]  L2(R).
(iii) Let + >  and f, g  H+(R). Then

F -1[-1]  f g =

F -1[- 1(-·)]  g f.

(12)

Using the kernel K, this equality extends to functions g  L2(R)  L(R) and finite
Borel measures µ:

F -1[-1 F Kh]  µ g = F -1[- 1(-·) F Kh]  g dµ.

(13)

Proof.
(i) Analogously to [24], we deduce from Corollary 4.11 of [16] that (1 + iu)-- 1(-u) is a
Fourier multiplier on Bps,q by Assumption 2(ii). It remains to note that j : Bps,q(R)  Bps,-q(R), f  F -1[(1 + iu) F f ] is a linear isomorphism [28, Thm. 2.3.8].
(ii) Since the gamma density 1,1 is of bounded variation, it is contained in B11,(R) by (51). Using the isomorphism j from (i), we deduce m,1  B1m,(R) and thus by Besov
embeddings (47) and (44)
F -1[(1 + iu)-m- 1]  B1m,-(R)  B10,1(R)  L1(R).
If m -  > 1/2 we can apply the embedding B1m,-(R)  B2m,--1/2(R)  L2(R).

11

(iii) For f  H+(R) (i) and the Besov embeddings (44), (46) and (47) yield

F -1[- 1]  f L2

F -1[- 1]  f B20,1

f B2,1

f H+ < .

Therefore, it follows by Plancherel's equality

F -1[- 1]  f

(x)g(x) dx =

1 2

- 1(-u) F f (-u) F g(u) du

= F -1[-1(-·)]  g (x)f (x) dx.

To prove the second part of the claim for g  L2(R), we note that by Young's inequality

F -1[-1 F Kh] L2

F -1[- 11[-1/h,1/h]] L2 Kh L1 < 

due to the support of F K and Assumption (5) on the decay of K. Since µ is a finite measure and g is bounded, Fubini's theorem yields then

g(x) F -1[-1 F Kh]  µ (x) dx = g(x) F -1[- 1 F Kh](x - y)µ( dy) dx = F -1[- 1(-·) F Kh]  g (y)µ( dy),

where we have used the symmetry of the kernel. In order to apply Fubini's theorem for
the case g  L(R), too, we have to show that F -1[- 1 F Kh] L1 is finite. We replace the indicator function by a function   C(R) which equals one on [-1/h, 1/h] and
has got compact support. We estimate

F -1[-1 F Kh] L1

F -1[-1] L1 Kh L1 .

(14)

Using -1 is twice continuously differentiable and has got compact support we obtain

(1 + x2) F -1[- 1](x) 

F -1[(Id - D2)-1](x)  (Id - D2)-1 L1 < ,

where we denote the identity and the differential operator by Id and D, respectively. This shows that (14) is finite.

4.1 Convergence of the finite dimensional distributions
As usual, we decompose the error into a stochastic error term and a bias term:

t - t = t - E[t] + E[t] - t

=

t(x) F -1

F

Kh

n - 



(x) dx +

t(x)(Kh  fX (x) - fX (x)) dx.

12

4.1.1 The bias

The bias term can be estimated by the standard kernel estimator argument. Let us consider the singular and the continuous part of  separately. Applying Plancherel's identity and H¨older's inequality, we obtain

|ts(x)(Kh  fX (x) - fX (x))| dx

1 =
2

| F ts(u)(F K(hu) - 1) F fX (-u)| du

u -(+s)(F K(hu) - 1)  u +s | F s(u) F fX (u)| du

h+s u-(+s)(F K(u) - 1)  s Hs fX H

The term u-(+s)(F K(u) - 1)  is finite using the a Taylor expansion of F K around 0 with (F K)(l) = 0 for l = 1, . . . ,  + s by the order of the kernel (4).
For the smooth part of t Plancherel's identity yields

|tc(x)(Kh  fX - fX )(x)| dx

=1 2

|

F

[

1 ix+1

tc(x)](Id

+

D){(F

K (hu)

-

1)

F

fX

(-u)}|

du

|

F

[

1 ix+1

tc(x)](F

K (hu)

-

1

+

h

F

[ixK ](hu))

F

fX

(-u)|

du

-

|

F

[

1 ix+1

tc

(x)](F

K

(hu)

-

1)

F

[ixfX

](-u)|

du.

The first term can be estimated as before and for the second term we note that xfX (x) 

L2(R)

=

H 0 (R)

by

Assumption

1(i)

such

that

the

additional

smoothness

of

1 ix+1



c

(x)

yields

the right order. Therefore, we have | E[t] - t| h+s and thus by the choice of h, the bias

term is of order o(n-1/2).

4.1.2 The stochastic error

We notice that c - a Hc

x - Cs x  (c(x) - a(x)) Hc <  for any s > c, where

we used the pointwise multiplier property (48) as well as the Besov embeddings (47) and (45).

We have s  L2 and by (44), (46) and (47)

c  a  + c - a  a  + c - a Hc < ,

since c > 1/2. Consequently we can apply the smoothed adjoint equality (13) and obtain for the stochastic error term

t(x) F -1

F

Kh

n - 



(x) dx

= F -1[- 1(-·) F Kh]  t(x)(Pn - P)( dx).

(15)

Therefore, it suffices for the convergence of the finite dimensional distributions to bound the

term

sup
h(0,1)

F -1[-1(-·) F Kh]  (x) 2+ P( dx),

(16)

13

for any function   Zs,c. Then the stochastic error term converges in distribution to a normal random variable by the central limit theorem under the Lyapunov condition [i.e., 19, Thm. 15.43 together with Lem. 15.41]. Finally, the Cram´er-Wold device yields the convergence of the finite dimensional distributions in Theorem 1.
First, note that the moment conditions in Assumptions 1 and 2 and the estimate

|x|pfY (x)

|x - y + y|pfX (x - y)f(y) dy (|y|pfX )  f + fX  (|y|pf),

for x  R, p 1, yield finite (2 + )th moments for P since

|x|2+fY (x) dx |x|2+fX L1 f L1 + fX L1 |x|2+f L1 < .

(17)

To estimate (16), we rewrite

F -1[-1(-·)]  c(x) = F -1

-1

(-u)(Id

+

D)

F

[

1 iy+1



c(y)](u)

(x)

= F -1

-1

(-u)

F

[

1 iy+1



c

(y)](u)

(x)

+ F -1

-1(-u)

F

[

1 iy+1



c(y)]

(u) (x)

=

(1

+

ix)

F

-1[- 1(-u)

F

[

1 iy+1

 c (y)](u)](x)

+

F

-1

[(- 1)

(-u)

F

[

1 iy+1



c(y)](u)](x),

(18)

owing to the product rule for differentiation. Hence,

F -1[- 1(-·)]  (x) = F -1[- 1(-u) F s(u)](x)

+

(1

+

ix)

F

-1

[- 1

(-u)

F

[

1 iy+1



c

(y)](u)](x)

+

F

-1

[(- 1)

(-u)

F

[

1 iy+1



c(y)](u)](x).

(19)

While F -1[- 1(-·)] may exist only in distributional sense in general, it is defined rigorously through the right-hand side of the above display for   Zs,c. Considering   Kh instead of
, we estimate separately all three terms in the following. The continuity and linearity of the Fourier multiplier F -1[-1(-·)], which was shown in
Lemma 5(i), yield for the first term in (19)

F -1[-1(-u) F s(u) F Kh(u)] H =

F -1 -1(-·) F [s  Kh]

 s  Kh B2,+2 

 s H+ ,

B2,2

where the last inequality holds by F Kh  K L1. Using the boundedness of fY and the
continuous Sobolev embedding H/4(R)  L2+(R) by (44), (47) and (46), we obtain

F -1[-1(-u) F s(u) F Kh(u)] L2+(P) F -1[- 1(-u) F s(u) F Kh(u)] L2+ F -1[- 1(-u) F s(u) F Kh(u)] H  s H+

(20)

14

To estimate the second term in (19), we use the Cauchy­Schwarz inequality and Assumption 2(ii):

F

-1[-1(-u)

F[

1 ix+1

 c (x)](u)

F

Kh(u)]



- 1(-u)

F

[

1 ix+1

c]

F

Kh(u)

L1

u -1/2---1(-u) L2

u

1/2++

F

[

1 ix+1

 c (x)]

L2

1 ix+1



c(x)

.H 1/2+ +

Thus (1 + x2)(2+)/2fY (x) dx <  from (17) yields

(1

+

ix)

F

-1[- 1(-u)

F[

1 iy+1

 c (y)](u)

F

Kh(u)](x)

L2+ (P)

1 ix+1



c(x)

.H 1/2++

(21)

The last term in the decomposition (19) can be estimated similarly using the Cauchy­Schwarz inequality and Assumption 2(ii) for (-1)

F

-1[(-1)

(-u)

F

[

1 ix+1

 c (x)](u)

F

Kh(u)]

L2+ (P)

(- 1)

(-u)

F[

1 ix+1

 c (x)](u)

L1

u 1/2--(-1) L2

u

-1/2++

F

-1[

1 ix+1



c(x)](u)

L2

1 ix+1



c(x)

.H -1/2+ +

Combining (20), (21) and (22), we obtain

(22)

sup F -1[- 1(-·) F Kh]  (x) L2+(P)
h(0,1)

 ,Z+,1/2++

(23)

which is finite for  small enough satisfying  +  s and 1/2 +  +  c. Since F Kh converges pointwise to one and | F -1[-1(-·) F Kh]  (x)|2 is uniformly integrable by the bound of the 2 +  moments, the variance converges to

F -1[- 1(-·)]  (x) 2 P( dx).

4.2 Tightness

Motivated by the representation (15) of the stochastic error, we introduce the empirical process

 n(t) := n

F -1[- 1(-·) F Kh]  t(x)(Pn - P)( dx),

t  R.

(24)

In order to show tightness of the empirical process, we first show some properties of the class
of translations H := {t|t  R} for   Zs,c.
Lemma 6. For   Zs,c the following is satisfied:
(i) The decomposition t = tc + ts satisfies the conditions in the definition of Zs,c with
Rat. We have supt t Zs,c < .

15

(ii) For any   (0, s) there is a  > 0 such that t - s Zs-,c- |t - s| holds for all
s, t  R with |t - s| 1

Proof.

(i) Since

ts

2 H s

=

u 2s |eitu F s(u)|2 du =

s

2 H

s

,

both claims hold for the singular

part. Applying the pointwise multiplier property of Besov spaces (48) as well as the

Besov embeddings (47) and (45), we obtain for some M > c and a  C(R) as in

definition (6)

x  tc(x) - at(x) Hc =

x x-t 
x x-t 

CM CM

x - t  tc(x) - at(x) Hc x  c(x) - a(x) Hc ,

which is finite for all t  R since x  x - t -  CM (R). For the second claim we
estimate similarly

Rsup
t

1 ix+1

tc(x)

H c

R Rsup
t

at(x) ix+1

Hc +

1 ix+1

CM sup
t

tc - at

H c

1 ix+1

H c

a

CM +

1 ix+1

CM

c - a

Hc < .

(ii) For the singular part note that
ts - ss Hs- u s F s(u) L2 u -(1 - ei(t-s)u) 
Ru - L( \(-|t-s|-1/2,|t-s|-1/2))
 (1 - ei(t-s)u) L((-|t-s|-1/2,|t-s|-1/2)) |t - s|/2  |t - s|1/2.
For c we have

1 ix+1

(tc(x)

-

sc(x))

H c -

1 ix+1

tc(x)

-

1 ix+1

tc(x)

 s-t Hc-

+

1 i(x-s+t)+1

sc

(x)

-

1 ix+1

sc(x)

.
H c -

The first term can be treated analogously to s. Using some integer M  N strictly
larger than c, the second term can be estimated by

1 i(x-s+t)+1

sc(x)

-

1 ix+1

sc(x)

H c -

|t - s|

1 i(x-s+t)+1

1 ix+1

sc

(x)

H c -

|t - s|

1 i(x-s+t)+1

CM

1 ix+1

sc

(x)

H c -

|t - s|,

where we used again pointwise multiplier (48), embedding properties of Besov spaces (47) and (45) as well as (i).

16

4.2.1 Pregaussian limit process

Let G be the stochastic process from Theorem 1. It induces the intrinsic covariance metric d(s, t) := E[(Gs - Gt)2]1/2.
Theorem 7. There exists a version of G with uniformly d-continuous sample paths almost
surely and with suptR |Gt| <  almost surely.
The proof of the theorem shows in addition that R is totally bounded with respect to d.
The boundedness of the sample paths follows from the totally bounded index set and the uniform continuity. Further we conclude that G defined in (7) is P­pregaussian by van der
Vaart and Wellner [30, p. 89]. Thus G is a tight Borel random variable in (R) and the law
of G is uniquely defined through the covariance structure and the sample path properties in the theorem [30, Lem. 1.5.3].

Proof. To show that the class is pregaussian, it suffices to verify polynomial covering numbers. To that end we deduce that

d(s, t) =

gt - gs

2 L2(P)

-

t - s, fX

2

1/2

gt - gs L2(P)

(25)

decreases polynomial for |t - s|  0, for max(s, t)   and for min(s, t)  . Using the same estimates which show the moment bound (23) but replacing F Kh = 1, we obtain

F [- 1(-·)]   L2(P)

 Z+,1/2++

(26)

and thus by choosing  and  small enough Lemma 6 yields d(s, t)  - t s Z+,1/2++ |t - s| . We now turn to the estimation of the tails. We will only consider the case s, t N

since the case s, t N can be treated in the same way. Without loss of generality, let s < t.

For the smooth component of  we have to show that

1 ix+1

(tc(x)

-

sc(x))

H c

with

t, s

N decays polynomially in N . It suffices to prove

1 ix+1

(tc

-

at)(x)

H c

and

1 ix+1

(at

-

as)(x) Hc with a  C(R) from definition (6) of Zs,c both decay polynomially in N . Let

M

>

c

and





CM (R)

with

(x)

=

1

for

x



R

\[-

1 2

,

1 2

]

and

(x)

=

0

for

x



[-

1 4

,

1 4

].

The

pointwise multiplier property (48) yields

1 ix+1

(tc

-

at)(x)

H c

=

(x/N ) + (1 - (x/N ))

1 ix+it+1

( c

-

a)(x)

H c

1 ix+it+1

CM

(x/N )(c - a)(x)

Hc +

1-(x/N ) ix+it+1

CM

c - a Hc

x - (x/N ) CM x  (c - a)(x) Hc + N -1 c - a Hc

N -( 1)

and for N large enough such that supp(a )  [-N/2, N/2] we obtain

1 ix+1

(at

-

as)(x)

H c

=

(x/N ) ix+1

(at

-

as)(x)

H c

(x/N ) ix+1

H c

(at - as)(x)

CM

(ix + 1)-3/4 Hc (x/N )(ix + 1)-1/4 CM N -1/4.

To bound the singular part it suffices to show that

F -1[-1(-·)]  ts L2(P) ,

t N,

17

decays polynomially in N . To this end, we split the integral domain into

-N/2

F -1[-1(-·)]  ts

2 L2(P)

=

-

| F -1[-1(-·) F s](x)|2fY (x + t) dx



+ | F -1[-1(-·) F s](x)|2fY (x + t) dx.

-N/2

(27)

To estimate the first term, we use the following auxiliary calculations

ix F -1[- 1(-·) F s](x) = - F -1[(-1) (-·) F s](x) + F -1[- 1(-·) F [iys(y)]](x)
and with an integer M  N strictly larger than s and a function   CM (R) which is equal
to one on supp(s) and has compact support

ys(y) Hs = y(y)s(y) Hs

y(y) Bs,2 s(y) Hs y(y) CM < ,

where we used the pointwise multiplier property (48) of Besov spaces as well as the Besov
embeddings (47) and (45). Thus ix F -1[- 1(-·) F s](x)  L2(R). Applying this and the
boundedness of fY to the first term in (27) yields

-N/2
| F -1[-1(-·) F s](x)|2fY (x + t) dx
-

-N/2
| F -1[-1(-·) F s](x)|2 dx

-

-N/2

4N -2

|x F -1[-1(-·) F s](x)|2 dx

-

N -2.

Using Ho¨lders's inequality and the boundedness of fY , we estimate the second term in (27) by

F -1[-1(-·) F s](x)

2 L2+

 /(2+)
|fY (x + t)|(2+)/ dx
-N/2

F -1[-1(-·) F s](x)

2 L2+

 /(2+)

fY (x) dx
N/2

.

While the first factor is finite according to our bound (20), which also holds when F Kh is omitted, the second one is of order N - due to the finite (2 + )th moment of P. Therefore,
the second term in (27) decays polynomially.

4.2.2 Uniform central limit theorem We recall the definition of the empirical process n in (24).

18

Theorem 8. Grant Assumptions 1 and 2. Let
(n(t1), . . . , n(tk)) -L (Gt1, . . . , Gtk )
for all t1, . . . , tk  R and for all k  N. If either s  + 1/2 and hnn1/4   as n  
for some  >  - s + 1/2 or if s >  + 1/2, then
n -L G in (R).
Proof. We split the empirical process n into three parts 
n = n (T1(x) + T2(x) + T3(x))(Pn - P)( dx),

where T1, T2 and T3 correspond to the three terms in decomposition (19) and are given by (28), (29) and (30) below. For the first term

T1(x) = F -1[-1(-u) F ts(u) F Kh(u)](x)

(28)

we distinguish the two cases s >  + 1/2 and s  + 1/2. In the first case we will show that T1 varies in a fixed Donsker class. In the second case the process indexed by T1 is critical, this is where smoothed empirical processes and the condition on the bandwidth are
needed. Tightness of T1 in this case will be shown in Section 4.2.3. We will further show that the second term T2 and the third term T3 are both varying in fixed Donsker classes for all s > . In particular the three processes indexed by T1, T2 and T3, respectively, are tight. Applying the equicontinuity characterization of tightness [30, Thm. 1.5.7] with the maximum
of the semimetrics yields that n is tight. Since we have assumed convergence of the finite dimensional distribution the convergence of n in distribution follows [30, Thm. 1.5.4].
Here we consider only the first case s >  + 1/2. We recall that ts is contained in
Hs(R). By the Fourier multiplier property of the deconvolution operator in Lemma 5(i)
and by suph>0,u | F Kh(u)| K L1 <  the functions T1 are contained in a bounded set
of H1/2+(R) for some  > 0 small enough. We apply [23, Prop. 1] with p = q = 2 and
s = 1/2 +  and conclude that T1 varies in a universal Donsker class. The second term is of the form

T2(x)

=

(1

+

ix)

F

-1[- 1(-u)

F

[

1 iy+1

tc(y)](u)

F

Kh(u)](x).

(29)

By Assumption 2(ii) we have -1(u) u . For some  > 0 sufficiently small, the functions

1 iy+1

tc(y),

t



R,

are

contained

in

a

bounded

set

of

H ++1/2 (R)

by

Lemma

6.

We

obtain

that the functions T2(x)/(1+ix) are contained in a bounded subset of H1/2+(R). Corollary 5

in [23] yields with p = q = 2,  = -1, s = 1/2 +  and  =  that T2 is contained in a fixed

P-Donsker class.

Similarly, we treat the third term

T3(x)

=

F -1[(-1)

(-u)

F

[

1 iy+1

tc(y)](u)

F

Kh(u)](x).

(30)

By Assumption 2(ii) we have (- 1) u -1. As above we conclude that the functions T3
are contained in a bounded set of H+3/2(R). By [23, Prop. 1] with p = q = 2 and s =  + 3/2
the term T3 varies in a universal Donsker class.

19

4.2.3 The critical term

In this section, we treat the first term T1 in the case s  + 1/2. We define qt := F -1[- 1(-u) F ts(u)].

(31)

For simplicity in point (e) below it will be convenient to work with functions Kh of bounded support. Thus we fix  > 0 and define the truncated kernel

Kh(0) := Kh1[-,].

By the Assumption (5) on the decay of K we have suph>0 Kh - Kh(0) BV < . We conclude F (Kh - Kh(0))(u) (1 + |u|)-1 with a constant independent of h > 0. By Assumption 2(ii)
we have |- 1(u)| (1 + |u|). The functions ts(u), t  R, are contained in a bounded set of Hs(R). Consequently T1 with Kh - Kh(0) instead of Kh is contained in a bounded set of Hs-+1(R). With the same argument as used for T3 we see that this term is contained in a
universal Donsker class because s -  + 1 > 1 by assumption. So it remains to consider T1 with the truncated kernel Kh(0).
In order to show tightness of the process indexed by T1 with the truncated kernel Kh(0) we check the assumptions of Theorem 3 by Gin´e and Nickl [14] in the version of Nickl and
Reiß [24, Thm. 12] for the class Q = {qt|t  R} and for µn( dx) := Kh(0n)(x) dx, where qt(x)
was defined in (31). By Section 4.2.1 the class G is P-pregaussian. From the proof also follows that Q is P-pregaussian since this is just the case c = 0.
We write
Q := r - q r, q  Q, r - q L2(P)  .
Let  >  - s + 1/2 0 be such that hn n1/4  . We fix some   ( - s + 1/2,   1) and obtain hn log(n)-1/2n1/4  . We need to verify the following conditions.

(a) We will show that the functions in Q~n := {qt  µn|t  R} are bounded by Mn := Ch-n 
for some constant C > 0. Since qt is only a translation of q0 it suffices to consider q0. By the definition of Zs,c in (6), by Lemma 5(i) and by the Besov embedding (47)

q0 = F -1[- 1(-u) F s(u)]  B2,s2-(R)  B21,/2- (R).

By our assumptions on the kernel (5) it follows that K is integrable and thus that K is
of bounded variation. Next we apply continuous embeddings for Besov spaces (44) and
(46), (49) as well as the estimate for Khn B1,1 in Gin´e and Nickl [14, p. 384], which also applies to truncated kernels, and obtain

q0  Kh(0n) 

q0  Kh(0n) B0 ,1

q0  Kh(0n) B21,/12

Kh(0n) B1,1

h-n  .

(32)

(b) For r  Q holds r  Kh(0) L2(P) r  Kh(0) - r L2(P) +  . Thus it suffices to show that q  Kh(0) - q L2(P)  0 uniformly over q  Q. We estimate

qt  Kh(0) - qt L2(P)

-1(-·) F s(F Kh(0) - 1) L2 .

-1(-·) F s is an L2­function and F Kh(0) is uniformly bounded and converges to one as h  0. By dominated convergence the integral converges to zero.

20

(c) The estimates in (a) can be used to see that the classes Q~n have polynomial L2(Q)­
covering numbers, uniformly in all probability measures Q and uniformly in n. The function q0Kh(0n) is the convolution of two L2-functions and thus continuous. The estimate (32) and embedding (50) yield that q0  Kh(0n) is of finite 2­variation. We argue as in Lemma 1 by Gin´e and Nickl [15]. As function of bounded 2­variation q0  Kh(0n) can be written as a composition gn  fn of a nondecreasing function fn and a function gn, which satisfies a H¨older condition |gn(u) - gn(v)| |u - v|1/2, see, for example, [8, p. 1971]. More precisely, we can take fn(x) to be the 2­variation of q0  Kh(0n) up to x and the envelopes of fn to be multiples of Mn2 = C2h-n 2 . The set Fn of all translates of the nondecreasing function fn has VC­index 2 and thus polynomial L1(Q)­covering numbers [7, Thm. 5.1.15]. Since each 2­covering of translates of fn for L1(Q) induces an ­covering of translates of gn fn for L2(Q) we can estimate the covering numbers by
N (Q~n, L2(Q), ) N (Fn, L1(Q), 2) (Mn/ )4,

with constants independent of n and Q. The conditions for inequality (22) by Gin´e and Nickl [14] are fulfilled, where the envelopes are Mn = Chn- and Hn() = H() =
C1 log() + C0 with C0, C1 > 0. Consequently

E as n  .

1 n

n

jf (Xj)

j=1

(Q~ n )n-1/4

max

log(n) n1/4

,

hn- n

log(n)

0

(d) We apply Lemma 1 of [14] to show that

n 1Q~n =
n1

x  R qt(x - y)Kh(0n)(y) dy t  R

is in the L2(P)-closure of K L1-times the symmetric convex hull of the pregaussian class
Q. The condition qt(· - y)  L2(P) is satisfied for all y  R since qt  L2(R) and fY is bounded. qt(x - ·)  L1(|µn|) is fulfilled owing to Kh(0n), qt  L2(R). The third
condition that y  qt(· - y) L2(P) is in L1(|µn|) holds likewise since fY is bounded and
Kh(0n)  L1(R).
(e) The L2(P)­distance of two functions in Q~n can be estimated by

E (qt  Kh(0)(X) - qs  Kh(0)(X))2 1/2

= qt(· - u)Kh(0)(u) - qs(· - u)Kh(0)(u) du
L2(P)
|Kh(0)(u)| qt(· - u) - qs(· - u) L2(P) du

Kh(0) L1 sup qt(· - u) - qs(· - u) L2(P)
|u| 
= Kh(0) L1 sup qt+u - qs+u L2(P).
|u| 

21

As seen in the proof that Q is pregaussian, the covering numbers grow at most polynomi-
ally. We take N large enough such that N 2. Then s, t > N implies s + u, t + u > N/2
and s, t < -N implies s + u, t + u < -N/2. Since this is only a polynomial change in
N , the growth of the covering numbers remains at most polynomial. This leads to the entropy bound H(Q~n, L2(P), ) log(-1) for  small enough and independent of n. We define n() := log(-1)2. The bound in the condition is of the order log(n)-1/2n1/4. As seen before (a) this growth faster than Mn = Ch-n  .

5 Proof of the lower bound

First we show asymptotic linearity of .
Lemma 9. Supposing Assumptions 1 and 2 and   Zs,c with s >  and c > (1/2)+s, the estimator  with hn = o(n-1/(2+2s)) is asymptotically linear with influence function x  F -1[-1(-·)]  (y)(x - P)( dy) and thus  is Gaussian regular.
Proof. The analysis of the bias of  in Section 4.1.1 yields

 = + F -1[- 1(-·) F Kh]  (y)(Pn - P)( dy) + oP (n-1/2) = + F -1[- 1(-·)]  (y)(Pn - P)( dy) + F -1[- 1(-·)(F Kh - 1)]  (y)(Pn - P)( dy) + oP (n-1/2).

Since E

2

F -1[-1(-·)]  ( dx - d P)

4 E | F -1[- 1(-·)]  |2 d P

is finite and E[ F -1[(- 1(-·)]  )( dx - d P)] = 0 by (23) it suffices to show

F -1[-1(-·)(F Kh - 1)]  (y)(Pn - P)( dy) = oP (n-1/2).

(33)

For convenience we write h := F -1[-1(-·)(F Kh - 1)]   and let  > 0. Since (Yj) are independent and identically distributed, we obtain

P n1/2 h(y)(Pn - P)( dy) >   -2n E

h(y)(Pn - P)( dy) 2

=  -2n E

h(y)h(z)(Pn - P)( dy)(Pn - P)( dz)

n

=  -2n-1

E

j,k=1

h(y)h(z)(Yj - P)( dy)(Yk - P)( dz)

=  -1 E

h(y)(Yj - P)( dy) 2

4 -1 |h(y)|2 P( dy).

22

By uniform integrability of h2 with respect to P by (23) and pointwise convergence h  0 as h  0 we conclude |h(y)|2 P( dy)  0 and thus (33). From asymptotic linearity follows Gaussian regularity by Proposition 2.2.1 of [1].

Let us now briefly discuss the consequence of Assumption 4 in terms of Fourier multipliers. Standard calculus yields |(- 1)(k)(u)| u -k for k = 0, . . . , (   M ) + 1. With the same arguments as in the proof of Lemma 5(i) we deduce that

(1 + iu)+k(k)(u) and (1 + iu)-+k(-1)(k)(u)
are Fourier multipliers on Bps,q(R) for all s  R, p, q  [1, ] and k = 0, . . .   M .

(34)

5.1 Information bound for smooth 

In this subsection we prove Theorem 2.

Step 1: To determine the solution of the maximization problem (10), we define h := Sg = (g 

f)fY-1/2 with score operator S such that the

Therefore, g,  =

we obtain g = F -1[-1(-·)]

S-1h = F -1[-1]   fY h = h, (S

Fisher  ( fY -1) 

information (9) satisfies

I g, g

=

h

2 L2

.

h). Owing to the adjoint equation (12),

holds. Ignoring all restrictions on g, the

supremum is thus attained at

h := (S-1)  = (F -1[- 1(-·)]  ) fY .

(35)

Let us obtain

define ¯ :=
r  L1(R) 

 + 1/2 +
L2(R) and

1 and r := F F -1[- 1(u)]

-=1[r(1+(Idiu-)-D¯)¯-. 1T(uhe)]r.eBfoercea,uthsee

Fubini's theorem and the fundamental theorem of calculus, provided ( fY

of Lemma 5(ii) we
condition g = 0,
h)(k)  L1(R), k =

0, . . . ¯, imply

0 = F -1[-1]  ( fY h) = r 

¯
fY h +
k=1

¯ (-1)k( k

fY h)(k)

=r

¯
fY h +

¯ (-1)k k

k=1

( fY h)(k) .

lFimorxeach(kf=Y h1),(k.-. .1,)

¯ the (x) -



(intfeYghra)b(ki-li1ty)(-ofx()

fY =0

h)(l), l = and thus

k

-

1, k,

yields

then

 ( fY

h)(k)

=

0 = F -1[-1]  ( fY h) =

fY h,

(36)

ssipnacne{rfY=}F:r(0) = 1. Hence, we should project the solution h onto the L2-orthogonal space

h := h - h,fY f2LY2

fY

= F -1[-1(-·)]   - (F -1[-1(-·)]  )fY fY

= F -1[- 1(-·)]   - fX fY ,

(37)

23

where we used (F -1[- 1(-·)]  )fY = fX by (12). This leads to the candidate for the maximization of (10) given by

g = S-1h = S-1(S-1)  - , fX S-1 fY = I-1  - , fX fX

= F -1[-1]  F -1[-1(-·)]   fY -

fX fX

and (12) yields g,  = I g, g and the bound

g,  2 I = I g, g =

F -1[- 1(-·)]   2fY -

2
fX .

(38)

Inequality (11) Thm. 2.3.1]. It

holds then remains to

by the check

tlhoecaclovnedristiioonnsofinth(e8)H, a´(jekf­YLheC)(akm) coLn1v(oRlu)tifoonr

theorem k = 0, . .

[1, . ¯

Sfarntodempth2a:ftYWthheep,trfhoYrveeen-fHoowld+t(ahRpep)ilnifctoeargtsirooanmbieoliftyt+hoe>f adf.jYoihnt

equality = F -1

is allowed. [-1(-·)] 

The -

latter  fX

will follow fY and its

derivatives up to order ¯ which makes the calculation (36) rigorous.

For convenience we denote

 ¯  := F -1[-1(-·)]   = r  



¯ k

(-1)k



(k)


.

k=0

Owing to Young's inequality together with r  L1(R)  L2(R) and (k)  L2(R) for any k 0, we obtain   Cs(R)  Hs(R) for any s 0. It suffices to show fY(k)  L1(R) for
k = 0, . . . , ¯. Note that by (34)

(Id + D)kf L1

F -1[(1 - iu)k] B10,1

F -1[(1 - iu)k- ] B10,1

is finite for  > k since then F -1[(1 - iu)k-] = -k,1  B1,-k(R)  B10,1(R) by the proof of

Lemma 5(ii). Recalling that  / Z, we conclude iteratively f(k)  L1(R) for k = 0, . . . ,  .

Therefore,

fY(¯) L1

fX(¯-  ) L1 f(  ) L1 < 

by Assumption 3 and similarly for derivatives of lower order. Moreover, we conclude for ¯-  ( + 1/2, ¯) that

fY  B1¯,-1 (R)  B2¯,-1 -1/2(R)  H+ (R)

for some + >  by the embeddings (46) and (46). Since also fY  H+(R), using   Cs(R)

for s > , we can apply the adjoint equality (12) in Step 1.

Step 3: We will show now g/fX  <  which justifies fX ±  g 0 for some choice of

 > 0 small enough.

By Step 1 g = F -1[-1]  (fY ) - , fX fX . For the second term Assumption 3 implies

, fX fX /fX 

 L2 fX  fX L1 < . Hence, we only need to show F -1[- 1] 

(fY ) fX . Using the Besov embedding (45), the Fourier multiplier property of (34) and

the pointwise multiplier property of Besov spaces (48), we obtain for some +  (,  + 1)

F -1[- 1]  (fY ) 

fY B ,1

 fB ,1 Y B ,1

 Cs fY C+ .

24

for any s > . In Step 2 we have seen that   Cs(R). Moreover,

fY


C+ =
k=0

fY(k)  + sup
x=y

fY(  )(x) - fY(  )(y) (x - y)+- 


fX  f(k) L1 + sup
k=0 x=y

|fX (x - z) - fX (y |x - y|+- 

-

z)| f(



)(z) dz



fX 

f(k) L1 + fX C+- 

k=0

f(  ) L1 < ,

(39)

using the Besov embedding fX  W12(R)  B1,+1-  +1  C+-  . Hence, g  L(R). Since
fX is a continuous, strictly positive function, we conclude that the quotient g/fX is bounded
on every compact subset of R. Therefore, it suffices to estimate the tails. For |x| large enough

Assumption 3 implies, using again (34),

| F -1[-1]  (fY )(x)| fX (x)

xM F -1[-1]  (fY ) (x)

M M k
k=0

F -1 (-1)(k) F [yM-kfY ] (x)

M k=0

yM -k fY

.B+,1-k

Note that the above calculation shows that -1 is a Fourier multiplier on the weighted Besov space with weight function x M [cf. 10, Def. 4.2.1/2 and Thm. 5.4.2]. Each term in the above

sum can be estimated by

yM -k Cs fY C+

M -k

=

M -k l

(-1)l F -1

(-1)(l)(-u) F [(ix)M-k-l]

l=0

Cs fY C+ ,

where with abuse of notation + <  +1 is slightly larger in the last line and s > +. By (39)
we have fY  C+(R). Now, (ix)M-k-l  S (R) is again a Schwartz function and thus it suffices to show F -1[(- 1)(k)(-u) F ]  Cs(R) for s > ,   S (R) and k = 0, . . . , M . For
k = 0 this is already done in Step 2. We proceed analogously: for any integer s 0 we have

F -1 (-1)(k)(-u) F [] (s) 
= F -1 (1 + iu)(-¯+k)0(-1)(k)(-u)  (Id - D)(¯-k)0
(1 + iu)(-¯+k)0(- 1)(k)(-u) L2 Ds(Id - D)(¯-k)0 L2 u ((-¯+k)0)+-k L2 Ds(Id - D)(¯-k)0 L2 . Owing to ¯ >  + 1/2, the first factor is finite since

(s) 

((-¯ + k)  0) +  - k

 - ¯ < -1/2, ¯ - 1/2 - k < -1/2,

for ¯ k, for ¯ < k

and the second factor is the L2-norm of a Schwartz function and thus finite, too.

25

5.2 Approximation lemma

To prove convergence of the information bounds it suffices to show that

gn ,   (S )-1, (S )-1 - , fX 2 and Sgn , Sgn = gn , n  (S )-1, (S )-1 - , fX 2

(40) (41)

where we used the equality gn, n = I gn, gn = Sgn, Sgn , which holds naturally for the maximizer of the information bound In. For (40) we note

gn ,  = I-1 n,  - n, fX , fX = (S )-1n, (S )-1 - n, fX , fX

where the Cauchy­Schwarz inequality yields

| fX , n -  | = | (S )-1(n - ), fY |  (S )-1(n - ) L2  0

(42)

and

| (S )-1(n - ), (S )-1 | = | (S )-1(n - ), (S )-1 | (S )-1(n - ) L2 (S )-1 L2  0

as n  . Analogously follows (41), where we use that the assumption of the lemma implies (S )-1n, (S )-1n  (S )-1, (S )-1 as n  . The second part of the claim n   has already been shown in the estimate (42).

5.3 Information bound for non-regular 

To prove the efficiency of t for t  R in Theorem 4, it is suffices by Lemma 3 and (35) to

show

(S )-1(n - ), (S )-1(n - ) 1/2 = F [- 1(-·)]  (n - ) L2(P)  0

(43)

as n  . Using the moment bound (23) replacing F Kh by 1, we obtain

F [-1(-·)]  (n - ) L2(P)

n -  .Z+,1/2++

By assumption we have Z+,1/2++  Zs,c for  small enough. Because the space of
Schwartz-functions is dense in every Sobolev space Hs(R), s 0, S (R) is also dense in Zs,c
and thus the information bound (11) holds for all   Zs,c. Finally, applying Theorem 25.48
of [29] and Theorem 7 from above completes the proof of Theorem 4.

A Appendix: Function spaces

Let us define the Lp-Sobolev space for p  (0, ) and m  N

m

Wpm(R) := f  Lp(R)

fX(k) Lp < 

k=0

In particular, Wp0(R) = Lp(R). Due to the Hilbert space structure, the case p = 2 is crucial.
It can be described equivalently with the notation u = (1 + u2)1/2 by,  0,

H(R) :=

f  L2(R)

f

2 H

:=

u 2| F f (u)|2 du < 

26

which we call Sobolev space, too. Obviously, W2m(R) = Hm(R). Also frequently used are the Ho¨lder spaces. Denoting the space of all bounded, continuous functions with values in R as C(R) we define,  0,

C(R) :=

f  C(R)

f


C :=
k=0

f (l)



+

sup
x=y

|f (

 )(x) - f ( |x - y|-

 

)(y)|

<



,

where  denotes the largest integer smaller or equal to . A unifying approach which

contains all function spaces defined so far, is given by Besov spaces [28, Sect. 2.3.1] which we

will discuss in the sequel. Let S (R) be the Schwartz space of all rapidly decreasing infinitely

differentiable functions with values in C and S (R) its dual space, that is the space of all

tempered distributions. Let 0 <   S (R) with supp   {x|1/2 |x| 2} and (x) > 0

if {x|1/2 0(x) :=

< |x| 1-

< 2}.

 j=1

j

Then define (x) such that

j(x) := (2-jx)(

 k=-

the sequence {j}j=0 is a

(2-kx))-1, j = 1, 2, smooth resolution of

. . . , and unity. In

particular, F-1[j F f ] is an entire function for all f  S (R). For s  R and p, q  (0, ]

the Besov spaces are defined by

Bps,q :=

f  S (R) f Bps,q :=


2sjq

F -1[j F f ]

q Lp

1/q
<

.

j=0

We omit the dependence of · Bps,q to  since any function with the above properties defines an equivalent norm. Setting the Besov spaces in relation to the more elementary function
spaces, we first note that the Schwartz functions S (R) are dense in every Besov space Bps,q with p, q <  and H(R) = B2,2(R) as well as C(R) = B ,(R), where the latter holds
only if  is not an integer [28, Thms. 2.3.3 and 2.5.7]. Frequently used are the following
continuous embeddings which can be found in [28, Sect. 2.5.7, Thms. 2.3.2(1), 2.7.1]: For
p 1, m  Z

Bpm,1(R)  Wpm(R)  Bpm,(R) and B0 ,1(R)  L(R)  B0 ,(R)
and for s 0

(44)

Bs ,1(R)  Cs(R)  Bs ,(R).

(45)

Furthermore, for 0 < p0 p1 , q 0 and - < s1 s0 < 

Bps00,q(R)  Bps11,q(R)

if

s0

-

1 p0

s1

-

1 p1

(46)

and for 0 < p, q0, q1  and - < s1 < s0 < 

Bps,0q0 (R)  Bps,1q1 (R).

(47)

Another important relation is the pointwise multiplier property of Besov spaces [28, (24) on

p. 143] that is

f g Bps,q

f gBs ,q

Bps,q

(48)

for s > 0, 1 p  and 0 < q .

27

The Besov norm of a convolution can be bounded by Lemma 7 (i) in [25]. Let 1 p, q, r, s

, - < ,  < , 0 1/u = 1/p + 1/r - 1 1, 0 1/v = 1/q + 1/s 1. For f  Bp,q(R)

and g  Br,s(R)

f  g Bu,+v

f Bp,q g .Br,s

(49)

f

Using for any (x+h)-f (x) and

function f : (hl f )(x) :=

RR
1h(hl-1f

and )(x),

h l

 R the difference N, the Besov can be

operators h1 f (x) := equivalently described

by

f Bpsq  f Lp + f B psq with f B psq :=

|h|-sq-1

Mh f

q Lp

dh

1/q

for s > 0, p, q 1 and any integer M > s [28, Thm. 2.5.12]. The space of all f  S (R) for which f B psq is finite is called homogeneous Besov space B psq(R) [28, Def. 5.1.3/2, Thm. 2.2.3/2] and thus Bpsq = Lp(R)  B psq(R) for s > 0, p, q 1. Of interest is the relation of homogeneous Besov spaces to functions of bounded p-variation. Let BVp(R) denote the space of measurable functions f : R  R such that there is a function g which coincides with f
almost everywhere and satisfies

n
sup |g(xi) - g(xi-1)|p -  < x1 < · · · < xn < , n  N < 
i=1
and we define BVp(R) as the quotient set BVp(R) modulo equality almost everywhere. Then,

B p11/p(R)  BVp(R)  B p1,/p (R),

for p > 1

(50)

by [4, Thm. 5]. For p = 1 holds by [14, Lem. 8]

BV1(R)  L1(R)  B11,(R).

(51)

References
[1] Bickel, P. J., C. A. Klaassen, Y. Ritov, and J. A. Wellner (1998). Efficient and Adaptive Estimation for Semiparametric Models. Springer, New York.
[2] Bickel, P. J. and Y. Ritov (2003). Nonparametric estimators which can be "plugged-in". Ann. Statist. 31 (4), 1033­1053.
[3] Bissantz, N., L. Du¨mbgen, H. Holzmann, and A. Munk (2007). Non-parametric confidence bands in deconvolution density estimation. J. R. Stat. Soc. Ser. B Stat. Methodol. 69 (3), 483­506.
[4] Bourdaud, G., M. Lanza de Cristoforis, and W. Sickel (2006). Superposition operators and functions of bounded p-variation. Rev. Mat. Iberoam. 22 (2), 455­487.
[5] Butucea, C. and F. Comte (2009). Adaptive estimation of linear functionals in the convolution model and applications. Bernoulli 15 (1), 69­98.
[6] Dattner, I., A. Goldenshluger, and A. Juditsky (2011). On deconvolution of distribution functions. The Annals of Statistics 39 (5), 2477­2501.

28

[7] de la Pen~a, V. H. and E. Gin´e (1999). Decoupling: From Dependence to Independence. Springer, New York.
[8] Dudley, R. M. (1992). Fr´echet differentiability, p-variation and uniform Donsker classes. Ann. Probab. 20 (4), 1968­1982.
[9] Dudley, R. M. (1999). Uniform Central Limit Theorems. Cambridge University Press, Cambridge.
[10] Edmunds, D. E. and H. Triebel (1996). Function Spaces, Entropy Numbers, Differential Operators. Cambridge University Press, Cambridge.
[11] Fan, J. (1991a). Asymptotic normality for deconvolution kernel density estimators. Sankhy¯a: The Indian Journal of Statistics 53 (1), 97­110.
[12] Fan, J. (1991b). On the Optimal Rates of Convergence for Nonparametric Deconvolution Problems. The Annals of Statistics 19 (3), 1257­1272.
[13] Fo¨llmer, H. and A. Schied (2004). Stochastic finance: an introduction in discrete time (extended ed.), Volume 27 of de Gruyter Studies in Mathematics. Walter de Gruyter & Co., Berlin.
[14] Gin´e, E. and R. Nickl (2008). Uniform central limit theorems for kernel density estimators. Probab. Theory Related Fields 141 (3-4), 333­387.
[15] Gin´e, E. and R. Nickl (2009). Uniform limit theorems for wavelet density estimators. Ann. Probab. 37 (4), 1605­1646.
[16] Girardi, M. and L. Weis (2003). Operator-valued Fourier multiplier theorems on Besov spaces. Mathematische Nachrichten 251 (1), 34­51.
[17] Goldenshluger, A. and S. V. Pereverzev (2003). On adaptive inverse estimation of linear functionals in Hilbert scales. Bernoulli 9 (5), 783­807.
[18] Hall, P. and S. N. Lahiri (2008). Estimation of distributions, moments and quantiles in deconvolution problems. Ann. Statist. 36 (5), 2110­2134.
[19] Klenke, A. (2007). Probability Theory: A Comprehensive Course (Universitext) (1st ed.). Springer, London.
[20] Kosorok, M. R. (2008). Introduction to Empirical Processes and Semiparametric Inference (1st ed.). Springer Series in Statistics. Springer, New York.
[21] Lounici, K. and R. Nickl (2011). Global uniform risk bounds for wavelet deconvolution estimators. Ann. Statist. 39 (1), 201­231.
[22] Nickl, R. (2006). Empirical and Gaussian processes on Besov classes. In High dimensional probability, Volume 51 of IMS Lecture Notes Monogr. Ser., pp. 185­195.
[23] Nickl, R. and B. M. Po¨tscher (2007). Bracketing metric entropy rates and empirical central limit theorems for function classes of Besov- and Sobolev-type. J. Theoret. Probab. 20 (2), 177­199.
29

[24] Nickl, R. and M. Reiß (2012). A Donsker Theorem for L´evy Measures. arXiv 1201.0590. [25] Qui, B. H. (1981). Bernstein's theorem and translation invariant operators. Hiroshima
Math. J. 11 (1), 81­96. [26] Radulovi´c, D. and M. Wegkamp (2000). Weak convergence of smoothed empirical pro-
cesses: beyond Donsker classes. In High dimensional probability, II, Volume 47 of Progr. Probab., pp. 89­105. Birkh¨auser, Boston. [27] Schmidt­Hieber, J., A. Munk, and L. Du¨mbgen (2012). Multiscale Methods for Shape Constraints in Deconvolution: Confidence Statements for Qualitative Features. arXiv 1107.1404. [28] Triebel, H. (2010). Theory of Function Spaces. Birkha¨user Verlag, Basel. Reprint of the 1983 Edition. [29] van der Vaart, A. W. (1998). Asymptotic statistics. Cambridge Series in Statistical and Probabilistic Mathematics. Cambridge University Press. [30] van der Vaart, A. W. and J. A. Wellner (1996). Weak convergence and empirical processes. Springer Series in Statistics. Springer, New York. [31] van Es, B. and H.-W. Uh (2005). Asymptotic normality of kernel-type deconvolution estimators. Scand. J. Statist. 32 (3), 467­483.
30

SFB 649 Discussion Paper Series 2012
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "HMM in dynamic HAC models" by Wolfgang Karl Härdle, Ostap Okhrin and Weining Wang, January 2012.
002 "Dynamic Activity Analysis Model Based Win-Win Development Forecasting Under the Environmental Regulation in China" by Shiyi Chen and Wolfgang Karl Härdle, January 2012.
003 "A Donsker Theorem for Lévy Measures" by Richard Nickl and Markus Reiß, January 2012.
004 "Computational Statistics (Journal)" by Wolfgang Karl Härdle, Yuichi Mori and Jürgen Symanzik, January 2012.
005 "Implementing quotas in university admissions: An experimental analysis" by Sebastian Braun, Nadja Dwenger, Dorothea Kübler and Alexander Westkamp, January 2012.
006 "Quantile Regression in Risk Calibration" by Shih-Kang Chao, Wolfgang Karl Härdle and Weining Wang, January 2012.
007 "Total Work and Gender: Facts and Possible Explanations" by Michael Burda, Daniel S. Hamermesh and Philippe Weil, February 2012.
008 "Does Basel II Pillar 3 Risk Exposure Data help to Identify Risky Banks?" by Ralf Sabiwalsky, February 2012.
009 "Comparability Effects of Mandatory IFRS Adoption" by Stefano Cascino and Joachim Gassen, February 2012.
010 "Fair Value Reclassifications of Financial Assets during the Financial Crisis" by Jannis Bischof, Ulf Brüggemann and Holger Daske, February 2012.
011 "Intended and unintended consequences of mandatory IFRS adoption: A review of extant evidence and suggestions for future research" by Ulf Brüggemann, Jörg-Markus Hitz and Thorsten Sellhorn, February 2012.
012 "Confidence sets in nonparametric calibration of exponential Lévy models" by Jakob Söhl, February 2012.
013 "The Polarization of Employment in German Local Labor Markets" by Charlotte Senftleben and Hanna Wielandt, February 2012.
014 "On the Dark Side of the Market: Identifying and Analyzing Hidden Order Placements" by Nikolaus Hautsch and Ruihong Huang, February 2012.
015 "Existence and Uniqueness of Perturbation Solutions to DSGE Models" by Hong Lan and Alexander Meyer-Gohde, February 2012.
016 "Nonparametric adaptive estimation of linear functionals for low frequency observed Lévy processes" by Johanna Kappus, February 2012.
017 "Option calibration of exponential Lévy models: Implementation and empirical results" by Jakob Söhl und Mathias Trabs, February 2012.
018 "Managerial Overconfidence and Corporate Risk Management" by Tim R. Adam, Chitru S. Fernando and Evgenia Golubeva, February 2012.
019 "Why Do Firms Engage in Selective Hedging?" by Tim R. Adam, Chitru S. Fernando and Jesus M. Salas, February 2012.
020 "A Slab in the Face: Building Quality and Neighborhood Effects" by Rainer Schulz and Martin Wersing, February 2012.
021 "A Strategy Perspective on the Performance Relevance of the CFO" by Andreas Venus and Andreas Engelen, February 2012.
022 "Assessing the Anchoring of Inflation Expectations" by Till Strohsal and Lars Winkelmann, February 2012.
SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

SFB 649 Discussion Paper Series 2012
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
023 "Hidden Liquidity: Determinants and Impact" by Gökhan Cebiroglu and Ulrich Horst, March 2012.
024 "Bye Bye, G.I. - The Impact of the U.S. Military Drawdown on Local German Labor Markets" by Jan Peter aus dem Moore and Alexandra Spitz-Oener, March 2012.
025 "Is socially responsible investing just screening? Evidence from mutual funds" by Markus Hirschberger, Ralph E. Steuer, Sebastian Utz and Maximilian Wimmer, March 2012.
026 "Explaining regional unemployment differences in Germany: a spatial panel data analysis" by Franziska Lottmann, March 2012.
027 "Forecast based Pricing of Weather Derivatives" by Wolfgang Karl Härdle, Brenda López-Cabrera and Matthias Ritter, March 2012.
028 "Does umbrella branding really work? Investigating cross-category brand loyalty" by Nadja Silberhorn and Lutz Hildebrandt, April 2012.
029 "Statistical Modelling of Temperature Risk" by Zografia Anastasiadou, and Brenda López-Cabrera, April 2012.
030 "Support Vector Machines with Evolutionary Feature Selection for Default Prediction" by Wolfgang Karl Härdle, Dedy Dwi Prastyo and Christian Hafner, April 2012.
031 "Local Adaptive Multiplicative Error Models for High-Frequency Forecasts" by Wolfgang Karl Härdle, Nikolaus Hautsch and Andrija Mihoci, April 2012.
032 "Copula Dynamics in CDOs." by Barbara Choro-Tomczyk, Wolfgang Karl Härdle and Ludger Overbeck, May 2012.
033 "Simultaneous Statistical Inference in Dynamic Factor Models" by Thorsten Dickhaus, May 2012.
034 "Realized Copula" by Matthias R. Fengler and Ostap Okhrin, Mai 2012. 035 "Correlated Trades and Herd Behavior in the Stock Market" by Simon
Jurkatis, Stephanie Kremer and Dieter Nautz, May 2012 036 "Hierarchical Archimedean Copulae: The HAC Package" by Ostap Okhrin
and Alexander Ristig, May 2012. 037 "Do Japanese Stock Prices Reflect Macro Fundamentals?" by Wenjuan
Chen and Anton Velinov, May 2012. 038 "The Aging Investor: Insights from Neuroeconomics" by Peter N. C. Mohr
and Hauke R. Heekeren, May 2012. 039 "Volatility of price indices for heterogeneous goods" by Fabian Y.R.P.
Bocart and Christian M. Hafner, May 2012. 040 "Location, location, location: Extracting location value from house
prices" by Jens Kolbe, Rainer Schulz, Martin Wersing and Axel Werwatz, May 2012. 041 "Multiple point hypothesis test problems and effective numbers of tests" by Thorsten Dickhaus and Jens Stange, June 2012 042 "Generated Covariates in Nonparametric Estimation: A Short Review." by Enno Mammen, Christoph Rothe, and Melanie Schienle, June 2012. 043 "The Signal of Volatility" by Till Strohsal and Enzo Weber, June 2012. 044 "Copula-Based Dynamic Conditional Correlation Multiplicative Error Processes" by Taras Bodnar and Nikolaus Hautsch, July 2012
SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

SFB 649 Discussion Paper Series 2012
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
045 "Additive Models: Extensions and Related Models." by Enno Mammen, Byeong U. Park and Melanie Schienle, July 2012.
046 "A uniform central limit theorem and efficiency for deconvolution estimators" by Jakob Söhl and Mathias Trabs, July 2012
SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

