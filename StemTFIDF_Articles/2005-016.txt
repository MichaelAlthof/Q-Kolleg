BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2005-016
Common Functional Component Modelling
Alois Kneip* Michal Benko**
* Department Statistics and Mathematics, Johannes Gutenberg-Universität Mainz, Germany
** CASE - Center for Applied Statistics and Economics, Humboldt-Universität zu Berlin, Germany
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universität zu Berlin Spandauer Straße 1, D-10178 Berlin

1 Common functional component modelling
Alois Kneip and Michal Benko

ACKNOWLEDGEMENT
Financial support of Deutsche Forschungsgemeinschaft via SFB 649 "O¨ konomisches Risiko", Humboldt-Universit¨at zu Berlin, is gratefully acknowledged. JEL classification: C13, G19

1.1 Introduction

Functional data analysis (FDA) has become a popular technique in applied statistics. In particular, this methodology has received considerable attention in recent studies in empirical finance. In this talk we discuss selected topics of functional principal components analysis that are motivated by financial data.

By definition, FDA deals with the analysis of samples of functions. However, in practice the functions of interest are often not directly observed but are regression curves which have to be reconstructed from discrete, noisy data. In Section 2 we present a new method for efficient estimation of functional principal components in such situations. It consists in an adaptation of a technique introduced by Kneip and Utikal (2001) for the case of density functions.

Inference for two independent functional samples is considered. Bootstrap tests are developed to test whether principal components coincide and the two samples thus possess "common" functional principal components. The procedure possesses an important application in modelling implied volatilites as described in Benko and Ha¨rdle (2004).

In this section we will focus on one sample of i.i.d. smooth random functions

x1(t), . . . , xN (t)  L2[0, 1], t  [0, 1]. For v, w  L2[0, 1] let

v, w

=

b a

v(t)w(t)dt,

and

1 Common functional component modelling

let · = ·, · 1/2 denote the usual L2-norm. The Karhunen-Lo`eve decomposition then
provides a basic tool to describe the distribution of the random functions xi. With 1  2  . . . and 1, 2, . . . denoting eigenvalues and corresponding orthonormal eigenfunctions of the covariance operator C of xi we obtain

xi = µ + ijj, i = 1, . . . , N,
j=1

(1.1)

where µ = E(xi) is the mean function and ij = xi -µ, j are (scalar) factor loadings with E(i2j) = j. Structure and dynamics of the random functions can be assessed by analyzing the "functional principal components" j as well as the distribution of the factor loadings.
An important property of (1.1) consists in the known fact that the first L principal components provide a "best basis" for approximating the sample functions in terms of the integrated square error.
For any choice of L orthonormal basis functions v1, . . . , vL
L
(v1, . . . , vL) = E( xi - µ - xi - µ, vj vj 2)
j=1

is minimized by vj = j. In many important applications a small number of functional principal components will suffice to approximate the functions xi with a high degree of accuracy.

For a given sample an empirical analog of (1.1) can be constructed by using eigenvalues

1,n  2,N  . . . and orthonormal eigenfunctions 1,N , 2,N , . . . of the empirical

N

covariance

operator

CN ,

where

CN

=

1 N

xi - x¯,  (xi - x¯). If K denotes the number

i=1

of nonzero eigenvalues of CN then

K
xi = x¯ + ij,N j,N ,
j=1

i = 1, . . . , N,

(1.2)

where

x¯

is

the

sample

mean,

and

1 N

i i2j,N = j,N . Obviously, j,N and j,N estimate

j and j for j = 1, 2, . . . .

However, in practice, the sample functions xi are often not directly observed, but have to be reconstructed from noisy observations Yij at discrete design points tik:

yik = xi(tik) + ik, k = 1, . . . , Ti, where ik are independent noise terms with E(ik) = 0, Var(ik) = i2.

(1.3)

2

1.1 Introduction

In this context the standard approach to estimate functional principal components is to first estimate individual functions nonparametrically and then to determine eigenfunctions of the resulting estimated empirical covariance operator (compare, e.g., Ramsay and Silverman (1997)).
We propose an alternative approach which in a first step relies on estimating the elements of the matrix

Mlk = xl - x¯, xk - x¯ , l, k = 1, . . . , N.

(1.4)

Some simple linear algebra shows that all nonzero eigenvalues 1,N  2,N . . . of CN and l1  l2 . . . of M are related by j,N = lj/N . When using additionally the
corresponding orthonormal eigenvectors p1, p2, . . . of M , the empirical scores jr,N = xj - x¯, r,N as well as the empirical eigenfunctions r,N are obtained by jr,N =
lrpjr and

r,N =

-1 N
lr pir (xi - x¯) =
i=1

-1 N
lr pirxi.
i=1

(1.5)

The elements of M are functionals which can be estimated with asympotically negligi-

ble bias and a parametric rate of convergence Ti-1/2. If the data in (1.3) is generated from a balanced, equidistant design, then it is easily seen that for i = j this rate of

T

convergence

is

achieved

by

the

estimator

Mij

=

1 T

yik yj k .

k=1

In the case of a random design some adjustment is necessary: Set T d=ef min{T1, T2, . . . , TN } and define an equidistant grid {tk d=ef k/(T - 1), k = 0, 1, . . . , T - 1} on [0, 1]. Then, for each i = 1, . . . , N and k = 1, . . . , T find the index of the first and second nearest
neighbor of tk:

k(i) = arg min |tij - tk| and k (i) = arg min |tij - tk|.

j=1,...,Ti

j=k (i)

Finally, construct the estimators

1T

1T

Mij = T

yik(i)yjk(j) for i = j and Mii = T

yik(i)yik (i).

k=1

k=1

(1.6)

The aim of using special estimator (1.6) for the diagonal terms is to avoid the additional bias. Alternatively we can construct a bias corrected estimator using some nonparametric estimation of variance i2.
The eigenvalues ^l1  ^l2 . . . and eigenvectors p1, p2, . . . of the resulting matrix M then provide estimates ^r,N = ^lr/N and ^jr = ^lrp^jr. Estimates ^r,N of the empirical
3

1 Common functional component modelling

functional principal component r,N can be determined from (1.5) when replacing the unknown true functions xi by nonparametric estimates x^i (as, for example, local polynomial estimates with bandwidths hi):

^r,N =

-1 N
^lr p^irx^i.
i=1

(1.7)

When considering (1.7), it is important to note that ^r,N is defined as a weighted average of all estimated sample functions. Averaging reduces variance, and efficient
estimation of r,N therefore requires undersmoothing of individual function estimates x^i. Indeed, under suitable additional regularity conditions it can be shown that for an optimal choice of smoothing parameters and twice continuously differentiable xi, we obtain the rate of convergence r,N - ^r,N = OP ((N T )-2/5). Here, T = mini Ti.

A natural question is how many functions K should be used when approximating

the sample functions by a factor model of the form (1.2), when relying on estimated

principal components and scores. This question is crucial from statistical and practical

point of view, although it is not discussed often in the literature. We propose a

bootstrap test which successively tests the hypothesis H0 : K0+1,N = · · · = N,N = 0

for K0 = 1, 2, 3, . . . based on the respective residual average integrated square error:

^N (1, . . . , K0 )

=

1 N

N r=K0 +1

^lr

.

The idea of this procedure is based on the fact that the estimated eigenfunctions that

correspond to small estimated eigenvalues (with relative small importance) are rather

driven by the sampling noise than can be interpreted as a component of the variation of

the underlying population. In other words we do not want to use eigenfunctions whose

relative importance cannot be significantly distinguished from random components

generated by noise.

1.2 Two sample inference

Clearly, in the framework described by (1.1) - (1.3) we are faced with two sources of
variability of estimated functional principal components. Due to sampling variation
r,N will differ from the true component r, and due to (1.3) there will exist an additional estimation error when approximating r,N by ^r,N . The results of Dauxois, Pousse and Romain (1982) imply that r - r,N = OP (N -1/2), and the results of the proceeding section therefore imply that the difference between ^r,N and r,N is of smaller order of magnitude if T is sufficiently large compared to N . Inference about
functional principal components under (1) - (3) will then be first order equivalent to
an inference based on known functions xi.

We are mainly interest in two sample problems. Thus let

x11(t), x12(t), . . . , xN1 1 (t) and x21(t), x22(t), . . . , x2N2 (t)

(1.8)

4

1.2 Two sample inference

denote two independent samples of smooth functions. The problem of interest is to
test whether the functional principal components r in the respective decompositions (1.1) are common (identical) for both groups. In this case only the factor loadings ir may vary across samples. Then r = r1 = r2 and

xpi = µp + iprr, p = 1, 2.
r=1

(1.9)

This hypothesis has been used in the work of Fengler, H¨ardle and Villa (2003) and Benko and H¨ardle (2004) in modelling implied volatilites. It can be seen as a functional generalization of the concept of "common principal components" as introduced by Flury (1988) in multivariate analysis.
If the functions xpi were directly observed, then in order to test the hypothesis
H0 : r1 = r2

for r = 1, 2, . . . one could rely on the test statistics

Dr = r1,N - r2,N 2 .

It can be shown that critical values of Dr can be determined by a bootstrap procedure: Under H0 we have Dr = r1,N - r1 - (r2,N - r2) 2. The distribution of r1,N - r1 - (r2,N - r2) 2 can then be approximated by the bootstrap distribution of r1,N - r1,N - (r2,N - r2,N ) , where r1,N and ^r2,N are estimates to be obtained from
independent bootstrap samples

x11(t), x21(t), . . . , x1N1 (t) and x21(t), x22(t), . . . , xN22 (t).

(1.10)

In the practically more relevant situation that all curves in both samples have to be
reconstructed from noisy observations according to (1.3), Dr must be replaced by D^r = ^r1,N - ^r2,N 2, where estimates are determined by the procedure described above. Bootstrap estimates are then obtained by resampling the observations corre-
sponding to the unknown curves xi. The procedure is asymptotically valid if T is sufficiently large such that the additional estimation error is asymptotically negligi-
ble. Of course, the test should only be performed for components which can be savely distinguished from noise, and 1  r  min K01, K02.

5

1 Common functional component modelling 6

Bibliography
Benko, M.and H¨ardle, W. (2004). Common Functional IV Surface Analysis Statistical Tools for Finance and Insurance, edited by C´izek, P., H¨ardle, W., Weron, R. to appear by Springer.
Dauxois, J., Pousse, A. and Romain, Y. (1982). Asymptotic Theory for the Principal Component Analysis of a Vector Random Function: Some Applications to Statistical Inference, Journal of Multivariate Analysis 12 : 136-154.
Fan, J. and Huang, L. (1999 ). Nonparametric Estimation of Quadratic Regression Functionals, Bernoulli 5,: 927-949.
Hall, P., Kay, J.W. and Titterington, D.M. (1990 ). Asymptotically optimal differencebased estimation of variance in nonparametric regression, Biometrika 77: 520:528.
Flury, B. (1988). Common Principal Components and Related Models, Wiley, New York.
Fengler, M., Ha¨rdle, W. and Villa, P. (2003). The Dynamics of Implied Volatilities: A common principle components approach, Review of Derivative Research 6 : 179-202.
Fengler, M., H¨ardle, W. and Mammen, E. (2003). Implied Volatitlity String Dynamics, CASE Discussion Paper, http://www.case.hu-berlin.de.
Kneip, A. and Utikal, K. (2001). Inference for Density Families Using Functional Principal Components Analysis, Journal of the American Statistical Association 96 : 519-531.
Ramsay, J. and Silverman, B. (1997). Functional Data Analysis, Springer, New York.

SFB 649 Discussion Paper Series
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "Nonparametric Risk Management with Generalized Hyperbolic Distributions" by Ying Chen, Wolfgang Härdle and Seok-Oh Jeong, January 2005.
002 "Selecting Comparables for the Valuation of the European Firms" by Ingolf Dittmann and Christian Weiner, February 2005.
003 "Competitive Risk Sharing Contracts with One-sided Commitment" by Dirk Krueger and Harald Uhlig, February 2005.
004 "Value-at-Risk Calculations with Time Varying Copulae" by Enzo Giacomini and Wolfgang Härdle, February 2005.
005 "An Optimal Stopping Problem in a Diffusion-type Model with Delay" by Pavel V. Gapeev and Markus Reiß, February 2005.
006 "Conditional and Dynamic Convex Risk Measures" by Kai Detlefsen and Giacomo Scandolo, February 2005.
007 "Implied Trinomial Trees" by Pavel Cízek and Karel Komorád, February 2005.
008 "Stable Distributions" by Szymon Borak, Wolfgang Härdle and Rafal Weron, February 2005.
009 "Predicting Bankruptcy with Support Vector Machines" by Wolfgang Härdle, Rouslan A. Moro and Dorothea Schäfer, February 2005.
010 "Working with the XQC" by Wolfgang Härdle and Heiko Lehmann, February 2005.
011 "FFT Based Option Pricing" by Szymon Borak, Kai Detlefsen and Wolfgang Härdle, February 2005.
012 "Common Functional Implied Volatility Analysis" by Michal Benko and Wolfgang Härdle, February 2005.
013 "Nonparametric Productivity Analysis" by Wolfgang Härdle and Seok-Oh Jeong, March 2005.
014 "Are Eastern European Countries Catching Up? Time Series Evidence for Czech Republic, Hungary, and Poland" by Ralf Brüggemann and Carsten Trenkler, March 2005.
015 "Robust Estimation of Dimension Reduction Space" by Pavel Cízek and Wolfgang Härdle, March 2005.
016 "Common Functional Component Modelling" by Alois Kneip and Michal Benko, March 2005.
SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

