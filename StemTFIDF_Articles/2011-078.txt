BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2011-078
Spatially Adaptive Density Estimation by Localised Haar Projections
Florian Gach* Richard Nickl* Vladimir Spokoiny**
* University of Cambridge, United Kingdom ** Weierstrass Institute (WIAS) Berlin, Germany
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universit‰t zu Berlin Spandauer Straﬂe 1, D-10178 Berlin

Spatially Adaptive Density Estimation by Localised Haar Projections
Florian Gach, Richard Nickl, and Vladimir Spokoiny 
University of Cambridge  and Weierstrass Institute Berlin 
March 2011
Abstract Given a random sample from some unknown density f0 : R  [0, ) we devise Haar wavelet estimators for f0 with variable resolution levels constructed from localised test procedures (as in Lepski, Mammen, and Spokoiny (1997, Ann. Statist.)). We show that these estimators adapt to spatially heterogeneous smoothness of f0, simultaneously for every point x in a fixed interval, in sup-norm loss. The thresholding constants involved in the test procedures can be chosen in practice under the idealised assumption that the true density is locally constant in a neighborhood of the point x of estimation, and an information theoretic justification of this practice is given.
Keywords: spatially inhomogeneous smoothness, bandwidth choice, propagation approach
JEL-Classification: C14
1 Introduction
One of the most enduring challenges in statistical function estimation is to devise procedures that adapt to the locally variable complexity of the unknown function. For
Financial support by the German Research Foundation (DFG) through the Collaborative Research Center 649 "Economic Risk" is gratefully acknowledged
Statistical Laboratory, Department of Pure Mathematics and Mathematical Statistics, University of Cambridge, CB30WB, Cambridge, UK. Email: f.gach@statslab.cam.ac.uk, r.nickl@statslab.cam.ac.uk
Weierstrass Institute for Applied Analysis and Stochastics, Mohrenstrasse 39, 10117 Berlin, Germany. Email: spokoiny@wias-berlin.de
1

example, if one observes a random sample X1, ..., Xn with density f0 : R  R, then f0 may exhibit spatially inhomogeneous smoothness: The density could be infinitelydifferentiable on most of its support except for a few points xm where it behaves locally like |x - xm|m for some distinct numbers m. The location of the irregular points xm will usually not be known, and neither the corresponding degree of smoothness m. Moreover f0 could possess a so-called multifractal behavior, changing its H®older exponents continuously on its domain of definition ≠ in fact, as shown in Jaffard [11], `typical' functions in the Besov spaces usually considered in nonparametric statistics are always multifractal. Donoho and Johnstone [1] and Donoho, Johnstone, Kerkyacharian, and Picard [2], [3] have suggested that methods based on wavelet shrinkage can, to a certain extent, adapt to spatially inhomogeneous complexity of the unknown function f0. Moreover, Lepski, Mammen, and Spokoiny [12] showed that this is not intrinsic to wavelet methods, and that similar spatial adaptation results can be proved for kernel methods based on locally variable bandwidth choices.
There are several ways in which one can measure spatial adaptivity of an estimator. A minimal requirement may be to devise a rule f^n(x) that estimates f0(x) in an optimal way at every point x, and the methods suggested in [1] and [12] meet this requirement. These procedures depend on the point x, and the natural question arises as to how a given procedure performs globally as an estimator for f0. To address this question, Donoho et al. [3] and Lepski et al. [12] considered global Lr-loss, r < , and argued that taking Lr-loss over Besov-bodies B(s, p, q) where smoothness is measured in Lp, r > p, gives a way to assess the spatial performance of an estimator. A probably more transparent approach to the spatial adaptation problem is to consider sup-norm loss for estimators with locally variable bandwidths: one aims to find an estimator f^n(x) that is locally optimal for estimating f0(x), and simultaneously so for all x. This approach was not considered in the literature so far ≠ the results [6], [7], [8], [9] address the spatially homogeneous setting only.
A first contribution of this article is to show that a dyadic histogram estimator with variable bin size spatially adapts to possibly inhomogeneous local H®older smoothness of f0, in global sup-norm loss. More precisely, for K(x, y) the Haar wavelet projection kernel, we shall construct

f^n(x)

=

2^jn(x) n

n

K(2^jn(x)x, 2^jn(x)Xi),

i=1

where ^jn(x) is a variable resolution level that depends both on x and the sample, and

2

show that the random variable

1 sup
x r(n, x, f0)

f^n(x) - f0(x)

is stochastically bounded, where r(n, x, f0) is the local minimax adaptive rate of estimation of f0 at the point x. In fact we prove an explicit finite-sample oracle inequality that compares the estimator f^n to an optimal (oracle-type) estimator that is described in detail below.
While this result shows that spatial adaptation is indeed possible in a strong theoretical way, a drawback shared by most results in the literature on adaptive estimation remains: The theoretical findings give no indication whatsoever as to how to choose the numerical constants in the thresholds that feature in shrinkage- or Lepski-test-based methods. It has become a common practice that thresholding constants are chosen according to simulation results where simulations are drawn as if the true underlying signal is very simple (say, uniform or piecewise constant). This practice has not had any general theoretical corroboration until recently Spokoiny and Vial [14] gave, in a simple Gaussian regression model, a certain justification based on the idea of `propagation'. The results in [14] are heavily tied to the simplicity of the model used, in particular to the strong Gaussianity assumption employed, and to the fact that pointwise loss is considered. In the present paper we show how the ideas of [14] generalise, subject to some nontrivial modifications, to nonparametric density estimation. A key idea in the proofs in [14], translated into the density estimation context, is to replace the sampling distribution by a locally constant product measure. The 'transportation cost' of this replacement is easy to control in the Gaussian setting of [14], but in the density estimation case the fluctuations of the likelihood ratios between the unknown sampling distribution and relevant locally constant product measures do not obey a Gaussian regime, but turn out to be of Poisson type, so that the 'Gaussian intuitions' of [14] could be entirely misleading. We show however that the main information theoretic idea of [14] remains sound in this Poissonian setting as well: We use a Lepski-type procedure to construct ^jn(x), and we show that if we compute sharp thresholds for this procedure as if the true density f0 belonged to a family F of locally constant densities, then the resulting estimator is spatially adaptive in sup-norm loss. In contrast to the results in [14], the rates of convergence we obtain for the risk of the final estimator are exact rate-adaptive.
While the techniques and results of this paper generalise in principle to more complex estimation problems that involve in particular adaptation to higher degrees of smoothness, we prefer to stay within the simpler setting of Haar wavelets, which allows for a

3

clean exposition of the main ideas.

2 Uniform spatial adaptation using propagation methods

We will use the symbol g T to denote the supremum suptT |g(t)| of a function g over some set T , but we will still use the symbol g  to denote supxR |g(x)| if no confusion can arise.
For any j  N, we define a dyadic partition of (0, 1] into 2j-many disjoint subintervals by setting Ij,k = (k2-j, (k + 1)2-j], k = 0, . . . , 2j - 1; and for 0 < x  1 we denote by Ij,k(x) the unique interval containing x. For j  N, k = 1, . . . , 2j - 1, let Vj,k be the space of all bounded density functions on R that are constant on Ij,k. Via the local projections



2j Kj,x(f )(z) : =

Ij,k(x) f (y)dy

if z  Ij,k(x),

f (z)

otherwise,

we map any bounded density f onto Vj,k(x). (Note that Kj,x(f ) is indeed a density since Kj,x(f ) and f assign the same probability to the interval Ij,k(x).) For f  Vj,k and j  j we clearly have Kj ,x(f ) = f .

2.1 Estimation procedure
Let X, X1, ..., Xn be i.i.d. with bounded density f0 : R  [0, ), n > 1. We wish to construct a single estimator which estimates f0(x) in an optimal way, uniformly so for points x in the interval (a, b]. We shall take without loss of generality (a, b] = (0, 1], and we shall assume throughout that f0 is bounded away from zero on (0, 1]. Let K(x, y) = k (x - k)(y - k) be the projection kernel based on the Haar wavelet  = 1(0,1]. We shall write Kj(x, y) = 2jK(2jx, 2jy), and the associated linear density estimator is the dyadic histogram estimator given by
1n fn(j, x) := n Kj(x, Xi).
i=1
We make the important observation that Ef fn(j, x) = 2jPf (Ij,k(x)), which directly follows from the identity Kj(x, y) = 2j1Ij,k(x)(y). If f is constant on Ij,k(x) this in particular implies Ef fn(j, x) = f (x). (In other words: for any locally (at x) constant density f the bias of fn(j, x) equals zero if the resolution level is chosen fine enough.)
We finally note that the estimator fn(j, x) by construction only depends on data

4

points falling into Ij,k(x). This amounts to n2-j being the `effective' sample size for estimating f0 at x.

2.2 Local choice of the resolution level
We fix jmax := jmax,n  N satisfying 2-jmax  (log n)2/n for some d > 0. For thresholds n to be specified below, and for J  N, J  jmax and 0 < x  1, we define

^jn(J, x) = min j  N, J  j  jmax :  n2-j fn(j , x) - fn(j, x)  n fn(j, x) for all j , j < j  jmax

(1)

as well as

^jn(x) = ^jn(0, x).

(2)

(If the condition in (1) is not met for any j, J  j  jmax, we set ^jn(J, x) = jmax.) Given the locally variable resolution level ^jn, we define the family of nonlinear estimators

f^n(J, x) := fn(^jn(J, x), x), f^n(x) := fn(^jn(x), x), x  [0, 1].

(3)

These are estimators for f0(x) based on a locally variable resolution level depending on x, and they are density-analogues of the estimators introduced in [12] in the context of the Gaussian white noise model. Note that by construction ^jn(x) is a step function in x. Introducing the parameter J will be useful in what follows ≠ effectively, f^n(J, x) is a nonlinear estimator based on a search over the resolution levels j  J that stops at
jmax.

2.3 Threshold choice by propagation
One of the main challenges for all adaptive procedures is the choice of the thresholds n used in the tests defined in (1). Define the standardisation



1

 1 := fn(j,x)

sn(j, x) 0

if fn(j, x) > 0; otherwise.

We suggest to choose the thresholds in such a way that the following condition is satisfied:
Condition 1 Let Fj,k be any triangular array of subsets of Vj,k, j  jmax, k = 0, . . . , 2j- 1, and let k(m) be the unique k such that Ijmax,m  Ij,k. We say that the thresholds n

5

satisfy the uniform propagation condition UP(, Fj,k) for some fixed  > 0 if for every n, every j  jmax, every m = 0, . . . , 2jmax - 1, and every f  Fj,k(m) we have that

 Ef  sup max
xIjmax,m jj jmax

2

n2-j log n

f^n(j , x) - fn(j , x)

sn(j , x)





 n22jmax .

(4)

(Note that since ^jn(j )  j we have that fn(j , x) = 0 implies f^n(j , x) = 0 for the fully data-driven estimator f^n(j ), and so the error |f^n(j , x) - fn(j , x)| is then 0.)
An interpretation of this condition can be given along the following lines: For 0 <
x  1 the class Fj,k(x) contains only densities f that can be exactly reconstructed on Ij,k(x) by Kj(x, y)f (y)dy, so that the bias of the linear estimator fn(j , x) equals zero locally. In particular, any choice of the resolution level finer than j will only increase the variance without reducing the bias, and we would want ^jn(j , x) to detect that and equal, with large probability, j . This property of ^jn will then be mirrored in the fact that f^n(j , x) - fn(j , x) = 0 for every j  j on an event with large probability, in which case the l.h.s. of (4) is exactly equal to zero. The quantity /(n22jmax) stands for the a priori expected tolerance for a probabilistic error of ^jn to detect the `correct' resolution
level on each interval Ijmax,m in this `no-bias' situation. The following lemma shows that Condition 1 is not empty and that thresholds n
satisfying the uniform propagation condition exist. It shows furthermore that the thresh
olds can be taken to be of order log n and independent of f , which will be crucial in understanding the adaptive properties of f^n below.

Lemma 1 Let Fj,k equal Vj,k intersected with the set

f : 0 <   inf f (x),
0<x1

f M

for some fixed 0 < , M < . Then for every given  > 0 there exists a numerical constant  > 0 that depends only on  such that for any threshold choice

n   log n
the uniform propagation condition UP(, Fj,k) is at least satisfied for n larger than some index that only depends on  and M .
 While Lemma 1 proves the existence of thresholds of the order log n under the uniform propagation condition ≠ a fact that will be seen to imply adaptivity of f^n below
6

≠ it does not suggest a practical choice of n. Instead, this choice can be made by direct evaluation of (4), as follows: Condition 1 only concerns the local error bounds over small intervals Ijmax,m on which the function f is constant, which effectively means that it suffices to check this condition only for classes of densities which are constant on the interval of interest. The particular choice of the interval Ijmax,m is unimportant. Secondly, all quantities in Condition 1 depend on known quantities after f is chosen. By construction of the estimators fn and f^n the random variable featuring in (4) ≠ we call it T ≠ only depends on the number of data points falling into each of the (uniquely determined) j -fine intervals containing Ijmax,m. This observation allows for an easy computation of the l.h.s. of (4) along the following lines: Fix 0  p  1. Then, for any f  Fj,k(m) satisfying 2-jf = p on Ij,k(m), the number Z of observations falling into the interval Ij,k(m) is binomial B(n, p). Conditionally on Z = k, take k-many independent random variables that are uniform on Ij,k(m) and count the number of observations Vj in each of the j -fine intervals. Then compute fn, f^n; and T . This shows that T does only depend on Vj , j  j  jmax, and that the l.h.s. of (4) is therefore equal to E[E[T (Vj, . . . , Vjmax)|Z]].
The practical choice of n can then be obtained via a Monte Carlo simulation of (4) by choosing n as the smallest threshold for which (4) is satisfied in the simulation for one specific interval Ijmax,m uniformly over the class of all densities constant on this interval. Given jmax and , this procedure has to be performed only for one fixed interval Ijmax,m, and then applies for every m simultaneously.
2.4 Local small bias condition
The idea behind Condition 1 is that we take `idealised' classes of densities F for which we compute sharp thresholds n. The danger arises that the true density f0 may be very different from the elements in F, which may lead to wrong thresholds (and inference). We have to assess the error that comes from replacing f0 by an element from F, in a neighborhood of a given point x. This can be fundamentally quantified in terms of the log-likelihood ratio between f0 and its local (at x) approximand in F. As we shall see, one of the deeper reasons behind the fact that propagation methods imply adaptation results is that this error can be related to the usual bias term in linear estimation.
Condition 2 Given real numbers j,x, 0 < x  1, j  N  {0} satisfying l ,x  l,x for every l > l, we say that f0 satisfies the local small bias condition at x  (0, 1] and
7

with j,x  j,x(f0) if

VarKj,x(f0) log

f0 Kj,x(f0)



j,x(f0)

for all j  N.

The local 'cost' of transporting a product measure

n i=1

f0(xi)

to

n i=1

Kj,x(f0)(xi

)

can be quantified by n times the variance featuring in the above condition, and we shall

have to restrict ourselves to resolution levels j for which this transportation cost is at

most a fixed constant times the logarithm of the sample size n. The smallest resolution level for which this is still the case will be defined as j(x): More precisely, for some

fixed positive constant , define the local resolution level

j(x) := j(x, n, , f0) = min {j  N : j  jmax, nj,x(f0)   log n} .

(5)

While this is an information-theoretic definition of j, a key observation of this subsection is that it has the classical `bias-variance' tradeoff generically built into it for suitable choices of j,x(f0).

Lemma 2 Suppose f0 is bounded by some finite number M > 0 and that

inf
0<x1

f0(x)





>

0.

Then f0 satisfies Condition 2 with

j,x(f0)

=

M 2

2-j

f0 - Kj,x(f0)

2.

Proof. First, observe that Kj,x(f0) is bounded by M and bounded below by  >
0. Then, using that Kj,x(f0) coincides with f0 outside of Ij,k(x) and the inequality | log x - log y|  max(x-1, y-1)|x - y|, we get

VarKj,x(f0)

log

f0 Kj,x(f0)



log f0(y) Kj,x(f0)(y)

2
Kj,x(f0)(y)dy

 max f0(y)-2, Kj,x(f0)(y)-2 (f0(y) - Kj,x(f0)(y))2Kj,x(f0)(y)dy



M 2

(f0(y)

-

Kj,x(f0)(y))2dy



M 2

2-j

Kj,x(f0) - f0

2 

.

8

The lemma shows that the quantity (n/ log n)j,x(f0) can be viewed as the square of the `bias divided by the variance' of linear projection estimators for f0(x). Hence, to choose the smallest j  jmax such that (n/ log n)j,x(f0) is still bounded by a fixed constant  means to locally balance the `variance' and `bias' term in the nonparametric setting.
To be more concrete, let us briefly discuss what this means in the classical situation where the bias is bounded by local regularity properties of the unknown density f0. Since we are interested in spatial adaptation, we wish to take locally inhomogeneous smoothness into account by appealing to local H®older conditions: Let 0 < t  1 and let us say that a function g : R  R is locally t-H®older at x  R if for some  > 0

|g(x + m) - g(x)|

sup
0<|m|

|m|t

< .

Define further a `local' Ho®lder ball of bounded functions

C(t, x, L, ) := g : R  R, max

|g(x + m) - g(x)|

g , sup
0<|m|

|m|t

L

.

Condition 2 then has the following more classical interpretation in terms of local smoothness properties of f0:

Lemma 3 If f0  C(t, x, L, ) for some 0 < t  1, then the local bias f0 - Kj,x(f0)  is bounded by c2-jt for some constant c(t, L, ). Furthermore, if

inf
0<x1

f0(x)





>

0,

then Condition 2 is satisfied with

j,x(f0)

=

c2

L 2

2-j(2t+1).

(6)

9

Proof. Let y  Ij,k(x) be arbitrary. Then, using the substitution 2jz = 2jy - u,

|f0(y) - Kj,x(f0)(y)| = 2j

(f0(y) - f0(z))dz

Ij,k(x)

1
 |f0(y) - f0(x) + f0(x) - f0(y - 2-ju)|du
-1

1
 2|f0(y) - f0(x)| + |f0(x) - f0(y - 2-ju)|du
-1

By definition of x, y, Ij,k(x) we have |y - x|  2-j, and also |y - 2-ju - x|  2-j+1 by the triangle inequality, so that for 2-j+1   the last quantity is bounded by c02-jt in view of f0  C(t, x, L, ). If 2-j > /2, then the quantity in the last display can still be bounded by 6 f0   6L, so that choosing c1 = 6L(2/)t establishes the desired bound for c = max(c0, c1). To prove the second claim, apply Lemma 2.
Using the bound from the last lemma to verify Condition 2, we see that, by definition of j(x) and for f0  C(t, x, L, ),

n2-j(x)

t
n 2t+1



log n

log n

(7)

is the locally (at x) optimal adaptive rate of convergence, so that the local small bias condition constructs a minimax optimal resolution level j(x) at every x  [0, 1].

2.5 Main results
We now state the main results, starting with the following `oracle' inequality.
Theorem 1 Let f^n(∑) be the density estimator defined in (3) with thresholds n that satisfy the uniform propagation condition UP(, Fj,k) for some Fj,k. Suppose f0 satisfies Condition 2 for every 0 < x  1, and let j(x) be as in (5). Then we have

for any U satisfying

Ef0 sup
0<x1

n2-j(x) f^n(x) - fn(j(x), x)

log n

sn(j(x), x)

  n +  ne4U log n n

U  sup log

f0

.

0<x1

Kj(x),x(f0) 

(8) (9)

10

 If n = O( log n) ≠ as follows under the conditions of Lemma 1 ≠ and if one chooses  < 1/2, U as in the remark below, then the r.h.s. of (8) is O(1) as n tends to infinity. Theorem 1 thus implies that the estimator f^n with resolution levels chosen by the propagation approach is close to the linear `oracle' estimator evaluated at the locally optimal resolution level j(x), and this uniformly so on (0, 1].

Remark 1 If Fj,k is as in Lemma 1 and f0 is bounded by M and bounded below by , we may apply Lemma 2 (using 2-jmax  d(log n)2/n) to get the bound

log f0 = log 1 + f0 - Kj(x),x(f0)  log 1 +  ,

Kj(x),x(f0)

Kj(x),x(f0)

dM log n

which tends to zero as n tends to infinity.

Our results then imply the following uniform spatial adaptation result:

Tf^nh(∑e)obreemthe2deAnsssiutymeestthimatatfo0risfrobomun(d3e)dwbiythMthraensdhosladtsisfines=inOf 0(<xlo1gfn0)(xth) at

 > 0. satisfy

Let the

uniform propagation condition UP(, Fj,k) for Fj,k as in Lemma 1. Let j(x) be as in

(5) with  < 1/2 and with j,x as in Lemma 2. Then

sup
0<x1

n2-j(x) log n

f^n(x) - f0(x)

= OPrf0 (1).

(10)

If j(x) ≠ with  < 1/2 ≠ is based on j,x as in Lemma 3, then (10) holds true and the rate is the adaptive locally optimal rate of convergence at every 0 < x  1 where f0 is locally t-H®older with 0 < t  1, see the discussion in Section 2.4 surrounding (7). A more classical way to formulate Theorem 2 is hence as follows.

Theorem 3 Suppose the assumptions of Theorem 2 are satisfied and that the true density f0 lies in C(t(x), x, L(x), (x)), 0 < x  1, and t(∑), L(∑), (∑) are bounded and uniformly bounded away from zero on (0, 1]. Let j(x) be as in (5) with  < 1/2 and
with j,x as in Lemma 3. Then

sup
0<x1

n log n

t(x)/(2t(x)+1)
f^n(x) - f0(x) = OPrf0 (1).

11

3 Proofs

3.1 Proof of Theorem 1

A first idea is to use a moment bound, localised at any point x of estimation, on the log-likelihood ratio between f0 and its approximand in Vj,k.
Lemma 4 If, for fixed 0 < x  1,

VarKj,x(f0)

log

f0 Kj,x(f0)



D log n n

(11)

for some 0 < D <  and every n  N, then, for every n  N,

EKj,x(f0)

n f0(Xi) i=1 Kj,x(f0)(Xi)

2
 n2De4U

holds for any U satisfying

U  log f0

.

Kj,x(f0) 

Proof. Since the Kullback-Leibler distance

K(f0, Kj,x(f0))

=

-EKj,x(f0)

log

f0 Kj,x(f0)



0

is non-negative, we have

EKj,x(f0)

n f0(Xi) i=1 Kj,x(f0)(Xi)

2



E e2

log

f0 Kj,x (f0

)

-EKj,x (f0

)

log

f0 Kj,x (f0 )

Kj,x (f0 )

n

by the i.i.d. assumption. Using the power series expansion of the exponential function

and that the variables in the exponent are centered, one easily bounds the previous

display by

2De4U log n 1+

n
 e2De4U log n = n2De4U .

n

Here is the proof of Theorem 1: We first note that Condition 2 allows us to take j,x(f0) to be constant on the intervals Ij,k. Consequently, j(∑) from (5) is then constant on every interval Ijmax,m, and we set
jm = sup j(x).
xIjmax ,m
12

To prove the theorem, we split

Ef0 sup
0<x1

n2-j(x) f^n(x) - fn(j(x), x)

log n

sn(j(x), x)

 Ef0 sup
0<x1

n2-j(x) log n

f^n(x) - fn(j(x), x) sn(j(x), x)

1{^jn(x)<j(x)}

+Ef0 sup
0<x1
=: I + II

n2-j(x) log n

f^n(x) - fn(j(x), x) sn(j(x), x)

1{^jn(x)j(x)}

according to whether ^jn(x) comes to lie below the local resolution level j(x) or not. By definition of ^jn(x) in (1) one immediately has
I   n . log n

About II: Define

Sm

=

sup
xIjmax ,m

max
jm jjmax

n2-j f^n(j, x) - fn(j, x) .

log n

sn(j, x)

(12)

Using that on the event ^jn(x)  j(x) we necessarily have f^n(x) = f^n(j(x), x), we see that

II  Ef0 sup
0<x1

n2-j(x) f^n(j(x), x) - fn(j(x), x)

log n

sn(j(x), x)



Ef0

max
m

sup
xIjmax ,m

max
jm jjmax



2jmax

max
m

Ef0 Sm.

n2-j f^n(j, x) - fn(j, x)

log n

sn(j, x)

(13)

13

We use the Cauchy-Schwarz inequality to bound

Ef0 Sm = ∑∑∑
= ∑∑∑

n

Sm(x1, . . . , xn) f0(xi)dx1 ∑ ∑ ∑ dxn

i=1

Sm(x1,

.

.

.

,

xn)

n i=1

f0(xi) Kjm ,x(f0)(xi)

n i=1

Kjm ,x(f0)(xi)dx1

∑

∑

∑

dxn



EKjm ,x(f0)Sm2

EKjm ,x(f0)

n f0(Xi) i=1 Kjm ,x(f0)(Xi)

2

by the square-root of the second moment of Sm under the `idealised' density Kjm ,x(f0) times the square-root of the second moment of the likelihood ratio. (Here, x is any point

in Ijmax,m.) Using Condition 1 and Lemma 4, we obtain a bound for the last term in

(13) of order

2jmax

max
m

Ef0

Sm



 ne4U , n

which concludes the proof of the theorem.

3.2 Proof of Theorems 2 and 3
We first prove Theorem 2: Clearly,

sup
0<x1

n2-j(x) log n

f^n(x) - f0(x)

 sup
0<x1

n2-j(x) f^n(x) - fn(j(x), x)

log n

sn(j(x), x)

fn(j(x), x)

+ sup
0<x1

n2-j(x) log n

|fn(j(x),

x)

-

f0(x)|

.

The first factor of the first summand is bounded in probability in view of Theorem 1 and 
of Lemma 1 and the hypothesis n = O( log n). The second factor of the first summand is also bounded in probability since

sup
0<x1

max
jjmax

|fn(j,

x)

-

Ef0 fn(j,

x)|

=

oPf0

(1)

14

by Proposition 2, using 2-jmax  d(log n)2/n, and since supx,j |Ef0fn(j, x)|  f0  < . It remains to prove that the second summand is bounded in probability, and we
achieve this by bounding the moment

Ef0 sup
0<x1

n2-j(x) log n

|fn(j(x),

x)

-

Ef0 fn(j(x),

x)|

+ sup
0<x1

n2-j(x) log n

|Ef0 fn(j(x),

x)

-

f0(x)|



Ef0

sup
0<x1

max
jjmax

n2-j log n

|fn(j,

x)

-

Ef0 fn(j,

x)|

+ max sup
m xIjmax,m

n2-j log

(x)
n

|Ef0

fn

(j



(x),

x)

-

f0

(x)|.

The first term is bounded by a fixed constant using Proposition 2 below. Recalling the definition of jm from the beginning of the proof of Theorem 1 and choosing j,x(f0) from Lemma 2, the second term is bounded by

max
m

n2-jm log n

sup
xIjmax ,m

|Ef0 fn(jm , x)

-

f0(x)|

 max
m

n2-jm log n

Kjm ,x(f0) - f0





 ,

M

where x is any point in Ijmax,m, and this completes the proof. We next prove Theorem 3: Using the hypotheses on t(∑), L(∑), (∑), the proof of
Lemma 3 shows that f0 satisfies Condition 2 with

j,x(f0) = c 2-j(2t(x)+1),

(14)

0 < c < , where c does not depend on x. Using that t(∑) is bounded below by some positive number implies that

jmax,x(f0)

=

c

2-jmax(2t(x)+1)



 log n .
n

holds for n large enough (independent of x  (0, 1]), so that j(x), when based on j,x(f0) as in (14), is asymptotically equivalent to the minimax optimal locally adaptive

15

rate, uniformly so for all x.

3.3 Proof of Lemma 1
The proof relies on Propositions 1 and 2 which are given below. Recall first from Section 2.1 that for f  Vj,k and j  j we necessarily have Ef fn(j , x) - f (x) = 0 for every x  Ij,k, so the bias at x  Ij,k is exactly zero, a fact we shall use repeatedly below without separate mentioning. Write

sup max n2-j f^n(j , x) - fn(j , x)

xIjmax,m j j log n

sn(j , x)

= sup max
xIjmax,m j j

n2-j log n
l>j

fn(l, x) - fn(j , x) sn(j , x)

1{^jn(j ,x)=l}.

To treat the indicator, observe that

(15)

{^jn(j , x) = l}  n2-l |fn(l , x) - fn(l - 1, x)| > n fn(l - 1, x) for some l  l
  n2-l |fn(l , x) - Ef fn(l , x) + Ef fn(l - 1, x) - fn(l - 1, x)|

f (x) > n 2 for some l  l

f (x)

 min fn( , x) 
j

2

Observe that the first set is a subset of

 n2-l

fn(l , x) - Ef fn(l , x)

 n

f (x) for some l  l 4



n2-(l-1) |fn(l - 1, x) - Ef fn(l - 1, x)| > n

f (x) 4





n

 max  j

n2-

fn( ) - Ef fn( ) Ijmax,m >

 f Ij,k(m) 4 =: B1


16

 and that, using y  y for y  , the second set is contained in

max |fn(
j

, x) - Ef fn(

, x)|

>

f (x) 2

f (x)



max |fn(
j

, x) - Ef fn(

, x)|

>

2


  sup |fn( , x) - Ef fn( , x)| >
xIjmax,m, j

  f Ij,k(m)
2 := B2; 

so that {^jn(j , x) = l}  B1  B2 =: B, a set which does not depend on j , x or l. Hence,

1{^jn(j ,x)=l}  1B uniformly in j , x, l, so that the quantity in (15) is bounded from above by

1B sup max
xIjmax,m j j

n2-j

fn(l, x) - fn(j , x) ,

log n
l>j

sn(j , x)

and therefore the second moment of (15) is bounded, using the Cauchy-Schwarz inequality, by

Prf (B)1/2 sup max
xIjmax,m j j

n2-j log n
l>j

fn(l, x) - fn(j , x) sn(j , x)

2
=: I ◊ II.
4,Prf

We first bound II: By the triangle inequality and since the bias is exactly zero, this term is less than or equal to

2 sup max
xIjmax,m j j

n2-j log n
l>j

fn(l, x) - Ef fn(l, x) sn(j , x)

2 4,Prf

+2 sup max
xIjmax,m j j

n2-j

fn(j , x) - Ef fn(j , x)

log n
l>j

sn(j , x)

2
.
4,Prf

(16)

17

Define now S = {supxIjmax,m minj j fn(j , x)  /2}. Note that, by definition of fn(j ), fn(j , x) > 0 implies fn(j , x)  2j /n. Then, for every 1  p < ,

1

Ef

sup max xIjmax,m j j sn(j , x)

 23p/2-1 p/2

p
= Ef

p

1

sup
xIjmax ,m

max
j j

sn(j

,

x) (1S

+

1Sc )

+2p-1np/2Ef 1

sup
xIjmax ,m

min |fn(j
j j

, x)

-

Ef fn(j

, x)

+

f (x)|

<

 2



23p/2-1 p/2

+

2p-1np/2Prf



sup
xIjmax,m, j

|fn(j
j

, x)

-

Ef fn(j

, x)|

>

2



23p/2-1 p/2

+2p-1np/2Prf

sup
xIjmax,m, j

 n2-j
j

|fn(j

, x) - Ef fn(j

, x)|

>

  d log n
2



23p/2-1 p/2

+

2p-1np/2cn-

2d 4c

log

n

for large n in view of Proposition 1 (using that 2-jmax  d(log n)2/n), so that this expectation is bounded uniformly in n by some constant c1(p, , M ). Using this, the Cauchy-Schwarz inequality and Proposition 2, the square of the first term in (16) is less than or equal to

c222jmax jm4 ax 
◊Ef  sup max
xIjmax,m lj

4

n2-l log n

|fn(l,

x)

-

Ef

fn(l,

x)|

sup
xIjmax ,m

max
lj

1 sn(j

,

x)







c222jmax jm4 ax

Ef

 sup
xIjmax ,m

max
lj

81/2

n2-l log n

|fn(l,

x)

-

Ef

fn(l,

x)|



 ◊ Ef

1 sup max xIjmax,m lj sn(l, x)

81/2   c322jmax jm4 ax;

and the same reasoning also implies that the second term in (16) is less than or equal to some constant, so that we can conclude, using the lower bound of 2-jmax, that

II  c4n

(17)

18

for some fixed constant c4 that depends only on  and M . To bound I, we have the following: First, using Proposition 1 below, we see





n

Prf (B1)

=

Prf

max  j

n2-

fn( ) - Ef fn( ) Ijmax,m >



Dn-

2  4D

 f Ij,k(m) 4
(18)

for large n, with D only depending on M . Furthermore, using 2-jmax  d(log n)2/n and Proposition 1 below,

Prf (B2)


  Prf sup n2- |fn( , x) - Ef fn( , x)| >
xIjmax,m, j



Dn-

d2 4D

log

n

 d f Ij,k(m) log n 
2

for large n. Thus, choosing  large enough but finite depending on the choice of , we obtain for n large enough

I ◊ II  c4Dn

n-

2  4D

+

n-

d2 4D

log n



 n22jmax .

This completes the proof.

3.4 Uniform-in-bandwidth bounds for Haar wavelet density estimators and some consequences
The following exponential inequality was used repeatedly in the proofs.

Proposition 1 Let jmax  N such that 2-jmax  d(log n)2/n. Let I = (2-jk, 2-j(k + 1)] for some j  jmax and k  Z, and suppose f : R  [0, ) is a density that satisfies
f I  M and inf f (x)   > 0.
xI

There exist constants C1(d), C2(d) and an index n(, M ) such that for all n  n(, M ) and all C3  C2(d), if

 C1(d) f I log n  u  C3 f I n2-jmax ,

(19)

19

then

Prf

sup

max

 n2-j |fn(j , x) - Ef fn(j , x)|  u



De-

u2 D

,

xI jj jmax

where D only depends on C3 and M .

Proof. Writing



n2-j fn(j , x) - Ef fn(j , x)

=2

 2jmax 2j -jmax
n2

n
(K(2j x, 2j Xi) - Ef K(2j x, 2j Xi)) ,

i=1

we have to consider the supremum

2

2jmax sup
n hH

n
(h(Xi) - Ef h(Xi))
i=1

of the (scaled) empirical processes indexed by the class of functions

H :=

 2j -jmax K(2j x, 2j (∑)) : x  I, j  j . 2

This class has constant envelope 1/2 since j  jmax and since supx,y |K(x, y)| = 1. Furthermore, noting that K2(x, y) = K(x, y) for every x, y, we have for h  H that

Ef h2(X)

=

2j -jmax 4

K2(2j x, 2j y)f (y)dy

=

2j -jmax 4

2-j

(k(x)+1)
f (y)dy



2-jmax

2-j k(x)

4

f

I.

Note further that H is a VC-type class of functions by using Lemma 2 in [7] and a simple computation on covering numbers (including an obvious covering of the set [2-jmax, 1] 
[0, 1]). Rewrite



Prf sup max n2-j |fn(j , x) - Ef fn(j , x)|  u

xI jj jmax
n
= Prf sup (h(Xi) - Ef h(Xi))
hH i=1

  u n2-jmax
2

20

and apply expression (21) in [8], with

2 := 2-jmax f I  1 44

and



c1(d)  :=

log n

f I log

n fI

if f I  1,

c2(d)

otherwise;

for appropriate constants c1(d), c2(d) that only depend on d.

Proposition 2 Let jmax, I and f be as in Proposition 1. Then there exists a constant D(d, , M ) such that for every 1  p <  we have

 Ef sup max
xI jj jmax

p

n2-j log n

fn(j , x) - Ef fn(j , x) 

 Dp.

(20)

Proof. The proof follows from considering the same empirical process as in the proof of Proposition 1, and using bounds for p-th moments of empirical processes indexed by uniformly bounded VC-classes of functions, e.g., the bound in the display following (21) in [8], with 2 and  as in the proof of Proposition 1, together with Proposition 3.1 in [5].

References
[1] Donoho, D. L. and Johnstone, I. M. (1994). Ideal spatial adaptation by wavelet shrinkage. Biometrika 81 425-455.
[2] Donoho, D. L.; Johnstone, I. M.; Kerkyacharian, G.; and Picard, D. (1995). Wavelet shrinkage: asymptopia? J. Roy. Statist. Soc. Ser. B 57 301-369.
[3] Donoho, D. L.; Johnstone, I. M.; Kerkyacharian, G.; and Picard, D. (1996). Density estimation by wavelet thresholding. Ann. Statist. 24 508-539.
[4] Gine¥, E. and Guillou, A. (2002). Rates of strong uniform consistency for multivariate kernel density estimators. Ann. Inst. H. Poincar¥e Probab. Statist. 38 907921.

21

[5] Gine¥, E.; Latala, R.; and Zinn, J. (2000). Exponential and moment inequalities for U -statistics. In: High Dimensional Probability II (eds. E. Gin¥e, D. Mason, J. A. Wellner), 13-38.
[6] Gine¥, E. and Nickl, R. (2009). An exponential inequality for the distribution function of the kernel density estimator, with applications to adaptive estimation. Probab. Theory Related Fields 143 569-596.
[7] Gine¥, E. and Nickl, R. (2009). Uniform limit theorems for wavelet density estimators. Ann. Probab. 37 1605-1646.
[8] Gine¥, E. and Nickl, R. (2010). Adaptive estimation of a distribution function and its density in sup-norm loss by wavelet and spline projections. Bernoulli, 16 1137-1163.
[9] Goldenshluger, A. and Lepski, O. (2009). Structural adaptation via Lp-norm oracle inequalities. Probab. Theory Related Fields 143 41-71.
[10] Ha®rdle, W.; Kerkyacharian, G.; Picard, D.; and Tsybakov, A. (1998). Wavelets, approximation, and statistical applications. Lecture Notes in Statistics 129. Springer, New York.
[11] Jaffard, S. (2000). On the Frisch-Parisi conjecture. J. Math. Pures Appl. 79 525552.
[12] Lepski, I.; Mammen, E.; and Spokoiny, V. (1997). Optimal spatial adaptation to inhomogeneous smoothness: an approach based on kernel estimates with variable bandwidth selectors. Ann. Statist. 25 929-947.
[13] Polzehl, J. and Spokoiny, V. (2006). Propagation-separation approach for local likelihood estimation. Probab. Theory Related Fields 135 335-362.
[14] Spokoiny, V. and Vial, C. (2009) Parameter tuning in pointwise adaptation using a propagation approach. Ann. Statist. 37 2783-2807.
22

SFB 649 Discussion Paper Series 2011
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "Localising temperature risk" by Wolfgang Karl H‰rdle, Brenda LÛpez Cabrera, Ostap Okhrin and Weining Wang, January 2011.
002 "A Confidence Corridor for Sparse Longitudinal Data Curves" by Shuzhuan Zheng, Lijian Yang and Wolfgang Karl H‰rdle, January 2011.
003 "Mean Volatility Regressions" by Lu Lin, Feng Li, Lixing Zhu and Wolfgang Karl H‰rdle, January 2011.
004 "A Confidence Corridor for Expectile Functions" by Esra Akdeniz Duran, Mengmeng Guo and Wolfgang Karl H‰rdle, January 2011.
005 "Local Quantile Regression" by Wolfgang Karl H‰rdle, Vladimir Spokoiny and Weining Wang, January 2011.
006 "Sticky Information and Determinacy" by Alexander Meyer-Gohde, January 2011.
007 "Mean-Variance Cointegration and the Expectations Hypothesis" by Till Strohsal and Enzo Weber, February 2011.
008 "Monetary Policy, Trend Inflation and Inflation Persistence" by Fang Yao, February 2011.
009 "Exclusion in the All-Pay Auction: An Experimental Investigation" by Dietmar Fehr and Julia Schmid, February 2011.
010 "Unwillingness to Pay for Privacy: A Field Experiment" by Alastair R. Beresford, Dorothea K¸bler and Sˆren Preibusch, February 2011.
011 "Human Capital Formation on Skill-Specific Labor Markets" by Runli Xie, February 2011.
012 "A strategic mediator who is biased into the same direction as the expert can improve information transmission" by Lydia Mechtenberg and Johannes M¸nster, March 2011.
013 "Spatial Risk Premium on Weather Derivatives and Hedging Weather Exposure in Electricity" by Wolfgang Karl H‰rdle and Maria Osipenko, March 2011.
014 "Difference based Ridge and Liu type Estimators in Semiparametric Regression Models" by Esra Akdeniz Duran, Wolfgang Karl H‰rdle and Maria Osipenko, March 2011.
015 "Short-Term Herding of Institutional Traders: New Evidence from the German Stock Market" by Stephanie Kremer and Dieter Nautz, March 2011.
016 "Oracally Efficient Two-Step Estimation of Generalized Additive Model" by Rong Liu, Lijian Yang and Wolfgang Karl H‰rdle, March 2011.
017 "The Law of Attraction: Bilateral Search and Horizontal Heterogeneity" by Dirk Hofmann and Salmai Qari, March 2011.
018 "Can crop yield risk be globally diversified?" by Xiaoliang Liu, Wei Xu and Martin Odening, March 2011.
019 "What Drives the Relationship Between Inflation and Price Dispersion? Market Power vs. Price Rigidity" by Sascha Becker, March 2011.
020 "How Computational Statistics Became the Backbone of Modern Data Science" by James E. Gentle, Wolfgang H‰rdle and Yuichi Mori, May 2011.
021 "Customer Reactions in Out-of-Stock Situations ≠ Do promotion-induced phantom positions alleviate the similarity substitution hypothesis?" by Jana Luisa Diels and Nicole Wiebach, May 2011.
SFB 649, Spandauer Str. 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

SFB 649 Discussion Paper Series 2011
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
022 "Extreme value models in a conditional duration intensity framework" by Rodrigo Herrera and Bernhard Schipp, May 2011.
023 "Forecasting Corporate Distress in the Asian and Pacific Region" by Russ Moro, Wolfgang H‰rdle, Saeideh Aliakbari and Linda Hoffmann, May 2011.
024 "Identifying the Effect of Temporal Work Flexibility on Parental Time with Children" by Juliane Scheffel, May 2011.
025 "How do Unusual Working Schedules Affect Social Life?" by Juliane Scheffel, May 2011.
026 "Compensation of Unusual Working Schedules" by Juliane Scheffel, May 2011.
027 "Estimation of the characteristics of a LÈvy process observed at arbitrary frequency" by Johanna Kappus and Markus Reiﬂ, May 2011.
028 "Asymptotic equivalence and sufficiency for volatility estimation under microstructure noise" by Markus Reiﬂ, May 2011.
029 "Pointwise adaptive estimation for quantile regression" by Markus Reiﬂ, Yves Rozenholc and Charles A. Cuenod, May 2011.
030 "Developing web-based tools for the teaching of statistics: Our Wikis and the German Wikipedia" by Sigbert Klinke, May 2011.
031 "What Explains the German Labor Market Miracle in the Great Recession?" by Michael C. Burda and Jennifer Hunt, June 2011.
032 "The information content of central bank interest rate projections: Evidence from New Zealand" by Gunda-Alexandra Detmers and Dieter Nautz, June 2011.
033 "Asymptotics of Asynchronicity" by Markus Bibinger, June 2011. 034 "An estimator for the quadratic covariation of asynchronously observed
ItÙ processes with noise: Asymptotic distribution theory" by Markus Bibinger, June 2011. 035 "The economics of TARGET2 balances" by Ulrich Bindseil and Philipp Johann Kˆnig, June 2011. 036 "An Indicator for National Systems of Innovation - Methodology and Application to 17 Industrialized Countries" by Heike Belitz, Marius Clemens, Christian von Hirschhausen, Jens Schmidt-Ehmcke, Axel Werwatz and Petra Zloczysti, June 2011. 037 "Neurobiology of value integration: When value impacts valuation" by Soyoung Q. Park, Thorsten Kahnt, Jˆrg Rieskamp and Hauke R. Heekeren, June 2011. 038 "The Neural Basis of Following Advice" by Guido Biele, Jˆrg Rieskamp, Lea K. Krugel and Hauke R. Heekeren, June 2011. 039 "The Persistence of "Bad" Precedents and the Need for Communication: A Coordination Experiment" by Dietmar Fehr, June 2011. 040 "News-driven Business Cycles in SVARs" by Patrick Bunk, July 2011. 041 "The Basel III framework for liquidity standards and monetary policy implementation" by Ulrich Bindseil and Jeroen Lamoot, July 2011. 042 "Pollution permits, Strategic Trading and Dynamic Technology Adoption" by Santiago Moreno-Bromberg and Luca Taschini, July 2011. 043 "CRRA Utility Maximization under Risk Constraints" by Santiago MorenoBromberg, Traian A. Pirvu and Anthony RÈveillac, July 2011.
SFB 649, Spandauer Str. 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

SFB 649 Discussion Paper Series 2011
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
044 "Predicting Bid-Ask Spreads Using Long Memory Autoregressive Conditional Poisson Models" by Axel Groﬂ-Kluﬂmann and Nikolaus Hautsch, July 2011.
045 "Bayesian Networks and Sex-related Homicides" by Stephan Stahlschmidt, Helmut Tausendteufel and Wolfgang K. H‰rdle, July 2011.
046 "The Regulation of Interdependent Markets", by Raffaele Fiocco and Carlo Scarpa, July 2011.
047 "Bargaining and Collusion in a Regulatory Model", by Raffaele Fiocco and Mario Gilli, July 2011.
048 "Large Vector Auto Regressions", by Song Song and Peter J. Bickel, August 2011.
049 "Monetary Policy, Determinacy, and the Natural Rate Hypothesis", by Alexander Meyer-Gohde, August 2011.
050 "The impact of context and promotion on consumer responses and preferences in out-of-stock situations", by Nicole Wiebach and Jana L. Diels, August 2011.
051 "A Network Model of Financial System Resilience", by Kartik Anand, Prasanna Gai, Sujit Kapadia, Simon Brennan and Matthew Willison, August 2011.
052 "Rollover risk, network structure and systemic financial crises", by Kartik Anand, Prasanna Gai and Matteo Marsili, August 2011.
053 "When to Cross the Spread: Curve Following with Singular Control" by Felix Naujokat and Ulrich Horst, August 2011.
054 "TVICA - Time Varying Independent Component Analysis and Its Application to Financial Data" by Ray-Bing Chen, Ying Chen and Wolfgang K. H‰rdle, August 2011.
055 "Pricing Chinese rain: a multi-site multi-period equilibrium pricing model for rainfall derivatives" by Wolfgang K. H‰rdle and Maria Osipenko, August 2011.
056 "Limit Order Flow, Market Impact and Optimal Order Sizes: Evidence from NASDAQ TotalView-ITCH Data" by Nikolaus Hautsch and Ruihong Huang, August 2011.
057 "Optimal Display of Iceberg Orders" by Gˆkhan Cebirolu and Ulrich Horst, August 2011.
058 "Optimal liquidation in dark pools" by Peter Kratz and Torsten Schˆneborn, September 2011.
059 "The Merit of High-Frequency Data in Portfolio Allocation" by Nikolaus Hautsch, Lada M. Kyj and Peter Malec, September 2011.
060 "On the Continuation of the Great Moderation: New evidence from G7 Countries" by Wenjuan Chen, September 2011.
061 "Forward-backward systems for expected utility maximization" by Ulrich Horst, Ying Hu, Peter Imkeller, Anthony RÈveillac and Jianing Zhang.
062 "On heterogeneous latent class models with applications to the analysis of rating scores" by AurÈlie Bertrand and Christian M. Hafner, October 2011.
063 "Multivariate Volatility Modeling of Electricity Futures" by Luc Bauwens, Christian Hafner and Diane Pierret, October 2011.
SFB 649, Spandauer Str. 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

SFB 649 Discussion Paper Series 2011
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
064 "Semiparametric Estimation with Generated Covariates" by Enno Mammen, Christoph Rothe and Melanie Schienle, October 2011.
065 "Linking corporate reputation and shareholder value using the publication of reputation rankings" by Sven Tischer and Lutz Hildebrandt, October 2011.
066 "Monitoring, Information Technology and the Labor Share" by Dorothee Schneider, October 2011.
067 "Minimal Supersolutions of BSDEs with Lower Semicontinuous Generators" by Gregor Heyne, Michael Kupper and Christoph Mainberger, October 2011.
068 "Bargaining, Openness, and the Labor Share" by Dorothee Schneider, October 2011.
069 "The Labor Share: A Review of Theory and Evidence" by Dorothee Schneider, October 2011.
070 "The Power of Sunspots: An Experimental Analysis" by Dietmar Fehr, Frank Heinemann and Aniol Llorente-Saguer, October 2011.
071 "Econometric analysis of volatile art markets" by Fabian Y. R. P. Bocart and Christian M. Hafner, October 2011.
072 "Financial Network Systemic Risk Contributions" by Nikolaus Hautsch, Julia Schaumburg and Melanie Schienle, October 2011.
073 "Calibration of self-decomposable LÈvy models" by Mathias Trabs, November 2011.
074 "Time-Varying Occupational Contents: An Additional Link between Occupational Task Profiles and Individual Wages" by Alexandra Fedorets, November 2011.
075 "Changes in Occupational Demand Structure and their Impact on Individual Wages" by Alexandra Fedorets, November 2011.
076 "Nonparametric Nonstationary Regression with Many Covariates" by Melanie Schienle, November 2011.
077 "Increasing Weather Risk: Fact or Fiction?" by Weining Wang, Ihtiyor Bobojonov, Wolfgang Karl H‰rdle and Martin Odening, November 2011.
078 "Spatially Adaptive Density Estimation by Localised Haar Projections" by Florian Gach, Richard Nickl and Vladimir Spokoiny, November 2011.
SFB 649, Spandauer Str. 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

