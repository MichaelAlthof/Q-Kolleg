BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2016-013
The importance of timevarying parameters
in new Keynesian models with zero lower bound
Julien Albertini* Hong Lan*²
* Humboldt-Universität zu Berlin, Germany *² University of International Business and Economics (Beijing),
People's Republic of China This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universität zu Berlin Spandauer Straße 1, D-10178 Berlin

The importance of time-varying parameters in new Keynesian models with zero lower
bound

Julien Albertini
HUMBOLDT UNIVERSITY

Hong Lan
UIBE, BEIJING

March 7, 2016
Abstract

In this paper we question the ability of New Keynesian models to reproduce the behavior of the nominal interest rate. In particular, we wonder if the model is able to reproduce infrequent but long ZLB spells as observed in the data. Starting from the canonical model, we compare alternative specifications like exogenous and endogenous time-varying parameters. We solve the different models with global approximation methods and estimate them using the simulated method of moments. While the canonical model fails to reproduce typical ZLB spells, the endogenous time-varying parameters specification seems to be a promising avenue for research. We draw the implications of the alternative model's specifications for the understanding of the monetary policy during ZLB episodes.

Keywords: New Keynesian model, ZLB, Time-varying parameters, Method of moments.

JEL Classification: E3, J6

1 Introduction

Following the Great Recession, several central banks slashed interest rates close to zero like the FED, the European Central Bank, the Bank of Canada,

Corresponding author.

Email address: albertij@cms.hu-berlin.de, Tel.:

+493020935710. Spandauer Str. 1, 10178 Berlin

lanhongken@gmail.com Tel.: +49302093 1466. We wish to thank Michael Burda, Simon

Voight, Maren Brede and seminar participants at Humboldt University and Rennes 1 Univer-

sity for fruitful comments and suggestions. Finally, we thank Thomas Dengler for the proof-

reading of the article. This research was supported by the Deutsche Forschungsgemeinschaft

through the SFB 649 "Economic Risk". The usual disclaimer applies.

1

the Bank of England, etc (see Figure 1). Despite little experiences with liquidity traps, it is fairly easy to see that ZLB episodes (1) have occurred relatively few in the past and (2) may have long durations1. These two moments are difficult to reproduce in new Keynesian models with a Taylor rule. The major reason is that having a model able to reproduce the inflation and the output dynamics - the two major inputs in the Taylor rule - implies relatively short ZLB spells. Huge demand shocks or a long sequence of bad shocks are required to produce long ZLB spells but at the expense of a dramatic fall in output and inflation that are inconsistent with the data. The US nominal interest rate under the unconventional monetary policy is one of the recent examples. To circumvent the disconnection between the observed rate and the outcome of the Taylor rule, many alternative specification have been proposed in past research but most of them concern periods where the nominal interest rate was not binding.

Rate in %

Rate in %

20 Canada
United Kigdom
15

10

5

0 1980
15

1990

2000

2010

Rate in % Rate in %

12 10 8 6 4 2 0 1980

1990

Euro Sweden
2000 2010

United States

8

15 Switzerland Denmark
10
5
0 1980 1990 2000 2010
Japan

Rate in %

6 10
4 5
2

0 1940 1950 1960 1970 1980 1990 2000 2010

0 1960 1970 1980 1990 2000 2010

Figure 1: Nominal interest rate. Canada: BOC key interest rate, US: 3-month treasury bill, Euro: ECB refinancing rate, Sweden: Riksbank reposits rate, UK: BoE Official Bank Rate, Japan: BoJ overnight call rate, Switzerland: 3 month LIBOR rate CHF, Denmark: Nationalbanken lending rate.
1See also Hamilton et al. (2015) for a discussion on the interest rate in OECD countries since the 19th century.

2

The novelty of this paper is to question whether the invariant structure of parameters in the new Keynesian model, and particularly those belonging to the feedback interest rate rule, is responsible for the models' inability to reproduce infrequent but long ZLB spells. We wonder how important are the time varying parameters when we fit the model to the data. Do time varying parameters matter for explaining the cyclical behavior of the nominal interest rate when it binds occasionally? To answer these questions, we consider the canonical New Keynesian model with the ZLB constraint on the nominal interest rate and introduce several alternative specifications: exogenous (drifting) and endogenous time-varying parameters. We solve the nonlinear model with global approximation methods and estimate parameters using the simulated method of moments over a sample covering the ZLB episode in the thirties and/or the one starting in 2008Q. We target a broad range of moments (57 moments) including moments up to order four, cross-lagged correlation and specific moments characterizing the ZLB.
Our major results are the following. The canonical New Keynesian model is able to reproduce several moments, including the proportion over time the nominal interest rate is stuck at the ZLB. However, the model fails to match the average duration of a ZLB spell, even if some spells last more than 20 quarters. We embed exogenous drifting parameters on inflation target and the response of the interest rate to inflation and output growth. We show that while it increase the duration of ZLB spells, it does perform way better than the canonical version. Thereafter, we consider endogenous time-varying parameters according. ZLB episodes are longer and less frequent in line with the empirical counterparts. It performs better in matching the data and, contrary to the other models, it is able to forecast the US prolonged ZLB spells from the middle 2009 to 2015.
Related literature
Several papers document the time-variant structure of the Taylor rule and models' parameters. Fernández-Villaverde & Rubio-Ramírez (2008) and Fernández-Villaverde et al. (2010) questioned the fit of the new Keynesian model under time-invariant parameters. They show that there is overwhelming evidence of changes in monetary policy during the last decades and that stochastic volatility matters for explaining variation in aggregate volatility. Liu et al. (2011) and Bianchi (2013) consider a DSGE model where parameters evolve according to a markov-switching process. They show that a framework that incorporates regime-switching in shock variances and in the inflation target fits better the U.S. time-series data. More recently, Canova & Ferroni (2015) investigate the impact of parameter variations on the decision rules of an estimated DSGE model. By comparing time-invariant structures to a structure allowing for variations in exogenous and endogenous parameters they find
3

that the latter may have a strong influence on the dynamics in response to a structural shock. Furthermore, they highlight the important misspecifications of time-invariant structures when estimating the structural model.
The burgeoning literature on volatility shocks known as risk shocks or uncertainty shocks reflects the crucial role of drifting parameter in explaining business cycle dynamics. As documented in Blanchard & Simon (2001), Stock & Watson (2003), Sims & Zha (2006), Justiniano & Primiceri (2008), Bloom (2009), Fernandez-Villaverde et al. (2011) and many others, the volatility of employment growth, consumption growth and output of the U.S. economy from 1984 to 2007 has evidently declined by one third compared to their values during the 1970s and early 1980s. Nominal volatilities also have declined by more than half. This period of volatility reduction in aggregate time series, often labeled as the Great Moderation, motivates the study of its causes. The literature thus far offers three main ways of modeling, and therefore analyzing this volatility shift: i) stochastic volatility, i.e., model the volatility of the exogenous processes under investigation as an autoregressive process, or ii) a GARCH process, or iii) the volatility switches between two (or more) states, i.e., Markov regime switching models. As pointed out by Fernandez-Villaverde et al. (2011), stochastic volatility can capture many important features of the empirical volatility shift and differentiates the special effect of volatility from others. This approach has been adopted in many studies.
However, despite considerable efforts on the study of time varying structures, most of the studies have not considered the presence of the ZLB while it can fundamentally affect the way parameters vary over the cycle and therefore the propagation mechanism. In a pioneering paper Krugman (1998) reexamine the theory of liquidity traps in light of the Japanese slump. He shows that such a situation lead to unconventional conclusion in macroeconomic models. Eggertsson & Woodford (2003) argue that the zero bound can be a significant constraint on the ability of a central bank to combat deflation and therefore on the optimal monetary policy.
Three papers are very closely related to our study. Gust et al. (2012) use Bayesian techniques to estimate the non-linear version of the new Keynesian model with ZLB in order to quantify the lower bound's role in exacerbating the Great Recession. While they rely on nonlinear procedure to solve and estimate the model, they do not consider time varying parameters at all. Aruoba et al. (2013) do consider regime-switching in the Central Bank inflation target but do not estimate the model on a period where the nominal interest rate was stuck at the ZLB. We aim instead at understanding how the ZLB affects structural parameters and their time-varying properties. Furthermore, we consider alternative time-varying parameters than the inflation target. In line with Chung et al. (2012), we tackle the underestimation of the probability to hit the ZLB for the ability of New Keynesian models to forecast the recent events. While they point out the role of uncertainty about models' parameters and latent vari-
4

ables, they do not provide a clear solution for DSGE models to produce long ZLB spells. In addition we consider endogenous time-varying parameters in which parameters depend on the state variables.
The literature on time-varying parameters and the ZLB are naturally connected. Our study goes one step further by bridging the gap between the recent behavior of the nominal interest rate in modern economies and the ability of the new Keynesian model to reproduce the dynamics of key macroeconomic variables. We consider alternative specifications and show how they affect the analysis of monetary policy and the forecast power of new Keynesian models.
The rest of the paper is organized as follows. Section 2 is devoted to the presentation of the New Keynesian DSGE model. Section 3 addresses the solution and estimation method. Estimation results are presented in Section 4. Simulations and counterfactual experiments are provided in Section 5. Section 6 concludes. We provide a separate appendix describing the model, the solution and the estimation method in more detail.

2 The model
We build a standard New Keynesian DSGE model with Rotemberg sticky prices, monopolistic competition and a Taylor rule on the nominal interest rate. In the baseline model (Model A), we consider three alternative source of disturbances: a discount factor shock, an output growth shock and a monetary policy shock. In model B and C, we allow for exogenous and endogenous time-varying parameters respectively.

2.1 The representative household
Households intertemporal utility is defined by:

()

t

 max E0
ct,dt,nt t=0

k
k=0

[log(ct) - nt]

(1)

where ct is aggregate consumption and nt is the level of employment supplied
by households.  denotes the risk aversion coefficient. t represents a dis-
count factor shock that we interpret as a preference shock. The representative household takes as given {pt, wt, it}t=0 and the initial wealth (d0) in order to maximize equation (1) subject to the budget constraint:

ptct + dt = dt-1(1 + it-1) + wtnt + t - Tt 5

(2)

where t are the firms' profits, dt bonds, pt the aggregate price and Tt is a
lump-sum tax. Optimality conditions are given by the following equations (with t = pt/pt-1 and wtR = wt/pt):

t = c-t 1

t

=

(1

+

it

)Et

t+1

t+1 t+1

wtR = ct

(3) (4) (5)

2.2 Firms

The final good producer operates in a perfectly competitive market. He pro-
duces a good yt using intermediate goods yjt. The demand for the intermediate good j writes:

yjt

=

(

pjt pt

)-

yt

(6)

where  is the elasticity of substitution between goods. The nominal price

index

is

defined

by

pt

=

[ 1
0

]1 p1jt-dj 1- .

There

is

a

continuum

of

monopolis-

tically competitive producers indexed by j using labor njt to produce and sell

output yjt to final good producers:

yjt = atnjt

(7)

where at is the total factor productivity evolving in the following manner:

at = Gat-1zt

(8)

and zt is an aggregate shock. Firm j maximizes its intertemporal profit (9) taking {pt, wt}t=0 as given, subject to (6) and (7):

 max
pjt,njt

E0

 t=0

(
t k=0

) k

t 0

 

pjt pt

yjt

-

wt pt

njt

-

 yt 2

( pjt
 pjt-1

-

)2 1

(9)

The price adjustment cost--governed by --is proportional to output and  is the steady state gross inflation rate. Dropping subscript j by symmetry, the optimality conditions are:

6

mct 0

= =
+

w(E1ttR-t+1)+t+t1mct t-+1(t t(+1t--1)1)yyt+t 1

(10) (11)

where mct is the Lagrange multiplier associated with (7). Equation (11) is the forward-looking New Keynesian Phillips Curve.

2.3 Monetary and fiscal authorities
We assume that the central bank adjusts the nominal interest rate following a Taylor rule (bounded by the ZLB) in response to deviations of inflation and output from their steady-state values:

1 + it

=

(1

+

it-1)i

[ G 

( t 

)

( yt y

)y ]1-i

it = max(it, 0)

(12) (13)

where  is the inflation target. In the benchmark model (Model A)  = .

2.4 Market clearing

The aggregation of individual profits t is given by: t = ptyt - ntwt -

pt yt t .

yt

[ 1

-

 2

( t 

-

)2] 1

=

ct

(14)

Since zt evolves according to a random walk, we define the stationary variables as: y~t = yt/zt, c~t = ct/zt and ~ t = tzt. After rearrangement, the equilibrium conditions write:

~ t 0

= =

(1 (1

+ -

it ) Et ) +

t+1 
 ~ t

~ t+1 -Gzt+1t(t+1t

-

) 1

~ t-1

+ =

Et y~t

[1t+-1 ~2~t+t(1

t-t+11)(2]t+1

-

) 1

y~t+1 y~t

(15)
(16) (17)

7

2.5 Aggregate shock
The aggregate shocks considered in the benchmark model follow an autoregressive process2:

t mt zt

= = =

mztt-tz--m111e¯ex1x-pp((zemxzp,tm(),t )  ,t )

with ,t  N (0, 1) with m,t  N (0, 1) with z,t  N (0, 1)

(18)

2.6 Time-varying parameters
We consider two cases: exogenous and endogenous time varying-parameters. In the first case (Model B), the drift is conducted by a two-states markov process. Let st = 1, 2 define the regime. State 1 corresponds to the normal time monetary policy and state 2 corresponds to the unconventional monetary policy. The parameters may then take two values:

{

(st) =

(1) if (2) if

st = 1 st = 2

(19)

P a transition matrix defining the probability to switch between the two states:

[]

P=

p1 1 - p2 1 - p1 p2

(20)

and pj is the transition probability P[st = j|st-1 = j]. The state st then evolves exogenously according to the transition matrix P.
In the second case (Model C), we consider that st has still two states but evolves endogenously. In particular we assume that the switch from state i
to state j is triggered by the endogenous state variable of the model i.e. the
nominal interest rate it. Formally, we consider the following representation:

{

st =

1 2

if if

it > ij it  ij

(21)

where j = 1, 2 is such that the previous state st-1 = j. For instance, starting from an initial state s0 = 1, the monetary policy parameters change if the nominal interest rate falls below a threshold i1. If that is the case, s1 = 2 and parameters revert back to their state 1 value if the nominal interest rate becomes higher than i2 (which can be different from i1). The above specification

2The monetary shock is defined as an AR(1) process since it is how we write it in the Matlab program. However, we impose zero persistence during estimation.

8

is fairly flexible and captures the potential non linear behavior of the nominal interest rate. The intuition is that a low interest rate can be reached when the desired rate it falls dramatically. The decision to switch back to the normal monetary policy rule may occur not necessarily at the same threshold, reflecting a prudential behavior of the central bank.

3 Solution and estimation method
3.1 Solution method
Several papers document the importance of global solution methods for solving models with occasionally binding constraints. Braun et al. (2012) find that local approximation methods involves spurious approximation that have crucial implications for the size of the fiscal multiplier. In this line of research, Carlstrom et al. (2014) show that the errors from a linear approximation can be huge when the model allows for a stochastic exit of the fiscal expansion. Hirose & Inoue (2013) highlight that the estimates of structural parameters can be biased in an estimated DSGE model where the existence of the ZLB is omitted in the estimation process. The ZLB can not be accurately studied using linear-approximation methods. We use instead a Parameterized Expectation Algorithm (PEA) to approximate the solution. It consists in approximating the conditional expectations of the system using Chebyshev polynomials. These parametric functions display suitable orthogonality and convergence properties to minimize the error distance approximation. We consider a third-order Chebyshev polynomial over a simulated grid. In addition, we use a Chebyshev interpolation when considering the Markov-Switching representation for time-varying parameters. A full description of the algorithm is provided in the appendix, section A.1.

3.2 Estimation method

We calibrate the elasticity of substitution between goods to 6 which gives a gross markup 1.2.  is pinned down from Equations (5) and (10) given that c = y = n = 1 at the steady state and mc = ( - 1)/ from Equation (11). We estimate the rest of the parameters. In Model A:

A = {i, , y, , ¯, , , m, z, , m, z}

which amount to 13 parameters. In Model B we have:

B

=

{A, i,




,


y

,

,

p1,

p2}

9

In Model C, the set of parameters is given by :
C = {A, i, , y, , i1, i2}
We use the simulated method of moments (hereafter SMM) to estimate the model's parameters.
3.2.1 Data
We consider three time series from the US economy: (1) the 3-month treasury bill, (2) the implicit GDP deflator and (3) the real GDP. The first one is taken in level. We apply log difference to the second and to the third to get the inflation rate and the output growth rate. The sample covers the period 1920 Q1 - 2015 Q1. By taking into consideration this long time series we benefit from further information on the behavior of the nominal interest rate at ZLB to make comparisons. Figure 2 depicts contour plots of the ergodic distributions of the interest rate and inflation on the left panel and the interest rate and output growth on the right panel. We can see that the points are located around the steady state value and low interest rate episodes are fairly uncommon.

Inflation rate (annual percent) Output growth rate (Quarterly percent)

30
20
10
0
-10
-20
-30 2 4 6 8 10 12 14 Interest rate (annual percent)

6 4 2 0 -2 -4 -6
2 4 6 8 10 12 14 Interest rate (annual percent)

Figure 2: Data points. Period 1920Q1 - 2015Q1.

3.2.2 Simulated method of moments
The general idea is to find a set of parameter values that minimize the distance between the unconditional moments of simulated series and the unconditional moments of the data. This method is particularly suitable for several
10

reasons. First, it is fairly easy to implement regarding the non-linear nature of the problem. Likelihood based-methods (Maximum likelihood and Bayesian techniques) require specific filters like the particle filter to generate artificial series for unobservable variables (see Fernández-Villaverde & Rubio-Ramírez (2008)) and evaluate the likelihood. Such a filter is computationally intensive because it requires to solve the model a huge number of times. Secondly, moments matching is relevant in light of the question at hand: is a simple New Keynesian model able to reproduce infrequent but long ZLB spells? Hence, we add to our targets a specific set of moments characterizing the ZLB. Thirdly, the SMM does not requires an identical number of exogenous shocks and endogenous variables as in the likelihood based-methods. As shown by Karamé et al. (2008), the SMM has fewer requirements and may target a large set of moments. Ruge-Murcia (2012), show that SMM is computationally efficient and delivers accurate estimates, even when the simulated series are relatively short.
We target the following moments: (a) the means, (b) the standard deviations, (c) the skewness, (d) the kurtosis, (e) up to fourth-order autocorrelation and (f) the cross-(lagged) correlations of the three variables. Furthermore, the behavior of the economy at the ZLB is characterized by (g) the probabilities to enter and to exit the ZLB, (h) the proportion over time the economy hits the ZLB and (i) the average duration of the ZLB spells. Therefore, we gauge the ability of the model to match 57 moments, a difficult task to achieve regarding the simplicity of the canonical model.
Consider the set of q parameters  and a set of p moments Mi, i = d for observed moments coming from the data and i = s for simulated moments from the model. The idea is to find the value for the q structural parameters that minimizes the distance between the set of p moments from the data and from the model. The problem writes:

^ = arg min f ()W f ()


(22)

where W stands for the weighting matrix and f (.) a function providing the difference between simulated and empirical moments.
Our estimation strategy differs from Aruoba et al. (2013) and Gust et al. (2012) in several dimensions. Indeed, the first ones estimate the structural parameters of the NK model on Japanese and US data over the pre-ZLB period i.e. until 1994Q4 for Japan and 2007Q4 for the US. For that purpose, they use the perturbation method and the Bayesian techniques, applying the particle filter (see Fernández-Villaverde & Rubio-Ramírez (2007)). Contrary to them, we rely on a full nonlinear procedure and include the ZLB spell which starts in 2008Q4 in the US. Our objective is to take into account the role of the ZLB on the estimated value of the structural parameters and the regime-switching. The second study uses global approximation and applies Bayesian methods.

11

They use a surrogate algorithm which nests in the standard linear procedure (Kalman filter) to evaluate the likelihood function and to pre-estimate the set of admissible parameters. Thereafter, the proposed parameters are considered for solving the nonlinear model and for estimation which relies on the particle filter to evaluate the likelihood function.
4 Results
4.1 Estimated parameters
The values of the parameters are given in Table 1. The first striking result is that Model A and B have roughly the same parameters3. Our results contrast with Bianchi (2013) or Liu et al. (2011) who found - albeit in a different model - a large gap between the values of monetary policy parameters in the two regimes. One of the potential explanation is that our estimation procedure relies on the simulated method of moments which target unconditional moments and include the ZLB episodes. Therefore, having an additional independent and exogenous shock for the regime switching process does not help much more because regime shift are triggered randomly over the cycle. If we think that the regime switching are rather endogenously determined and triggered when the nominal interest rate falls dramatically, then switching to a regime during economic bursts lowers the ability of the model to match the ZLB moments. We come back later on this result.
The estimated value of the discount factor is relatively high in the three cases and the steady state inflation and output growth point toward a mild 1.5-2 percent value at annual rate. In the three models, the estimation implies a very low price rigidity, less than 40. For instance, in the log-linearized Phillips curve, the value p = 90 corresponds to the traditional Calvo parameter of 0.75 when  = 6. The standard deviation of the shocks are in line with standard values in the literature. The volatility of the demand shock is found to be around 0.005 in model A and B and equal to 0.006 in model C. While the standard deviation of output growth shock is as high as the discount factor in model A and B, it is half the size in model C. Similarly, the endogenous time-varying parameter model seems to require less volatility in the monetary shock. The estimation also implies a strong persistence of the discount factor shock as compared to the other shocks but the output growth shock is shown to be more persistent in the model C.
3Our initial guest for Model B parameters in the estimation algorithm was the estimated value of Model A. Nonetheless the algorithm explore different values and we also use different values to initialize the parameters.
12

Variables
Discount factor Steady inflation Steady output Growth Price rigidity Std discount shock Std ouptut growth shock Std monetary shock AC(1) discount shock AC(1) output growth shock AC(1) monetary shock Interest rate persistence Response to inflation Response to output Interest rate persistence 2
Response to inflation 2
Response to output 2
Target inflation 2 Prob(st = 1|st-1 = 1) Prob(st = 2|st-1 = 2) Threshold in state 1 Threshold in state 2

Symbol
 
G p  z m  z m i  y 
i



y

p1 p2 i1 i2

Model A
0.999 1.004 1.004 35.90 0.005 0.005 0.002 0.850 0.083 0.100 0.516 1.458 0.207
-
-
-
-

Model B
0.999 1.004 1.004 36.08 0.005 0.005 0.003 0.850 0.084 0.100 0.519 1.460 0.209 0.520
1.460
0.210
1.0044 0.552 0.446
-

Model C
0.998 1.005 1.004 40.005 0.006 0.003 0.001 0.820 0.501 0.098 0.199 1.401 0.250 0.980
1.503
0.249
1.020 -
0.000 0.001

Table 1: Estimated structural parameters. Model A: benchmark model, Model B: exogenous time-varying parameters, Model C: endogenous time-varying parameters. The targeted inflation in regime 1 is the steady state inflation 

Last but not least, the monetary and the regime switching parameters differ substantially in the three models. While the interest rate persistence is at the middle of standard values in calibration exercises in Model A and B, it is found to be very low in regime of Model C. However, in the latter, the persistence increases up to 0.98 in regime 2, leading to an average balanced value. The response to inflation and output deviation are similar among the three models and do not exhibit a significant change between regime one and two. On the other side the inflation target is the same among the regimes in model B while it strongly differs in model C. Its value is found to be way higher4 than in regime 1. This result push in favor of an endogenous time-varying inflation target and not only a time-varying response of the interest rate to inflation and output as in Bianchi (2013). The Model B implies a slight difference in the transition probabilities with regime 1 being more likely than regime 2. In
4Since the inflation target appears two times in the Taylor rule, the overall coefficient is 1/-1 which is a decreasing function of . Therefore, when  is high the inflation target is low since  > 1.

13

model C the interest rate thresholds are centered around the ZLB. The switch from regime one to regime two is at the ZLB while the threshold is a bit higher in the opposite direction. This last result implies a small prudential policy characterized by the will to keep low interest rate for a prolonged period of time when the regime two is visited.
4.2 Moments comparisons
We now discuss the model's ability in reproducing key moments of macroeconomic variables. Results are shown in Table 4.2, Figure 3 and 4 and Table 3. Since Model A and B are strongly similar, we only present and discuss the simulations from Model A and C and report in the separate appendix the simulations form Model B.
The models matches well the observed behavior of the nominal interest rate in terms of mean and volatility. The skewness is of the right sign and the kurtosis is fairly close in the short sample. The confidence interval of the kurtosis does not encompasses the observed value for the long sample but is not completely away from the observed value. On the other side, the persistence is not as high as in the data either in Model A or Model C.
The model has more difficulties to reproduce the cyclical behavior of inflation and output growth. The model assign zero probabilities in capturing the observed mean of t and yt albeit the confident interval are not so far in model C. The volatility of inflation implied by the model is almost five time lower than the observed one over the sample. This is not surprising regarding the record of huge inflation during the fifties and, to some extent, during the seventies. The data are more stable since the eighties, easing the model to generate sufficient volatility of inflation. On the other side, the volatility of output growth is more easily reproduced, especially in model A.
The skewness is shown to be of the right sign for inflation in Model A while Model C assign more probability to a positive skewness. Model A and C assign both a positive skewness for output but the credible set does not rule out a negative one. The tail of the distribution shows that inflation is widely spread in the data, a target that is difficult to match in the model. The models slightly underpredicts the kurtosis of output growth.
Interestingly, the correlations are not so bad regarding the simplicity of the models. Model A did a good job in reproduction the cross-lagged correlation between inflation and output growth as well as the correlation between interest rate and output growth. The correlation between interest rate and inflation has the good shape but is too strong when compared to the data. In Model C, the three types of correlations are well reproduced. Last but not least the persistence are well reproduced except for the output growth. One of the reason is that the model does not have any mechanism that cause sluggish adjustments
14

of output like habits in consumption.

Variables

Data 1921Q1-2015Q1

Model A

MEAN

it 3.48 3.11

[ 2.46, 4.13]

t 2.61 1.20

[ 0.79, 1.70]

yt 3.44 1.92

[ 1.70, 2.15]

STANDARD DEVIATION

it 3.02 2.60

[ 2.16, 3.03]

t 5.16 1.48

[ 1.06, 1.87]

yt 2.03 1.73

[ 1.49, 2.00]

SKEWNESS

it 1.02 0.53

[ 0.09, 0.96]

t

-0.55

-1.21

[ -1.90, -0.36]

yt

-0.73

0.07

[ -0.27, 0.45]

KURTOSIS

it 4.24 2.61

[ 1.87, 3.63]

t

13.74

6.01

[ 3.04, 9.94]

yt 6.68 4.20

[ 3.07, 5.58]

F 143.433

dist 0.555

Model B
3.10
[ 2.45, 4.14 ]
1.19
[ 0.77, 1.70 ]
1.93
[ 1.72, 2.17 ]
2.62
[ 2.17, 3.06 ]
1.50
[ 1.07, 1.89 ]
1.76
[ 1.51, 2.04 ]
0.55
[ 0.10, 0.96 ]
-1.22
[ -1.91, -0.37]
0.07
[ -0.27, 0.45 ]
2.61
[ 1.88, 3.64 ]
6.00
[ 3.04, 9.95 ]
4.21
[ 3.08, 5.61 ]
142.376 0.553

Model C
3.51
[ 2.34, 4.78 ]
2.20
[ 1.94, 2.45 ]
1.70
[ 1.46, 1.96 ]
2.96
[ 2.41, 3.40 ]
0.97
[ 0.76, 1.22 ]
1.30
[ 1.13, 1.51 ]
0.41
[ -0.07, 1.07 ]
0.27
[ -0.48, 1.00 ]
0.11
[ -0.15 0.39 ]
2.31
[ 1.84, 3.35 ]
4.13
[ 2.84, 5.75]
3.53
[ 2.90, 4.34]
130.282 0.529

Table 2: First to fourth-order moments After estimating, the model is simulated 10000
times over N = 376 quarters horizon. N being the number of observations. We keep 95% of
the moments computed on each bootstrap simulations to build confident intervals (in brackets). F stands for the F-value obtained in the estimation. It is equal to F = f ()W f (). dist = ||ms - md||/||md|| stands for the relative difference between simulated moments (ms) and data moments (md).

15

)


t

,

t+Q

Corr(i

Auto Corr(i , i )
t t-q

a) Interest rate - Inflation
1

b) Inflation - Output growth
0.4

c) Interest rate - Output growth
0.2

)

y)
t

0.8 0.1 0.2
0.6 0

,yt



,

Corr(i
t+Q


t+Q

0.4 0

Corr(

-0.1 0.2

-0.2

0

Model Data

-0.2

-0.2 -4q -3q -2q -1q 0 1q 2q 3q 4q
d) Interest rate
1

-0.4 -4q -3q -2q -1q 0 1q 2q 3q 4q
e) Inflation
0.9

-0.3 -4q -3q -2q -1q 0 1q 2q 3q 4q
f) Output growth
0.4

y)
t-q

0.8 0.3 0.8 0.7 0.2

t-q)

,

,

y
t


t

Corr(

Corr(

0.6 0.1 0.6
0.5 0

Auto

Auto

0.4 0.4 -0.1 0.3 -0.2

0.2 0.2 -0.3 -1q -2q -3q -4q -1q -2q -3q -4q -1q -2q -3q -4q
Figure 3: Correlations and autocorrelation. Model A vs data.

a) Interest rate - Inflation
0.8

b) Inflation - Output growth
0.4

c) Interest rate - Output growth
0.2

0.6
0.4
0.2
0
-0.2 Model Data
-0.4 -4q -3q -2q -1q 0 1q 2q 3q 4q
d) Interest rate
1

Corr(


t+Q

,



y)
t

0.2
0
-0.2
-0.4 -4q -3q -2q -1q 0 1q 2q 3q 4q
e) Inflation
1

Corr(i
t+Q

,

yt

)

0.1
0
-0.1
-0.2
-0.3 -4q -3q -2q -1q 0 1q 2q 3q 4q
f) Output growth
0.4

y)
t-q

0.9 0.8 0.3

t-q)



0.8 0.2 0.6

,

,

y
t


t

Corr(

Corr(

0.7 0.1

0.4 0.6

0

Auto

Auto

0.5 0.2 -0.1

0.4 0 -0.2 -1q -2q -3q -4q -1q -2q -3q -4q -1q -2q -3q -4q
Figure 4: Correlations and autocorrelation. Model C vs data.

)


t

,

Corr(it+Q

Auto Corr(i , i )
t t-q

16

We now investigate the model's ability to reproduce the spells and the frequency of ZLB episodes. Our first target is the ratio of the average time spent at the ZLB over the total observation length. The data is characterized by two major ZLB spells that are fairly distant from one another, leading to a ratio of 15%. This ratio is well reproduced by the model and even overestimated. The confident interval is wide and admits values that range from 5% to more than 30% in Model A and to more than 40% in Model C. The second target, the mean duration of a ZLB spell is 11.6 quarters in the data. It should be noted that the longest ZLB spell is about 25 quarters (Great Recession5). This target is far from being satisfied in Model A. Indeed, the model only generates a modest value of 4 quarters. In Model A, the maximum duration we obtain in our simulations lasts 28 quarters but this even is extremely unlikely as shown by the confidence interval. Model C reproduce fairly well a typical ZLB duration. The key mechanism is that the regime switching leads to a brutal decline in the inflation target together with a very persistent nominal interest rate. During a demand driven recession, the desired interest rate falls strongly thanks to the low interest rate persistence in regime 1. The regime then switches to a more prudential case (regime 2), leading to a desired interest rate below zero for a prolonged period of time. It follows that the probability to leave the zero lower bound P(it > 0|it-1 = 0) is very unlikely as in the data. In Model A and B, this statistic is around 0.23 while in the data it is estimated around 0.07. The fall in the desired interest rate below zero only lasts for a few period until the next trend reversal.
The probability to leave the ZLB is crucial for the policy analysis in DSGE models because underestimating the duration of the ZLB may lead to spurious conclusions about the conduct of monetary policy. This result echoes the study of Chung et al. (2012). They tackle the underestimation of the probability to hit the ZLB for models' ability to forecast the nominal interest rate during the Great Recession. However, from a pure frequentist perspective, this probability defined as P(it = 0|it-1 > 0), is shown to lie between one and two percent at quarterly frequencies in the data. Despite having a fairly long sample for the nominal interest rate that includes the last recession, ZLB episodes are obviously infrequent. Hamilton et al. (2015) survey the behavior of the nominal interest rate in many OECD economies back to the 19th century to 2014. Except for the US economy - which experienced a low interest rate during the late thirties - the liquidity trap is a relatively new situation. Indeed, apart from the US, none of the countries they presented hit the ZLB before the Japan economy at the end of the nineties.
The canonical New Keynesian model does a decent job in matching the
5Our data set stops in 2015 Q1 but at the time we write these lines (January 2016) the nominal interest rate seems to leave the zero floor, implying a ZLB spell of 28 quarters. This does not imply strong difference.
17

probability of entering a liquidity trap situation. It even predicts a value slightly above the observed one. Then, why should we be concerned about this statistic? We argue that the focus should be placed on the exit rate of the liquidity trap, not only the entry rate. Indeed, the simulated probability of leaving the liquidity trap in the canonical New Keynesian model is way higher than what is observed in the data, leading to short ZLB spells. To overcome this issue the proposed endogenous time-varying parameters specification did a very good job in capturing the essential feature of the ZLB.

Variables Proportion ZLB

Data 1921Q1-2015Q1
0.15

Mean ZLB duration

11.60

P(it > 0|it-1 > 0) P(it = 0|it-1 > 0) P(it > 0|it-1 = 0) P(it = 0|it-1 = 0)

0.98 0.02 0.07 0.93

Model A 0.21
[ 0.08, 0.32]
4.29
[ 2.56, 7.08]
0.94
[ 0.90, 0.97]
0.06
[ 0.03, 0.10]
0.23
[ 0.15, 0.40]
0.77
[ 0.60, 0.85]

Model B
0.22
[ 0.09, 0.33 ]
4.34
[ 2.57, 7.13 ]
0.94
[ 0.90, 0.97]
0.06
[ 0.03, 0.10]
0.23
[ 0.14, 0.39 ]
0.77
[ 0.61, 0.86 ]

Model C
0.24
[ 0.06 , 0.47 ]
11.02
[ 4.09, 27.00 ]
0.97
[ 0.94, 0.99]
0.03
[ 0.01, 0.06]
0.09
[ 0.04, 0.22]
0.91
[ 0.78, 0.96]

Table 3: ZLB moments. After estimating, the model is simulated 10000 times over N = 376
quarters horizon.N being the number of observations. We keep 95% of the moments computed on each bootstrap simulations to build confident intervals (in brackets).

Last but not least, we report two statistics that are useful for models' comparison (see the last two lines of Table ). The first statistic labeled F is at the core of estimation procedure and the algorithm consists in minimizing it. Then the lower, the better. The second one is a summary of the distance between moments from the data and from the model. It is slightly different from the first one as it does not use any weighting matrix. Not surprisingly, Model A and B are fairly similar in terms of performance. Model C however seems to be more consistent with the data and provides a better data generating process.

4.3 Fore/past-casting
As mentioned previously, the occurrence of a liquidity trap is a rare event. The use of past values to forecast the nominal interest rate makes the probability to enter and to leave the ZLB extremely unlikely, especially if the data set only covers the Great moderation. As shown by Chung et al. (2012), the difficulties encountered by central bankers and professional forecasters lies in the
18

duration of the ZLB spells. Most of the scenarios during 2009 and 2010 point toward an exit from the ZLB in the near future.
An alternative way of assessing the model's performance is to look how good it predicts the path of the variables. In particular we wonder if the model would have been able to predict the prolonged ZLB episode during the Great Recession. In order to investigate this issue, we simulate the model using the smoothed shock series until the beginning of the Great Recession. Thereafter we use a bootstrap procedure to generate potential trajectories and compare it to the observed ones. To be consistent with other studies, we start our forecast in 2009Q3. It should be noted that we use estimated parameters for this exercise. At a first glance this strategy may seem inappropriate since we use parameters estimated on a sample covering the Great Recession in order to forecast exactly the Great Recession. However, by doing so we provide the model the best information available to generate a consistent nominal interest rate trajectory. If the model is not able to make it, there is no reason to believe that without such information the model will do better. In that case, we can reject the structural model. Otherwise, it does not necessarily mean that the model is a good data generating process but it has the potential and additional tests are required.
19

Annual percent

Nominal interest rate
7 Data
6 Model median
5

5 4 3

Inflation

Annual percent

42

31

20

1 -1

0 1998 2000 2002 2004 2006 2008 2010 2012 2014 2016
Output Growth
4

-2 1998 2000 2002 2004 2006 2008 2010 2012 2014 2016

3

2

1

0

-1

-2

-3 1998 2000 2002 2004 2006 2008 2010 2012 2014 2016

Quarterly percent

Figure 5: Model projections 2009Q3 - Model A. The smoothed shock series is used until 2009Q3 to simulate the model. Thereafter, we perform a forecast from 2009Q3 to 2015Q1 using stochastic simulations in order to generate future path for the variables. We use 10000 bootstraps simulations. The light gray shaded area corresponds to the 80% confident interval and the dark gray shaded area to 50% confident interval.

20

Annual percent

Nominal interest rate
7

5

Data

6

Model median

4

Annual percent

5 3
4 2
3
1 2

10

Inflation

0 1998 2000 2002 2004 2006 2008 2010 2012 2014 2016
Output Growth
4

-1 1998 2000 2002 2004 2006 2008 2010 2012 2014 2016
Regime
2

3 1.8
2
1 1.6

Regime No

0 1.4
-1 1.2
-2

-3 1 1998 2000 2002 2004 2006 2008 2010 2012 2014 2016 1998 2000 2002 2004 2006 2008 2010 2012 2014 2016

Quarterly percent

Figure 6: Model projections 2009Q3 - Model B. The smoothed shock series is used until 2009Q3 to simulate the model. Thereafter, we perform a forecast from 2009Q3 to 2015Q1 using stochastic simulations in order to generate future path for the variables. We use 10000 bootstraps simulations. The light gray shaded area corresponds to the 80% confident interval and the dark gray shaded area to 50% confident interval.
Results are reported in Figures 5 and 6. It is shown that a prolonged period of low interest rate is rather unlikely in the canonical New Keynesian model. The simulations show that the most likely scenario in 2009Q3 is a rapid takeoff of the interest rate. A three years period of low interest rate is not ruled out with 50% chance. Due to the high standard deviation of the shocks the credible set is fairly large and allows for the scenario, albeit extremely unlikely, of a ZLB spell until 2015Q1. The projection does encompass most of the realizations of inflation at 80% chance but the most likely scenario underestimate the observed path of inflation. The same is true for output growth which returns to its normal level very quickly. On the other side, Model C predict with 100 percent chance a ZLB episode from 2009Q3 to 2012Q1. The most likely sce-

21

nario is the one we observed i.e. a ZLB episode that lasts until 2015Q1. The regime shift is detected exactly in 2009Q3. Furthermore, Model C better predicts the subsequent rise in inflation in 2012 but overestimates it for the very end of the sample.
4.4 Driving forces behind business cycle fluctuations
In this section we investigate the respective role of shocks, the ZLB and the regime switching in explaining the fluctuations of macroeconomics variables. To do that we perform several counterfactual exercises. 4.4.1 Shock decomposition Which shock better explains the path of aggregate variables? For this exercise we first extract the smoothed shock series given the observable variables. The computation is fairly straightforward because we have three shocks and three observable variables. However, since the model in highly non linear one has to rely on a Newton algorithm instead of the popular Kalman filter. As shown in Figure 7 the model has no difficulties in reproducing the exact path of the variables since 1921Q1 despite the huge volatility in inflation and output growth during the 30s and 40s.
22

Nominal interest rate
20

40

Inflation

15 20

Annual percent

Annual percent

10 0

5 -20

0 -40 1920 1940 1960 1980 2000 2020 1920 1940 1960 1980 2000 2020
Output Growth
10
Model Data 5

Quarterly percent

0

-5

-10 1920 1940 1960 1980 2000 2020
Figure 7: Time series.
Let's first analyze the behavior of the shocks. In the spirit of Fernández-Villaverde et al. (2015), the smoothed shock series we obtain from model A are depicted (see Figure 8) against the different periods at the Federal Reserve. While our model is different from their, we find similar salient features concerning the monetary shock. In particular we observe a fall in the monetary shock at the beginning of the Burns' period (70-79) and a rapid upward adjustment during the 80s and consistent with the Volcker disinflation period. We also find a more stable period during the Greenspan tenure without any major policy change. The Bernanke tenure is characterized by a drop in the monetary policy shock during the year 2008 and the subsequent periods, explaining a part of the decline in the interest rate and it's prolonged period at the ZLB. The remaining part that explains the low the interest rate lies in the rise in the discount factor shock until the Yellen tenure.
In Model C (see Figure 19) we observe a similar pattern in the shock series until the Bernanke period. The major difference is that the monetary shock is completely shut down when the interest rate reached the ZLB. In fact, the regime switching detected in 2009Q3 involves sufficient propagation mechanisms to keep the nominal interest rate at a the ZLB until 2015Q1. The model therefore need less adverse demand shocks to reproduce the nominal interest

23

rate path, which is more consistent with the US recovery since 2010.

Discount factor shock

Output Growth shock 1.08

1 1.06

0.99

1.04

0.98

1.02

0.97

1

0.96

0.98

0.95

0.96 0.94

1960 1965 1970 1975 1980 1985 1990 1995 2000 2005 2010 2015 1960

1.005

Monetary policy shock

1

1970

1980

1990

2000

2010

Burns & Miller (70-79)

0.995 0.99
0.985

Volcker (79-87) Greenspan (87-06)

0.98

Bernanke (06-14)

0.975
0.97 1960 1965 1970 1975 1980 1985 1990 1995 2000 2005 2010 2015
Figure 8: Smoothed shocks. Model A

Yellen (14-..)

24

Discount factor shock
1 0.95 0.9 0.85

1.08 1.06 1.04 1.02
1 0.98

0.96 0.8
0.94
1960 1965 1970 1975 1980 1985 1990 1995 2000 2005 2010 2015 1960
Monetary policy shock
1.01

1

0.99

0.98

0.97

0.96

0.95

Output Growth shock
1970 1980 1990 2000 2010 Burns & Miller (70-79) Volcker (79-87) Greenspan (87-06) Bernanke (06-14) Yellen (14-..)

1960 1965 1970 1975 1980 1985 1990 1995 2000 2005 2010 2015

Figure 9: Smoothed shocks. Model C

Which shock better explains the recent macroeconomic fluctuations? To address this question, we simulate the model using the smoothed shocks previously calculated. To disentangle the contribution of each shock we simulate three alternative trajectories corresponding to a single shock. Figure 10 and 11 shows that the discount shock plays a major role in explaining inflation variations, especially the mild deflation observed in 2009. The monetary shock seems to account for a small share while the output growth shock has virtually no impact on inflation. The same is true for the nominal interest rate where the path implied by the discount factor shock is close to the observed one. The monetary shock tends to reduce the nominal interest rate slightly during the ZLB spell. Finally, it seems that the output growth shock and the discount shock plays in opposite direction to produce the observed variation in output.

25

Annual percent

8 6 4 2 0
2000
4 2

Nominal interest rate
2005 2010
Output Growth

Annual percent

Inflation
4 2 0 -2

2015

2000 2005
Discount shock only Monetary shock only Output growth shock only Data

2010

2015

Quarterly percent

0

-2
2000 2005 2010 2015
Figure 10: Decomposition of shocks to the variations of the endogenous variables. Model A

26

Annual percent

Nominal interest rate

10

Discount shock only

7

8

Monetary shock only

6

Output growth shock only

Data 5
6 4

Annual percent

43

2 2
1
00

Inflation

2000 3

2005 2010
Output Growth

2015 2000 2002 2004 2006 2008 2010 2012 2014
Regime
2

2 1.8
1

Regime No

Quarterly percent

0 1.6

-1
1.4 -2

-3 1.2

-4 2002 2004 2006 2008 2010 2012 2014

1 1998 2000 2002 2004 2006 2008 2010 2012 2014 2016

Figure 11: Decomposition of shocks to the variations of the endogenous variables. Model C

4.4.2 The importance of the ZLB and regime switching
To what extent does the ZLB explain the deepness of a recession? To answer this question, we simulate the model using the smoothed shock series previously obtained but we drop the ZLB constraint. In other words we show what would have been the path of the variable if the effective rate was the desired rate. Results are reported in Figure 12 and in Figure 13. In model A and C, it seems that the ZLB does not have a strong impact on output nor on inflation. The nominal interest rate would have remained slightly below the ZLB in the two models. This results echoes to a companion paper Albertini & Poirier (2015) where we find that while the unemployment rate is strongly affected by the ZLB, the inflation rate is not impacted so much.

27

Annual percent

Nominal interest rate

Inflation

4 No ZLB Data
3
2
1
0
-1
-2 2007 2008 2009 2010 2011 2012 2013 2014
Output Growth

Annual percent

3 2 1 0 -1
2008 2009 2010 2011 2012 2013 2014 2015

1 0.5
0 -0.5
-1 -1.5
-2 2009 2010 2011 2012 2013 2014 2015

Quarterly percent

Figure 12: Counterfactual analysis. Model A

Last but not least, we wonder what is the impact of the regime switching in Model C. To investigate this issue, we perform two counterfactual analysis. In the first one we wonder what would have been the path of the variable in the absence of the time-varying parameters. In Model C we force the model to remain in the same regime, i.e. regime 1. The second case raises the question: how would have behave the variables if the regime 2 was triggered earlier? We force the model to triggered regime 2 at the very beginning of the crisis, i.e. in 2008 Q1.
The results presented in Figure 13 shows that a not having changing the monetary policy rule in 2009Q3 would have implied an economic relapse characterized by lower inflation and a deflation in 2011Q4 similar in magnitude to the one in 2009 Q2. The impact on output growth is more ambiguous. It would have been lower on average until 2011Q4 and spikes in 2012Q1. The nominal interest rate would have been about 2 pp on average and seems to fall to the ZLB at the very end of the sample.
The last case - an earlier switch to regime 2 - have opposite effects on infla-

28

tion. It would have generated much more inflation that the observed on but the resulting output growth would have been similar on average. The nominal interest rate would have hitting the ZLB earlier and would have remained low until 2015. We conclude that if goal was to avoid an economic relapse caused by a fall in inflation the monetary policy did a good job in keeping low interest rate. However, a policy reducing the interest rate to the ZLB earlier would even have been better in terms of higher inflation.

Annual percent

Nominal interest rate
5

Inflation
5

Annual percent

44
3 3
2 2
1
1 0
-1 0

-2 -1 2007 2008 2009 2010 2011 2012 2013 2014 2015 2007 2008 2009 2010 2011 2012 2013 2014 2015

Output Growth
4

Regime
2

No ZLB 3 1.8 Data
No Regime switch 2 Switch to Regime 2 earlier 1 1.6

Regime No

0 1.4
-1 1.2
-2
-3 1 2007 2008 2009 2010 2011 2012 2013 2014 2015 2007 2008 2009 2010 2011 2012 2013 2014 2015

Quarterly percent

Figure 13: Counterfactual analysis. Model C

5 Conclusion
The novelty of the present paper is to investigate if the New Keynesian model is able to generate infrequent and long ZLB spells. While the canonical model fails to generate these two crucial statistics, a model that embed endogenous time-varying parameters performs very well. It is more able to match the data and to predict a prolonged ZLB spells that the US economy experienced fol-
29

lowing the Great Recession. The key point is that the regime switching of the monetary policy rule is not triggered randomly but is triggered when the economy is in a special state. This state is characterized by a low interest rate. The monetary policy switches to a regime where the target inflation is lower and the interest rate extremely persistent. This state lasts until the nominal interest rate is slightly above zero. Our counterfactual analysis suggests that such policy is prudential and have avoid an economic relapse with deflation.
The model is of course too stylized to characterized the behavior of the nominal interest rate. For now, what we think it is missing is the behavior of the labor market. For instance, the 30th January 2013 in the FOMC, Janet Yellen declare "the Committee decided to keep the target range for the federal funds rate at 0 to 1/4 percent and currently anticipates that this exceptionally low range for the federal funds rate will be appropriate at least as long as the unemployment rate remains above 6-1/2 percent, [...]". More recently, she states "To support continued progress toward maximum employment and price stability, the Committee today reaffirmed its view that the current 0 to 1/4 percent target range for the federal funds rate remains appropriate.". The labor market seems to be important in determining the path of the interest rate, especially because of it's non linear behavior. There is certainly a regime switching behind the monetary policy but this one may also strongly depend on the interest rate. This is in our agenda for future research.
Acknowledgments This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk". The usual disclaimer applies.
References
Albertini, J. & Poirier, A. (2015). Unemployment benefit extensions at the zero lower bound. Review of Economic Dynamics, 18(4), 733 ­ 751.
Aruoba, S. B., Cuba-Borda, P., & Schorfheide, F. (2013). Macroeconomic Dynamics Near the ZLB: A Tale of Two Countries. NBER Working Papers 19248, National Bureau of Economic Research, Inc.
Bianchi, F. (2013). Regime Switches, Agents' Beliefs, and Post-World War II U.S. Macroeconomic Dynamics. 30(2), 463­490.
Blanchard, O. & Simon, J. (2001). The Long and Large Decline in U.S. Output Volatility. Brookings Papers on Economic Activity, 32(1), 135­174.
Bloom, N. (2009). The Impact of Uncertainty Shocks. Econometrica, 77(3), 623­ 685.
30

Braun, R. A., Körber, L. M., & Waki, Y. (2012). Some unpleasant properties of log-linearized solutions when the nominal rate is zero. Technical report.
Canova, F. & Ferroni, F. (2015). Approximating time varying structural models with time invariant structures. Discussion papers.
Carlstrom, C. T., Fuerst, T. S., & Paustian, M. (2014). Fiscal Multipliers under an Interest Rate Peg of Deterministic versus Stochastic Duration. Journal of Money, Credit and Banking, 46(6), 1293­1312.
Chung, H., Laforte, J.-P., Reifschneider, D., & Williams, J. C. (2012). Have We Underestimated the Likelihood and Severity of Zero Lower Bound Events? Journal of Money, Credit and Banking, 44, 47­82.
Den Haan, W. J. & Marcet, A. (1990). Solving the stochastic growth model by parameterizing expectations. Journal of Business & Economic Statistics, 8(1), 31­34.
Den Haan, W. J. & Marcet, A. (1994). Accuracy in simulations. Review of Economic Studies, 61(1), 3­17.
Eggertsson, G. B. & Woodford, M. (2003). The Zero Bound on Interest Rates and Optimal Monetary Policy. Brookings Papers on Economic Activity, 34(1), 139­235.
Fernandez-Villaverde, J., Guerron-Quintana, P., Rubio-Ramirez, J. F., & Uribe, M. (2011). Risk Matters: The Real Effects of Volatility Shocks. American Economic Review, 101(6), 2530­61.
Fernández-Villaverde, J., Guerrón-Quintana, P., & Rubio-Ramírez, J. F. (2010). Fortune or Virtue: Time-Variant Volatilities Versus Parameter Drifting in U.S. Data. NBER Working Papers 15928, National Bureau of Economic Research, Inc.
Fernández-Villaverde, J., Guerrón-Quintana, P., & Rubio-Ramírez, J. F. (2015). Estimating dynamic equilibrium models with stochastic volatility. Journal of Econometrics, 185(1), 216­229.
Fernández-Villaverde, J. & Rubio-Ramírez, J. F. (2007). Estimating Macroeconomic Models: A Likelihood Approach. Review of Economic Studies, 74(4), 1059­1087.
Fernández-Villaverde, J. & Rubio-Ramírez, J. F. (2008). How Structural Are Structural Parameters? In NBER Macroeconomics Annual 2007, Volume 22, NBER Chapters (pp. 83­137). National Bureau of Economic Research, Inc.
31

Gordon, R. J. (1986). The American Business Cycle: Continuity and Change. Number gord86-1 in NBER Books. National Bureau of Economic Research, Inc.
Gust, C., López-Salido, J. D., & Smith, M. E. (2012). The Empirical Implications of the Interest-Rate Lower Bound. CEPR Discussion Papers 9214, C.E.P.R. Discussion Papers.
Hamilton, J. D., Harris, E. S., Hatzius, J., & West, K. D. (2015). The Equilibrium Real Funds Rate: Past, Present And Future. NBER working paper, 21476.
Hirose, Y. & Inoue, A. (2013). Zero Lower Bound and Parameter Bias in an Estimated DSGE Model. Departmental Working Papers 1306, Southern Methodist University, Department of Economics.
Judd, K. L. (1998). Numerical Methods in Economics, volume 1 of MIT Press Books. The MIT Press.
Judd, K. L., Maliar, L., & Maliar, S. (2012). Merging Simulation and Projection Approaches to Solve High-Dimensional Problems. NBER Working Papers 18501, National Bureau of Economic Research, Inc.
Justiniano, A. & Primiceri, G. E. (2008). The time-varying volatility of macroeconomic fluctuations. American Economic Review, 98(3), 604­41.
Karamé, F., Patureau, L., & Sopraseuth, T. (2008). Limited participation and exchange rate dynamics: Does theory meet the data? Journal of Economic Dynamics and Control, 32(4), 1041­1087.
Krugman, P. R. (1998). It's Baaack: Japan's Slump and the Return of the Liquidity Trap. Brookings Papers on Economic Activity, 29(2), 137­206.
Liu, Z., Waggoner, D. F., & Zha, T. (2011). Sources of macroeconomic fluctuations: A regime-switching DSGE approach. Quantitative Economics, 2(2), 251­301.
Malin, B. A., Krueger, D., & Kubler, F. (2011). Solving the multi-country real business cycle model using a smolyak-collocation method. Journal of Economic Dynamics and Control, 35(2), 229­239.
Ruge-Murcia, F. (2012). Estimating nonlinear DSGE models by the simulated method of moments: With an application to business cycles. Journal of Economic Dynamics and Control, 36(6), 914­938.
Schmitt-Grohé, S. & Uribe, M. (2009). Liquidity traps with global Taylor Rules. International Journal of Economic Theory, 5(1), 85­106.
32

Sims, C. A. & Zha, T. (2006). Were There Regime Switches in U.S. Monetary Policy? American Economic Review, 96(1), 54­81.
Stock, J. H. & Watson, M. W. (2003). Has the Business Cycle Changed and Why? In NBER Macroeconomics Annual 2002, Volume 17, NBER Chapters (pp. 159­230). National Bureau of Economic Research, Inc.

A Data

Variables

Type

Source

Nominal interest rate Nominal interest rate Output Output
Gross inflation rate Gross inflation rate

Rate, 3 month treasury bill, Monthly, Not s.a 1934M1 - 2015M12 U.S. Yields On Short-Term States Securities 3-Month Treasury 1920M1 - 1934M3 Quantities, s.a, Index numbers, 2005 $ 1947Q1 - 2015Q4 Quantities, s.a,
Index numbers, 1972 $ 1920Q1 - 1946Q4 Rate, GDP: Implicit Price Deflator, Quarterly. s.a Index 2005=100, Growth 1947Q1 - 2015Q4 Rate, GNP: Implicit Price Deflator, Quarterly. s.a Index 1972=100, Growth 1920Q1 - 1946Q4

Federal Reserve Bank of St. Louis (FRED)
NBER historical data
Bureau of Economic Analysis (BEA)
Gordon (1986)
Federal Reserve Bank of St. Louis (FRED)
NBER historical data Gordon (1986)

Code TB3MS
m13029a Table 1.1.3 RGNP72
GDPDEF q04216a GNPD72

Table 4: Data source and definitions. When merging data from FRED and from NBER
we re-scale NBER data so as to get a consistent series.

B Model equations
B.1 Full set of equations
· Euler equations:

33

· Output:

t

=

1 ct

t

=

(1

+

it

)Et

t+1

t+1 t+1Gzt+1

· Marginal cost:

yt = nt

· Real wage:

mct = wt

wt = ct · New Keynesian Phillips Curve (NKPC):

· Taylor rule:

0

= +

(E1t-t+1)+t+t1mct t-+1(t t(+1t--1)1)yyt+t 1

1 + it

=

(1

+

it-1)i

( G 

( t ) ¯

( yt y

)y )1-i

mt

it = max(it, 0)

· Market clearing:

· Shocks:

yt

[ 1

-

 2

( t 

-

)2] 1

=

ct

t = t- 1¯1- exp(,t) with ,t  N (0, 1) zt = zt-z 1 exp(zz,t) with z,t  N (0, 1) mt = mt-m1 exp(mm,t) with m,t  N (0, 1)

34

(23) (24) (25) (26) (27)
(28)
(29)
(30)
(31) (32) (33)

B.2 Compact form
Let define the expectation functions:

1t 2t

= =

Et

t+1

t+1 t+1zt+1

Et

t+1

t+1

t+1 

( t+1 

-

) 1

yt+1

Combining Equations (26), (27) and (30) gives:

mct

=

yt

[ 1

-

 2

(

t 

-

)2] 1

Combining Equations (23) and (30) gives:

(34) (35)
(36)

t

=

yt

[ 1

-

 2

1 ( t


-

1)2]

Plugging Equations (36) and (37) in (28):

0

= +

(E1t-t+1)+t+1mytc[t1--2t((t t--11))2]



t+1 

( t+1 

-

) 1

yt+1 yt

which gives after some rearrangement:

yt

=

1 

[ 

- 1

1-+2 ( tt

(-t1)-2

) 1

-

] 2t

Plugging Equations (30) in (24) leads:

(37) (38)

(1 + it)1t

=

yt

[ 1

-

G  ( t
2

-

1)2]

(39)

For a given vector of state variable and expectation functions, the model can be summaries by a single equation whose unknown is t by plugging the nominal interest rate rule (Equations (29)), the output definition (Equation (38)) in
(39):

35

· Unconstrained case

(1

+

it-1)i

( G 

( t ¯

)

( yt y

)y )1-i zt

mt 1t

=



-

1

+



t 

( t


-

G

) 1

-

2t

[ 1

-

 2

( t


-

1)2]

· Constrained case

1t

=



-

1

+



t 

( t


-

G

) 1

-

2t

[ 1

-

 2

( t


-

1)2]

(40) (41)

C Solution method
In order to explicitly take into account the non-linearity induced by the ZLB, we use a projection method: Parameterized Expectation Algorithm (PEA). It consists of approximating the conditional expectations of the system previously described using Chebyshev polynomials. These parametric functions display suitable orthogonality and convergence properties to minimize the error distance approximation. We consider a third-order Chebyshev polynomial over a fixe complete grid. Our strategies is accurate because we use a Newton Algorithm checking for the ZLB. Then, one can approximate kinks in all decision rules accurately. We first present some numerical technics that will be helpful for the understanding of the general algorithm6.

C.1 Some useful notations and operators
Throughout the algorithm we will use the following notations and operators.
· In is a n x 1 column vector whose elements (cells) are each equal to one.
· 1{cond} is an indicator variable taking the value 1 if the condition is satisfied and zero otherwise.
·  stands for the Kronecker product.
·  stands for the Hadamar product (or Schur product). It is an element by element product. If A and B are two matrices of the same dimension with aij
6This appendix does not intend to be a mathematical note on the algorithm but a general description on the way the model is solved using Matlab. For this reason, many variables will be treated as vectors or matrices, as it is the case in Matlab.

36

and bij being the elements of A and B respectively and i = 1, ..., I, j = 1, ..., J, the Hadamar product of A and B is equal to:



AB

=



a11b11 a21b21
...

a12b12 a22b22
...

...
... ...

a1J b1J a2J b2J
...



aI1bI1 aI2bI2 . . . aIJbIJ

· D is the approximation order of the Chebyshev polynomial.

· K is the number of state variables.

· Kx is the number of exogenous state variables.

· Kn is the number of endogenous state variables.

· C is the number of control variables.

C.2 Preliminary results on Chebyshev functions
To approximate the unknown functions, the expectations and the policy rules, we use Chebyshev polynomials. The domain of Chebyshev polynomials is the interval [-1, 1]. We will see later on how to manage an [a, b] interval. Let D be the approximation order of the Chebyshev polynomial. With one state variable x, the Chebyshev polynomials of order d is built according to the following recursion:
Td+1(x) = 2x Td(x) - Td-1(x)
with T0(x) = 1 and T1(x) = x. Applying the trigonometric identities Td(cos(x)) = cos(nx) where cos(nx) is an orthogonal sequence on [0, 2], the d-th member of the polynomial is
Td(x) = cos(d arccos(x))
The complete Chebyshev polynomial of a variable x writes:

D
((x), ) =  dTd(x) d=0

where

(x)

=

2

x b

- -

a a

-

1

a and b are the minimum and the maximum bounds of the ergodic distribution of the variable x respectively. Then, (x) maps x in the interval [-1,1]. d are

37

the parameters that we have to determine to find the policy rules. When the
number of state variables is higher than one, we have to build a multidimen-
sional Chebysev polynomial. In the complete base approach, the product of polynomial terms must have an order not higher than D. Let K be the number of state variables such that x = {x1, x2, ..., xK}. The multidimensional Chebyshev polynomial writes:

DD

K

  ((x), ) = d1=0 ... dK=0 d1...dk 1{sK=1 dsD} k=1 Tdk ((xk))

Where 1 is a variable taking the value 1 if the product of the {d1, ..., dD}th member of the polynomial has a total order sK=1 ds not higher than D and 0 otherwise. For instance, in our model we assume third-order Chebyshev
polynomials with four state variables. For each control variable  = 1, ..., C the policy rule writes7:

((t), ) = 1 + 2 (it-1) + 3 cos(2 arccos((it-1))) + 4 cos(3 arccos((it-1))) + 5 (nt-1) + 6 (nt-1) cos(2 arccos((it-1))) + ...
The Chebyshev polynomial has dD1=0 ... dDK=0 1{sK=1 dsD} elements. It should be noted that the Chebyshev polynomial obeys the continuous orthogonality relationship:
1  -1 Ti(x)Tj(x) (1 - x2)dx = 0, for all i = j
This property states that the Chebyshev polynomials are orthogonal on [-1,1] with respect to the inner product defined by the weighting function: (1 - x2).

C.3 Grid of the state variables
After describing the polynomials basis, one has to build the grid on which the polynomials will be projected. There are many different methods encompassing different sub-routines for that. Two major strategies have emerged in the PEA literature: (1) fix grid methods and (2) simulated grid methods. While both are very accurate and have good convergence properties, the first one has the disadvantage of being cumbersome when the number of state variables is high. Indeed, the fix grid methods consist in building a multidimensional grid of the state variables mapping all the different combinations. The size of the
7For the sake of clarity, we normalized the subscript of coefficient .
38

grid increases exponentially with the number of state variables, leading the the popular curse of dimensionality problem. Alternative fix grid method like the Smolyak collocation method (see Judd (1998), Malin et al. (2011)) improves the speed of resolution because the size of the grid only increase polynomially with the number of state variables. However, it makes the convergence more difficult in a model characterized by occasionally binding constraints. With several state variables, we rely on the simulation based-methods. The idea is to use simulations to approximate the ergodic measure of the solution. We cover the support of the constructed ergodic measure with a simulated grid. Because the simulation points will be use as a grid for evaluating the polynomials, we only consider area of the state-space that are visited in equilibrium and disregard the area that are never visited. This methods is borrowed from Judd et al. (2012) and is referred as time iteration method.
Let defined a sequence for the exogenous shocks by {j}tT=0, j = 1, ..., Kx. Given autocorrelation coefficients and standard deviations, the stochastic processes are built using the recursive structure:

xj,t = xj,jt-1x1j -j exp(j j)

j = 1, ..., Kx

The difficult task is to get a sequence of the endogenous state variable: it in our model. Since it depends on inflation (in the compact model), one has to
solve at each time for inflation given an initial guess for expectations, an initial
value of the endogenous state variable it-1 and the value of the shocks at time t.

C.4 General algorithm (Model A)
Step 1 Choose the order of the Chebyshev polynomial D and build the multidimensional Chebyshev polynomials using:
Tn(x) = cos(n arccos(x)) Step 2 Get a sequence of shock {j}tT=0 and build the stochastic processes {jt}tT=0, j = , m, z
Step 3 Initialize the sequence of the nominal interest rate using its deterministic steady state value. We therefore have a matrix of state variables St with T lines and K columns.
Step 3 Initialize the expectations function coefficients . In our case, we only set the coefficients associated to the constants to be equal to their deterministic steady state8. The rest being equal to zero.
8It is possible to use a log-linear or a perturbation method to initialize the coefficients. But the algorithm converges anyway.
39

Step 4: Iteration: For t = 2 : T,
a) Given , compute the expectation functions ((St); ), (.) maps the state variables in a [-1; 1] interval. b) Given ((St); ), it-1 and the stochastic processes at time t, compute inflation t from Equation (40) using a Newton algorithm with a convergence criterion 10e - 10.
c) Given t, compute output from Equation (38) and the nominal interest rate from the Taylor rule.
d) Check if the nominal interest rate falls below the ZLB. If not, keep t previously calculated. Otherwise, re-calculate9 t according to Equation (41) as well as yt, ct and t.

Step ables

5 Given {Ct }tT=0 ,

the sequence of endogenous state variables compute the sequence of expectation terms:

{St }tT=0

and

control

vari-

1t 2t

= =

t+1

t+1 t+1zt+1

t+1t+1

t+1 

( t+1 

-

) 1

yt+1

tpShoetleynpneow6mGciaoilevfbefiancsiiteshne{tssXetq}u:tTe=n0ce=of{sta(tSetv)}artT=ia0blaen{dSut}setT=o0rdwineacraynlecaosmt psuqutearthese

sequence of to calculate

 = (XtXt)-1(Xtt)

Step 7 Check if the coefficients are the same using an Euclidian norm and a convergence criterion (10-8 in our algorithm). Formally, it writes

| - | ||



10-8

Otherwise, defined  =  and return to step 4. Repeat this procedure until convergence.

C.5 General algorithm (Model B)
When some parameters follow a markov process we need to compute two policy rules and combine them to calculate the expectation functions. Recall
9For this step, it should be noted that we don't have to use a Newton algorithm since we face a quadratic equation that have two solutions. A standard solution of low inflation and another solution implying a deflationary trap (see Schmitt-Grohé & Uribe (2009). However, the algorithm never falls in the deflationary trap which calls for about minus 100% inflation, a highly implausible value.
40

however that we only have one expectation function for each forward equation. The switch from state 1 to state 2 is compute using a uniform shock st  U(0, 1) and the transition matrix P to check whether the draw is lower than the
corresponding probability given in P. The following step are added/modified
in the general algorithm of Model A:

Step 3b: Initialize the state s0 = 1,

Step 4: Iteration: For t = 2 : T, a) Compute the next period state st given st-1 using the shock st and the matrix of coefficient P.
b) Given , compute ((St); ). c) Given ((St); ), it-1 and the stochastic processes at time t, compute inflation t(st) from Equation (40) using a Newton algorithm with a convergence criterion 10e - 10. t(st) is calculated in the two regimes st = 1, 2. d) Given t(st), compute output from Equation (38) and the nominal interest rate it(st) from the Taylor rule. d) Check if the nominal interest rate falls below the ZLB. If not, keep t(st) previously calculated. Otherwise, re-calculate t(st) according to Equation (41) as well as yt(st), ct(st) and t(st).

Step ables

5 Given the {Ct (st )}tT=0 ,

sequence compute

of endogenous the sequence of

state variables {St}tT=0 expectation terms:

and

control

vari-

1t (st)

=

t+1

t+1(st+1) t+1(st+1)zt+1

(

)

2t (st)

=

t+1

t+1

(st+1)

t+1(st+1) 

t+1(st+1) 

-

1

yt+1(st+1)

and

1t = P (st, 1)1t (1) + P (st, 2)1t (2) 2t = P (st, 1)2t (1) + P (st, 2)2t (2)

C.6 General algorithm (Model C)
We now describe the algorithm when the monetary policy rule parameters depend on the value of the desired nominal interest rate. Step 4 is modified as follow:
Step 4: Iteration: For t = 2 : T,
41

a) Compute the next period state st given st-1 and conditional on whether it > ist or not.
b) Given , compute ((St); ). c) Given ((St); ), it-1 and the stochastic processes at time t, compute inflation t(st) from Equation (40) using a Newton algorithm with a convergence criterion 10e - 10. t(st) is calculated in the two regimes st = 1, 2. d) Given t(st), compute output from Equation (38) and the nominal interest rate it(st) from the Taylor rule. d) Check if the nominal interest rate falls below the ZLB. If not, keep t(st) previously calculated. Otherwise, re-calculate t(st) according to Equation (41) as well as yt(st), ct(st) and t(st).

Step ables

5 Given the {Ct (st )}tT=0 ,

sequence compute

of endogenous the sequence of

state variables {St}tT=0 expectation terms:

and

control

vari-

1t (st)

=

t+1

t+1(st+1) t+1(st+1)zt+1

(

)

2t (st)

=

t+1

t+1

(st+1)

t+1(st+1) 

t+1(st+1) 

-

1

yt+1(st+1)

and

1t = F (st, 1)1t (1) + F (st, 2)1t (2) 2t = F (st, 1)2t (1) + F (st, 2)2t (2)

with transition matrix F equal to

[

F=

f1 1 - f1

] 1 - f2
f2

(42)

Note that f1 and f2 are endogenously determined and are calculated at each loop of the algorithm. The calculation of the transition probabilities is described in Section D.

D Simulations
D.1 ZLB moments
D.1.1 Transition probabilities To estimate the probability of moving from one state to another we use the Maximum likelihood function. Assuming i~ corresponds to the case where it is above the ZLB, the states of the Markovian matrix are : {0, i~}. We denote by p

42

the transition matrix with no restriction and pij the probability of moving from state i to state j. It is defined by

pij = Pr(it+1 = j|it = i)
Defining the transition counts Kij as the number of times the state i is followed by j, the log-likelihood function can be written in the following manner:

L(p) =  kij log pij i,j

with kij = log Kij

The estimation procedure consists of choosing the value of pij that maximizes the log-likelihood function subject to:

 pij = 1 j

With m = 2 states, the above optimization problem is characterized by 2 La-

grange multipliers (i) and takes the following form:

(
j

)

 p^ij

=

arg

max
pij

L(p) - i
i=1

pij - 1
j

The first-order conditions with respect to pij are:

0

=

kij p^ij

- i



p^ij

=

kij i

Using the constraint we have i = mj=1 kij. By replacing it in the first-order conditions we obtain the maximum likelihood estimator of the transition prob-
ability p^ij from state i to state j:

p^ij

=

kij mj=1 kij

D.1.2 ZLB duration
In order to characterize ZLB durations we sum transition counts when the economy hit the ZLB until it takes the liquidity trap off. Let Dn be the n-th ZLB spell of a simulated time series of length T expressed in quarters, n = 1, ...N. N being the total number of ZLB spells that is endogenous. Formally, Dn writes:

Dn =  kjj j 43

The average ZLB spells is computed as follow:

Et(Dn)

=

1 N


n

Dn

The average occurrence of ZLB spells i.e. the proportion of time the economy is stuck at the ZLB, Pz, is defined as:

Pz

=

1 T


n

Dn

E Accuracy and computing time of the algorithm

E.1 The Zero lower bound
We consider a 0.03 point shocks to the discount factor and a 0.01 point shock to the monetary policy and output growth to shed light the intuition. A oneperiod shock to the discount factor drives the nominal interest rate at the ZLB during nine quarters in Model A and B. It leads to a deflation of about 3 pp. and a fall in output growth rate by 7 pp. The shock to monetary policy rule lowers the interest rate which remains stuck at the ZLB only for 2 quarters and implies a rise in inflation of around 3 pp. on an annual basis. Despite having the same magnitude, the output growth shock does not drive the nominal interest rate to the ZLB but induces a fall in inflation of 1.6 pp on an annual basis and a fall in output growth rate of about 6 pp.
Now consider the cases without ZLB. The ZLB affects the propagation of shocks though two channels. The first one corresponds to the direct impact of the "non-decline" in the nominal interest rate in the Euler equation (Equation (4)). The second effect comes from the expectation functions that takes into account the regime switching from the ZLB. In the first case (case b) we assume that the policy rules remains the same but we simply allow the nominal interest rate to fall below zero. In the second case (case c) we recompute the policy rule and the corresponding expectation terms when the nominal interest rate is allowed to fall below zero. The difference between the two highlights the role of the ZLB in agents expectations.
In case b, the desired interest rate (the one that would have been effective in the absence of the ZLB) is around minus 0.025 following a discount factor shock and a monetary policy shock. The difference between case a and b shows that the path of inflation and output growth is roughly unchanged following a shock to the discount factor or to the output growth rate. Inflation and output growth raise more following monetary shock. In case c, following a shock to the discount factor, the decline in the interest rate, inflation and the output

44

growth rate is dampening by a factor 2. The intuition is that agents, by expecting that the interest rate will always adjust, do not expect a situation characterized by a strong deflation and a dramatic contraction in output. When the real interest rate is prevented from rising too much because the Taylor rule is always effective, it involves a higher output growth and a lower decline in inflation. The intuition is similar for the output growth shock except that the simulation does not involve a ZLB periods. Following a monetary shock, the downward adjustment of the nominal interest rate involves stronger inflation expectations. The initial increase in the monetary shock and the sluggish response of inflation caused by price rigidities lead to an initial rise in output followed by a sharp contraction below its initial level.
The important message here is that the impact of the ZLB on agents expectations is huge. Linearization techniques or monetary shocks as a mechanism to make binding interest rate may lead to spurious conclusions. The reason is that in such cases agents do not internalize in their expectations the probability to hit and to leave the ZLB while it has non-trivial effects on the macroeconomic variables. The canonical model implies that when the monetary authority losses traction, a recession can be fairly costly in terms of inflation and output.
45

Interest rate

Inflation

Discount shock
0.01

Monetary shock
0.01

10 ×1O0-u3tput growth shock

0
-0.01
-0.02 0q
1.005

0

-0.01

-0.02

5q 10q 15q 20q

0q

1.008

a. With ZLB b. Without ZLB c. Without ZLB
5q 10q 15q 20q

8
6 0q

1.005

5q 10q 15q 20q

1 1.006 1.004

0.995

1.004

1.003

0.99 0q
5

1.002

5q 10q 15q 20q

0q

2

1.002

5q 10q 15q 20q

0q

2

5q 10q 15q 20q

010

-5 0 -2

-10 -1 -4

0q 5q 10q 15q 20q

0q 5q 10q 15q 20q

0q 5q 10q 15q 20q

Output growth

Figure 14: Impulse response functions. Model A, recessionary unexpected shock of 0.04 in absolute term. Quarters are displayed on the x axis. The impulse responses are expressed in level, quarterly rate for the nominal interest rate, quarterly gross rate for inflation and quarterly rate in percentage for output growth.

46

Interest rate

Inflation

Discount shock
0.01

0

-0.01

-0.02 0

5 10 15

Monetary shock
0.01

0
-0.01
-0.02 20 0

a1. With ZLB a2. With ZLB b1. Without ZLB b2. Without ZLB c1. Without ZLB c2. Without ZLB
5 10 15 20

10 ×10-3Output growth shock
9
8
7
6 0 5 10 15 20

1.005
1
0.995
0.99 0

1.007

1.006

1.005

1.004

1.003

5 10 15 20

0

1.0045

1.004

1.0035

1.003

1.0025

5 10 15 20

0

5 10 15 20

521

0 01
-1 -5 0
-2

-10 -1 -3

0 5 10 15 20

0 5 10 15 20

0 5 10 15 20

Output growth

Figure 15: Impulse response functions. Model B, recessionary unexpected shock of 0.04 in absolute term. Quarters are displayed on the x axis. The impulse responses are expressed in level, quarterly rate for the nominal interest rate, quarterly gross rate for inflation and quarterly rate in percentage for output growth.

47

Interest rate

Inflation

0.02
0.01
0
-0.01 0q
1.01
1.005
1
0.995 0q 5
0
-5
-10 0q

Discount shock
5q 10q 15q 20q

15 ×10-3 Monetary shock
10
5
0
-5 0q 5q 10q 15q

20q

11 ×10-3 Output growth shock
10
9
8 0q 5q 10q 15q 20q

1.008

1.007

1.006

1.005

1.004

5q 10q 15q 20q

0q

1.005

1.0048

1.0046

1.0044

1.0042

5q 10q 15q 20q

0q

5q 10q 15q 20q

3 0.5

20
1 -0.5 a. With ZLB b. Without ZLB
0 -1 c. Without ZLB

-1 -1.5

5q 10q 15q 20q

0q 5q 10q 15q 20q

0q 5q 10q 15q 20q

Output growth

Figure 16: Impulse response functions. Model C, recessionary unexpected shock of 0.04 in absolute term. Quarters are displayed on the x axis. The impulse responses are expressed in level, quarterly rate for the nominal interest rate, quarterly gross rate for inflation and quarterly rate in percentage for output growth.

E.2 Residuals in equilibrium equations
Den Haan & Marcet (1990), Den Haan & Marcet (1994) and Judd (1998) use a simple and powerful algorithm to evaluate the accuracy of dynamic models. They compute the residuals of the Euler equations by simulating the model. We perform a similar exercise using the log10 of all residuals in absolute value. In our simulation, the residual are all way lower than -3 in log 10 basis.
E.3 Coverage of the grid points
One source of inaccuracy arises from the coverage of the grid points. If simulated points from the historical decompositions are fairly outside the coverage implied by simulated points used when solving and estimating the model, it means that the model is not solved on points that are visited in equilibrium.
48

This may involve potential spurious approximations even if the residuals are low. Indeed, some points not visited during estimation would have probably affected the policy rules if they was. For this purpose, we check if the ergodic distributions of states variables are most of them included in the ergodic distribution of the initial simulated grid. By most of, we mean that the grid covers at least 95% of the simulated series of the state variables (which is the case in our simulations  99%).

E.4 Computing time
Solving a model with global approximation methods and estimating it is challenging. However, the method we use involves decent computing time on a standard computer i.e. not a supercomputer. All the programs are run on Matlab R2015b. This last version is faster than previous ones due to the C++ pre-computing and the automatic parallelization. The computer used is a laptop but fairly powerful (at that time) with processor i7-4790K (4Ghz multithreading and 4.4Ghz in turbo mode on a single core), 32Gb RAM 1866Mhz, GeForce GTX 980m graphic card (1536 CUDA cores) and SSD Samsung 850 pro SATA III (Sequential Read: Max. 550 MB/s Sequential Write: Max. 520 MB/s).

Model Model A

Number of parameters
13

Time 2h 10m 48s

Model B 19 0h 24m 06s

Model C 19 0h 16m 18s

Table 5: Computing times. Times include the resolution and the estimation, not the simu-
lations that produce impulse response or bootstrap moments. The model is solved many times during estimation. However, each time the model is solved we record the solution and use it as initial guess to solve the model for the new set of parameter that are often -different from the previous ones, leading to a more rapid convergence. Furthermore, we use a standard calibration to initialize the parameters in the Model A for the estimation. The estimated parameters are used in Model B as initial values. Model C also use the estimated value from Model B to initialize the parameters prior to estimation. It explains the faster computing time in the more complex models.

49

)


t

,

t+Q

Corr(i

F Supplementary figures

a) Interest rate - Inflation
1 Model
0.8 Data
0.6
0.4
0.2
0

Corr(


t+Q

,



yt)

b) Inflation - Output growth
0.4 0.2
0 -0.2

Corr(i
t+Q

,

yt

)

c) Interest rate - Output growth
0.2 0.1
0 -0.1 -0.2

-0.2 -4q -3q -2q -1q 0 1q 2q 3q 4q
d) Interest rate
1

-0.4 -4q -3q -2q -1q 0 1q 2q 3q 4q
e) Inflation
0.9

-0.3 -4q -3q -2q -1q 0 1q 2q 3q 4q
f) Output growth
0.4

y)
t-q

0.8 0.3 0.8 0.7 0.2

t-q)



,

,

y
t


t

Corr(

Corr(

0.6 0.1 0.6
0.5 0

Auto

Auto

0.4 0.4 -0.1 0.3 -0.2

0.2 0.2 -0.3 -1q -2q -3q -4q -1q -2q -3q -4q -1q -2q -3q -4q

Figure 17: Correlations and autocorrelation. Model B vs data.

Auto Corr(i , i )
t t-q

50

Annual percent

Nominal interest rate
6 Data Model median
5 4 3 2 1 0 2000 2005 2010
Output Growth
3

Annual percent

4 3 2 1 0 -1 2015 2000

2

1

0

-1

-2 2002 2004 2006 2008 2010 2012 2014

Inflation
2005 2010

2015

Quarterly percent

Figure 18: Model projections 2009Q3 - Model B. The smoothed shock series is used until 2009Q3 to simulate the model. Thereafter, we perform a forecast from 2009Q3 to 2015Q1 using stochastic simulations in order to generate future path for the variables. We use 10000 bootstraps simulations. The light gray shaded area corresponds to the 80% confident interval and the dark gray shaded area to 50% confident interval.

51

1 0.99 0.98 0.97 0.96 0.95
1960 1.005
1 0.995 0.99 0.985 0.98 0.975 0.97
1960

1970 1965

Discount factor shock

1.08

1.06

1.04

1.02

1

0.98

0.96

0.94

1980 1990 2000 2010

1960

Monetary policy shock

Output Growth shock
1970 1980 1990 2000

2010

Burns & Miller (70-79) Volcker (79-87) Greenspan (87-06) Bernanke (06-14) Yellen (14-..)

1970 1975 1980 1985 1990 1995 2000 2005 2010 2015

Figure 19: Smoothed shocks. Model B

52

Annual percent

8 6 4 2 0
2000
4 2

Nominal interest rate
2005 2010
Output Growth

Annual percent

Inflation
4 2 0 -2

2015 2000

2005

Discount shock only Monetary shock only Output growth shock only Data

2010

2015

Quarterly percent

0

-2 2000 2005 2010 2015

Figure 20: Decomposition of shocks to the variations of the endogenous variables. Model A

53

Annual percent

Nominal interest rate
5

No ZLB

4

4 Data

33

Annual percent

2 2
1
01

Inflation

-1 0
-2 2007 2008 2009 2010 2011 2012 2013 2014 2015 2007 2008 2009 2010 2011 2012 2013 2014 2015
Output Growth

1

0.5

0

-0.5

-1

-1.5

-2 2008 2009 2010 2011 2012 2013 2014 2015

Figure 21: Counterfactual analysis. Model B

Quarterly percent

54

SFB 649 Discussion Paper Series 2016
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "Downside risk and stock returns: An empirical analysis of the long-run and short-run dynamics from the G-7 Countries" by Cathy Yi-Hsuan Chen, Thomas C. Chiang and Wolfgang Karl Härdle, January 2016.
002 "Uncertainty and Employment Dynamics in the Euro Area and the US" by Aleksei Netsunajev and Katharina Glass, January 2016.
003 "College Admissions with Entrance Exams: Centralized versus Decentralized" by Isa E. Hafalir, Rustamdjan Hakimov, Dorothea Kübler and Morimitsu Kurino, January 2016.
004 "Leveraged ETF options implied volatility paradox: a statistical study" by Wolfgang Karl Härdle, Sergey Nasekin and Zhiwu Hong, February 2016.
005 "The German Labor Market Miracle, 2003 -2015: An Assessment" by Michael C. Burda, February 2016.
006 "What Derives the Bond Portfolio Value-at-Risk: Information Roles of Macroeconomic and Financial Stress Factors" by Anthony H. Tu and Cathy Yi-Hsuan Chen, February 2016.
007 "Budget-neutral fiscal rules targeting inflation differentials" by Maren Brede, February 2016.
008 "Measuring the benefit from reducing income inequality in terms of GDP" by Simon Voigts, February 2016.
009 "Solving DSGE Portfolio Choice Models with Asymmetric Countries" by Grzegorz R. Dlugoszek, February 2016.
010 "No Role for the Hartz Reforms? Demand and Supply Factors in the German Labor Market, 1993-2014" by Michael C. Burda and Stefanie Seele, February 2016.
011 "Cognitive Load Increases Risk Aversion" by Holger Gerhardt, Guido P. Biele, Hauke R. Heekeren, and Harald Uhlig, March 2016.
012 "Neighborhood Effects in Wind Farm Performance: An Econometric Approach" by Matthias Ritter, Simone Pieralli and Martin Odening, March 2016.
013 "The importance of time-varying parameters in new Keynesian models with zero lower bound" by Julien Albertini and Hong Lan, March 2016.
SFSBF6B4694, 9S,pSapnadnaduaeureSrtrSatßraeß1e, 1D,-D10-1107187B8eBrleinrlin htthpt:t/p/:/s/fbs6fb4694.w9.iwwiiw.hiu.h-bue-brleinrl.idne.de
ThTishrisesreasercahrcwhawsassupsuppoprtoerdtebdybtyhethDeeDuetsucthseche ForFsocrhsuchnugnsgesgmeeminesicnhsachftatfht rtohuroguhgthhethSeFSBF6B4694"9Ec"oEnconmoimc RicisRki"s.k".

