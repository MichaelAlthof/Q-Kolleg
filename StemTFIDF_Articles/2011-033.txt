BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2011-033
Asymptotics of Asynchronicity Markus Bibinger*
* Humboldt-Universität zu Berlin, Germany
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universität zu Berlin Spandauer Straße 1, D-10178 Berlin

Asymptotics of Asynchronicity
Markus Bibinger1
Institut fu¨r Mathematik, Humboldt-Universita¨t zu Berlin, Unter den Linden 6, 10099 Berlin, Germany
Abstract In this article we focus on estimating the quadratic covariation of continuous semimartingales from discrete observations that take place at asynchronous observation times. The Hayashi-Yoshida estimator serves as synchronized realized covolatility for that we give our own distinct illustration based on an iterative synchronization algorithm. We consider high-frequency asymptotics and prove a feasible stable central limit theorem. The characteristics of non-synchronous observation schemes affecting the asymptotic variance are captured by a notion of asymptotic covariations of times. These are precisely illuminated and explicitly deduced for the important case of independent time-homogeneous Poisson sampling.
Keywords: non-synchronous observations, quadratic covariation, Hayashi-Yoshida estimator, stable limit theorem, asymptotic distribution
MSC Classification: 62M10, 62G05, 62G20, 91B84
JEL Classification: C14, C32, C58, G10
1. Introduction
Nonparametric estimation methods for the quadratic variation of semimartingales have become an issue of great interest in recent years. One reason is the interpretation of the quadratic variation of the continuous part as integrated volatility in financial modeling. If a semimartingale is observed discretely at times ti, 0  i  n on a finite time horizon [0, T ], the sum of squared returns (increments of the semimartingale), called realized volatility, converges to the quadratic variation as sup (ti - ti-1)  0 as n  . The same fact pertains to the multi-dimensional case where the realized covolatilities of two processes converge to the quadratic covariations. More usually multivariate data, in particular financial time series, are recorded at times following non-synchronous observation schemes. Therefore, realized covolatility estimates most commonly incorporate a previous-tick interpolation approach. Though, this machinery leads to the so-called Epps effect [8] that realized covolatilities tend to zero as the sampling frequency increases. Especially for the more and more available ultra highfrequency financial tick-data this issue poses problems. A solution for the asynchronous estimation problem has been proposed in [13]. We call this estimator which arises as realized covolatility from all products of returns with overlapping observation time instants Hayashi-Yoshida estimator. Our investigation of that estimation approach leads to several useful rewritings and interpretations. The final representation is based on an iterative synchronization procedure which has been used first in [19]. This synchronized realized covolatility and the data aggregation technique for synchronization can serve as a basis for combined approaches in various generalizations of the underlying statistical model. A very important enhancement of the model in that we take market microstructure noise into account is covered in [4] and [5] by extending the synchronized realized covolatility to a generalized multiscale estimator. The asymptotic theory developed in the article on hand is grounded on stable limit theorems for semimartingales from [16]. We obtain a stable limit theorem for the process associated with the estimation
1Financial support from the Deutsche Forschungsgemeinschaft via SFB 649 `O¨ konomisches Risiko', Humboldt-Universita¨t zu Berlin, is gratefully acknowledged.
1

error of a Hayashi-Yoshida estimator for the quadratic covariation at time t  [0, T ] and for the overall estimator by the marginal distribution at t = T the stable weak convergence to a centred mixed normal limiting distribution. The random asymptotic variance splits up in two terms induced by an idealized synchronous approximation and an additional error due to the lack of synchronicity. The article is arranged in six sections. In the following Section 2 we give insight into the concept of stable weak convergence and a short review on the essential theory from the literature. In Section 3 the HayashiYoshida estimator and our related synchronization algorithm that we have first presented in [4] is revisited and the asymptotic theory including the key result is provided in Section 4. The detailed proof of the central Theorem 2 is postponed to the Appendix A. Following some simple illustrative and motivating examples before, Section 5 comes up with the analysis for the important time-homogeneous independent Poisson sampling case for which we evaluate all ingredients of the asymptotic variance explicitly. To benefit from the stable central limit theorem and provide a basis for statistical inference, we give a consistent estimator for the asymptotic variance in Section 6.

2. Stable convergence and Jacod's stable limit theorem revisited

This section is devoted to the notion of stable weak convergence which will be an essential concept for the development of our limit theory throughout this article. The concept of stable convergence goes back to [21] and results about stable limit theorems were extended in [1] and [9]. The reason what makes stable weak convergence a key element of our asymptotic considerations, is that it allows to conclude joint weak convergence when we derive results about asymptotic mixed normality. In the case that a sequence of random variables (Xn) weakly converges to a mixed Gaussian limiting random variable V Z, with Z being standard normally distributed, Z  N(0, 1), and a strictly positive random variable V , independent of Z, we cannot derive confidence intervals if the distribution of V is unknown. However, if a consistent estimator Vn2 for the asymptotic variance V 2 is available (in the sense that Vn2 -p V 2), the stable weak convergence will assure that (Xn, Vn2) (V Z, V 2) jointly and also that Xn/Vn Z. The last implication also holds in a stable version: Xn/Vn st Z. For that reason, if we are in situations as described above we gain from proving stable weak convergence which paves the way towards statistical inference. Next, we present the formal definition and the main properties of stable weak convergence of sequences of random variables.

Let (Xn) be a sequence of random variables defined on some probability space (, F, P) and taking values in a Polish space (E, E). We say that the sequence (Xn) converges weakly in L1 to X if for any bounded

random variable Z

lim
n

E

[Z Xn ]

=

E

[Z X ]

holds.

Definition 1. For a sub--field G  F the sequence of random variables (Xn) is said to converge G-stably, if there is a random probability measure µ on ( × E, G  E) such that

lim
n

E

[Z

f

(Xn

)]

=

µ(d, dx)Z()f (x)
×E

for all f  Cb(E) (continuous and bounded) and G-measurable bounded random variables Z. If G = F , we say (Xn) converges stably in law to X (Xn st X).

Remark 1. G-stable convergence is the weak convergence in L1 of E [f (Xn)|G] for all f  C(E) to µ  f . This implies convergence in distribution to the probability measure  defined by

(B) = µ(d, B)1{X()B}P(d) .

If (Xn) converges stably, the limiting law is µ(, · ).

2

The following proposition states some useful equivalent characterizations of (G-)stable convergence.

Proposition 2.1. (Xn) converges G-stably is equivalent to:
(i) For every G-measurable random variable Z on , (Z, Xn) converges in law. (ii) For every G-measurable random variable Z on , (Z, Xn) converges G-stably.
(iii) The sequence (Xn) is tight, and for all G  G and f  C(E), the sequence E [1Gf (Xn)] converges.

This proposition is proved in [17] as part of Proposition IX.1.4. Stable (weak) convergence is a stronger

mode of ordinary convergence in distribution. It is weaker than convergence in probability, but we empha-

size that the limit depends on the limiting random variable X itself and not only on the distribution of X.

If (Xn) converges stably to X, X is defined on an extension ( , F , P = µ) of the original probability

space, so that

f  C(E) :

lim
n

E

[f

(Xn

)Z

]

=

E

[f (X)Z]

.

In the situation that we face in this article, a Gaussian random variable which is independent of F will

appear as limiting law. In this case we call the extension of the original probability space orthogonal. In particular, if Xn st X holds with an F -measurable random variable X (L1-convergence), the foregoing proposition yields that (Xn, X) (X, X) and, hence (Xn -X) 0 holds, which implies convergence in
probability. Therefore, in all cases where stable weak convergence is a suitable adequate concept, limiting

laws are defined on a genuine extension of the original probability space.

The following proposition gives the result that stable convergence is the suitable concept to derive feasible

central limit theorems and confidence intervals if the asymptotic variances in limit theorems are unknown

random, but can be estimated consistently.

Proposition 2.2. Let (Xn, Vn) be real-valued random variables defined on (, F , P). If Xn st X with a mixed normal limiting random variable X  N(0, V 2) and Vn -p V with V being F -measurable. Then

Xn/Vn st N(0, 1)

holds true.

Note that we use the same denotation expression for mixed normal laws and common normal laws and the difference becomes clear out of the context and by the specific variances. On the assumptions of the proposition (Xn, Vn) st (X, V ) is implied and the convergence of Xn/Vn follows by the continuous mapping theorem. This proposition is part of Proposition 2.5 in [20]. We restricted ourselves to real-valued random variables in the last proposition. A more general version can be found in [17]. The concept of stable convergence also carries over to stochastic processes. For this extension of stable convergence to stochastic processes, or more precisely to semimartingales, the Polish space E in Definition 1 is chosen to be the Skorohod space. The following limit theorem for stable convergence of continuous local martingales will be the foundation for our later deduced limit theorem in this article:

Theorem 1 (Jacod's theorem: A martingale version). If (Mt, Ft) with 0  t <  is a continuous local martingale defined on the probability space (, F , P), we denote by M the set of bounded (Ft)-adapted martingales orthogonal to M = (Mt, Ft) what means that M, M   0. If (Xn) is a sequence of
continuous (Ft)-adapted local martingales for which

[Xn]t -p Vt t  [0, )

(1)

with a continuous process V holds, the following two conditions

[Xn, M ]t -p 0 t  [0, )

(2a)

[Xn, N ]t -p 0 t  [0, ) and  N  M

(2b)

are sufficient that (Xn) converges (F )-stably in law to WVt , where W is a standard Brownian motion independent of F.

3

This theorem is a simplified martingale version of the more general theorem 2­1 in [16]. A similar special version of the theorem is also used in [10]. A comprehensive illustrative overview on Jacod's stable limit theory and further motivation and applications of this result can be found in [20]. A discrete-time version of that theorem (cf. 3­1 in [16]) is the following:

Corollary 2.3. Assume that Ztn = Tn,it Xn,i is the endpoint of a discrete martingale and the Xn,i are FTn,i -measurable square integrable random variables and (Wt, Ft) a Brownian motion and Tn,i = Tn,i+1 - Tn,i  0 as n  . If there exists a predictable process (vs)s0 such that

E Xn2,i|FTn,i-1
Tn,i t

-p

t
vs2 ds ,
0

(3a)

 >0:

1E Xn2,i |F{Xn,i> } Tn,i-1 -p 0 ,

Tn,i t

(3b)

E

Xn,i(WTn,i

-

W )|FTn,i-1

Tn,i-1

-p 0 ,

Tn,i t

(3c)

E

Xn,i(MTn,i

-

M )|FTn,i-1

Tn,i-1

-p 0 ,

Tn,i t

(3d)

for all bounded Ft-martingales with M0 = 0 and [W, M ]  0. Then the following stable convergence of the process Ztn holds true:

t
Ztn st Zt = vs dWs
0

(4)

where W  is a Brownian motion defined on an orthogonal extension of the original probability space.

The limiting process in the foregoing Theorem 1 is a time-changed Brownian motion. The Brownian

motion is of central importance in the theory of continuous local martingales, since every continuous local

martingale Mt (Xtn) we have

corresponds to a a representation

Dambis, Dubins-Schwarz time-changed as Dambis, Dubins-Schwarz Brownian

BmrootwionniaWn m[nXonti]tonanBd[Mth]et .

For each sequence

converges weakly to a limiting Brownian motion WV by the asymptotic Knight-theorem. We refer to

Theorem 7.7 in [6] for a proof. The conditions (2a) and (2b) about the quadratic covariations converging

to zero in probability ensure that the weak convergence to WV is stable.

For one fixed 0 < T <  we have the result that XTn converges stably in law to a centred mixed normal

distribution:

XTn st N (0, VT ) .

(5)

The independence of the limiting Brownian motion W and (V, Y ) for any F-measurable random variable Y assures that (WVT , Y ) has the same law as (VT Z, Y ) with Z  N(0, 1) and independent of (VT , Y ). Note, that in the original theorem 2­1 in [16] for semimartingales the same conditions as in our Theorem 1 are imposed for the predictable quadratic (co-)variation processes that coincide with the quadratic (co-)variations for continuous semimartingales. Additionally, a condition that the drift can be neglected asymptotically is imposed. Compared to Theorem 3­1 in [16], we allow for non-equidistant discrete partitions which does not harm the deduction of Theorem 3­1 from Theorem 2­1 in [16]. A conditional Lindeberg-condition (3b) and a convergence condition on the conditional variances (3a) are analogous as in central limit theorems for triangular martingale arrays. The main difference to the stable limit theorem Corollary 3. 1 in [12] (page 58 ff. ) is that a certain nesting condition on the filtrations is replaced by conditions (3c) and (3d). Usually the reference Brownian motion W is given and "fully generates" the Xn,is in the sense that (3d) holds.

4

The theorem also extends to a multi-dimensional setting which is formulated separately in the next corollary. For this purpose let M  denote the transpose of a vector M and the (d × r)-dimensional quadratic covariation [M, N ]t := M i, N j t ij with 1  i  d and 1  j  r for a d-dimensional M and r-dimensional N . Recall that convergence in probability of a vector is equivalent to convergence in proba-
bility for every component.

Corollary 2.4. Let (Mt, Ft) be a d-dimensional continuous local martingale and M again the set of
(Ft)-adapted bounded martingales orthogonal to M (to all components). A sequence of r-dimensional continuous (Ft)-adapted local martingales (Xn) with

t
[Xn, Xn]t -p Vt = wsws ds ,
0
where ws is a predictable Rr  Rr process, and

(6)

[Xn, M ]t -p 0  t  [0, ) ,

(7a)

[Xn, N ]t -p 0  t  [0, ) and  N  M ,

(7b)

converges stably in law to the process

t 0

ws

dWs

,

where

W

is

a

r-dimensional

standard

Brownian

motion

independent of F.

Jacod's theorem provides a convenient stable central limit theorem for our purpose. Nesting conditions
on the sequence of filtrations that are required for other stable limit theorems as in [12] and [22] are not
satisfied here.
Furthermore, the concept of stable convergence enables us to prove the stable weak convergence to mixed Gaussian limiting random variables under an equivalent martingale measure P~ after a Girsanov transfor-
mation, where the drift processes are zero. Stable convergence guarantees that the asymptotic law carries
over to the case with drift under the original measure P. It is in this sense commutative with measure change (cf. [18]). If we have the result that Zn st m + AVAR · N(0, 1) under P~ with a standard Gaussian distribution independent of F, defined on an orthogonal extension of the original probability space and F-measurable bounded random variables m and AVAR, the same convergence holds true under P. Since stable convergence Zn st Z implies for all f  C(E) and F -measurable bounded random variables X

E [Xf (Zn)] = E~ (dP/dP~)Xf (Zn)  E~ (dP/dP~)Xf (Z) = E [Xf (Z)] ,

by uniform integrability of Xf (Zn)(dP/dP~) with

dP/dP~ = exp

-

t1 0 sdBs + 2

t
s2 ds
0

,

where ss + µs = 0.

3. A synchronized realized covolatility estimator

Assumption 1. On a filtered probability space (, F , (Ft) , P), X = (Xt)tR+ and Y = (Yt)tR+ are continuous semimartingales defined by the following stochastic differential equations:

dXt = µXt dt + tX dBtX , dYt = µtY dt + tY dBtY ,

with two (Ft)­adapted standard Brownian motions BX and BY and t dt = d BX , BY t. The drift

processes µtX and µYt are (Ft)­adapted locally bounded stochastic processes and the spot volatilities

tX and tY and t are assumed to be (Ft)­adapted with continuous paths. We assume strictly positive

volatilities and the Novikov condition E

exp

(1/2)

T 0

(µ

·

/

·

)t2

dt

<  for X and Y .

5

We consider the estimation of the quadratic covariation [X, Y ]T of two continuous semimartingales, also called Ito^ processes, X and Y as defined in Assumption 1 from discrete observations following nonsynchronous sampling schemes. We impose the following regularity assumptions on the underlying asynchronous sampling schemes:
Assumption 2. The deterministic observation times T X,n = {0  t(0n) < t1(n) < . . . < t(nn)  T } of X and T Y,m = {0  0(m) < 1(m) < . . . < m(m)  T } of Y are assumed to be regular in the following sense: There exists a constant 0 <   1/3 such that

nX = sup
i{1,...,n}
mY = sup
j{1,...,m}

t(in) - ti(-n)1 , t(0n), T - tn(n) = O n-2/3- , j(m) - j(-m1) , 0(m), T - m(m) = O m-2/3-

.

(8a) (8b)

We consider asymptotics where the number of observations of X and Y are assumed to be of the same asymptotic order n = O(m) and m = O(n) and express that shortly by n  m.

For synchronous data n = m and t(in) = i(n) for all i  {0, . . . , n} holds. In the non-synchronous case the number of observations (n + 1) of X and (m + 1) of Y may differ and the sets of observation times T X,n also contain times t(in) / T Y,m and j(n) / T X,n. We work within the general model where also synchronous observation times can take place and hence T Y,m and T X,n are not assumed to be disjoint.
In the following, we omit the superscripts (n) and (m) for observation times to increase the readability.
Although the sequences of observation times are modeled deterministically, we remark that the case of
random sampling times that are independent of the observed processes is included in that analysis regarding
the conditional law given the observation times. We use the short notation Xti , i = 1, . . . , n from now on for increments Xti - Xti-1 and analogously for Y . In [13] the consistency of the estimator

(HY )

nm

[X, Y ]T =

1Xti Yj ,[min (ti,j )>max (ti-1,j-1)]

i=1 j=1

is proved, where the product terms include all increments of the processes with overlapping observation time intervals, for a similar model of discretely observed Ito^ diffusions with deterministic correlation, drift and volatility functions. Consistency directly carries over to our setting including random correlation, drift and volatility processes. The estimator is also in our setting, furthermore, unbiased if drift terms are zero and else asymptotically unbiased. In [14] it has further been shown that on stronger regularity assumptions on the observation schemes this Hayashi-Yoshida estimator is asymptotically distributed according to a Gaussian law. For a general strategy leading to a synchronization mechanism that keeps to the Hayashi-Yoshida approach and its valuable properties, we focus on an alternative useful method to handle the asynchronicity of the data. It has been introduced in [19], where it was called pseudo-aggregation. The method translates the Hayashi-Yoshida estimator into an iterative algorithm that allows to rewrite the estimator without indicator functions. This can be done by aggregation of addends for which partial sums are telescoping. A first simple rewriting of the Hayashi-Yoshida estimator is obtained by taking the sum of the products of all increments of X with the telescoping sums of aggregated observed increments of Y for that observation time instants overlap with the according observation time instant of X (or in the symmetric way):



(HY )

n

[X, Y ]T = Xti 


1Yj [min (ti,j )>max (ti-1,j-1)]

i=1 j{1,...,m}


m



= Yj 

1Xti  .[min (ti,j )>max (ti-1,j-1)]

j=1

i{1,...,n}

6

first step: · for t0 < 0 and µ0 = min (w  {1, . . . , n}|0  tw):

H0 = {t0, . . . , tµ0 } and G0 = {0}

q1 =

µ0 + 1 if 0 = tµ0 µ0 if 0 < tµ0

and r1 = 1

· for t0 = 0:

H0 = {t0} and G0 = {0} q1 = 1 and r1 = 1

· for t0 > 0 and w0 = min (l  {1, . . . , m}|t0  l):

H0 = {t0} and G0 = {0, . . . , w0 }

q1 = 1 and r1 =

w0 + 1 if t0 = w0 w0 if t0 < w0

ith step (given Hi-1 and Gi-1): · for tqi < ri and µi = min (w  {qi + 1, . . . , n}|ri  tw): Hi = {tqi , . . . , tµi } and Gi = {ri }

qi

qi+1 = µi + 1 if ri = tµi

qi+1 = µi

if ri < tµi

and ri

ri+1 = ri + 1

· for tqi = ri :

Hi = {tqi } and Gi = {ri } qi qi+1 = qi + 1 and ri ri+1 = ri + 1

· for tqi > ri and wi = min (l  {ri + 1, . . . , m}|tqi  l): Hi = {tqi } and Gi = {ri , . . . , wi }

qi qi+1 = qi + 1 and ri

ri+1 = wi + 1 if tqi = wi

ri+1 = wi

if tqi < wi

Algorithm 1: Iterative algorithm for construction of the joint grid from asynchronous data.

Defining the next-tick interpolation ti,+ := min0jm (j|j  ti) and the previous-tick interpolation ti,- := max0jm (j|j  ti), the last expression can be illustrated

(HY )

n

[X, Y ]T

=

Xti

Y - Yti,+

ti-1,-

i=1

.

The algorithm which we will use is a more enhanced method to aggregate the data in an adequate way. For this purpose (N + 1) sets Hi and Gi are constructed, where N < min (n, m), each set including one
or more than one observation time of X and Y , respectively. This method to construct a joint grid for the
observations of the two processes is described by Algorithm 1.
The Algorithm 1 that we have first presented in [4] stops after (N + 1) steps when the last observation time is reached. We pass over from the original observations to the sums of observed increments XHi over sets Hi and Y Gi over sets Gi, respectively. The observations are grouped together so that the resulting realized

7

covolatility estimator

N nm

X Hi Y Gi =

1Xti Yj [min (ti,j )>max (ti-1,j-1)]

i=0 i=1 j=1

calculated from the `synchronized' observations

XHi =

Xtj , Y Gi =

Yj , i  {0, . . . , N } .

tj Hi

j Gi

for the integrated covolatility will coincide with the one by [13] stated above. We use a different illustration of this estimator compared to [19] making use of telescoping sums. With the denotation expressions from Algorithm 1

µi = max (k|tk  Hi), qi = min (k|tk  Hi),

wi = max (k|k  Gi) and ri = min (k|k  Gi) , i  {0, . . . , N }

and for the purpose of a simpler notation

Xgi = Xtµi , Xli = Xtqi-1 ,

Yi = Ywi , i  {0, . . . , N } and Yi = Yri-1 , i  {1, . . . , N }

with l0 := t0, 0 := 0, XHi and Y Gi can be written as telescoping sums XHi = (Xgi - Xli ), Y Gi = (Yi - Yi ) . This leads to

(HY )

N

[X, Y ]T = (Xgi - Xli ) (Yi - Yi ) ,

i=1

(9)

where summation starts with i = 0 or i = 1 since the addend for i = 0 is always zero. Although we use this
specific new illustration throughout this article, we will call this realized covolatility of our synchronized
observations also Hayashi-Yoshida estimator in the following. In this notation gi denotes the greatest and li the last observation time before the least element of the set Hi and analogously i and i of Gi.

Example An illustration of the application of Algorithm 1 to observations is given in Figure 1. In this example, we have H0 = {t0}, G0 = {0}, H1 = {t1, t2, t3}, G1 = {1}, H2 = {t3}, G2 = {2, 3}, H3 = {t4, t5, t6}, G3 = {4}, H4 = {t6, t7}, G4 = {5}, H5 = {t7, t8}, G5 = {6}, H6 = {t8}, G6 = {7, 8}, H7 = {t9}, G7 = {8, 9}, H8 = {t10}, G8 = {9, 10} .
The example highlights the important features of the synchronization procedure. The sets Hi and Gi are in general not disjoint and the maxima of consecutive sets can be the same time points. The minimum of a successive set can as well equal the maximum of the prevenient. Contrarily, consecutive minima are not equal. For further examples we refer to [19]. Of course the example is just for illustration and the number of observations is much smaller than in practice. The synchronization of n + 1 = 11 and m + 1 = 11 observations leads to N + 1 = 9 synchronized observations in this example.

The fact that we obtain (N + 1) < min (n, m) + 1 synchronized observations indicates heuristically that the efficiency of such techniques of covariance estimation mainly depends on the number of observations available for the less liquid process which is observed at a lower frequency. By Assumption 2 we restrict us to the case that n and m are of the same order. Thus for the suprema of times between two observations

nX = O N -2/3- and nY = O N -2/3-

holds with a constant 0 <   1/3.



In the next section, we show that on Assumption 1 and 2 the estimator (9) is N -consistent and, on further

8

Figure 1: Example for synchronization using Algorithm 1.

assumptions on the asymptotic behavior of the asynchronous sampling schemes, asymptotically normally distributed. Using standard interpolation methods such an estimator cannot be obtained. Another recent approach to deal with non-synchronous discrete observations in a general setting including market microstructure noise has been proposed by [2]. This method is also related to our approach. The so-called refresh times are the cumulative sums of waiting times until both processes are observed. Assume that in the ith step of Algorithm 1 tqi < ri holds. Then the next observation times of X are grouped together ending with the first observation time tµi-1 < ri  tµi greater or equal than ri . Then we start the next comparison step and compare this last observation time grouped to the set Hi to ri+1, except for the case where two synchronous observations appeared, where we compare the two following times. Since in the completely asynchronous case at the refresh times only one of the two processes is observed, the refresh time method used in [2] includes a previous-tick interpolation for the unobserved process at the refresh times. Refresh times provide the `closest synchronous approximation' to the asynchronous sampling schemes that we define in Proposition 11 below. The number of refresh times which are denoted in this work by Ti, i = 0, . . . , N , equals the number of sets constructed by pseudo-aggregation. In a setting that also takes microstructure noise into account, a consistent estimator requires smoothing techniques to reduce the noise perturbation and the optimal convergence rate is slower (cf. [4]). The previous-tick interpolation, however, causes a negative bias due to asynchronicity when calculating the simple realized covolatility estimator based on the refresh time and previous-tick approach and it does not equal the estimator of Hayashi-Yoshida. The reason for this bias is that, due to the previous-tick interpolation, products of increments with overlapping observation time instants fall out of the realized covolatility. The pseudoaggregation Algorithm 1 used in this work corresponds to the refresh time method when replacing the previous-tick interpolation by a next-tick interpolation for the right end points of refresh time instants. Then, the resulting realized covolatility of `synchronized observations'

(HY )

N

[X, Y ]T = (Xgi - Xli ) (Yi - Yi )

i=1

N

= X - XTiX,+

TiX-1,-

i=1

Y - YTiY,+

TiY-1,-

(10)

coincides with the Hayashi-Yoshida estimator and has no bias due to asynchronicity. As figured out in the simulation study of [4] the asymptotically vanishing influence of the bias due to pure previous-tick interpolation also shows up in the setting with noise for finite sample sizes and mild noise variances for that combined estimators are constructed in [2] and [4], among others. Figure 2 visualizes refresh times Ti, i = 0, . . . , 8 for our above given example. For this example the

9

Figure 2: Example for synchronization using Algorithm 1 including refresh times.

realized covolatility calculated with refresh time previous-tick interpolated values equals
(Xt2 - Xt0 )(Y1 - Y0 ) + (Xt3 - Xt2 )(Y3 - Y1 ) + (Xt5 - Xt3 )(Y4 - Y3 )+ (Xt6 - Xt5 )(Y5 - Y4 ) + (Xt7 - Xt6 )(Y6 - Y5 ) + (Xt8 - Xt7 )(Y7 - Y6 )+
(Xt9 - Xt8 )(Y8 - Y7 ) + (Xt10 - Xt9 )(Y10 - Y8 )
and is biased downwards due to non-synchronicity, whereas (9) yields
(Xt3 - Xt0 )(Y1 - Y0 ) + (Xt3 - Xt2 )(Y3 - Y1 ) + (Xt6 - Xt3 )(Y4 - Y3 )+ (Xt7 - Xt5 )(Y5 - Y4 ) + (Xt8 - Xt6 )(Y6 - Y5 ) + (Xt8 - Xt7 )(Y8 - Y6 )+
(Xt9 - Xt8 )(Y9 - Y7 ) + (Xt10 - Xt9 )(Y10 - Y8 ) ,
which is an unbiased estimator for observations of processes according to Assumption 1, when drift terms are assumed to be zero.

4. Asymptotic distribution theory

In this section the elements for an analysis of the asymptotic properties of the estimator (9) are developed where the emphasis is on the asymptotic distribution of the estimator. The following technical Proposition constitutes the theoretical justification that the refresh times Ti(n), 1  i  N introduced in the foregoing section can serve as a convenient basis to decompose the overall estimation error of the synchronized realized covolatility (9). For every N these times induce a partition of the time horizon [0, T ] that we call the closest synchronous approximation.
Proposition 4.1. If we define Ti(N) := min (gi, i), i = 0, . . . , N , the set T syn,N = {T0(N), . . . , TN(N)} induces a partition of the time span [0, T ] in the sense that  i[Ti(N), Ti(+N1)) = [T0(N), T - TN(N)). The following equality holds true:

Ti(N) = min gi(N), i(N) = max li(+N1), i(+N1) , i = 1, . . . , N - 1

(11)

and on Assumption 2 N := supi{1,...,N} Ti(N) - Ti(-N1) = O N -2/3- holds.
In the following we frequently leave out superscripts indicating dependence on N to guarantee clarity and increase the readability.
Proof. Assume without loss of generality gi  i for an arbitrarily fixed i  {1, . . . , N - 1}. Taking Algorithm 1 into account, we proof that (11) holds true. If gi < i, then the observation times i and gi,+ := min tk  T X |tk > gi are compared in the (i + 1)th step of the synchronization Algorithm 1 and gi,+ = min tk  T X |tk  Hi+1 holds true. Thus, gi = li+1 and (11) holds true. We remark that in this case i  Gi+1 and thus i > i+1 = i,- := max k  T Y |k < i  i-1. If gi = i, then the observation times gi,+ and i,+ are compared in the (i + 1)th step of Algorithm 1 and

10

li+1 = i+1 = gi = i what implies (11).
Equation (11) does not hold true for i = 0, N and T0 = t0  0 because we have set l0 = t0 and 0 = 0. Although consecutive maxima gi of the sets Hi and i of the sets Gi, respectively, can be equal, Ti > Ti-1
holds for all i  {1, . . . , N } because gi+1 = gi implies that i+1 > i and i+1 = i implies that gi+1 > gi. Hence, the set T syn induces a partition of the time span [0, T ].

The times Ti, i = 0, . . . , N defined through (11) equal the refresh times from [2] as has been mentioned in the last section. We use Proposition 4.1 to split the error of the estimator (9) for the integrated covolatility [X, Y ]T in two asymptotically uncorrelated parts. The error of the estimator (9) can be written

NT

(Xgi - Xli ) (Yi - Yi ) -

ttX tY dt = DTN + ANT

i=1 0

where

N
DTN :=
i=1

XTi - XTi-1 YTi - YTi-1 -
t0 0
- ttX tY dt -
0

Ti
ttX tY dt
Ti-1
T
ttX tY dt
tn m

(12)

is a synchronous-type discretization error of the realized covolatility estimator evaluated with synchronous observations at the times Ti, i = 0, . . . , N , which is the closest synchronous approximation to the asynchronous sampling scheme, and

N

ANT =

1(Yi - Yi ) (Xgi - XTi ) {Ti=i} +

i=1

N
1+ (XTi - Xli ) (Yi - YTi ) {Ti=gi} +
i=1

YTi - YTi-1 XTi - XTi-1

1X - XTi-1

li {Ti-1=i}

1Y - YTi-1

i {Ti-1=li}

(13)

is the remaining additional error due to the lack of synchronicity. When we write the increments involved in the estimator (9) in the way

Xgj - Xlj = Xj+ + XjS + Xj- , Yj - Yj = Yj+ + YjS + Yj- ,
where Xj+ = Xgj - XTj denotes the next-tick interpolation error at right-end points, Xj- = XTj-1 - Xlj the previous-tick interpolation error at left-end points, XjS = XTj - XTj-1 , j = 1, . . . , N the increment over the time instant of the closest synchronous approximation and analogously for Y , DTN and ANT can be expressed:

N
DTN = XiS YiS ,

i=1

N

ANT =

Xi+(YiS + Yi-) + Yi+(XiS + Xi-) + Xi-YiS + Yi-XiS

i=1

.

DTN is an usual synchronous-type realized covolatility but incorporates an idealized sampling design at the times of the closest synchronous approximation for which we do not have observations in an asynchronous
setting. Nevertheless, this idealized approximation turns out to be helpful for our further analysis. The error due to non-synchronicity ANT hinges on the interpolations that have to be carried out since we do not observe X and Y at the times TiN , 1  i  N . The term is asymptotically centred since only products of increments over disjoint time instants remain whereas DTN is an unbiased estimator for [X, Y ]T . Since either X or Y is observed at a certain Ti, 1  i  N , one of each interpolation errors in the illustration
above equals zero.

11

Figure 3: Illustration of the synchronous approximation for our example.
Proposition 4.2. The Brownian parts of ATN and DTN are uncorrelated. This means, that if we assume the drift terms to be identically zero in Assumption 1, ANT and DTN are uncorrelated. If the drift terms are non-zero, ATN and DTN are asymptotically uncorrelated.
Proof. ANT and DTN are both centred. If Assumption 1 holds with µXt  µYt  0, the expectation of the product of ATN and DTN is zero, since the previous- and next-tick interpolated increments in (13) are centred and uncorrelated to the other three factors in each addend of the inner sums. If we allow for non-zero drift terms, Assumption 1 and Assumption 2 ensure that the increments over time intervals due to the drift induce terms at most of order N in probability by products of drift terms and at most of order N1/2 in probability by products of drift and Brownian increments in the overall correlation.
In Figure 3 the observation times j, j = 0, . . . , 11 of Y for our Example 1 from the last section are plotted against the observation times ti, i = 0, . . . , 11 of X. The dashed lines intersect for synchronous observation times t0 = 0, t3 = 3 and t10 = 10 on the diagonal of the square in Figure 3. A similar visualization of the realized covolatility estimator for synchronous and equidistant data would yield coextensive squares around the diagonal, over which multiplied increments are summed up. Refresh times are (in general) not equidistant but provide a synchronous realized covolatility estimator as an approximation. The Hayashi-Yoshida estimator (9) is the sum of products of increments with overlapping observation time instants. The relation to the synchronous approximation DTN is that we have next-tick interpolations and previous-tick interpolations to the times Ti, i = 0, . . . , 8 and take increments from previous-tick interpolated values to next-tick interpolated values. The time instants of DTN are visualized for our example in Figure 3. The previous- and next-tick interpolations are illustrated in Figure 4. The products of time instants leading to the error ATN are illustrated in the same picture by the grey rectangles. As can be seen for the example in Figure 4, ATN is the sum of the errors by the ith next-tick interpolation multiplied with the increments of the other process over [min (li, i), Ti] and the sum of the errors of the ith previous-tick interpolation multiplied with the increments of the other process over [Ti-1, Ti]. The sum of the increments over the squares in Figure 3, DT8 for our example, and the grey rectangles in Figure 4, AT8 for our example, is the Hayashi-Yoshida estimator evaluated at the end of the last section.
12

Figure 4: Illustration of the next- and previous-tick interpolated values and the error due to non-synchronicity for our example.

Definition 2 (quadratic (co-)variations of time). For any N  N let Ti(N), i = 0, . . . , N be the times from the partition of [0, T ] defined in (11) above and gi(N), i(N), li(N), i(N) the corresponding observation times designated by Algorithm 1 from the estimator (9). T /N is the mean of the time instants Ti(N) = Ti(N) - Ti(-N1), i = 1, . . . , N . Define the following sequences of functions

GN (t) = N T

Ti(N )

2
,

Ti(N ) t

(14a)

F N (t) = N T

(Ti(N) - i(N))(gi(N) - Ti(N)) + Ti(N) - li(N)

Ti(+N1) t

i(N) - Ti(N)

+Ti(+N1) Ti(N) - li(+N1) + Ti(+N1) Ti(N) - i(+N1) ,

(14b)

HN (t) = N T
Ti(+N1) t

Ti(N) - li(+N1)

gi(N) - Ti(N) + Ti(N) - i(+N1)

i(N) - Ti(N) ,

(14c)

for t  [0, T ] that we call sequences of quadratic (co-)variations of times.

A stable central limit theorem for the estimation error is deduced on the assumption that the sequences defined by (14a), (14b) and (14c) converge pointwise and the sequences of difference quotients uniformly:

Assumption 3 (asymptotic quadratic (co-)variation of times). Assume that for the sequences of sampling schemes and the times Ti(N), gi(N), i(N), li(N), i(N) and the sequences of quadratic (co-) variations of times GN (t), F N (t), HN (t) defined in Definition 2 the following holds true:
(i) GN (t)  G(t) , F N (t)  F (t) , HN (t)  H(t) as N  , where G(t), F (t), H(t) are continuously differentiable functions on [0, T ].

13

(ii) For any null sequence (hN ), hN = O N -1 GN (t + hN ) - GN (t)  G (t) hN

(15a)

F N (t + hN ) - F N (t)  F (t) hN

(15b)

HN (t + hN ) - HN (t)  H (t) hN
uniformly on [0,T] as N  .

(15c)

Assumption 3 is necessary to ensure that the sequence of variances of the estimator (9) converges as
n, m  . The derivative of the asymptotic quadratic variation of refresh times (15a) will appear in the asymptotic variance of the discretization error DTN , since refresh times are (in general) not equidistant. For
Ti(N) = T /N for all i  {0, . . . , N }, G (t) = 1[0,T ] holds true.
The uniform convergence of the difference quotients defined by (15b) and (15c) are necessary to ensure that the sequence of variances of ANT converges as N  . The assumptions imposed by (15a)-(15c) are weaker than assuming convergence of the joint sampling design of T X,n, T Y,m and are not very restric-
tive. They hold true whenever the sequences of sampling schemes tend to a certain state of asynchronicity
or have a uniform behaviour of non-synchronicity in the limit as n, m  . For homogeneous sampling
schemes these (co-)variations of time converge to linear limiting functions. The sequence of functions F N describe an interaction of interpolation steps between the two processes. In contrast, HN is defined to measure an impact of the in general non-zero correlations of next-tick and
previous-tick interpolations to the same refresh time Ti, for each process separately.

Example: Consider the synchronous equidistant sampling schemes with N = n = m and ti(n) = j(n) = i/n, i = 0, . . . , n. The left-hand side of Figure 5 shows the quadratic (co)variations of time GN , F N and HN for N = 30000. F N and HN are identically zero since there are no asynchronous observations and because Ti(N) = i/N, t(in) = i(n), 0  i  n, interpolation steps are redundant and ATN equals zero. The function GN is a step function that will tend to the identity on [0, T ] as N  .
Next, we consider a situation which originates from the complete synchronous equidistant one by shifting
one time-scale half a time instant 1/2N . Then we have completely non-synchronous sampling schemes
and we will call this situation intermeshed sampling. In this case the synchronous approximation is still
equidistant with instants 1/N and, hence, G is the identity function. F and H are linear limiting functions with slope 1 and 1/4, respectively. Interpolations are carried out for all 1  i  N for the same process for
which its first observation takes place after the first observation of the other process. All interpolation steps
equal 1/2N and thus H = 1/4 follows. Since for H interpolated time instants 1/2N are multiplied with
refresh time instants 1/N in both addends due to the specific structure, F equals the identity on [0, T ]. The functions GN , F N , HN for intermeshed sampling are illustrated in Figure 5 on the right-hand side.

In the next section we will show that for an important special case, independent homogeneous Poisson
sampling, (15a)-(15c) are fulfilled when replacing deterministic convergence by convergence in probability. Furthermore, the stochastic limits G (t), F (t), H (t) are calculated explicitly and are again constant on [0, T ]. For data applications one can calculate easily empirical versions G~n,m(t), F~n,m(t), H~n,m(t) of G (t), F (t), H (t) and use those as estimators for (15a)-(15c).
The key result of this section is the following Theorem 2. The detailed proof is postponed to the Appendix
A. This result gives insight into the asymptotic distribution of the Hayashi-Yoshida estimator. It improves
on the asymptotic normality result in [14], since the weak convergence is stable in the setting where we
allow for random correlation, drift and volatility processes. The representation of the asymptotic variance
using (15a)-(15c) differs from that in [15], where a similar stable convergence result is established, by

14

Figure 5: Quadratic (co-)variations of time for synchronous equidistant (left) and intermeshed (right) sampling.

the decomposition of the estimation error in (12) and (13) and the notion of (co-)variations of times. The latter provide helpful tools to describe the stylized facts and features of non-synchronous data and build the ground work for combined approaches for widespread generalizations and extensions of the underlying model. A very important one is the generalized multiscale estimator in [5] when market microstructure noise effects are taken into account.

Theorem 2. The estimation error of (9) converges on the Assumptions 1, 2 and 3 stably in law to a centred, mixed Gaussian distribution:

N N (Xgi - Xli ) (Yi - Yi ) - [X , Y ]T
i=1

st N (0 , vDT + vAT ) ,

(16)

with the asymptotic variance

TT

vDT +vAT = T G (t) tX tY 2 t2 + 1 dt + T

F (t) tX tY 2 + 2H (t) ttX tY 2 dt

00

where the two addends come from the asymptotic variances of DTN and ANT , respectively.

5. Independent Poisson sampling
In this section, we consider the model in which the sequences of observation times are supposed to be realizations of two homogeneous Poisson processes that are mutually independent and independent of the processes X and Y . Thereto, let n~(n)(t) and m~ (n)(t) be sequences of two independent homogeneous Poisson processes with parameters T n/1 and T n/2 (n  N), such that the waiting times between jumps of n~(n) and m~ (n) are exponentially distributed with expectations E t(in) = 1/n and E j(n) = 2/n , i  N, j  N. Thus, n~(n)(T ) and m~ (n)(T ) correspond to the sequences giving the numbers of observation times of X and

15

Y in the time span [0, T ]. The increments of the sampling times of the closest synchronous approximation (11) are maxima of the exponentially distributed waiting times and we obtain:

Tk(n)  F (t) = 1 - exp

- tn 1

- exp

- tn 2

+ exp

-tn

11 +
1 2

,k  N.

Denote N~ (T )(n) = maxNN {

N k=0

Tk(n)



T }.

We focus on the characteristics of the sampling

schemes affecting the asymptotics of the synchronized realized covolatility estimator (9). In particular

our interest is in the quadratic (co-)variations of times defined in Definition 2.

Proposition 5.1. In the independent homogeneous Poisson model for sampling schemes, it holds true that

GN (t) -p 2

1

-

1222

+

21222 (12 + 22)(1

+

2)2

t T

14 t = 9 T if 1 = 2 =  ,

(17a)



F N (t)

-p

  (12

212 + 12 +

22)

+



41222

t 

1

+

2

-

1 2 1 +2

2 (1 + 2)2  T

10 t = 9 T if 1 = 2 =  ,

(17b)

 HN (t) -p 2 


1

1

+

2

-

1 2 1 +2



1222

t 

2 (1 + 2)2  T

2t

= 9T

if 1 = 2 = 

.

(17c)

Proof. Poisson processes are Markovian and the exponential distribution of the increments between arrival

times is memoryless. Wald's identity ensures that E

N~ (T )(n) k=0

Tk(n)

= E N~ (T )(n)

E T1(n) . For

the proofs of these attributes and further information on properties of mutually independent homogeneous

Poisson processes we refer interested readers to [7].

First of all we ascertain that ti(n) = j(n)  (i, j)  {1, . . . , n~(n)(T )} × {1, . . . , m~ (n)(T )} almost surely. For an arbitrarily fixed i, the expected values of next-tick, previous-tick and refresh time instants yield

E gi(n) - Ti(n) = E gi(n) - Ti(n)

Ti(n) = i(n) P

Ti(n) = i(n)

= 1 2 , n 1 + 2

E i(n) - Ti(n)

= 2 1 , n 1 + 2

E Ti(n) - li(+n)1

=



y

n

e-

yn 2

e-

yn 1

0 2

dy

=

1 122 n (1 + 2)2

,

E Ti(n) - i(+n)1

=

1 n

122 (1 + 2)2

,

E Ti(+n1) - Ti(n)

= 1 + 2 - 1 12 . n n n 1 + 2

The conditional expectations given that the ith refresh time Ti(n) = i(n) is an arrival time of m~ (n) yield E Ti(+n1) - Ti(n)|Ti(n) = i(n) = E Ti(+n1) - Ti(n) and E Ti(n) - li(+n)1|Ti(n) = i(n) = E Ti(n) - li(+n)1 ,

16

since the latter previous-tick interpolation is zero with probability 1 if Ti(n) = i(n). Only for (Ti(n) - i(n)) the conditional expectation differs from the unconditional and can be calculated by further conditioning

E Ti(n) - i(n)|Ti(n) = i(n) =

E Ti(n) - i(n)|Ti(n) = i(n) , Ti(-n1) = (in) P Ti(-n1) = (in)|Ti(n) = i(n)

+ E Ti(n) - (in)|Ti(n) = i(n) , Ti(-n1) = li(n) P Ti(-n1) = li(n)|Ti(n) = i(n)

=

1

+

2

-

12 1 + 2

1 1 + 2

+

21

1

2 +

2

,

where the factor 21 in the second addend is simply the expectation of the waiting time for two jumps of n~. Here, we have used some simplifying symmetry aspects, a rigorous proof using the density functions is

obtained by calculation of

1E T - (n) i

(n) i { Ti(n)=i(n),Ti(-n1) =(in)}

=




x

n

e-x

n 1

e-y

n 2

y

n

e e-x

n 1

-y

n 2

dx dy

=

212

.

0 x 1

2

1 + 2

The conditional expectations on Ti(n) = gi(n) are deduced analogously. Since E Ti(n) - li(n) =
E Ti(n) - Ti(-n1) +E Ti(-n1) - li(n) and the (conditional) expectations of the products occurring in GN , F N ,
HN equal the products of (conditional) expectations thanks to the memorylessness of exponential distri-
butions, the latter results suffice to apply the law of large numbers to the empirical (co-)variations of times. For the asymptotics of GN (T ), F N (T ) and HN (T ), we conclude for the number of addends N~ (T )(n), that EN~ (T )(n) = (T /)n + O(n) with  = 1 + 2 - (12)/(1 + 2) what follows from EN~ (T )(n)E T1(N) = T + Op(n-1) and Var N~ (T )(n) = O(n-1) since

N~ (T )(n)



Var 

Tk(n) = Var N~ (T )(n) E

k=0

T1(n) 2 + E N~ (T )(n) Var T1(n) .

The exact probability mass functions of the counting processes N~ (t)(n) associated with the maxima of the waiting times t(in), j(n) have a quite complicated form, so that we only give the last two results on the expectation and the variance that are necessary for the proof of the proposition.
From the preceding conclusions, it follows that

GN (t) = N~ (T )(n) T

Ti(n)

2

-p

n2 2

Ti(n) t

212 n2

+

222 n2

-

2

12 (1 + 2)

21 n2

t ,
T

F N (t) = N~ (T )(n) T

(Ti(n) - i(n))(gi(n) - Ti(n)) +

Ti(+n1) t

Ti(n) - li(n)

i(n) - Ti(n)

+ Ti(+n1) Ti(n) - li(+n)1 + Ti(+n1) Ti(n) - i(+n)1

-p

t T 2

12 (1 + 2)

21

+

22

-

2 12 (1 + 2)

+

212 (1 + 2)

+

1

+

2

-

12 (1 + 2)

122 + 122 (1 + 2)2

,

HN (t) = N~ (T )(n) T
Ti(+n1) t

Ti(n) - li(+n)1

-p

t T 2

1222(1 + 2) (1 + 2)3

.

gi(n) - Ti(n) + Ti(n) - i(+n)1

i(n) - Ti(n)

17

Figure 6: Quadratic (Co-)variations of times for homogeneous Poisson sampling.

Inserting  we obtain formulae (17a)-(17c). In the evaluation of GN we have also used the second moment of T1(n) which can be calculated using the above given distribution function.
Figure 6 depitcs the quadratic (co-)variations of times for simulated mutually independent homogeneous Poisson processes. On the left-hand side both parameters have been set  = 1 for T = 1 and n = 30000. The stochastic limits are linear increasing functions on [0, 1] with slope 14/9, 10/9, 2/9 and 1/4, respectively. On the right-hand side we see the (co-)variations of times for T = 1, n = 30000, 1 = 1, 2 = 0.5. Those tend in probability to linear limiting functions with slope 82/49, 44/49, 8/49 and 2/9, respectively. In the model of non-synchronously observed Ito^ processes X and Y which fulfill Assumption 1 and observation times following an independent Poisson sampling scheme of the above given form, we derive the following stable central limit theorem as special case of Theorem 2:

Corollary 5.2. The estimation error of the synchronized realized covolatility estimator (9) converges on the Assumption 1 conditionally on the independent Poisson sampling scheme with 0 < 1 <  and 0 < 2 <  stably in law to a centred mixed Gaussian distribution:

N~ (T )(n) N~ (T )(n) 
i=0

X - Xgi(n)

li(n)



Y - Yi(n)

(in)

- [X , Y ]T  st N (0 , vT ) ,

(18)

with the asymptotic variance

T
vT = 2
0

ttX tY 2 dt +

2 12 + 1 (1 + 2)

T
tX tY 2
0

where the two addends come from the asymptotic variances of the discretization error DTN of the closest

synchronous approximation (12) and the additional error ATN due to interpolations (13), respectively, and



=

1

+

2

-

.1 2
1 +2

18

Proof. It is a basic result in the theory of extreme values that for the supremum of n i. i. d. exponentially distributed waiting times Ti with ETi = n-1, it holds true that supi (Ti) = Op (log (n)/n). We refer to [11] for a proof. In the setting of mutually independent homogeneous Poisson processes with parameters T n/1 and T n/2, we conclude that supi{1,...,N~ (T )(n)} = Op log N~ (T )(n)/N~ (T )(n) . Hence, Assumption 2 holds for the sampling design where the orders of nX , mY hold in probability. Then all findings in the proofs of Propositions A.2 and A.5 stay valid when we insert the (co-)variations of time deduced above in the limits of the variances.
The stable convergence holds conditionally given the observation times, what means that endogenous observation times are not covered but Poisson sampling independent of the processes X and Y . The asymptotic variance of the mixed Gaussian limit is in line with the results by [14] and [15]. We remark that one has to pay attention to the proportionality to  in the rate N~ (T )(n) when comparing the asymptotic variance to the one in [15]. From an applied point of view, the model considered in this section could be criticized for its flaw that sampling schemes of two correlated processes are modeled to follow two independent processes and for time homogeneity. Both seems to be rather unrealistic in financial time series. However, independent and homogeneous Poisson sampling times designs constitute the most commonly used model in this research area (cf. [23], [13] among others) because they are handy and allow for explicit calculations while the model is not too far away from the real world.

6. Asymptotic variance estimation

Finally, we state a consistent estimator for the asymptotic variance of the Hayashi-Yoshida estimator (9) from Theorem 2. Since in [14] a central limit theorem for the case of deterministic correlation and volatility functions has been proved, the asymptotic variance is non-random in that setting. In a recent publication [15], in that the authors also generalize the asymptotic distribution result to a stable central limit theorem in the setting of random volatility and correlation functions, a consistent estimation method for the asymptotic variance is provided using kernel estimates. Our estimator differs from this method and we incorporate only one time transformed histogram-type estimator.

Proposition 6.1. Define the estimator

N -1

AVARHY := N

(Xgj - Xlj )(Yj - Yj ) (Xgj - Xlj )(Yj - Yj )

j=1

+ 2(Xgj+1 - Xlj+1 )(Yj+1 - Yj+1 ) - 3T I~1

with

 HY 2

I~1

:=

KN j=1

  [X, Y ]GNj  GjN

 

GN (T ) KN

being a histogram-based estimator for

T 0

(ttX

tY

)2G

(t)dt.

The estimators for the increase of the

quadratic covariation on bins are Hayashi-Yoshida estimators of the type

HY

 [X, Y ]GjN :=

(Xgr - Xlr )(Yr - Yr ) .

r[GjN ,GNj+1)

It holds true that

TT

AVARHY -pT G (t) tX tY 2 t2 + 1 dt + T

F (t) tX tY 2dt + 2H (t) ttX tY 2dt

00

19

on the Assumptions 1, 2 and 3. Thus, we have on hand a consistent estimator for the asymptotic variance of the Hayashi-Yoshida estimator and the feasible stable central limit theorem

(HY )

[X, Y ]T

st N(0, 1) .

AVARHY

(19)

For more motivation and details on the construction of histogram estimators for which bins are chosen equispaced according to a transformed timescale associated with a certain monotonic function, as the asymptotic quadratic variation of refresh times here, we refer to [5]. Proposition 6.1 is proved in Appendix B.

A. Proof of Theorem 2

A.1. Discretization error of the synchronous approximation
Proposition A.1. On the Assumptions 1, 2 and (15a) the discretization error of the closest synchronous approximation converges stably in law to a centred mixed Gaussian distribution:

N T

DTN

st

N

0,

T
G (t)

tX tY

2 (2t + 1) dt

0

.

(A.1)

Proof. In the proofs superscripts of the sampling times are frequently omitted to increase the readability.

First note that on Assumption 1, by Girsanov's theorem we may without loss of generality further suppose

that µXt = µtY = 0 identically since we have learned in Section 2 that stable convergence is commu-

tative with measure change. Let Mt and Lt be the continuous martingales Lt =

t 0

sX

dWsX

,

Mt

=

t 0

sY

dWsY

where W X , W Y

are two standard Brownian motions with quadratic covariation

W X, W Y

t=

t 0

ssX sY

ds

and

denote

Li

=

Ti 0

sX

dWsX

,

Mi

=

Ti 0

sY

dWsY .

Proposition A.2. On the same Assumptions as in Proposition A.1, the process DtN defined by

DtN :=

N T (Li - Li-1)(Mi - Mi-1) -
Ti(N ) t

t
ssX sY ds
0

for 0  t  T converges as N   stably in law:

DtN st

t

 vDs

dWs

0

where W  is a Brownian motion independent of F and

(A.2)

vDs = G (s)(sX sY )2(s2 + 1) .

(A.3)

Proof. We will prove this stable convergence of the process associated with the transformed discretization error by application of Jacod's stable limit Theorem 1. It is also possible to use the discrete-time version of this Theorem from Corollary 2.3 which we apply in the next subsection. Using the definition of the quadratic covariation process of martingales or integration by parts formula, we find an illustration of the discretization error by a sum of stochastic integrals and an asymptotically

20

negligible term:

LTi - LTi-1
Ti(N ) t

MTi - MTi-1 =

(Li - Li-1) (Mi - Mi-1)

Ti(N ) t

= (LiMi - LiMi-1 - MiLi-1 + Li-1Mi-1)

Ti(N ) t

=
Ti(N ) t

Ti Ti

LsdMs +

MsdLs +  [L, M ]Ti

Ti-1

Ti-1

- Mi-1(Li - Li-1) - Li-1(Mi - Mi-1)

= [L, M ]T(t) - [L, M ]T0 +
Ti(N ) t

Ti Ti

(Ls - Li-1)dMs +

(Ms - Mi-1)dLs

Ti-1

Ti-1

where we denote T(t) := maxi (Ti(N)  t). Thus, we obtain

N T

DtN

=

N T
Ti(N ) t

Ti Ti

(Ls - Li-1)dMs +

(Ms - Mi-1)dLs

Ti-1

Ti-1

+ Op

N T

since [L, M ]T(t) - [L, M ]T0 = [L, M ]t + Op(1). Consider the centred continuous martingale

,

(N) :=

N T
Ti(N ) t

Ti Ti

(Ls - Li-1)dMs +

(Ms - Mi-1)dLs

Ti-1

Ti-1



+ (Ls - LT(t))dMs + (Ms - MT(t))dLs ,   [T(t), t] .

T(t)

T(t)

We calculate the corresponding quadratic variation process at time t:



(N )

N =

t T

Ti(N ) t

N =
T
Ti(N ) t

Ti Ti

(Ls - Li-1)dMs +

(Ms - Mi-1)dLs

+ 

Ti-1

Ti-1

t

Ti Ti

(Ls - Li-1)2d [M ]s +

(Ms - Mi-1)2d [L]s

Ti-1

Ti-1

(N) - (N)
t T(t)

Ti

+ 2 (Ls - Li-1)(Ms - Mi-1)d [M, L]s
Ti-1

+ (N) - (N)
t T(t)

N = T(Lemma A.3)
Ti(N ) t

Ti Ti

[L - Li-1]s d [M ]s +

[M - Mi-1]s d [L]s

Ti-1

Ti-1

Ti
+ 2 [L - Li-1]s [M - Mi-1]s d [M, L]s + Op(1)
Ti-1

NN =
T
i=1

Ti
d ([L - Li-1]s [M - Mi-1]s)
Ti-1

Ti
+ 2 [L - Li-1]s [M - Mi-1]s d [M, L]s + Op(1)
Ti-1

21

N =
T
Ti(N ) t

Ti sX 2 ds Ti sY 2 ds

Ti-1

Ti-1

+

Ti 2
ssX sY ds + Op(1)
Ti-1

N =
T
Ti(N ) t

(X Y )i 2 (Ti)2 + (X )i(Y )i 2 (Ti)2 + Op(1)

=
Ti(N ) t

G(N)(Ti) - G(N)(Ti-1) Ti

t
-p G (s)(s2 + 1)(sX sY )2 ds .
0

2

 X Y
Ti-1 Ti-1

1 + Ti-1 2

Ti + Op(1)

In this calculation we have used integration by parts and the change of variables Theorem for the integrals

with quadratic covariation integrators that are of finite variation. The second last equality is an applica-

tion of the mean value theorem (the volatility and the correlation processes are continuous and thus also

bounded on compact sets) where the constants (X )i, (Y )i and (X Y )i come from. The Riemann

sum converges and with Definition 2 and Assumption 3 this yields the convergence in probability of the

quadratic variation to

t 0

G

(s)(s2

+

1)(sX

sY

)2

ds

=

t 0

vDs .

The

third

equality

above

is

proved

in:

Lemma A.3. It holds true that the approximation error terms

Ti(N ) t

Ti Ti

(Ls - Li-1)2d [M - Mi-1]s -

[L - Li-1]s d [M - Mi-1]s

Ti-1

Ti-1

(A.4a)

Ti(N ) t

Ti Ti

(Ms - Mi-1)2d [L - Li-1]s -

[M - Mi-1]s d [L - Li-1]s

Ti-1

Ti-1

(A.4b)

Ti(N ) t

Ti Ti

(Ms - Mi-1)(Ls - Li-1)d [M, L]s -

[M - Mi-1, L - Li-1]s d [M, L]s

Ti-1

Ti-1

(A.4c)

N T

(Ti)2

Ti(n) t

(X Y )2i + (X )2i (Y )i2 -

converge to zero in probability.

22

  X Y
Ti-1 Ti-1 Ti-1

+

 X Y
Ti-1 Ti-1

(A.4d)

Proof. The proofs for (A.4a) and (A.4b) are completely analogous and we restrict ourselves to prove it for (A.4a). By Ito^'s formula

s

(Ls - Li-1)2 = 2

(Lr - Li-1)dLr + [L - Li-1]s

Ti-1

holds. The left-hand side of (A.4a) equals

Ti(N ) t

Ti Ti-1

s
2 (Lr - Li-1)dLr
Ti-1

d [M - Mi-1]r

=
Ti(N ) t

Ti Ti

2 (Ls - Li-1)([M - Mi-1]Ti ) dLs - 2 (Ls - Li-1)([M - Mi-1]s) dLs

Ti-1

Ti-1

22

by application of the integration by parts formula in the way

Ti Ti

ZTi [M - Mi-1]Ti =

Ztd [M - Mi-1]t +

[M - Mi-1]t dZt

00

with Zt :=

t Ti-1

2(Ls -Li-1)dLs

for

Ti-1



t



T

to

the

addends.

Therefore,

we

can

write

the

left-hand

side of (A.4a) in the way M(1N) + M(2N) with two centred continuous martingales M1(N), M(2N) defined

in the fashion of (N) above and calculate the quadratic covariation processes at time t:

M2(N )

=4
t

Ti(N ) t

Ti
(Ls - Li-1)2([M - Mi-1]s)2d [L]s + Op(1)
Ti-1



4 max sup (Ls
i s(Ti-1,Ti]

-

Li-1)2max sup [M
i s(Ti-1,Ti]

-

Mi-1]s2
Ti(N ) t

Ti
d [L]s + Op(1) .
Ti-1

The first addend is up to a logarithmic factor Op(N3 ) and hence M2(N) = Op(1) on Assumption 2. That M1(N) = Op(1) is proved analogously. This implies that (A.4a) is Op(1).
The strategy of the proof for (A.4c) follows the same approach, starting with the equation

s

(Ls - Li-1)(Ms - Mi-1) =

(Lr - Li-1)d(M - Mi-1)r +

Ti-1

+ [L - Li-1, M - Mi-1]s

s
(Mr - Mi-1)d(L - Li-1)r
Ti-1

and applying integration by parts as above with Zt =

t Ti-1

(Ls

-

Li-1)d(M

-

Mi-1)s

+

t Ti-1

(Ms

-

Mi-1)d(L - Li-1)s for Ti-1  t  Ti.

We complete the proof of the convergence of the quadratic variation with the proof for (A.4d). Denote

(X Y

2
)i

=

(X )2i

·

(Y

)2i

·

()2i

to

distinguish

between

the

values

from

the

application

of

the

mean

value theorems to the two different addends. An upper bound of the left-hand side of (A.4d) can be found

by elementary algebra and the triangle inequality for the absolute value:

N T

(Ti)2

Ti(N ) t

(X Y )2i + (X )i2(Y )2i -

22

  X Y
Ti-1 Ti-1 Ti-1

+

 X Y
Ti-1 Ti-1

N T

(Ti)2

(X )2i(Y )2i

()2i

-

2
Ti-1

+

(Y

)2

i

2
Ti-1

(X )2i - (TXi-1 )2

Ti(N ) t

+T2i-1 (TXi-1 )2 (Y )2i - (TYi-1 )2 + (Y )2i (X )2i - (TXi-1 )2 + (TXi-1 )2 (Y )i2 - (TYi-1 )2

= Op(1) .

The martingales (N) can be written for every N as time-changed Brownian motions B[(D(ND)S],N) = t
t(N) by the Dambis-Dubins-Schwarz theorem. The sequence of martingales (N) or associated timechanged Dambis-Dubins-Schwarz Brownian motions converges weakly to a limiting Brownian motion by
the asymptotic Knight-theorem. The limiting Brownian motion will be defined on an orthogonal extension
of the original probability space. To obtain the stable convergence result, we apply Jacod's Theorem 1 and
thus, we are left to verify conditions (2a) and (2b). Consider the quadratic covariation process of (N) and the reference martingale L

L, (N) =
t

N T
Ti(N ) t

Ti Ti

(Ls - Li-1)d [M, L]s +

(Ms - Mi-1)d [L]s + Op(1) .

Ti-1

Ti-1

23

The term of smaller order than 1 in probability comes from the increment of the covariation process on [T(t), t]. As before, this equality holds true for all t, since for t < T1 the covariation is Op(1). Integration by parts yields:

L, (N) =
t

N T
Ti(N ) t

([M, L]Ti - [M, L]Ti-1 )(Li - Li-1) - +([L]Ti - [L]Ti-1 )(Mi - Mi-1) -

Ti
[M, L]s d(Ls - Li-1)
Ti-1
Ti
[L]s d(Ms - Mi-1) .
Ti-1

It remains to show that this term converges to zero in probability. The term is centred and using Ito^ isometry we find the following upper bound for the second moment:



E

2
L, (N)
t



N 2
T

E

 

([M, L]Ti - [M, L]Ti-1 )2(Li - Li-1)2

Ti(N ) t

+([L]Ti - [L]Ti-1 )2(Mi - Mi-1)2

+

max
i{1,...,N }

sup
s(Ti-1 ,Ti ]

([M,

L]s

-

[M,

L]Ti-1 )2

i

Ti
d [L - Li-1]t
Ti-1

=O

+

max
i{1,...,N }

sup
s(Ti-1 ,Ti ]

([L]s

-

[L]Ti-1 )2

N N2 .

i

Ti
d [M - Mi-1]t
Ti-1

The term is bounded by a constant times N N2 since squared increments, cross products of increments and increments of the quadratic (co-)variations of L and M over time instants Ti(N) are bounded by Ti(N) times a constant. To sums with products of time instants we can apply Ho¨lder's inequality with the supremum norm to obtain upper bounds. There are at most order N-1 time instants Ti(N) of order supi Ti(N) = N since i Ti(N)  T and the time span T is fixed. Hence, L, (N) t = Op(1) t  [0, T ]. With the same strategy M, (N) t = Op(1) t  [0, T ] can be shown.
For every bounded Ft-martingale L satisfying L, L  0 the covariation

L, (N)

N =

tT

Ti(N ) t

Ti
(Ls - Li-1)d M, L s + Op(1) = Op(1)
Ti-1

converges to zero. The same holds true for every bounded Ft-martingale orthogonal to M . Applying Theorem 1, we deduce that Proposition A.2 holds true.

Proposition A.1 is a direct consequence of the stronger result in Proposition A.2 since for t = T the marginal distribution is a mixed normal distribution which is independent of F. The stable convergence assures that the convergence also holds under the original probability measure and non-zero drift terms with the same asymptotic law.

A.2. Error due to non-synchronicity
Proposition A.4. Let Assumptions 1, 2 and (15b)-(15c) from Assumption 3 be satisfied. The error ANT due to the lack of synchronicity converges stably in law to a centred mixed Gaussian distribution:

N T

ATN

st

N (0, vAT )

,

(A.5)

24

with asymptotic variance

TT

vAT =

F (t) tX tY 2 dt +

2H (t) ttX tY 2 dt .

00

(A.6)

Proof. First, we write the ith increments occurring as factors in the addends of the estimator (9) as the sum of the next-tick interpolation at Ti, the increments XTi = XTi - XTi-1 and YTi = YTi - YTi-1 , respectively, and the previous-tick interpolation at Ti-1 and multiply out the addends.

N

[X, Y ]T =

Xgi - XTi + XTi - XTi-1 + XTi-1 - Xli Yi - YTi + YTi - YTi-1 + YTi-1 - Yi

i=1

N

= (Xgi -XTi )YTi + (Yi -YTi )XTi + (XTi-1 -Xli )YTi + (YTi-1 - Yi )XTi
i=1

+(Xgi - XTi )(YTi-1 - Yi ) + (Yi - YTi )(XTi-1 - Xli ) + DTN

The indicator functions in (13) have been dropped since the corresponding addends are zero if the indicator functions were zero. Since at least one of the next-tick interpolation errors is zero and as well one of the previous-tick interpolation errors, too, two addends, namely the products of next-tick interpolation errors and the product of previous-tick interpolation errors, equal zero. Thus, the error due to asynchronicity can be written as the sum of the remaining six terms (where at least another three equal zero in each addend). We conclude, that the error ATN can be expressed in the following way:

N -1

ATN =

((Xgi - XTi )(YTi - Yi ) + (Yi - YTi )(XTi - Xli )

i=1

(XTi+1 - XTi )(YTi - Yi+1 ) + (XTi - Xli+1 )(YTi+1 - YTi ) + Op(1) .

In this equality an index shift has been applied to the partial sum of previous-tick interpolated errors multi-

plied with XTi and YTi , respectively, leading to the structure that in the ith addend the factors contain next- and previous-tick interpolated errors to the same Ti. The Op(1)-term emerges from end-effects when

shifting the original sum.

In the last illustration of ANT consecutive addends of the sum are uncorrelated in contrast to the non-shifted illustration. The reason is that, if without loss of generality i = Ti holds, (Xgi - XTi )YTi and (XTi -
Xli+1 )YTi+1 have in general a non-zero correlation whereas (Xgi - XTi )YTi and (XTi-1 - Xli )YTi
are uncorrelated. Furthermore, the fact that i = Ti  i+1 = Ti assures that the addends in the last illustration of ANT are uncorrelated. Roughly speaking we capture correlation between subsequent addends
of the outer sum and transfer it into additional correlation in the inner sum.

As in the foregoing proof of Proposition A.1, it is sufficient to prove the stable convergence result for

the zero-drift case. We denote, as before, the corresponding transformed processes Lt =

t 0

sX dWsX

and

Mt =

t 0

sY

dWsY

.

Consider the sum

AtN =

ANi : =

Ti(+N1) t

N T ((Lgi - LTi )(MTi - Mi ) + (Mi - MTi )(LTi - Lli )
Ti(+N1) t

+(LTi - Lli+1 )(MTi+1 - MTi ) + (MTi - Mi+1 )(LTi+1 - LTi )

(A.7)

for fixed 0  t  T .

Proposition A.5. Assume the same conditions as in Proposition A.4. For fixed 0  t  T the transformed error due to non-synchronicity ANt is the endpoint of a discrete, centred, square-integrable martingale with respect to the filtration Fi,N := F .Ti(+N1) The process ANt converges as N   stably in law:

AtN st At =

t

 vAs

dWs

0

(A.8)

25

where W  is a Brownian motion independent of F and

vAs = F (s) sX sY 2 + 2H (s) ssX sY 2 .

(A.9)

Proof. The expectation of the absolute value of the sum is bounded for all t  [0, T ] and AiN , i = 0, . . . , N are Fi,N = FTi(+N1) -measurable. Since

E ANi |Fi-1,N = E ANi |FTi(N) = E [(Lgi - LTi )(MTi - Mi ) + (Mi - MTi )(LTi - Lli )

+(LTi - Lli+1 )MTi+1 + (MTi - Mi+1 )LTi+1 |FTi(N) = E [Lgi - LTi ] (MTi - Mi ) + E [Mi - MTi ] (LTi - Lli )
+ (LTi - Lli+1 )E MTi+1 + (MTi - Mi+1 )E LTi+1

=0

for the conditional expectation of the increments holds, ANt is the endpoint of a Fi,N -martingale. The stable weak convergence to a limiting Brownian motion is proven with Corollary 2.3 to Jacod's Theorem 1. First, we verify the conditional Lindeberg condition that is implied by the stronger conditional Lyapunov condition. It is sufficient to proof the following:
Lemma A.6. The sum of the conditional fourth moments of the martingale increments ANi converges to zero in probability:



E

 

ANi

4

Fi-1,N

 

=

Op(1)

.

Ti(+N1) t

Proof. Throughout the proof C denotes a generic constant that does not depend on N . We consider different addends of the fourth conditional moments consecutively. The sum of conditional fourth moments incorporates addends of the following types:

· fourth-order moments:

N2 T2

E (Lgi - LTi )4 (MTi - Mi )4 ,

Ti(+N1) t

· second-order moments:

N2 T2

E (Lgi - LTi )2(MTi+1 )2 (LTi - Lli+1 )2(MTi - Mi )2 ,

Ti(+N1) t

· third- and first-order moments:

N2 T2

4(MTi - Mi )3(LTi - Lli+1 )3E MTi+1 (Lgi - LTi )

Ti(+N1) t

.

For the partial sum with addends of the first type an application of the Burkholder-Davis-Gundy (BDG)

26

inequalities yields

N2 T2

E (Lgi - LTi )4 (MTi - Mi )4

Ti(+N1) t

C

N2 T2

E

Ti(+N1) t

gi 2

(sX )2ds

(MTi - Mi )4

Ti

C

N2 T2

sup (sX )2

(MTi

s[0,T ]

Ti(+N1) t

-

Mi )4(gi

- Ti)2



Op

N N2

= Op(1) .

The last inequality can be deduced by the result that the convergence (N/(3T ))

i(MTi )4 

t 0

(sY

)4ds

holds almost surely as N   for the so-called realized quarticity ([3]) and that (gi - Ti)  N . Without

the result about the convergence of the realized quarticity, the asymptotic order in probability can be de-

rived by the convergence to zero of the expectation of the above sum and calculating the second moment

that is bounded from above by a constant times N 4N7 . For the partial sum including addends that incorporate second-order moments we obtain an upper bound

by application of the Cauchy-Schwarz inequality and the BDG inequalities:

N2 T2

6 E (Lgi - LTi )2(MTi+1 )2 (LTi - Lli+1 )2(MTi - Mi )2

Ti(+N1) t

N2

 T2

6

Ti(+N1) t

E [(Lgi - LTi )4] E (MTi+1 )4 (LTi - Lli+1 )2(MTi - Mi )2



C

N2 T2

6 E

Ti(+N1) t


gi 2
(sX )2ds E 
Ti

Ti+1
(sY )2ds
Ti

1
2 2  (LTi - Lli+1 )2(MTi - Mi )2

= Op(1) .

The stochastic order follows, since the term has the expectation



N2

C T2

6E

Ti(+N1) t


gi 2
(sX )2ds E 
Ti

Ti+1
(sY )2ds
Ti

1
2 2  E (LTi - Lli+1 )2(MTi - Mi )2





C

N2 T2

6E

Ti(+N1) t

gi 2
(sX )2ds E
Ti

Ti+1

2

(sY )2ds E

Ti

Ti 2
(sX )2ds E
li+1

Ti
(sY )2ds
i

1
2 2 

 C N 2N3 = O(1) ,

where again the Cauchy-Schwarz and BDG inequalities have been applied. The variance is bounded from above by a constant times N 4N7 , what can be shown by a similar calculation where thanks to the fact that Ti = i  i+1 = Ti the addends are uncorrelated and the variance of the sum equals the sum of variances.
We treat the third type of addends occurring in the sum of conditional fourth moments in the same way. Ito^
isometry yields

N2 T2

4(MTi - Mi )3(LTi - Lli+1 )3E MTi+1 (Lgi - LTi )

Ti(+N1) t

N2 = T2

4(MTi - Mi )3(LTi - Lli+1 )3E

Ti(+N1) t

gi
ssX sY ds .
Ti

27

This term has expectation

N2 T2

4E (MTi - Mi )3(LTi - Lli+1 )3 E

Ti(+N1) t

gi
ssX sY ds
Ti



N2 T2

4

Ti(+N1) t

E [(MTi - Mi )6] E (LTi - Lli+1 )6 E

gi
ssX sY ds
Ti





C

N2 T2

4 E 

Ti(+N1) t

Ti 3  (sY )2ds  E 
i

Ti
(sX )2ds
li+1

31/2  E

 CN 2N3 = O(1) ,

gi
ssX sY ds
Ti

and an analogous calculation as before yields that the variance is of order N 4N7 . Thereby, the sum converges to zero in probability.

Next, we consider the sum of conditional variances of the increments of the discrete martingale.

Lemma A.7.



E

 

ANi

2

FTi(N

)

 

p

Ti(+N1) t

t
F (s) sX sY
0

2 ds +

t
2H (s) ssX sY
0

2 ds .

(A.10)

It holds true that

Proof.



E

 

ANi

2

FTi(N

)

 

Ti(+N1) t

N =
T

E (Lgi -LTi )2(MTi -Mi )2 +(Mi -MTi )2(LTi -Lli )2 + (LTi -Lli+1 )2(MTi+1 )2

Ti(+N1) t

+ (MTi - Mi+1 )2(LTi+1 )2 + 2(Lgi - LTi )(MTi - Mi )(LTi - Lli+1 )MTi+1

+ 2(Mi - MTi )(LTi - Lli )(MTi - Mli+1 )LTi+1 FTi(N)

N = T(Ito^ isometry)
Ti(+N1) t

E

gi
(sX )2ds (MTi - Mi )2 + E
Ti

i
(sY )2ds
Ti

(LTi - Lli )2

+ (LTi - Lli+1 )2E

Ti+1
(sY )2ds + (MTi - Mi+1 )2E
Ti

+ 2(MTi - Mi )(LTi - Lli+1 )E + 2(LTi - Lli )(MTi - Mli+1 )E

gi
ssX sY ds
Ti
i
ssX sY ds
Ti

Ti+1
(sX )2ds
Ti

28

N = T(Lemma A.8)
Ti(+N1) t

E

gi
(sX )2ds
Ti

Ti
(sY )2ds + E
i

i
(sY )2ds
Ti

Ti
(sX )2ds
li

Ti
+ (sX )2dsE
li+1

Ti+1

Ti

(sY )2ds +

(sY )2dsE

Ti i+1

Ti+1
(sX )2ds
Ti

Ti
+ ssX sY ds E
li+1

gi Ti

ssX sY ds +

ssX sY ds E

Ti li+1

i
ssX sY ds
Ti

+ Op(1)

N = T(Lemma A.8)
Ti(+N1) t

gi Ti

i Ti

(sX )2ds (sY )2ds + (sY )2ds (sX )2ds

Ti i

Ti li

Ti Ti+1

Ti Ti+1

+ (sX )2ds

(sY )2ds +

(sY )2ds

(sX )2ds

li+1

Ti

i+1

Ti

Ti gi

Ti i

+2

ssX sY ds

ssX sY ds + 2

ssX sY ds

ssX sY ds + Op(1)

li+1

Ti

li+1

Ti

N = T(Lemma A.9)

(TXi TYi )2 ((Ti - i)(gi - Ti) + (i - Ti)(Ti - li) + (Ti - li+1)Ti+1

Ti(+N1) t

+ (Ti - i+1)Ti+1)+(Ti TXi TYi )2(2(Ti - li+1)(gi - Ti)+2(Ti - i+1)(i - Ti)) +Op(1)

=

Ti(+N1) t

F

(Ti+1) Ti+1

- -

F (Ti Ti

)

(TXi

TYi

)2

Ti+1

+

2 H(Ti+1) Ti+1

- -

H (Ti Ti

)

(Ti

TXi

TYi

)2

Ti+1

+

Op(1)

tt
-p F (s) sX sY 2 ds + 2H (s) ssX sY 2 ds .
00

In the last step we have involved Definition 2. The Riemann sum converges on the Assumption 3 (in par-

ticular (15b) and (15c)) in probability as N   to the expression

t 0

vAs ds

with

vAs

given

in

Proposition

A.5.

The detailed proofs of the approximations are postponed in the following two lemmas.

Lemma A.8. On the assumptions as before, the following equations hold true:

N T
Ti(+N1) t

Ti

(MTi - Mi )2 -

(sY )2ds

i

E

gi
(sX )2ds = Op(1) ,
Ti

N T
Ti(+N1) t

Ti
(sY )2ds
i

E

gi gi
(sX )2ds - (sX )2ds = Op(1) ,
Ti Ti

N T
Ti(+N1) t

Ti

(LTi - Lli )2 -

(sX )2ds

li

E

i
(sY )2ds = Op(1) ,
Ti

N T
Ti(+N1) t

Ti
(sX )2ds
li

E

i i
(sY )2ds - (sY )2ds = Op(1) ,
Ti Ti

N T
Ti(+N1) t

Ti

(MTi - Mi+1 )2 -

(sY )2ds

i+1

E

Ti+1
(sX )2ds = Op(1) ,
Ti

29

N T
Ti(+N1) t

Ti
(sY )2ds
i+1

E

Ti+1

Ti+1

(sX )2ds -

(sX )2ds

Ti Ti

= Op(1) ,

N T
Ti(+N1) t

Ti

(LTi - Lli+1 )2 -

(sX )2ds

li+1

E

Ti+1
(sY )2ds = Op(1) ,
Ti

N T
Ti(+N1) t

Ti
(sX )2ds
li+1

E

Ti+1

Ti+1

(sY )2ds -

(sY )2ds

Ti Ti

= Op(1) ,

N T
Ti(+N1) t

Ti

(MTi - Mi )(LTi - Lli+1 ) -

ssX sY ds

li+1

E

gi
ssX sY ds = Op(1) ,
Ti

N T
Ti(+N1) t

Ti
ssX sY ds
li+1

E

gi gi

ssX sY ds -

ssX sY ds = Op(1) ,

Ti Ti

N T
Ti(+N1) t

Ti

(LTi - Lli )(MTi - Li+1 ) -

ssX sY ds

i+1

E

i
ssX sY ds = Op(1) ,
Ti

N T
Ti(+N1) t

Ti
ssX sY ds
i+1

E

i i

ssX sY ds -

ssX sY ds = Op(1) .

Ti Ti

Proof. We restrict ourselves to the proof of the first two equalities, since all other terms can shown to converge to zero in probability in an analogous way. The left-hand side of the first equality has an expectation equal to zero which can be concluded directly by Ito^ isometry:



N

E

 

T

Ti(+N1) t

Ti

(MTi - Mi )2 -

(sY )2ds

i

E



gi

(sX )2ds

=0. 

Ti

In order to derive the stochastic order of the term, consider the second moment:

 2

N

E

 

T

Ti(+N1) t

Ti

(MTi - Mi )2 -

(sY )2ds

i

E

gi

(sX )2ds

 

 

Ti



N2 = T2

E (MTi - Mi )4 - 2(MTi - Mi )2

Ti(+N1) t

Ti
(sY )2ds +
i

Ti
(sY )2ds
i

×E

gi
(sX )2ds
Ti

2
= O(1) ,

2 

where the asymptotic order is deduced by Ito^ isometry and the BDG inequalities. Since the error induced by this term in the approximation of the conditional variance before is centred and has a variance converging

30

to zero as N  , the error is asymptotically negligible. In the second equality we consider the error when the expected increment of the quadratic variation of X over the next-tick interpolated time interval is substituted by the integral itself. We proceed as before for the first approximation. Since



N

E

 

T

Ti(+N1) t

Ti
(sY )2ds
i

E



gi gi

(sX )2ds -

(sX )2ds

=0 

Ti Ti

and



N

E

 

T

Ti(+N1) t

Ti
(sY )2ds
i

E

N2

= T2

Var

Ti(+N1) t

Ti
(sY )2ds
i

2

gi gi

(sX )2ds -

(sX )2ds

 

Ti Ti


Ti

2

E  (sY )2ds  = O(1) ,

i

the approximation error is asymptotically negligible. The fact that i = Ti  i+1 = Ti has been used that guarantees that the addends of the sum are uncorrelated.

Lemma A.8 has been applied in the second and third equality in the evaluation of the sum of conditional variances and the proof of Lemma A.7 is completed by the following

Lemma A.9. On the same assumptions as before, the following equation holds true

N T
Ti(+N1) t

gi Ti

(sX )2ds

(sY )2ds - (TXi TYi )2(Ti - i)(gi - Ti) = Op(1)

Ti i

and analogously the errors in the five other addends converge to zero in probability when replacing the
product of increments of quadratic (co-)variations by the values of Ti , TXi , TYi multiplied with the corresponding times increments.

Proof. We prove the equality explicitly given in the lemma. The five remaining terms can be handled by the same strategy. By an application of the mean value theorem, elementary algebra and the triangle inequality for the absolute values, we deduce that

N T
Ti(+N1) t

gi Ti

(sX )2ds

(sY )2ds - (TXi TYi )2(Ti - i)(gi - Ti)

Ti i

N =
T

(Xi Yi )2 - (TXi TYi )2 (Ti - i)(gi - Ti)

Ti(+N1) t

N T

(Xi Yi )2 - (TXi TYi )2 (Ti - i)(gi - Ti)

Ti(+N1) t

N T
Ti(+N1) t

(Yi )2 (Xi )2 - (TXi )2 + (TXi )2 (Yi )2 - (TYi )2

(Ti - i)(gi - Ti)

N C
T
Ti(+N1) t
= Op(1)

sup (sX )2 - (TXi )2 + sup (sY )2 - (TYi )2 (Ti - i)(gi - Ti)

s[i ,Ti ]

s[Ti ,gi ]

holds on Assumption 1.

31

To prove the stability of the convergence in Proposition A.5, we show in the following that the discrete covariations of ANt with the F -generating underlying martingales L and M converge to zero in probability.
Lemma A.10.

E
Ti(+N1) t

AiN LTi(+N1) FTi(N)

-p 0 ,

E
Ti(+N1) t

ANi MTi(+N1) FTi(N)

-p 0 .

Proof. Both relations are proven similarly and we restrict ourselves to the proof of the first one. The left-hand side equals

N T E LTi+1 ((Lgi - LTi )(MTi - Mi ) + (Mi - MTi )(LTi - Lli )
Ti(+N1) t

+(LTi - Lli+1 )(MTi+1 - MTi ) + (MTi - Mi+1 )(LTi+1 - LTi ) FTi(N)

=

N T
Ti(+N1) t

E

gi
(sX )2ds (MTi - Mi ) + E
Ti

i
ssX sY ds (LTi - Lli )
Ti

+(LTi - Lli+1 )E

Ti+1
ssX sY ds + (MTi - Mi+1 )E
Ti

Ti+1
(sX )2ds
Ti

=:  .

 is centred and using Ito^ isometry the variance is shown to converge to zero:

N T
Ti(+N1) t

gi 2 Ti

i 2 Ti

E (sX )2ds E

(sY )2ds + E

ssX sY ds E

(sX )2ds

Ti i

Ti

li

Ti
+E (sX )2ds
li+1

Ti+1

2 Ti

E

ssX sY ds

+E

(sY )2ds

Ti i+1

Ti+1

2

E (sX )2ds

Ti

+2E

Ti
ssX sY ds E
li+1

gi
(sX )2ds E
Ti

Ti+1
ssX sY ds
Ti

+2E

Ti
ssY sY ds
i+1

 CN N2 = O(1) .

E

Ti+1
(sX )2ds E
Ti

i
ssX sY ds
Ti

Once more we can conclude that the addends are uncorrelated since i = Ti  i+1 = Ti and gi = Ti  li+1 = Ti, respectively.

Finally, we prove that the discrete covariation of our considered martingale with every bounded Ftmartingale that is orthogonal to Lt or Mt, converges to zero in probability. Hence, this lemma will complete the proof of Proposition A.5.

32

Lemma A.11. Assume that Lt and Mt are bounded Ft-martingales, with L, L  0 and M, M   0, respectively. It holds true that

E
Ti(+N1) t

AiN

L
Ti(+N1)

FTi(N )

-p 0 ,

E
Ti(+N1) t

ANi

M 
Ti(+N1)

FTi(N )

-p 0 .

Proof. As in the preceding lemma, we only prove the first part of the result. The left-hand side of the first equation equals

N T

E LTi+1 ((Lgi - LTi )(MTi - Mi ) + (Mi - MTi )(LTi - Lli )

Ti(+N1) t

+(LTi - Lli+1 )(MTi+1 - MTi ) + (MTi - Mi+1 )(LTi+1 - LTi ) FTi(N)

=

N T
Ti(+N1) t

E

gi
d L, L s (MTi - Mi ) + E
Ti

i
d M, L s (LTi - Lli )
Ti

+(LTi - Lli+1 )E

Ti+1
d M, L s + (MTi - Mi+1 )E
Ti

Ti+1
d L, L s
Ti

=

N TE
Ti(+N1) t

Ti+1
d M, L s (LTi - Lli+1 ) + E
Ti

i
d M, L s (LTi - Lli ) .
Ti

This term is centred and the has the variance


N T E
Ti(+N1) t

Ti+1
d M, L s
Ti

2 E

LTi - Lli+1 2 + E

i 2
d M, L s
Ti

× E (LTi - Lli )2 + E (LTi - LLi+1 )2 E

Ti+1
d M, L s E
Ti

i
d M, L
s Ti



N

= Ito^ isometry T

E

Ti(+N1) t

Ti+1
d M, L
s Ti

2 E

Ti
(sX )2ds
li+1

+E

i 2
d M, L s E
Ti

Ti
(sX )2ds
li

+E

Ti
(sX )2ds E
li+1

Ti+1
d M, L s E
Ti

i
d M, L s = O(1) .
Ti

Thus, the covariations converge to zero in probability.

The Lemma completes the proof of Proposition A.5.

The mixed normal limit in Proposition A.4 can be obtained as the marginal distribution of ANT in t = T.

Proposition A.4 for the error of the approximation by the discretization error of the closest synchronous approximation (13) and the stable limit theorem for this synchronous discretization error (12) given in Proposition A.1 suffice to imply Theorem 2. That is because the multivariate stable convergence Theorem

33

2.4 applies to the vector of the two uncorrelated terms and since the covariations converge to zero , the stable convergence to the mixed Gaussian limit with the sum of the two asymptotic variances is concluded.

B. Proof of Proposition 6.1

The proof will be divided into three parts in that the sum of squared products, products of consecutive increments and the histogram estimator are considered, respectively. Denote Xj+ = Xgj - XTj , Xj- =
XTj-1 - Xlj and XjS = XTj - XTj-1 , j = 1, . . . , N . In the first step it is proved that

N -1

TT

N Xgj - Xlj 2 Yj - Yj 2-pT G (t) tX tY 2 22t + 1 dt + T F (t) tX tY 2dt .

j=1

00

N -1

N -1

N Xj+ + XjS + Xj- 2 Yj+ + YjS + Yj- 2= N (Xj+)2(YjS + Yj-)2 +(Yj+)2(XjS + Xj-)2

j=1

j=1

+(Xj-)2(YjS )2 +(Yj-)2(XjS )2 +(XjS YjS )2 +Op(1)

All centred addends have a variance tending to zero as N   and converge to zero in probability.

The sum of the first four addends times the factor N/T has been proved to converge in probability to

T 0

F

(t)(tX tY

)2dt in

Lemma

A.7

where this term has appeared in the

sequence

of

conditional

variances

of the error due to non-synchronicity.

Hence, it remains to prove that N

N -1 j=1

(XjS

YjS

)2

p

T

T 0

(2t2

+

1)(tX tY

)2G

(t)dt.

For

this

purpose

recall the notation from the proof of Proposition A.1. With Lt =

t 0

sX

dWsX

,

Mt

=

t 0

sY

dWsY

,

Li = LTi , Mi = MTi , we can write the term

N -1

N -1

Ti

N ((L - Li-1)Ti (M - Mi-1)Ti )2 = N

2 (L - Li-1)t(M - Mi-1)t2d(L - Li-1)t

j=1

i=1 0

Ti
+ 2 (L - Li-1)t2(M - Mi-1)td(M - Mi-1)t
0
Ti
+ 4 (L - Li-1)t(M - Mi-1)td [M - Mi-1, L - Li-1]t
0

Ti Ti
+ (M - Mi-1)2t d [M - Mi-1]t + (L - Li-1)2t d [L - Li-1]t
00

,

where we have applied Ito^'s formula. The sum of the first two addends converges to zero in probability since it is centred and the variance converges to zero. Since

Ti Ti

(L - Li-1)t(M - Mi-1)td [M - Mi-1, L - Li-1]t =

(L - Li-1)t(M - Mi-1)td [M, L]t ,

0 Ti-1

the sum of the third addends has been considered in the proof of Proposition A.2 as part of the quadratic

variation of the discretization error of the closest synchronous approximation and converges in probability

to 2 T

T 0

G

(t)(ttX tY

)2dt.

The

remaining

sum

of

the

fourth

addends

is

also

similar

to

the

other

part

of

the quadratic variation in the proof of Proposition A.2. An analogous approximation and integration by

34

parts yields

Ti Ti

(M - Mi-1)t2d [M ]t +

(L - Li-1)t2d [L]t

Ti-1

Ti-1

Ti Ti

= [M - Mi-1]t d [M ]t + [L - Li-1]t d [L]t + Op(1)

Ti-1

Ti-1

Ti
= d([L - Li-1]t [M - Mi-1]t) + Op(1)
Ti-1

and the convergence of the above given term to T

T 0

(tX

tY

)2G

(t)dt.

In the second part of the proof we are concerned with the term

N -1
2N (Xj+ + XjS + Xj-)(Xj++1 + XjS+1 + Xj-+1)(Yj+ + YjS + Yj-)(Yj++1 + YjS+1 + Yj-+1)
j=1

N -1

= 2N

XjS YjS XjS+1YjS+1 + Xj+YjS Xj-+1YjS+1 + Yj+XjS Yj-+1XjS+1 + Op(1) .

j=1

The sum incorporating all centred addends converges to zero in probability. The last two addends capture

the only dependence between consecutive addends in the error due to non-synchronicity (13), namely when

next-tick interpolations and previous-tick interpolations at the same Ti, i = 1, . . . , N are included. Those

have appeared in the proof of Lemma A.7 and have been proved to converge to T

T 0

2H

(t)(tX tY

)2dt

in probability. That 2N

(XjS YjS XjS+1YjS+1) p 2

T 0

G

(t)(ttX tY

)2dt

follows

with

the

methodology

from [5] and Lemma 1 from [23] using the concept of a time-change in the asymptotic quadratic variation

of refresh times such that i(Ti - T /N )2 = O(N -1) holds true. Using the mean value theorem and (Tj)2 - TjTj+1 = Tj(Tj - T /N ) + Tj(T /N - Tj+1) together with the Cauchy-Schwarz

inequality

N -1
N

Tj

Tj

-

T N

j=1

N

N -1
(Tj )2
j=1

N -1 j=1

Tj

-

T N

2

yields the result. The Hayashi-Yoshida estimators on the bins in the histogram-based estimator (19) fulfill

(HY )
 [X, Y ]GNj =

GNj
ttX tY dt + Op
GNj-1

KN1/2N -1/2

so that the estimation error of the sum is of order KN3/4N -1/2 in probability and for KN   , N   , KN N -2/3  0 consistency holds and we conclude consistency of the estimator of the asymptotic variance.

References
[1] D. Aldous, G. Eagleson, On mixing and stability of limit theorems, Annals of Probability 6 (1978) 325­331.
[2] O.E. Barndorff-Nielsen, P.R. Hansen, A. Lunde, N. Shephard, Multivariate realised kernels: consistent positive semi-definite estimators of the covariation of equity prices with noise and nonsynchronous trading, SSRN working paper 1154144, University of Aarhus (2008).

35

[3] O.E. Barndorff-Nielsen, N. Shephard, Econometric analysis of realized volatility and its use in estimating stochastic volatility models, Journal of the Royal Statistical Society 64 (2002) 253­280.
[4] M. Bibinger, Efficient covariance estimation for asynchronous noisy high-frequency data, Scandinavian Journal of Statistics 38 (2011) 23­45.
[5] M. Bibinger, An estimator for the quadratic covariation of asynchronously observed ito^ processes with noise: Asymptotic distribution theory, preprint version, Humboldt-Universita¨t zu Berlin (2011) URL=http://sfb649.wiwi.hu-berlin.de/papers/pdf/SFB649DP2011-034. pdf.
[6] P. Billingsley, Probability and Measure, Springer, New York, 2 edition, 1991.
[7] D.R. Cox, V. Isham, Point processes, Monographs on applied probability and statistics series, Chapman and Hall, New York, 1980.
[8] T.W. Epps, Comovements in stock prices in the very short run, Journal of the American Statistical Association 74 (1979) 291­298.
[9] P.D. Feigin, Stable convergence of semimartingales, Stochastic Processes and their Applications 19 (1985) 125 ­ 134.
[10] M. Fukasawa, Realized volatility with stochastic sampling, Stochastic Processeses and their Applications 120 (2010) 209­233.
[11] L. de Haan, A. Ferreira, Extreme Value Theory: An Introduction, Springer, New York, 2006.
[12] P. Hall, C. Heyde, Martingale Limit Theory and its Application, Academic Press, Boston, 1980.
[13] T. Hayashi, N. Yoshida, On covariance estimation of non-synchronously observed diffusion processes, Bernoulli 11 (2005) 359­379.
[14] T. Hayashi, N. Yoshida, Asymptotic normality of a covariance estimator for nonsynchronously observed diffusion processes, Annals of the Institute of Statistical Mathematics 60 (2008) 367­406.
[15] T. Hayashi, N. Yoshida, Nonsynchronous covariation process and limit theorems, Stochastic Processes and their Applications In Press, Uncorrected Proof (2011).
[16] J. Jacod, On continuous conditional gaussian martingales and stable convergence in law, Se´minaire de Probabilitie´s (1997) 232­246.
[17] J. Jacod, A.N. Shiryaev, Limit Theorems for Stochastic Processes, Springer, New York, 2003.
[18] P. Mykland, L. Zhang, Inference for continuous semimartingales observed at high frequency, Econometrica 77 (2009) 1403­1445.
[19] A. Palandri, Consistent Realized Covariance for Asynchronous Observations Contaminated by Market Microstructure Noise, Technical Report, University of Copenhagen, 2006.
[20] M. Podolskij, M. Vetter, Understanding limit theorems for semimartingales: a short survey, Statistica Nederlandica 64 (2010) 329­351.
[21] A. Re´nyi, On stable sequences of events, Sankhya: The Indian Journal of Statistics, Series A 25 (1963) 293­302.
[22] H. van Zanten, A multivariate central limit theorem for continuous local martingales, Statistics and Probability Letters 50 (2000) 229 ­ 235.
[23] L. Zhang, Efficient estimation of stochastic volatility using noisy observations: A multi-scale approach, Bernoulli 12 (2006) 1019­1043.
36

SFB 649 Discussion Paper Series 2011
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "Localising temperature risk" by Wolfgang Karl Härdle, Brenda López Cabrera, Ostap Okhrin and Weining Wang, January 2011.
002 "A Confidence Corridor for Sparse Longitudinal Data Curves" by Shuzhuan Zheng, Lijian Yang and Wolfgang Karl Härdle, January 2011.
003 "Mean Volatility Regressions" by Lu Lin, Feng Li, Lixing Zhu and Wolfgang Karl Härdle, January 2011.
004 "A Confidence Corridor for Expectile Functions" by Esra Akdeniz Duran, Mengmeng Guo and Wolfgang Karl Härdle, January 2011.
005 "Local Quantile Regression" by Wolfgang Karl Härdle, Vladimir Spokoiny and Weining Wang, January 2011.
006 "Sticky Information and Determinacy" by Alexander Meyer-Gohde, January 2011.
007 "Mean-Variance Cointegration and the Expectations Hypothesis" by Till Strohsal and Enzo Weber, February 2011.
008 "Monetary Policy, Trend Inflation and Inflation Persistence" by Fang Yao, February 2011.
009 "Exclusion in the All-Pay Auction: An Experimental Investigation" by Dietmar Fehr and Julia Schmid, February 2011.
010 "Unwillingness to Pay for Privacy: A Field Experiment" by Alastair R. Beresford, Dorothea Kübler and Sören Preibusch, February 2011.
011 "Human Capital Formation on Skill-Specific Labor Markets" by Runli Xie, February 2011.
012 "A strategic mediator who is biased into the same direction as the expert can improve information transmission" by Lydia Mechtenberg and Johannes Münster, March 2011.
013 "Spatial Risk Premium on Weather Derivatives and Hedging Weather Exposure in Electricity" by Wolfgang Karl Härdle and Maria Osipenko, March 2011.
014 "Difference based Ridge and Liu type Estimators in Semiparametric Regression Models" by Esra Akdeniz Duran, Wolfgang Karl Härdle and Maria Osipenko, March 2011.
015 "Short-Term Herding of Institutional Traders: New Evidence from the German Stock Market" by Stephanie Kremer and Dieter Nautz, March 2011.
016 "Oracally Efficient Two-Step Estimation of Generalized Additive Model" by Rong Liu, Lijian Yang and Wolfgang Karl Härdle, March 2011.
017 "The Law of Attraction: Bilateral Search and Horizontal Heterogeneity" by Dirk Hofmann and Salmai Qari, March 2011.
018 "Can crop yield risk be globally diversified?" by Xiaoliang Liu, Wei Xu and Martin Odening, March 2011.
019 "What Drives the Relationship Between Inflation and Price Dispersion? Market Power vs. Price Rigidity" by Sascha Becker, March 2011.
020 "How Computational Statistics Became the Backbone of Modern Data Science" by James E. Gentle, Wolfgang Härdle and Yuichi Mori, May 2011.
021 "Customer Reactions in Out-of-Stock Situations ­ Do promotion-induced phantom positions alleviate the similarity substitution hypothesis?" by Jana Luisa Diels and Nicole Wiebach, May 2011.
SFB 649, Ziegelstraße 13a, D-10117 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

SFB 649 Discussion Paper Series 2011
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
022 "Extreme value models in a conditional duration intensity framework" by Rodrigo Herrera and Bernhard Schipp, May 2011.
023 "Forecasting Corporate Distress in the Asian and Pacific Region" by Russ Moro, Wolfgang Härdle, Saeideh Aliakbari and Linda Hoffmann, May 2011.
024 "Identifying the Effect of Temporal Work Flexibility on Parental Time with Children" by Juliane Scheffel, May 2011.
025 "How do Unusual Working Schedules Affect Social Life?" by Juliane Scheffel, May 2011.
026 "Compensation of Unusual Working Schedules" by Juliane Scheffel, May 2011.
027 "Estimation of the characteristics of a Lévy process observed at arbitrary frequency" by Johanna Kappus and Markus Reiß, May 2011.
028 "Asymptotic equivalence and sufficiency for volatility estimation under microstructure noise" by Markus Reiß, May 2011.
029 "Pointwise adaptive estimation for quantile regression" by Markus Reiß, Yves Rozenholc and Charles A. Cuenod, May 2011.
030 "Developing web-based tools for the teaching of statistics: Our Wikis and the German Wikipedia" by Sigbert Klinke, May 2011.
031 "What Explains the German Labor Market Miracle in the Great Recession?" by Michael C. Burda and Jennifer Hunt, June 2011.
032 "The information content of central bank interest rate projections: Evidence from New Zealand" by Gunda-Alexandra Detmers and Dieter Nautz, June 2011.
033 "Asymptotics of Asynchronicity" by Markus Bibinger, June 2011.
SFB 649, Ziegelstraße 13a, D-10117 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

