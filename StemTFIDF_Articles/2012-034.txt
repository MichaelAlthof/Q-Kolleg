BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2012-034
Realized Copula
Matthias R. Fengler* Ostap Okhrin*
* Humboldt-Universität zu Berlin, Germany
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universität zu Berlin Spandauer Straße 1, D-10178 Berlin

Realized Copula

Matthias R. Fengler and Ostap Okhrin
May 11, 2012
Abstract
We introduce the notion of realized copula. Based on assumptions of the marginal distributions of daily stock returns and a copula family, realized copula is dened as the copula structure materialized in realized covariance estimated from within-day high-frequency data. Copula parameters are estimated in a method-of-moments type of fashion through Hoeding's lemma. Applying this procedure day by day gives rise to a time series of copula parameters that is suitably approximated by an autoregressive time series model. This allows us to capture time-varying dependency in our framework. Studying a portfolio risk-management application, we nd that time-varying realized copula is superior to standard benchmark models in the literature.
Keywords: realized variance, realized covariance, realized copula, multivariate dependence JEL classication: G12, C13, C14, C22, C50
Financial support from the Deutsche Forschungsgemeinschaft via SFB 649  Ökonomisches Risiko, HumboldtUniversität zu Berlin, is gratefully acknowledged. The authors thank Francesco Audrino, Daniel Buncic, Umberto Cherubini, Roxana Halbleib, Wolfgang Härdle, Nikolaus Hautsch, Helmut Herwartz, Sabrina Mulinacci, Yarema Okhrin, Mark Podolskij and participants at the Statistics Seminar at the University of Augsburg, at ISI 2011 (Dublin), at the Statistische Woche 2011 (Leipzig), at the Risk Calibration Workshop 2011 at the Academia Sinica (Taipei), at the 14th Conference of the ASMDA International Society (Rome) and at the 3rd XMU-HUB workshop on `Nonparametric and Nonstationary Econometrics' (Xiamen) for valuable comments and discussions. We remain responsible for errors and omissions.
School of Economics and Political Science, University of St. Gallen, Bodanstrasse 6, 9000 St. Gallen, Switzerland. Email: matthias.fengler@unisg.ch
C.A.S.E.  Center for Applied Statistics and Economics, Ladislaus von Bortkiewicz Chair of Statistics,
School of Business and Economics, Humboldt-Universität zu Berlin, Spandauer Straÿe 1, 10178 Berlin, Germany.
Email: ostap.okhrin@wiwi.hu-berlin.de
1

1 Introduction
Realized variance (RV) and realized covariance (RC) estimated from high-frequency intraday data have proved to be accurate ex-post measures for conditional variance and conditional covariance of daily returns. Being nonparametric in nature, RV and RC permit the econometrician to obtain proxies for nancial (co)volatility without having to specify a priori an explicit (and potentially misspecied) model. An inherently latent variable, such as volatility, can thus be treated as an observable (Andersen, Bollerslev, Diebold and Ebens; 2001; Andersen, Bollerslev, Diebold and Labys; 2001). These insights spurred intensive research in the eld and lead to widespread use of measures of RV and RC in numerous applications in nance, such asset pricing, portfolio optimization, risk management, and volatility forecasting.
The present article continues this agenda. We estimate RC matrices from high-frequency intraday data and take them as valid ex-post proxies for daily conditional covariance. Unlike previous studies, we complement these estimates by making assumptions on the marginal distributions of daily returns and the copula associated with their joint multivariate distribution. Based on these assumptions, we estimate the copula shape parameters by means of the covariance moment condition provided by Hoeding's lemma. The procedure yields daily estimates of copula shape
parameters as materialized in daily RC. We therefore call it realized copula (RCop) . The resulting
time series of RC-implied copula shape parameters is subsequently modeled by standard time series techniques thereby allowing the dependence structure to be time-varying with the business cycle.
For risk-management purposes at the daily frequency, the benets of using copulae to capture salient features of multivariate dependence, such as tail-dependence and other attributes of nonnormality like skewness and fat-tailedness, are widely recognized (Jin; 2009, and references therein). Yet RV-based models often work with a (conditional) Gaussian structure. RCop allows to drop the rather restrictive Gaussian assumption and oers a more realistic description of the joint tails of the daily return distribution. It may therefore yield more accurate estimates of the quantiles of a portfolio's prot and loss distribution. Our empirical analysis conrms this expectation.
In this research, we combine two strands of literature. The rst strand is a series of studies in the RV literature extending the univariate heterogeneous autoregressive (HAR) model to the multivariate level. The HAR model, originally suggested by Corsi (2009), is a stationary, restricted AR(22) model and captures long-range dependence in RV data by means of a cascade of volatility components that are interpreted as a daily, weekly and monthly volatility component. It nowadays is a standard benchmark model for modeling RV with unraveled forecasting performance.1 A nontrivial challenge in constructing a multivariate HAR model is to ensure positive-deniteness of predicted covariance matrices. One therefore considers modeling nonlinear transformations of RC such as the Cholesky factorization (Chiriac and Voev; 2011) or the matrix log transformation (Bauer and Vorkink; 2010), or direct modeling by means of a Wishart autoregressive process (Gouriéroux et al.; 2009; Jin and Maheu; 2010; Bonato et al.; 2011). Our RCop approach is in the spirit of this research, since the copula parameter, which we imply from RC and subsequently describe by a HAR model, denes  together with the assumptions on the marginals  an entire
1See Corsi, Audrino and Renò (2012) for a review. As an alternative to HAR models pure long-memory models
belonging to the ARFIMA class have been considered for modeling the variance processes, see e.g. Baillie (1996), Baillie et al. (1996), Andersen et al. (2003) among others. The forecasting performance of ARFIMA models for RV is very close to that of HAR-type models, but comes at the cost of a higher technical burden.
2

distribution and in consequence a well-posed covariance matrix.
The second stream of research our work is related to is the growing literature of dynamic copula models, such as Dias and Embrechts (2004) and Patton (2004, 2006), Chen and Fan (2006), Jondeau and Rockinger (2006), Giacomini et al. (2009), Jin (2009), Hafner and Manner (2010), Härdle et al. (2010), Christoersen et al. (2011). All these approaches share in common the notion of a copula structure that has time-varying parameters driven by past realizations of the underlying data generating process or by additional exogenous variables, such as latent state factor. By exploiting intra-day data, we uncover a daily series of RCop parameters which we subsequently model by formulating a time series model. We thus obtain a dynamic copula model for daily returns, where time-variation is governed by the underlying dynamics of RC measures.
Remarkably, the literature using copulae to model dependency in the context of high-frequency data is scarce. To the authors' knowledge Breymann et al. (2003) and Dias and Embrechts (2004) appear to be the only work. In this study, however, the copula model is directly applied to analyze realized intraday returns. This is not the purpose of the present investigation. Our aim is to exploit intraday information as condensed in the RV measure to improve on modeling daily returns. In this sense we follow recent suggestions by Engle and Gallo (2006), Shephard and Sheppard (2010), Hansen, Huang and Shek (2011) and Hansen, Lunde and Voev (2011) that combine both low and high-frequency observations in a model framework at daily frequency.
The paper is organized as follows. In Section 2 we introduce the notion of RCop, discuss estimation and suggest a forecasting framework for RCop for risk-management purposes. The competitor models of RCop are presented in Section 3. In Section 4 we explore the empirical properties of RCop and its competitors on two portfolios of heavily traded NYSE stocks using two years of high-frequency data. Section 5 concludes.

2 Realized copula

2.1 Notion and estimation of realized copula

Copulae have emerged as a convenient way for constructing multivariate distributions since they
allow to strictly separate the marginal distributions from cross sectional dependence, which is
captured by the copula function, see Nelsen (2006) for an introduction on copulae. The main
F dresult due to Sklar (1959) states that if is an arbitrary -dimensional continuous distribution function of the random variables X1, . . . , Xd, then the associated copula is unique and dened as a continuous function C : [0, 1]d  [0, 1] satisfying the equality

C(u1, . . . , ud) = F {F1-1(u1), . . . , Fd-1(ud)}, u1, . . . , ud  [0, 1],
where F1-1(·), . . . , Fd-1(·) are the quantile functions of the corresponding marginal distributions F1(x1), . . . , Fd(xd). If F belongs to the class of elliptical distributions, this results in a so called
elliptical copula. Most elliptical copulae, however, cannot be given explicitly, because the distri-
F Fbution function and the inverse marginal distributions i usually have integral representations.

One class of copulae that overcomes this drawback is the class of Archimedean copulae

C(u1, . . . , uk) = {-1(u1) + · · · + -1(ud)}, u1, . . . , ud  [0, 1],

(1)

3

where  : [0, )  [0, 1], with (0) = 1, () = 0. The function  is called the generator  of the copula and usually depends on a single parameter . The generator  is required to be d-monotone, i.e. dierentiable up to the order d - 2, with (-1)j (j)(x)  0, j = 0, . . . , d - 2 for any x  [0, ) and with (-1)d-2(d-2)(x) being nondecreasing and convex on [0, ), see McNeil
and Ne²lehová (2009). We give some examples of Archimedean copulae and their generators in
Table 1, see Joe (1996) and Nelsen (2006) for more details.

In the following we will specialize our presentation to a setting with a single copula shape parameter
such as the Archimedean copulae. We emphasize that the notion of RCop is not limited to this class
of copulae: for instance the survival copula derived from an Archimedean copula by Crot(u, v) = C(1 - u, 1 - v) + u + v - 1, such as the rotated Gumbel copula which we will use in our empirical
part, is not Archimedean.

Suppose there are two random variables Xi and Xj with marginal distributions Fi and Fj and Fjoint distribution ij and nite second moments. Hoeding's lemma (Hoeding; 1940) together X Xwith Sklar's theorem states that the covariance between i and j is a function in the copula parameter , the marginals and the joint distribution function:

ij() = =


Fi,j(xi, xj, ) - Fi(xi)Fj(xj) dxidxj
- - 
C{Fi(xi), Fj(xj)} - Fi(xi)Fj(xj) dxidxj .
- -

(2)

Usually this integral has no explicit form, but e.g. for the multivariate normal distribution, in

 = which case one gets ij

. In other cases it can be approximated by numerical integration.

For our notion of RCop, we equate (2) with a measure of RV, i.e. we dene the copula shape
parameter implicitly through the equation

hij,t = fij(t) =


Ct{Fi,t(xi), Fj,t(xj)} - Fi,t(xi)Fj,t(xj) dxidxj ,
- -

(3)

h twhere ij,t denotes an element of the RC matrix measured at day . We then exploit Hoeding's lemma in a method-of-moments type of fashion to estimate t.

Consider the case d = 2, with one o-diagonal element h12,t in the RC available. An estimate of

t is given by

^tMM = f1-21(h12,t) ,

(4)

fwhere

-1 12

denotes

the

inverse

function

of

(2).

In the general case for d > 2, dene the moment

condition gij () = hij,t - fij (), where i < j and i, j = 1, . . . , d. Stacking all gij into a vector g of

size d(d - 1)/2, we dene the estimator as

^tMM

=

arg

min 

g

()Wg() ,

(5)

where W is a positive denite weight matrix. A typical choice would be W = In with In denoting the n-dimensional unit matrix and n = d(d - 1)/2. For d = 2, (5) coincides with (4). We point
out that these two estimators bear much similarity with method-of-moments approaches where the
copula parameter of an Archimedean copula is estimated from Kendall's tau or Spearman's rho
(Genest and Rivest; 1993).

4

Finally, we suggest an ad hoc estimator. This estimator is based on the transformation of the linear correlation coecient of the normal distribution to Kendall's tau, and the consequent transformation of Kendall's tau to the copula parameter. Assuming a Gaussian setting, it is well known
that the linear correlation coecient ij translates into Kendall's tau by

iGj,t

=

2 

arcsin ij,t

.

(6)

fAs stated in Genest and Rivest (1993) Kendall's tau has the following representation  in the terms
of the generator function and the shape parameter of a two-dimensional Archimedean copula

1
f () = 4 -1(v)/(-1) (v) dv + 1 .
0

For many Archimedean copulae this leads to an explicit and invertible relationship between

Kendall's tau and their shape parameter, see Table 1. Then the ad hoc estimator is dened

by

^tad hoc

=

2 d(d - 1)

f-1(^iGj,t) .

(7)

i<j

Interestingly, despite being based on shaky theoretical grounds, the simulation results and our empirical ndings show that for settings with small and moderate dependence this ad hoc estimator performs similarly to the estimator based on Hoeding's lemma. It is, however, severely biased in situations with strong dependence.

Given the assumptions on the copula family and the marginal distributions, the structure

C^t{F1,t(x1), . . . , Fd,t(xd)} ,

(8)

^where t is any estimator presented above, fully characterizes the (ex-post) multivariate distribution
as materialized in the RV measure in date t. We therefore call it realized copula (RCop).

2.2 A forecasting framework for realized copula
For our portfolio risk management problem, we consider a model framework which combines daily and within-day modeling frequencies. The purpose is to exploit intra-day high-frequency data as an auxiliary source of information to improve on the 1-day ahead VaR forecasts. In this sense, our approach is close to the MIDAS approach by Ghysels et al. (2006), the multiplicative error model suggested by Engle and Gallo (2006) and Shephard and Sheppard (2010), and it can be embedded into the extensions thereof recently proposed by Hansen, Huang and Shek (2011) and Hansen, Lunde and Voev (2011), and Noureldin et al. (2011).
For the daily level, denote the log-prices of a d-dimensional vector of assets by P = (P1, . . . , Pd) and the associated daily returns by Pt = Pt - Pt-1 = rt, t = 1, . . . , T . We assume that the rconditional distribution of daily returns t can be approximated by
rt+1  Frt+1|Ft (Ht+1|t) ,
where Frt+1|Ft (Ht+1|t) denotes a conditional distribution function parametrized by Ht+1|t which is F ran t-measureable forecast of the RC matrix of t. This forecast will be derived from a sequence of
5

Hthe RC matrices obtained from past within-day high-frequency data. When replacing t+1|t by a
known function of past daily returns, this framework is identical to the one formalized in standard volatility models of the multivariate GARCH type as suggested by Bollerslev (1990), Engle (2002), and Tse and Tsui (2002). However, rather than taking an a priori stand on an underlying model
Hfor t as a function of past daily returns, this approach relies on a ner information structure
accumulated by intraday high-frequency returns for the VaR forecast.

By Sklar's theorem and following the notion of a conditional copula outlined in Patton (2006),
we replace Frt+1|Ft by Frt+1|Ft (Ht+1|t) = C^t+1|t {F1,t(h^1,t+1|t), . . . , Fd,t(h^d,t+1|t)}, where C denotes a copula belonging to some parametric family C = {C,   } which is specied in the following. Furthermore, Fj,t(h^j,t+1|t), j = 1, . . . , d, denote the marginal conditional distributions of daily h^returns depending on variance forecasts j,t+1|t. As reported in Andersen, Bollerslev, Diebold and
Ebens (2001), returns standardized by ex post RV are close to standard normal. We therefore
Nassume that Fj,t(h^j,t+1|t) is normal with variance h^j,t+1|t, i.e. (0, h^j,t+1|t). Finally, ^t+1|t is a
^forecast of the associated RCop parameter t which is estimated day by day from RC as outlined
in Section 2.1.

We complete the model by specifying the forecasting rules:

log h^1,t+1|t

log h1,t+1 01 + D1 log htD + W1 log hWt + M1 log hMt 

 

...

 

log h^d,t+1|t

=

Et


 log 

...
hd,t+1

   

=


 0d

+ Dd log htD

...
+ Wd log hWt



+

Md

log

hMt

  

,



^t+1|t

t+1

0 + DtD + WtW + MtM

(9)

where  and xtD

j==x(ta0jr,eDjd,aiWjly,,xMj tW)

, for j

=

1 5

= 1, . . . , d, and  = (0, D, W, M) are parameter vectors,

4 i=0

xt-i

weekly,

and

xMt

=

1 21

20 i=0

xt-i

monthly

averages

of

xpast realizations of t. This forecasting rule, which is motivated from the idea of heterogeneous

agents with diering investment horizons, is due to Corsi (2009). It has found wide application

in the RV literature as it approximately captures the long-memory patterns typically observed in
RV data.2 We extend this idea here also for the copula parameter . This extension, together

with the assumptions on the marginals, allows us to predict the entire multivariate distribution.

Moreover, since the copula parameter parametrizes in some sense the covariance matrix, this

setting (implicitly) provides well-dened covariance matrices. From this perspective, it is similar

in spirit to Bauer and Vorkink (2010) and Chiriac and Voev (2011) who subject RC to nonlinear

transformations, such as the matrix logarithm or the Cholesky decomposition, to ensure positive-

deniteness of the predicted RC, see Section 3 for further details. Our modeling approach can

therefore be interpreted as another multivariate extension of the univariate HAR model.

As is discussed in Bauer and Vorkink (2010) and Chiriac and Voev (2011), an unbiased prediction of the variables parameterizing the covariance matrix, will generally not yield unbiased forecasts of covariance when the transformation between both is nonlinear. This issue also applies to the present estimator, since the relationship between the copula parameter and covariance as presented by Hoeding's lemma is nonlinear. However, since we consider 1-day VaR forecasts, only, we
2Further renements of this base line model have been suggested by Andersen et al. (2007), Corsi et al. (2008),
Bollerslev et al. (2009), Corsi et al. (2010), and Audrino and Hu (2011), see Corsi, Audrino and Renò (2012) for an overview.

6

conjecture these biases to be small (see also Halbleib and Voev (2011) for corroborative evidence). As in Chiriac and Voev (2011), we therefore renounce on a bias adjustment.

2.3 Simulation Study

In order evaluate the performance of the moment based estimator we subject it to the following
simulation study. Given an assumption on a copula family (e.g. Clayton, Gumbel), we draw 1000
vector-valued random variates from the copula based on standard normal margins (we consider
dimensions d = 2 and d = 3). From these draws, the sample covariance matrix is estimated
by the unbiased covariance estimator. Afterwards the method-of-moment estimators outlined in
Section 2.1 are applied. This procedure is repeated 1000 times.

In Figure 1, we present the dierences of the estimates from the true parameter value along with

the mean (red) and the median (blue) dierence as functions of the underlying Gumbel copula parameter.3 We also contrast the results with a maximum likelihood (ML) estimator, namely

with the method of inference functions for margins due to Joe and Xu (1996). The shaded areas
are the 95% pointwise condence intervals computed from the 1000 repetitions of the exercise.

As is apparent from Figure 1, the moment-based estimators are unbiased and only slightly less

ecient than the ML estimator. The linear correlation estimator is strongly biased in settings of

strong dependence. For instance, in the two-dimensional Gumbel case for copula parameters larger

2/3than three, which corresponds to Kendall's tau larger than

, the estimates start to be severely

downward biased.

2.4 Portfolio risk-management and backtesting

Computing risk measures for portfolios of stocks followed by a subsequent backtesting analysis are standard procedures in applied risk management, see e.g., Berkowitz and O'Brien (2002), Giacomini et al. (2009), Jin (2009), Berkowitz et al. (2010) among others. Closest to our research is Giot and Laurent (2004) who appear to be among the rst to simultaneously include both low and high-frequency data for such an analysis.

For portfolio risk-management, the aggregate portfolio and loss (P&L) distribution must be de-
termined. Consider a portfolio, where at = {a1,t, . . . , ad,t} with ai,t  Rd denoting the number of Vshares in the portfolio. The market value t of this portfolio is given by

d
Vt = aj,tSj,t ,
j=1

(10)

Swhere j,t is the asset price. In this study, we will consider only portfolios which are equally weighted in terms of wealth allocation. This implies that aj,t = wj Vt/Sj,t where wj = 1/d, j = 1, . . . , d. Hence absolute portfolio weights are adjusted on a daily basis in order to keep the relative
contributions constant.
3Simulation results for the Clayton copula are similar and are therefore not reported.

7

The daily trading P&L on this portfolio is given by

d
Lt+1 = (Vt+1 - Vt) = ajSj,t {exp(rj,t+1) - 1} ,
j=1

(11)

r j Lwhere j,t denotes the log-return on asset . Denote the conditional distribution function of by

FLt+1|Ft (x) = P(Lt+1  x|Ft) .

(12)

As the practically most important risk measure, we employ the Value-at-Risk (VaR) at level  Fdened as the -quantile of Lt+1|Ft :

VaRt+1|Ft ()

=

F -1 Lt+1

|Ft

()

.

(13)

F d FIt follows that Lt+1|Ft is determined by the -dimensional distribution of log-returns rt+1|Ft de-
scribed by the general framework in Section 2.2. The accuracy of the VaR estimates therefore depends on how well the RCop model and the alternative approaches presented in Section 3 capture the unknown multi-dimensional conditional distribution of daily returns.

A variety statistical criteria have been suggested in the literature to measure the quality of esti-
{l }mated VaR, see e.g. Campbell (2006) and Christoersen (2009) for overviews. Let t be the
true realizations of the respective P&L distribution. Unconditional coverage testing focuses on the
^exceedances ratio of the respective VaR. The exceedances ratio is dened by

N ^ =
T
T
N = I{lt < VaRt()}
t=1

Nwhere

denotes the number of observed exceedances. A natural likelihood ratio test based on

binomial theory for H0 : ^ =  is

^N (1 - ^)T -N LRuc = 2 log N (1 - )T -N

which has asymptotically a 2(1) distribution under H0. This test is due to Kupiec (1995). We talso considered a simple -test based on the normal approximation for the binomial distribution
and independence testing as suggested by Berkowitz et al. (2010). Both alternative tests did not
yield additional insights, which is why these results will not be reported.

3 Competitor models
As competitor models, we choose four classical representatives. As models, which only exploit daily data, we consider a naïve rolling window approach and a locally adaptive estimation algorithm to capture time-varying dependency. As alternatives for RV models, which make use of high-frequency data, we employ another two approaches. Similarly to the RCop approach, both methods use linear time series models of nonlinear transformations of RC: the matrix logarithm and the Cholesky decomposition, respectively.
8

3.1 Rolling window and local change point detection

The rolling window approach estimates the time-varying copula parameter on a xed window of size
w, while the locally adaptive change point (LCP) detection algorithm4 allows for a time-varying
window width. We sketch the LCP algorithm here. Corresponding theory and further applications in volatility modeling and risk management may be found in Spokoiny (1998), Mercurio and Spokoiny (2004), Chen et al. (2008), ìºek et al. (2009), Giacomini et al. (2009), Spokoiny (2009), Chen et al. (2010), and Härdle et al. (2010).

In both cases, in the rolling window case and for LCP detection, the estimator is the maximum likelihood estimator

nt d
t = arg max L() = arg max log c{F1,t(x1,i), . . . , Fd,t(xd,i); t} fj,t(xj,i) ,  i=1 j=1

(14)

nwhere t denotes the sample size of the respective window width, on which estimation is carried out, c{·; t} the copula density and fj,t(x), j = 1, . . . , d the marginal densities. The marginal
Ndensities are assumed to be (0, ^t2), where ^t2 is the variance estimated from the (daily) returns
of respective homogeneous time interval. The estimator can be obtained by exact maximumlikelihood estimation, i.e. directly by a one-step maximization of (14), or by a two-step procedure, the method of inference functions for margins (IFM) due to Joe and Xu (1996). In the latter case one rst estimates the parameters of the marginals and  given these estimated parameters  those of the copula function. Through all this work we will use the less ecient, but computationally more benign IFM-method, see Härdle et al. (2009) for an comprehensive discussion of alternative estimation strategies for copula-based models.

In what follows, let t denote the time varying but otherwise unknown copula parameter. Locally
t I adaptive estimation selects for each time point 0 an interval during which t is reasonably well approximated by a constant . A possible measure of discrepancy between two copulae C (·; )

and C(·;  ) is the Kullback-Leibler divergence K{C(·;  ), C(·; )} = E  log{c(·;  )/c(·; )}, where c(·) is the copula density. The aim is to select I as close as possible to the so-called oracle choice

interval Ik , dened as the largest interval I = [t0 - mk ; t0], for which the small modeling bias

condition

I () = K{C(·; t), C(·; )}  , for some  0,  ,

(15)

tI

is fullled. The LCP is based on sequentially testing the hypotheses of homogeneity on intervals
Ik. We select Ik with k = -1, 0, 1, . . . as the sequence of intervals Ik  Ik+1, starting with k = 1. If there are no change points in Tk  Ik \ Ik-1, we accept Ik as an interval with a constant copula Tstructure. At the next step we take k+1 and test it for homogeneity. We repeat these steps until I Irejection or until the largest possible interval K is accepted, leading to an interval k^.
Testing for local homogeneity works as follows. Fix some t0 and let I = [t0 - m, t0] be an interval T I candidate and I be a set of interval points within . We estimate the copula parameter by I I Hthe ML estimator from observations in , assuming a homogeneous model within . Thus the 0
4Alternative change point methods for copulae have been developed by Dias and Embrechts (2004) and Guégan
and Zhang (2010).

9

Hhypothesis and 1 alternative can be formulated as:
H0 :   TI, t = , t  I = J  Jc = [, t0]  [t0 - m,  ) H1 :   TI , t = 1, t  J = [, t0], and t = 2 = 1, t  J c = [t0 - m,  ).

Denote by LI () and LJ (1) + LJc (2) the log-likelihood functions corresponding to H0 and H1,

respectively. Then the likelihood ratio test for the single change point with known xed location

 is given by

TI, = max{LJ (1) + LJc(2)} - max LI ().

1,2



Since the point is unknown, one denes the test statistic:

TI = max TI, .  TI

T II tests the homogeneity hypothesis in against a change point alternative with unknown location  (in the set TI ). TThe decision rule of the test requires to compare I with the critical value zI . IThe critical value depends on the interval , the dimension and the parameter of the copula. We
reject the hypothesis of homogeneity if TI > zI .

For running the tests, several parameters have to be specied. This includes the choice of the
I Tinterval candidates k and internal points Ik for each of these intervals and the choice of the zcritical values Ik . One possible example of the implementation is based on the choice of the I minterval candidates k in form of a geometric grid. We x 0, which is the smallest possible interval of homogeneity, and then dene mk = [m0ck-1] for k = 1, 2, . . . , K and c > 1, where [x] means the integer part of x. Furthermore, we set Ik = [t0 - mk, t0] and Tk = [t0 - mk-1, t0 - mk-2] for k = 1, 2, . . . , K. For the empirical results these parameters are set to c = 1.25, m0 = 40, K = 10
which corresponds to the settings found in Giacomini et al. (2009) and Härdle et al. (2010).

zIn this work, we use the sequential choice of critical values k discussed in Spokoiny (2009). Con-

ksidering the situation after steps of the algorithm, we may distinguish two cases. In case one,

 ka change point has been detected at some step

; in the second case, no change point has

Bbeen detected. Following notation in Spokoiny (2009), let = {T1  z1, . . . , T -1  z -1, T > z } be the event meaning the rejection of the null hypothesis at step and (^k) = (~ -1) on B for

= 1, . . . , k. By Monte-Carlo simulations from xed parametric models, we sequentially nd a

zminimal value of l which ensures the inequality

max E |L(~k) - L(~ -1)|1/2I(B )   R() k/(K - 1) ,
k=l,...,K

where I is the indicator function and R() = maxk=l,...,K |L(~k) - L()|1/2. For = 1 this

inequality depends only on z1 in B1 = {T1 > z1}. For every  2 we take z1, . . . , z -1 being xed

B z from previous steps, which means that

is controlled by , only. The parameter plays the

role of the level of signicance and inuences the sensitivity of the procedure to inhomogeneity.
For large values of , small critical values are obtained which makes the procedure more sensitive; decreasing makes the procedure more conservative. We set  = 0.5, following the detailed robustness analysis for various choices of in Giacomini et al. (2009).

To obtain forecasts of the estimated parameters in the rolling window and LCP approach we do not apply a forecasting rule as for the RV models. We simply extrapolate the current estimates to

10

the following day (i.e. hold them constant). The logic of this degenerated prediction is that both approaches assume that the parameters involved are estimated on a local interval of homogeneity. It therefore appears natural to assume that this interval of homogeneity continues to hold at the following day. As another benet we avoid tting time series models on estimates obtained from overlapping return data which is likely to invalidate the statistical analysis.

3.2 Realized variance models

While at the univariate level the HAR formulation as described in Section 2.2 has emerged as an undisputed base-line model (Corsi, Audrino and Renò; 2012), the literature has yet not found agreement on its most competitive multi-variate extension. This is because at the multi-variate level, it has remained challenging to maintain positive-deniteness of predicted covariance matrices. Two recent contributions addressing this issue are the matrix logarithm model due to Bauer and Vorkink (2010) and the Cholesky decomposition model due to Chiriac and Voev (2011).

In Bauer and Vorkink (2010), RC are modeled by means of the matrix exponential and its inverse
Afunction, the matrix logarithm. The matrix exponential is a function on a square matrix and
given by the series representation

H = expm(A) =  1 Ak . k!
k=0

(16)

AAs a most important property of (16), if is a real, symmetric, and positive-denite matrix, so is H = expm(A). With the converse being true as well, the inverse function of the matrix

exponential, the matrix logarithm,

A = logm(H) ,

(17)

is a useful device for guaranteeing predicted covariance matrices to be positive-denite.

Given a time series of RC matrices Ht, t = 1, . . . , T , of size d × d, Bauer and Vorkink (2010) suggest to apply the matrix logarithm, At = logm(Ht). Now, At, t = 1, . . . , T , forms a time series of symmetric d × d matrices. As a next step, the vech-operator is applied

at = vech(At) ,

(18)

which stacks the

upper

triangular of

At

columnwise

into a

1 2

d(d

+

1)

×

1

vector.

The vector

time

aseries t is now modeled along the lines of the univariate HAR model, i.e. by forming elementwise

weekly and monthly aggregates of daily components. The resulting forecasting rules for these

(averaged) aggregates take exactly the same form as presented in (9). By rst applying the reverse
vech-operator and then the matrix exponential to the predictions derived from this model, the respective predicted covariance matrix is obtained as Ht+1|t = expm(At+1|t), which is positiveadenite as long as the elements in t+1|t are real.

A similar approach is followed by Chiriac and Voev (2011), but the series of covariance matrices is decomposed into a series of Cholesky factors, i.e. now (17) is replaced by

AA = H ,

(19)

where A is a real upper triangular d×d matrix with positive diagonal elements. As before, applying rst (19) and subsequently the vech-operator to a time series Ht gives rise to the vector-valued

11

atime series t. Then weekly and monthly aggregates are derived and modeled along the forecasting arules in (9). Predictions t+1|t are converted to positive-denite predicted covariance matrices by applying the reverse vech-operator, which yields an upper triangular matrix At+1|t, and by computing the matrix product Ht+1|t = At+1|tAt+1|t.
4 Empirical part
4.1 Data description, data ltering, and realized variance estimation
The empirical part of this work is based on stock price data obtained from NYSE's Trades and Quotes (TAQ) database, for the period from 2 January, 2009, to 31 December, 2010. It covers a total of 470 days and contains the daily transaction data observed between 9:30 till 16:00 local time. The stocks we consider are IBM, Google, Oracle, Pzer (PFE), Exxon (XOM), which are among the most heavily traded names at NYSE.
High frequency data is known to be noisy such that the accuracy of the RV and RC estimates can be seriously impaired. We therefore subject the data to the ltering procedure established in by Barndor-Nielsen et al. (2009) for TAQ data comprising the following steps:
1. Delete entries outside 9:30-16:00 and with zero transaction price.
2. Delete entries with corrected trades or abnormal sale condition.
3. Replace multiple trades for the same time stamp by the median price.
4. Delete entries with prices above ask plus bid-ask spread or below bid minus bid-ask spread.
After applying this cleaning procedure we estimate RC matrices by the realized kernel estimator due to Barndor-Nielsen et al. (2011), see Appendix A for all relevant details on the procedure. The realized kernel estimator warrants a positive-denite estimate of RC and is robust to market micro structure noise, such as non-synchronous trading and the bid-ask-bounce. Descriptive statistics on estimated RC are displayed in the upper panels of Tables 3 and 4.5 They are well in line with those reported on stock market data in general (Andersen, Bollerslev, Diebold and Ebens; 2001) or for realized kernel estimators specically (Barndor-Nielsen et al.; 2009). In Figure 2 we display the series of realized correlations of the two portfolios. As is visible for the rst portfolio containing Google-IBM-Oracle, all realized correlations track each other very closely. This is natural given all stocks come from the information and communication technologies sector. The second portfolio, IBM-PFE-XOM, which is a mixed sector portfolio, comprises one pair of stocks (IBM-XOM) that in the rst part of the sample period is slightly stronger correlated that the other two pairs.
5Note that entries for RV of IBM are diering between the two tables. This is due to refresh time sampling
of the realized kernel estimator. Since both covariance matrices are estimated separately, refresh time sampling for both RV series diers for the two portfolios implying slightly diering estimates. An alternative would be to increase dimension and to directly estimate the six-dimensional RC. However, as a consequence of refresh time sampling, fewer data observations would be used in the resulting estimator. We therefore prefer to compute the smaller dimensional estimates. An estimator for RC overcoming this issue is suggested by Corsi, Peluso and Audrino (2012).
12

Aside from high-frequency intraday data, we also employ a sample of daily closing prices from 9 July 2007 to 31 December 2010, see Table 2 for the descriptive statistics. These data will be used for backtesting the out-of-sample VaR computations. The history is larger than the one for intraday data, since the competitor models based on daily data (rolling window and the LCP method) require a data history prior to the one which is under scrutiny in the VaR investigation.
4.2 Empirical results
Before looking at the out-of-sample VaR results it is instructive to study the in-sample estimates of the copula parameters and of the forecasting rules as outlined in Section 2.2. The discussion of the out-of-sample backtesting results follows.
4.2.1 In-sample results
For our empirical application we consider an Archimedean copula, the Clayton copula, and the rotated Gumbel (rGumbel) copula, which is not Archimedean. Both copulae exhibit lower taildependence, which is likely to be crucial for modeling risk measures for stock portfolios. In-sample results for the estimated copula parameters are displayed in the lower panels of Tables 3 and 4.
In the rst portfolio, the estimated parameters of the rotated Gumbel uctuates between one (independence case) and quite substantial dependence of around two (i.e. Kendall's tau of around 0.5)
with the mean estimate being rMGMum  1.4. Similar ndings apply to the Clayton copula whose
parameter estimates are between zero (independence case) and two. Necessarily, the estimates for both copulae agree on the implied dependence expressed by Kendall's tau. For the second portfolio estimated copula shape parameters are somewhat lower, as is to be expected comparing the upper and the lower panel in Figure 2. Here estimates are on average around 1.3 in the rotated Gumbel and 0.58 in the Clayton case. As suggested by the ndings of the simulation study in Section 2.3, for both portfolios, due to dependence being moderate overall, the ad hoc estimator provides estimates which are quite close to those in the exact case.
In the top panels of Figures 3 and 4 we plot the time series of the RCop shape parameters based on Hoeding's lemma (red line, rotated Gumbel), which is estimated from high-frequency intraday data, against the time series of the copula parameters of the naïve rolling window (black line, window size 250 days) and the adaptive LCP method (blue line), both obtained for daily data. As is visible, the RCop structure diers markedly from the one recovered for the latter two approaches. First the copula parameters obtained for the daily data appear to be higher on average than is suggested from intraday data. Second, they are less noisy, but their reaction to fundamental changes in the economy is more inert than for RCop, as can be well discerned in the second half of the sample period (May to Sep. 2010). The reason becomes apparent in the lower panels of Figures 3 and 4 where we plot the estimated interval lengths of the rolling window and the LCP method. For both portfolios, also the LCP method tends to identify rather long intervals of homogeneity, which is why both approaches deliver very close estimates for these periods. It is rst in September that LCP identies much smaller intervals of homogeneity. In consequence the estimated copula parameter jumps up. In contrast RCop reacts already between May and July to higher levels of dependence and by September has already returned to usual levels.
13

In the lower panels of Tables 5 and 6 we provide in-sample estimates for the RCop forecasting rules. Estimation is accomplished by ordinary least squares.6 Size of estimates for the log-RV models are as reported elsewhere in the literature (Corsi; 2009): dynamics of RV is mainly driven by yesterdays realization. The inuence of the weekly component is only half as big, followed by the monthly RV aggregate being smallest in magnitude, but signicant. Interestingly, this contrasts sharply with the covariance dynamics as implied by the copula parameters. The shape parameter of RCop appears to be mainly driven by the daily and the weekly aggregate, with the latter even outweighing the rst. The monthly component is not signicant at all. These ndings suggest that the dynamics of spillovers and (lower) tail-dependence as reected by the time-varying copula parameter are more sluggish than those of RV: after some initial shocks cross-sectional dependence tends to subside more slowly than RV, allowing the system to still maintain high coecients of tail-dependence and thus a high probability to incur simultaneous price deteriorations in all stocks, even when individual variances might have calmed down already.
4.2.2 Out-of-sample VaR backtesting results
Since it appears dicult to subject a given copula assumption to a specication test, an out-ofsample study, for instance by backtesting VaR, is a vital means of model validation.
The backtesting proceeds as follows. We shrink the relevant time frame for backtesting to 19 October 2009 to 31 December 2010 taking the initial sample of 200 days to estimate the HAR-type prediction rules for all RV-based models: RCop (Hoeding's lemma and ad hoc estimator), the matrix log transformation, and the Cholesky factorization. Given the linear prediction rules, a forecast is made for RC, RV and the RCop parameter. To achieve high accuracy of the relevant
quantiles of the future P&L distribution, we simulate it with 100 000 random draws. We then
check whether the following day's P&L realization is an exceedance or not. For the next VaR computation, the initial learning sample is shifted to include the new day with the initial day from the previous learning sample being dropped. We thus iterate through the entire sample. As described in Section 2.4 the portfolio weights are always adjusted to preserve the same relative weights within the portfolio.
As was explained in Section 3.1, the rolling window and the LCP method work with a degenerated forecasting rule: the current copula parameter, which is estimated on the current interval of homogeneity (either xed at 250 days or locally adaptive in the LCP method), is extrapolated as a constant to the next following day. To initialize the LCP, we start at 2 January 2009 and go into the past until the smallest interval of a constant parameter is found by rejecting the homogeneity test. The relevant variances of the rolling window and the LCP method are computed from the daily returns on the respective intervals of homogeneity. We then iterate through the backtesting sample as described above.
Tables 7 and 8 summarize the results for 1-day ahead quantiles of 1%, 5% and 10%. For the rst portfolio, which is reported in Table 7, the RCop approaches are best performing, with rotated Gumbel and Clayton being hardly distinguishable from each other. In particular the smallest quantiles are very well captured. Unconditional coverage testing based on the Kupiec test conrms this observation. In the second portfolio (Table 8) rolling window and LCP perform slightly better than RCop at the 1% quantile, but at the 5% and the 10% quantiles it is RCop that is superior.
6The estimation problem could also be treated in a seemingly unrelated regressions framework.
14

As before rotated Gumbel and Clayton are very similar.

As a result, the RV approaches based on the matrix log transformation and the Cholesky factor-

ization, which work with a Gaussian structure, appear to be dominated by the methods allowing

for a non-Gaussian multivariate distribution. This is particularly evident for the small quantiles.

allIt is important to note that at the margins

methods assume normality. The strikingly bet-

ter performance of the copula-based methods need therefore be attributed to non-trivial forms of

tail-dependence relevant for VaR-computations.

In Figures 5 and 6 we present the exceedances plots for the 1%-VaR risk for both portfolios. Both gures elucidate the ndings of the previous tables. As is visible in the top panels of both gures, the rolling window and the LCP method exhibit a much smoother quantile history than the RV-based approaches. In contrast, RCop (middle panel) responds very quickly to shocks in the economy and quantiles widen accordingly. In Figure 5, this is nicely visible in the mid of the sample (June 2010), where many exceedances occur. While rolling window and LCP do not detect these outbursts, RCop does and only few exceedances are recorded. Like RCop, also the two other Gaussian RV approaches are very sensitive to these events, but having zero tail-dependence their quantiles are not suciently fat-tailed, which leads to a number of exceedances. The same deciency inherent to Gaussian RV approaches is observed in Figure 6, where many exceedances occur during the rst days of the backtesting period.

Finally, as is also apparent from Tables 7 and 8 and Figures 5 and 6, for the moderate dependence in our sample, RCop based on the ad hoc estimator essentially delivers the same results as the accurate estimator using Hoeding's lemma. In many circumstances, we therefore expect the ad hoc estimator to be a suitable practical replacement for the exact estimator, making computations even more straight forward.

5 Conclusion
Based on assumptions of the marginal distributions of daily stock returns and a copula family, we introduce realized copula as the copula structure materialized in realized covariance estimated from within-day high-frequency data. We estimate the copula parameters in a method-of-moments type of fashion using Hoeding's lemma. The resulting time series of copula parameters is captured using a heterogeneous autoregressive model which is well established in the realized variance literature.
Realized copula allows to move beyond the usual Gaussian structure which realized variance models typically adopt. In an out-of-sample VaR backtesting analysis, we demonstrate the relevance of this feature. Comparing our approach with a rolling window and an adaptive change point algorithm (both estimated for daily data) and two classical multivariate realized variance based benchmark models (matrix log transformation, Cholesky factorization), we nd that models adopting a multivariate Gaussian structure are dominated by copula models. On the other hand, models that are only based on daily data appear to be too sluggish to respond to structural shifts in the economy. Realized copula unites advantages of both modeling approaches in being highly responsive to shocks in the economic system, but at the same time allowing for non-trivial forms of tail-dependence. Both features are most crucial for accurate risk-management and portfolio optimization.

15

Our empirical results demonstrate that judicious combinations of low and high frequency information, as pioneered by Engle and Gallo (2006) and Ghysels et al. (2006), can generate substantial improvements in the out-of-sample forecasting accuracy, see also Hautsch et al. (2011) for a recent account in portfolio allocation. It would therefore be desirable to carry the approach to larger dimensions than the two- and three-dimensional cases considered. While technically possible, such a model would still have a single copula parameter and thus come at the cost of a very strong homogeneity assumption, which presumably one does not want to maintain in a high-dimensional setting. This issue could be addressed by using richer, yet still parsimoniously parametrized copulae, such as hierarchical Archimedean copulae (Whelan; 2004; Härdle et al.; 2010; Savu and Trede; 2010) or vine copulae (Joe; 1996; Bedford and Cooke; 2002). As a critical challenge of such a realized copula framework, one would not only need to estimate the copula shape parameters, but also has to simultaneously identify the embedded copula structure. We therefore suggest this topic for future research.
16

References
Andersen, T. G., Bollerslev, T. and Diebold, F. X. (2007). Roughing it up: Including jump com-
ponents in the measurement, modeling and forecasting of return volatility, Review of Economics and Statistics 89(4): 701720.
Andersen, T. G., Bollerslev, T., Diebold, F. X. and Ebens, H. (2001). The distribution of realized
stock return volatility, Journal of Financial Economics 61: 4376.
Andersen, T. G., Bollerslev, T., Diebold, F. X. and Labys, P. (2001). The distribution of realized
exchange rate volatility, Journal of the American Statistical Association 96: 4255.
Andersen, T. G., Bollerslev, T., Diebold, F. X. and Labys, P. (2003). Modelling and forecasting
realized volatility, Econometrica 71: 579625.
Audrino, F. and Hu, Y. (2011). Volatility Forecasting: Downside Risk, Jumps and Leverage Eect. Working Paper.
Journal ofBaillie, R. (1996). Long memory processes and fractional integration in econometrics, Econometrics 73: 559.
Baillie, R., Bollerslev, T. and Mikkelsen, H. (1996). Fractionally integrated generalized autore-
gressive conditional heteroscedasticity, Journal of Econometrics 74: 330.
Barndor-Nielsen, O. E., Hansen, P. R., L. A. and Shepard, N. (2009). Realised kernels in practice:
trades and quotes, Econometrics Journal 12. Forthcoming.
Barndor-Nielsen, O., Hansen, P., Lunde, A. and Shephard, N. (2011). Multivariate realised kernels: Consistent positive semi-denite estimators of the covariation of equity prices with
noise and non-synchronous trading, Journal of Econometrics 162: 149169. JournalBauer, G. and Vorkink, K. (2010). Forecasting multivariate realized stock market volatility,
of Econometrics .
Bedford, T. and Cooke, R. M. (2002). Vines  a new graphical model for dependent random
variables, Annals of Statistics 30(4): 10311068.
Berkowitz, J., Christoersen, P. and Pelletier, D. (2010). Evaluating Value-at-Risk models with
desk-level data, Management Science . Forthcoming.
Berkowitz, J. and O'Brien, J. (2002). How accurate are Value-at-Risk models at commercial
banks?, Journal of Finance 57: 10931112.
Bollerslev, T. (1990). Modeling the coherence in short-run nominal exchange rates: a multivariate
generalized ARCH model, Review of Economics and Statistics 72: 498505.
Bollerslev, T., Kretschmer, U., Pigorsch, C. and Tauchen, G. (2009). A discrete-time model for
daily S&P500 returns and realized variations: Jumps and leverage eects, Journal of Econometrics 150(2): 151166.
17

Bonato, M., Caporin, M. and Ranaldo, A. (2011). A forecast-based comparison of restricted
Wishart autoregressive models for realized covariance matrices, European Journal of Finance
p. forthcoming.

Breymann, W., Dias, A. and Embrechts, P. (2003). Dependence structures for multivariate high-
frequency data in nance, Quantitative Finance 3(1): 116.
Journal of RiskCampbell, S. D. (2006). A review of backtesting and backtesting procedures,
9(2): 117.

Chen, X. and Fan, Y. (2006). Estimation and model selection of semiparametric copula-based
multivariate dynamic models under copula misspecication, Journal of Econometrics 135: 125
154.

Chen, Y., Härdle, W. and Jeong, S.-O. (2008). Nonparametric risk management with generalized
hyperbolic distributions, Journal of the American Statistical Association 14: 910923.
Journal ofChen, Y., Härdle, W. and Pigorsch, U. (2010). Localized realized volatility modelling, the American Statistical Association 105(492): 3761393.
JournalChiriac, R. and Voev, V. (2011). Modelling and forecasting multivariate realized volatility, of Applied Econometrics 26(6): 922947.
Christoersen, P. (2009). Backtesting, in R. Cont (ed.), Encyclopedia of Quantitative Finance,
John Wiley & Sons, New York.

Christoersen, P., Errunza, V., Jacobs, K. and Langlois, H. (2011). Is the potential for international

Working paperdiversication disappearing?,

, McGill University, Montreal, Canada.

ìºek, P., Härdle, W. and Spokoiny, V. (2009). Adaptive pointwise estimation in time-
inhomogeneous conditional heteroscedasticity models, Econometrics Journal 12(2): 248271.
Journal ofCorsi, F. (2009). A simple approximate long-memory model of realized volatility, Financial Econometrics 7(2): 174196.
inCorsi, F., Audrino, F. and Renò, R. (2012). HAR Modeling for realized volatility forecasting, L. Bauwens, C. Hafner and S. Laurent (eds), Handbook of Volatility Models and their Applications, Vol. 1, John Wiley & Sons, New York, p. forthcoming.

Corsi, F., Mittnik, S., Pigorsch, C. and Pigorsch, U. (2008). The volatility of realized volatility,
Econometric Reviews 27(1): 4678.

Corsi, F., Peluso, S. and Audrino, F. (2012). Missing in Asynchronicity: A Kalman-EM Approach for Multivariate Realized Covariance Estimation. Unpublished manuscript, University of St. Gallen.

Corsi, F., Pirino, D. and Renò, R. (2010). Threshold bipower variation and the impact of jumps
on volatility forecasting, Journal of Econometrics 159: 276288.

Dias, A. and Embrechts, P. (2004). Dynamic copula models for multivariate high-frequency data
in nance, Working paper, ETH Zürich.

18

Engle, R. F. (2002). Dynamical conditional correlation: A simple class of multivariate generalized
autoregressive conditional heteroscedastic models, Journal of Business and Economic Statistics
20(3): 339350.

Engle, R. F. and Gallo, G. M. (2006). A multiple indicators model for volatility using intra-daily
data, Journal of Econometrics 131: 327.

Genest, C. and Rivest, L. P. (1993). Statistical inference procedures for bivariate archimedean
copulas, Journal of the American Statistical Association 88(423): 10341043.

Ghysels, E., Santa-Clara, P. and Valkanov, R. (2006). Predicting volatility: Getting the most out
of return data sampled at dierent frequencies, Journal of Econometrics 131: 5995.

Giacomini, E., Härdle, W. K. and Spokoiny, V. (2009). Inhomogeneous dependence modeling with
time-varying copulae, Journal of Business and Economic Statistics 27(2): 224234.

Giot, P. and Laurent, S. (2004). Modelling daily Value-at-Risk using realized volatility and ARCH
type models, Journal of Empirical Finance 11: 379398.

Gouriéroux, C., Jasiak, J. and Sufana, R. (2009). The Wishart autoregressive processes of multi-
variate stochastic volatility, Journal of Econometrics 150: 167181.

Guégan, D. and Zhang, J. (2010). Change analysis of a dynamic copula for measuring dependence
in multivariate nancial data, Quantitative Finance 10(4): 421430.

Hafner, C. M. and Manner, H. (2010). Dynamic stochastic copula models: estimation, inference
and applications, Journal of Applied Econometrics . Forthcoming.

Halbleib, R. and Voev, V. (2011). Forecasting multivariate volatility using the VARFIMA model on
realized covariance Cholesky factors, Jahrbücher f. Nationalökonomie u. Statistik 231(1): 134
152.

Hansen, P. R., Huang, Z. and Shek, H. (2011). Realized GARCH: A joint model of returns and
realized measures of volatility, Journal of Applied Econometrics . Forthcoming.

Hansen, P. R., Lunde, A. and Voev, V. (2011). Realized beta GARCH: A multivariate GARCH

Technical reportmodel with realized measures of volatility and covolatility,

, CREATES Research

Paper 2010-74, Aarhus, Denmark.

Härdle, W. K., Okhrin, O. and Okhrin, Y. (2010). Time varying Hierarchical Archimedean Copulae,
SFB 649 Discussion Paper 2010-018, Sonderforschungsbereich 649, Humboldt Universität zu
Berlin, Germany.

Härdle, W., Okhrin, O. and Okhrin, Y. (2009). Modeling dependencies in nance using copulae,
in W. Härdle, N. Hautsch and L. Overbeck (eds), Applied Quantitative Finance, 2 edn, Springer
Verlag.

Harris, F. D., McInish, T., Shoesmith, G. and Wood, R. (1995). Cointegration, error correction, and
price discovery on informationally linked security markets, Journal of Financial and Quantitative Analysis 30: 563579.

19

Hautsch, N., Kyj, L. M. and Malec, P. (2011). The merit of high-frequency data in portfolio allo-
cation, Working paper SFB649DP2011-059, Sonderforschungsbereich 649, Humboldt University,
Berlin, Germany.
Hautsch, N., Kyj, L. M. and Oomen, R. C. (2009). A blocking and regularization approach to
high dimensional realized covariance estimation, Working paper SFB649DP2009-049, Sonder-
forschungsbereich 649, Humboldt University, Berlin, Germany.
Hoeding, W. (1940). Massstabinvariante Korrelationstheorie, Schriften des Mathematischen Seminars und des Instituts für angewandte Mathematik der Universität Berlin 5: 181233.
Jin, X. (2009). Large portfolio risk management with dynamic copulas, Technical report, McGill
University.
Jin, X. and Maheu, J. (2010). Modelling Realized Covariances and Returns. Working Papers.
Joe, H. (1996). Families mof -variate distributions with given margins and m(m - 1)/2 bivariate
dependence parameters, in L. Rüschendorf, B. Schweizer and M. Taylor (eds), Distribution with xed marginals and related topics, IMS Lecture Notes  Monograph Series, Institute of
Mathematical Statistics.
Joe, H. and Xu, J. J. (1996). The estimation method of inference functions for margins for multi-
variate models, Technical Report 166, Department of Statistics, University of British Columbia.
Jondeau, E. and Rockinger, M. (2006). The copula-GARCH model of conditional dependencies:
an international stock market application, Journal of International Money and Finance 25: 827
853.
Journal ofKupiec, P. (1995). Techniques for verifying the accuracy of risk measurement models, Derivatives 3: 7384.
dMcNeil, A. J. and Ne²lehová, J. (2009). Multivariate Archimedean copulas, -monotone functions
and l1 norm symmetric distributions, Annals of Statistics 37(5b): 30593097.
Mercurio, D. and Spokoiny, V. (2004). Statistical inference for time-inhomogeneous volatility
models, Annals of Statistics 32(2). Forthcoming.
Nelsen, R. (2006). An Introduction to Copulas, 2nd edn, Springer-Verlag, New York.
Noureldin, D., Shepard, N. and Sheppard, K. (2011). Multivariate high-frequency-based volatility
(HEAVY) models, Journal of Applied Econometrics . Forthcoming.
Patton, A. J. (2004). On the out-of-sample importance of skewness and asymmetric dependence
for asset allocation, Journal of Financial Econometrics 2: 130168.
Patton, A. J. (2006). Modeling asymmetric exchange rate dependence, International Economic Review 47(2): 527556.
Savu, C. and Trede, M. (2010). Hierarchies of Archimedean copulas, Quantitative Finance
10(3): 295304.
20

Shephard, N. and Sheppard, K. (2010). Realising the future: Forecasting with high frequency
based volatility (HEAVY) models, Journal of Applied Econometrics 25(2): 197231. Sklar, A. (1959). Fonctions de répartition à n dimensions et leurs marges, Publications de l'Institut
de Statistique de l'Université de Paris 8: 229231.
Spokoiny, V. (1998). Estimation of a function with discontinuities via local polynomial t with an
adaptive window choice, Annals of Statistics 26: 13561378.
Spokoiny, V. (2009). Multiscale local change point detection with applications to value-at-risk,
The Annals of Statistics 37(3): 14051436.
Tse, Y. and Tsui, A. (2002). A multivariate generalized autoregressive conditional heteroscedastic
model with time-varying correlations, Journal of Business and Economic Statistics 20(3): 351
362.
Whelan, N. (2004). Sampling from Archimedean copulas, Quantitative Finance 4: 339352.
21

A Estimation of realized variance

On the intra-day level, we adopt the model framework used in the realized variance literature
described e.g. in Barndor-Nielsen et al. (2011). We suppose that during the trading day [t - 1; t]

the log-price process follows a Brownian semimartingale (BSM) which is superimposed by market
dmicro structure noise. More precisely, denote the -dimensional ecient equilibrium price process

by t

Yt = Yt-1 +

u dWu

t-1

 W dwhere t càdlàg is a volatility matrix process and t is a -dimensional vector of independent Brownian motions. At observation times t - 1 = 0 < 1 < . . . < N = t, we record the ecient

price plus a covariance stationary additive component

Pi = Yi + Ui ,

Covwhere E(Ui) = 0 and h |hh| <  with h =

(Ui , Ui-h ) for h > 0. The purpose is

Yto estimate the quadratic variation of , i.e. [Y ]t,t-1 =

t t-1

udu

with



=



.

An ex-post

estimate of integrated covariance [Y ]t,t-1 =

t t-1

u

du

will

be

called

realized covariance and was

denoted by Ht in Section 2.1. For the estimation of [Y ] from discrete, non synchronous, and noisy

price observations, we use the realized kernel estimator, which is described in the following.

The multivariate realized kernel method introduced by Barndor-Nielsen et al. (2011) yields con-
sistent, positive semi-denite estimates of the covariation of equity prices in the presence of noise
and non-synchronous trading. Data synchronization is accomplished via refresh time sampling
(RTS), see also Harris et al. (1995) and Hautsch et al. (2009). The refresh times are dened as
the times needed for all the assets in the portfolio to trade or to refresh posted prices. After
all assets being traded, the most recent price is used to form the RTS time scale. Formally, the
rst refresh time is dened as 1 = max{1,1, . . . , d,1}. All subsequent refresh times are dened as i+1 = arg min{j,kj |j,kj > i, kj = 1, . . . , Nj; j  1 . . . d}, where Nj denotes the number of jprice observations made for asset . This synchronization leads to a new high-frequency vector of returns pi = Pi - Pi-1 , where i = 1, . . . , n, and n is the number of RTS observations. With RTS, nthe sample size of retained data depends on the degree of non-synchronicity between assets.

The multivariate realized kernel estimator is dened as
H |h| K(P ) = k
H +1
h=-H

h,

with h being a matrix of autocovariances given by

h =

n j=|h|+1

pj

pj

-h

,

h0

n j=|h|+1

pj-hpj

,

h<0

,

and k(x) being the Parzen kernel

 1 - 6x2 + 6x3 0  x  1/2



k(x) = 2(1 - x)3

1/2  x  1 .

 0 x>1

HIn the estimation of the multivariate bandwidth parameter

we strictly follow the suggestions

outlined in Barndor-Nielsen et al. (2009).

22

B Tables and gures

family Gumbel Clayton Nelsen (2006) (4.2.2)
Nelsen (2006) (4.2.3)
Frank

 exp{-x1/ } (x + 1)-1/

1 - x1/

(1 - )/(ex - )

-

1 

log{e-x(e-

-

1)

+

1}

 -1

(- log x)

(x- - 1)/

(1 - x)

log

1-(1-x) x

-

log

e-x -1 e- -1

domain
  [1, )   (0, )   [1, )
  [0, 1)   (0, )

f 1 - 1/

/(2 + )

( - 2)/

1

-

2

+(-1)2 log(1-) 32

1 + 4{D1() - 1}/

  fTable 1: Generator function

, the inverse

-1 

,

and

Kendall's

tau

 for selected Archimedean

copulae, see Nelsen (2006), Table 4.1. D1 is the Debye function of order 1, D1() =

 0

t/(et

-1)dt.

Google Oracle IBM Pzer Exxon

min. -0.123 -0.103 -0.061 -0.112 -0.150

median -0.143e-3 0.000e-3 0.604e-3 -0.690e-3 0.290e-3

mean 0.254e-3 0.743e-3 0.475e-3 -0.250e-3 0.182e-3

max. 0.182 0.122 0.109 0.096 0.158

std. 0.022 0.021 0.015 0.017 0.019

skewness 0.331 0.393 0.166
-0.236 0.126

kurtosis 7.192 4.729 4.712 6.233
12.546

Table 2: Descriptive statistics of the daily log return data of the stocks under consideration. Sample period 9 July 2007 to 31 December 2010.

23

RV(Google) RV(IBM) RV(Oracle) RC(Google,IBM) RC(Google,Oracle) RC(IBM,Oracle)
^tMM (rGumbel) ^tad hoc (rGumbel) ^tMM (Clayton) ^tad hoc (Clayton)

min. 2.277e-05 1.431e-05 5.220e-05 1.978e-06 5.359e-06 2.106e-06 1.073e-00 1.078e-00 1.475e-01 1.554e-01

median 1.714e-04 1.048e-04 2.208e-04 5.758e-05 7.628e-05 6.749e-05 1.353e-00 1.361e-00 7.028e-01 7.225e-01

mean 2.503e-04 1.704e-04 3.082e-04 9.112e-05 1.112e-04 1.015e-04 1.375e-00 1.382e-00 7.538e-01 7.645e-01

max. 0.003 0.001 0.002 0.001 0.001 0.001 1.935 1.937 1.986 1.875

std. 0.269e-3 0.180e-3 0.253e-3 0.110e-3 0.128e-3 0.113e-3
0.146 0.144 0.304 0.288

Table 3: Descriptive statistics of the realized kernels (variances and covariances) and realized copulae (method of moments and ad hoc for Clayton and rotated Gumbel copulae) of the GoogleIBM-Oracle portfolio.

RV(IBM) RV(Pzer) RV(Exxon) RC(IBM,Pzer) RC(IBM,Exxon) RC(Pzer,Exxon)
^tMM (rGumbel) ^tad hoc (rGumbel) ^tMM (Clayton) ^tad hoc (Clayton)

min. 1.474e-05 2.819e-05 2.455e-05 -1.550e-06 4.231e-08 -3.858e-06 1.011e-00 1.012e-00 2.271e-02 2.473e-02

median 1.014e-04 2.067e-04 1.281e-04 4.069e-05 5.198e-05 4.691e-05 1.264e-00 1.284e-00 5.247e-01 5.672e-01

mean 1.704e-04 2.837e-04 1.810e-04 6.553e-05 8.442e-05 7.187e-05 1.286e-00 1.303e-00 5.724e-01 6.057e-01

max. 0.194e-04 0.311e-04 0.229e-04 0.161e-04 0.111e-04 0.112e-04 1.788e-00 1.793e-00 1.644e-00 1.586e-00

std. 1.820e-04 2.467e-04 1.786e-04 9.599e-05 1.010e-04 8.744e-05 1.275e-01 1.302e-01 2.599e-01 2.604e-01

Table 4: Descriptive statistics of the realized kernels (variances and covariances) and realized copulae (method of moments and ad hoc for Clayton and rotated Gumbel copulae) of the IBMPFE-XOM portfolio.

Google
IBM
Oracle
^tMM (rGumbel) ^tad hoc (rGumbel) ^tMM (Clayton) ^tad hoc (Clayton)

0
-0.597 (0.234) -0.586 (0.232) -0.705 (0.260)
0.047 (0.015) 0.048 (0.016) -0.068 (0.022) -0.063 (0.020)

D
0.559 (0.054) 0.509 (0.055) 0.505 (0.054) 0.354 (0.056) 0.354 (0.056) 0.364 (0.056) 0.363 (0.056)

W
0.254 (0.074) 0.254 (0.078) 0.155 (0.079) 0.449 (0.083) 0.454 (0.083) 0.444 (0.084) 0.450 (0.084)

M
0.121 (0.054) 0.175 (0.059) 0.259 (0.066) 0.039 (0.073) 0.036 (0.073) 0.047 (0.077) 0.043 (0.077)

Table 5: Parameters of the in-sample HAR models for the Google-IBM-Oracle portfolio. Standard errors in brackets.
24

IBM
Pzer
Exxon
^tMM (rGumbel) ^tad hoc (rGumbel) ^tMM (Clayton) ^tad hoc (Clayton)

0
-0.599 (0.236) -0.523 (0.241) -0.734 (0.258)
0.048 (0.016) 0.049 (0.016) -0.139 (0.047) -0.124 (0.043)

D
0.492 (0.056) 0.488 (0.055) 0.418 (0.056) 0.270 (0.056) 0.280 (0.056) 0.255 (0.056) 0.262 (0.056)

W
0.255 (0.079) 0.238 (0.080) 0.411 (0.078) 0.441 (0.090) 0.437 (0.090) 0.466 (0.099) 0.468 (0.100)

M
0.190 (0.061) 0.216 (0.065) 0.092 (0.059) 0.085 (0.088) 0.084 (0.088) 0.126 (0.102) 0.121 (0.103)

Table 6: Parameters of the in-sample HAR models for the IBM-Pzer-Exxon portfolio. Standard errors in brackets.

model \  LCP m0 = 40 (rGumbel) ROL w = 250 (rGumbel)
MM (rGumbel)
ad hoc (rGumbel)
LCP m0 = 40 (Clayton) ROL w = 250 (Clayton)
MM (Clayton)
ad hoc (Clayton)
Gauss (Bauer and Vorkink; 2010)
Gauss (Chiriac and Voev; 2011)

0.01 0.0258 (0.028) 0.0221 (0.083)
0.0148 (0.462) 0.0148 (0.462)
0.0258 (0.028) 0.0221 (0.083)
0.0148 (0.462) 0.0148 (0.462)
0.0406 (1e-04) 0.0369 (6e-04)

0.05 0.0369 (0.3003) 0.0332 (0.1779) 0.0590 (0.5062) 0.0590 (0.5062)
0.0517 (0.9007)
0.0443 (0.6598) 0.0554 (0.6909) 0.0554 (0.6909) 0.0738 (0.0921) 0.0812 (0.0301)

0.1 0.0775 (0.2002) 0.0664 (0.0511)
0.0996 (0.9838) 0.0996 (0.9838)
0.0849 (0.3953) 0.0738 (0.1334) 0.0959 (0.8227) 0.0886 (0.5229) 0.1218 (0.2463) 0.1255 (0.1772)

^ pTable 7: VaR performance ( ) for the Google-IBM-Oracle portfolio. -values of the Kupiec test in m wbrackets. 0 denotes the smallest possible interval of homogeneity for the LCP method, is the
window width for the rolling window approach.

model \  LCP m0 = 40 (rGumbel) ROL w = 250 (rGumbel)
MM (rGumbel)
ad hoc (rGumbel)
LCP m0 = 40 (Clayton) ROL w = 250 (Clayton)
MM (Clayton)
ad hoc (Clayton)
Gauss (Bauer and Vorkink; 2010)
Gauss (Chiriac and Voev; 2011)

0.01
0.0111 (0.8618) 0.0111 (0.8618)
0.0074 (0.6494) 0.0074 (0.6494) 0.0185 (0.2110)
0.0111 (0.8618)
0.0074 (0.6494) 0.0074 (0.6494) 0.0369 (0.0006) 0.0406 (0.0001)

0.05 0.0443 (0.6598) 0.0332 (0.1779) 0.0554 (0.6909)
0.0517 (0.9007)
0.0554 (0.6909) 0.0369 (0.3003) 0.0554 (0.6909) 0.0554 (0.6909) 0.0738 (0.0921) 0.0738 (0.0921)

0.1 0.0701 (0.0847) 0.0517 (0.0038)
0.1033 (0.8561) 0.1033 (0.8561)
0.0923 (0.6670) 0.0590 (0.0157)
0.1033 (0.8561) 0.1033 (0.8561)
0.1107 (0.5631) 0.1144 (0.4390)

^ pTable 8: VaR performance ( ) for the IBM-Pzer-Exxon portfolio. -values of the Kupiec test in m wbrackets. 0 denotes the smallest possible interval of homogeneity for the LCP method, is the
window width for the rolling window approach.

25

ML MM

ad hoc

summary.table[, "mean lin.cor"]

summary.table[, "mean argminHL"]

 - ^ -1 0 1 2

5 10 
ML

15

5 10 
MM

15

5 10 
ad hoc

15

summary.table[, "mean lin.cor"]

summary.table[, "mean argminHL"]

 - ^ -1.0 -0.5 0.0 0.5 1.0 1.5 2.0

5 10 

15

5 10 

15

5 10 

15

Figure 1: Monte Carlo simulation. Top panel: two-dimensional case with Gumbel copula. Lower panel: three-dimensional case with Gumbel copula. Left plot: ML-IFM estimator. Middle plot: moment estimator based on Hoeding's lemma. Right plot: ad-hoc estimator based on linear correlation. Numbers are computed based on 1000 estimates of the respective parameters. Each parameter estimate is based on a sample size of 1000 randomly drawn observations. Red line is the mean of the dierences between estimate and true value, blue the median (hardly visible). Shaded area is the 95% interval based on the 1000 repetitions.

26

0.0 0.2 0.4 0.6 0.8

IBM vs Oracle IBM vs GOOGLE Oracle vs GOOGLE

Realized Correlations

Feb 2009 May 2009 Aug 2009 Nov 2009 Mar 2010 Jun 2010 Sep 2010 Date

Pfizer vs Exxon Pfizer vs IBM Exxon vs IBM

Realized Correlations

0.0 0.2 0.4 0.6 0.8

Feb 2009 May 2009 Aug 2009 Nov 2009 Mar 2010 Jun 2010 Sep 2010 Date
Figure 2: Realized correlation estimated by means of the realized kernel estimator between 2 Jan. 2009 to 31 Dec. 2010. Top panel: Google-IBM-Oracle portfolio. Lower panel: IBM-Pzer(PFE)Exxon(XOM) portfolio.
27

t 300 1.0 1.5 2.0 2.5

length 100 200

MM LCP, m0 = 40 Rolling Window, w = 250
Feb 2009 May 2009 Aug 2009 Nov 2009 Mar 2010 Jun 2010 Sep 2010
Figure 3: Estimated copula parameters for the case of the rotated Gumbel copula on the GoogleIBM-Oracle portfolio. Top panel: the naïve rolling window estimates (black line), the LCP estimates (blue line), and realized copula estimates based on Hoeding's lemma (red line). Lower panel: estimated interval length of the LCP procedure (blue line) and (constant) interval length of
naïve rolling window approach (black line). LCP (blue) is run with m0 = 40, which is the smallest
possible interval of homogeneity.
28

t 1.0 1.5 2.0 2.5

length 100 200

MM LCP, m0 = 40 Rolling Window, w = 250
Feb 2009 May 2009 Aug 2009 Nov 2009 Mar 2010 Jun 2010 Sep 2010
Figure 4: Estimated copula parameters for the case of the rotated Gumbel copula on the IBMPzer-Exxon portfolio. Top panel: the naïve rolling window estimates (black line), the LCP estimates (blue line), and realized copula estimates based on Hoeding's lemma (red line). Lower panel: estimated interval length of the LCP procedure (blue line) and (constant) interval length of
naïve rolling window approach (black line). LCP (blue) is run with m0 = 40, which is the smallest
possible interval of homogeneity.
29

PL function -20 0 20

rGumbel, Rolling Window

q

qq

q

qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq

q

+ ++ +

+ +

q

PL function -20 0 20

rGumbel, LCP

q

qq

q

qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq

q

+ ++ +

+ +

+

-40

-40

PL function -20 0 20

Nov 2009 Feb 2010 May 2010 Aug 2010 rGumbel, MM

Nov 2010
q

qq

q

qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq

q

+ +q q

q
+

+

PL function -20 0 20

Nov 2009 Feb 2010 May 2010 Aug 2010 rGumbel, ad hoc

Nov 2010
q

qq

q

qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq

q

+ +q q

q
+

+

-40

-40

PL function -20 0 20

Nov 2009 Feb 2010 May 2010 Aug 2010 Nov 2010

Gauss (Bauer and Vorkink; 2010)

q

qq
q
+ + ++ +qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq +q +q + + +q
+

PL function -20 0 20

Nov 2009 Feb 2010 May 2010 Aug 2010 Nov 2010

Gauss (Chiriac and Voev; 2011)

q

qq

q

+ ++ +qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq

q

+ +q +

+ +

+

-40

-40

Nov 2009 Feb 2010 May 2010 Aug 2010 Nov 2010

Nov 2009 Feb 2010 May 2010 Aug 2010 Nov 2010

Figure 5: Exceedances plot for the VaR(0.01) for the rotated Gumbel copula on the Google-IBM-
Oracle portfolio. From top left to lower right: Rolling window (window width w = 250), LCP method (smallest possible interval of homogeneity m0 = 40), realized copula (Hoeding's lemma),
realized copula (ad hoc), Bauer and Vorkink (2010) and Chiriac and Voev (2011). Prot & loss
(blue dots), the lower VaR(0.01) (green solid line), exceedances (red crosses).

30

PL function -5 0 5

PL function -5 0 5

rGumbel, Rolling Window

q

q

qq

q

qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq

q qq

+

qq q
+

q

q

+

rGumbel, LCP

q

q

qq

q

qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq

q qq

+

qq q
+

q

q

+

PL function -5 0 5

PL function -5 0 5

Nov 2009 Feb 2010 May 2010 Aug 2010 rGumbel, MM

Nov 2010
q

q

qq

q

qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq

q qq

q

qq q q

+

+

q

Nov 2009 Feb 2010 May 2010 Aug 2010 rGumbel, ad hoc

Nov 2010
q

q

qq

q

qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq

q qq

q

qq q q

+

+

q

PL function -5 0 5

PL function -5 0 5

Nov 2009 Feb 2010 May 2010 Aug 2010 Nov 2010

Gauss (Bauer and Vorkink; 2010)

q

q

qq

q

+ + + +qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq + +qq
+ + + +q q

q

Nov 2009 Feb 2010 May 2010 Aug 2010 Nov 2010

Gauss (Chiriac and Voev; 2011)

q

q

qq

q

+ + +qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq + +qq
+ + + + +q

+

Nov 2009 Feb 2010 May 2010 Aug 2010 Nov 2010

Nov 2009 Feb 2010 May 2010 Aug 2010 Nov 2010

Figure 6: Exceedances plot for the VaR(0.01) for the rotated Gumbel copula on the IBM-Pzer-
Exxon portfolio. From top left to lower right: Rolling window (window width w = 250), LCP method (smallest possible interval of homogeneity m0 = 40), realized copula (Hoeding's lemma),
realized copula (ad hoc), Bauer and Vorkink (2010) and Chiriac and Voev (2011). Prot & loss
(blue dots), the lower VaR(0.01) (green solid line), exceedances (red crosses).

31

SFB 649 Discussion Paper Series 2012
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "HMM in dynamic HAC models" by Wolfgang Karl Härdle, Ostap Okhrin and Weining Wang, January 2012.
002 "Dynamic Activity Analysis Model Based Win-Win Development Forecasting Under the Environmental Regulation in China" by Shiyi Chen and Wolfgang Karl Härdle, January 2012.
003 "A Donsker Theorem for Lévy Measures" by Richard Nickl and Markus Reiß, January 2012.
004 "Computational Statistics (Journal)" by Wolfgang Karl Härdle, Yuichi Mori and Jürgen Symanzik, January 2012.
005 "Implementing quotas in university admissions: An experimental analysis" by Sebastian Braun, Nadja Dwenger, Dorothea Kübler and Alexander Westkamp, January 2012.
006 "Quantile Regression in Risk Calibration" by Shih-Kang Chao, Wolfgang Karl Härdle and Weining Wang, January 2012.
007 "Total Work and Gender: Facts and Possible Explanations" by Michael Burda, Daniel S. Hamermesh and Philippe Weil, February 2012.
008 "Does Basel II Pillar 3 Risk Exposure Data help to Identify Risky Banks?" by Ralf Sabiwalsky, February 2012.
009 "Comparability Effects of Mandatory IFRS Adoption" by Stefano Cascino and Joachim Gassen, February 2012.
010 "Fair Value Reclassifications of Financial Assets during the Financial Crisis" by Jannis Bischof, Ulf Brüggemann and Holger Daske, February 2012.
011 "Intended and unintended consequences of mandatory IFRS adoption: A review of extant evidence and suggestions for future research" by Ulf Brüggemann, Jörg-Markus Hitz and Thorsten Sellhorn, February 2012.
012 "Confidence sets in nonparametric calibration of exponential Lévy models" by Jakob Söhl, February 2012.
013 "The Polarization of Employment in German Local Labor Markets" by Charlotte Senftleben and Hanna Wielandt, February 2012.
014 "On the Dark Side of the Market: Identifying and Analyzing Hidden Order Placements" by Nikolaus Hautsch and Ruihong Huang, February 2012.
015 "Existence and Uniqueness of Perturbation Solutions to DSGE Models" by Hong Lan and Alexander Meyer-Gohde, February 2012.
016 "Nonparametric adaptive estimation of linear functionals for low frequency observed Lévy processes" by Johanna Kappus, February 2012.
017 "Option calibration of exponential Lévy models: Implementation and empirical results" by Jakob Söhl und Mathias Trabs, February 2012.
018 "Managerial Overconfidence and Corporate Risk Management" by Tim R. Adam, Chitru S. Fernando and Evgenia Golubeva, February 2012.
019 "Why Do Firms Engage in Selective Hedging?" by Tim R. Adam, Chitru S. Fernando and Jesus M. Salas, February 2012.
020 "A Slab in the Face: Building Quality and Neighborhood Effects" by Rainer Schulz and Martin Wersing, February 2012.
021 "A Strategy Perspective on the Performance Relevance of the CFO" by Andreas Venus and Andreas Engelen, February 2012.
022 "Assessing the Anchoring of Inflation Expectations" by Till Strohsal and Lars Winkelmann, February 2012.
SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

SFB 649 Discussion Paper Series 2012
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
023 "Hidden Liquidity: Determinants and Impact" by Gökhan Cebiroglu and Ulrich Horst, March 2012.
024 "Bye Bye, G.I. - The Impact of the U.S. Military Drawdown on Local German Labor Markets" by Jan Peter aus dem Moore and Alexandra Spitz-Oener, March 2012.
025 "Is socially responsible investing just screening? Evidence from mutual funds" by Markus Hirschberger, Ralph E. Steuer, Sebastian Utz and Maximilian Wimmer, March 2012.
026 "Explaining regional unemployment differences in Germany: a spatial panel data analysis" by Franziska Lottmann, March 2012.
027 "Forecast based Pricing of Weather Derivatives" by Wolfgang Karl Härdle, Brenda López-Cabrera and Matthias Ritter, March 2012.
028 "Does umbrella branding really work? Investigating cross-category brand loyalty" by Nadja Silberhorn and Lutz Hildebrandt, April 2012.
029 "Statistical Modelling of Temperature Risk" by Zografia Anastasiadou, and Brenda López-Cabrera, April 2012.
030 "Support Vector Machines with Evolutionary Feature Selection for Default Prediction" by Wolfgang Karl Härdle, Dedy Dwi Prastyo and Christian Hafner, April 2012.
031 "Local Adaptive Multiplicative Error Models for High-Frequency Forecasts" by Wolfgang Karl Härdle, Nikolaus Hautsch and Andrija Mihoci, April 2012.
032 "Copula Dynamics in CDOs." by Barbara Choro-Tomczyk, Wolfgang Karl Härdle and Ludger Overbeck, Mai 2012.
033 "Simultaneous Statistical Inference in Dynamic Factor Models" by Thorsten Dickhaus, Mai 2012.
034 "Realized Copula" by Matthias R. Fengler and Ostap Okhrin, Mai 2012.
SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

