BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2010-006
Bayesian Estimation and Model Selection in the Generalised Stochastic Unit Root Model
Fuyu Yang* Roberto Leon-Gonzalez**
* Humboldt-Universit‰t zu Berlin, Germany **National Graduate Institute for Policy Studies Tokyo, Japan
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universit‰t zu Berlin Spandauer Straﬂe 1, D-10178 Berlin

Bayesian Estimation and Model Selection in the Generalised Stochastic Unit Root Model
Fuyu Yang Institute for Statistics and Econometrics
Humboldt-Universita®t zu Berlin Roberto Leon-Gonzalez
National Graduate Institute for Policy Studies
January, 2010

Abstract
We develop Bayesian techniques for estimation and model comparison in a novel Generalised Stochastic Unit Root (GSTUR) model. This allows us to investigate the presence of a deterministic time trend in economic series, while allowing the degree of persistence to change over time. In particular the model allows for shifts from stationarity I(0) to nonstationarity I(1) or vice versa. The empirical analysis demonstrates that the GSTUR model provides new insights on the properties of some macroeconomic time series such as stock market indices, inflation and exchange rates.
Keywords: Stochastic Unit Root, MCMC, Bayesian
JEL classification: C11, C32

Acknowledgements

Leon-Gonzalez would like to thank the Leverhulme Trust for financial support under Grant F/00 273/J. Fuyu Yang would like to thank the financial support from the EU Commission through MRTN-CT-2006-034270 COMISEF as well as the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

Institute for Statistics and Econometrics, Humboldt-Universita®t zu Berlin. fuyu.yang@wiwi.hu-berlin.de. Address: Spandauer Str. 1, D-10099 Berlin, Germany.
Fellow of the Rimini Centre for Economic Analysis.

Email:

1

1 Introduction

Application of econometric tests indicates that many macroeconomic time series contain

unit roots and are therefore nonstationary I(1) processes. Some of these results are in con-

tradiction with economic theories that imply the stationarity of some series (e.g. Purchasing

Power Parity). Further development in some nonlinear models, such as TAR (Caner and

Hansen 2001), STAR (van Dijk et al. 2002), ESTAR (Kapetanios et al. 2003), and al-

ternative forms of stationarity, such as ARFIMA (Koop et al. 1997), have been proposed

for reconciling the empirical evidence to economic theory. This paper develops Bayesian

techniques to test for a deterministic time trend while allowing changes in the degree of per-

sistence over time. For this purpose we use a Generalised Stochastic Unit Root (GSTUR)

model:

t = yt t

(1.1)

Pl t = exp( t) t 1 + i 4 t i + "t
i=1

(1.2)

t= 0+ 1 t 1+ + p t p+ t

(1.3)

where "t is i:i:d:N (0; 2") and t is i:i:d:N 0; 2 . This is a generalization of the STUR model proposed by Granger and Swanson (1997):

yt = exp( t)yt 1 + "t

(1.4)

t= 0+ 1 t 1+ t

(1.5)

where "t is i:i:d:N (0; "2) and t is i:i:d:N 0; 2 . One main distinctive feature of the STUR model is that it allows for the persistence of
macroeconomic series to vary with time. This time-varying persistence could be a characteristic of series that appear to be nonstationary after di§erencing or detrending. There is empirical evidence that persistence changes over time in some U.S. macroeconomic time series (Kim 2000, Kim 2002, Busetti and Taylor 2004, Harvey et al. 2006). Thus, tests

for a deterministic time trend hypothesis that ignore changes in persistence might lead to wrong conclusions. Therefore, previous evidence as to whether a macroeconomic series is trend stationary (TS) or di§erence stationary (DS) or neither (see Newbold et al. 2001) needs to be reconsidered. The crucial questions are: 1. how sure are we that economic

time series have a deterministic trend when the persistence is time-varying and 2. whether the variations of persistence correspond with historical events. As the STUR model, the GSTUR model allows for a time-varying degree of persistence. This allows the process to be I(1) at some periods of time and I(0) at others. Furthermore, the GSTUR generalizes the STUR model by allowing for a deterministic trend and a more complex lag structure in the measurement equation and transition equation.
While modelling the changes in persistence as a stochastic process seems attractive, the

estimation involved presents computational challenges. One motivation of using Bayesian techniques is that estimations for this highly parameterized model can be achieved by Markov Chain Monte Carlo (MCMC) techniques. Granger and Swanson (1997) used two methods to estimate the parameters in a STUR model (equations 1.4 and 1.5), which produced `wild estimates'that are `fairly imprecise'. Simulations via MCMC techniques, after

2

passing some diagnostic tests (e.g. Carlin and Chib 1995, Geweke 1989), can shed light on the posterior distribution properties for any feature of interest. Jones and Marriott (1999) provided a Bayesian method for parameter estimations for the STUR model. In this paper, Bayesian techniques for estimation and model comparison in a GSTUR model are developed.
The remainder of the paper is organized as follows. Section 2 describes the methods for Bayesian estimation and model selection. Section 3 presents the empirical results using Nelson and Plosser's S&P 500 series, the U.K. /U.S. long run exchange rates and UK ination rates. Section 4 briey concludes.

2 Bayesian Inference

Equation 3 de...nes the time-varying persistence parameter

we assume to be stationary. Thus the unconditional mean

is:

= 1

0
Pp
j j=1

t as an AR(p) process, which of the stationary process t

Let t = exp( t)

(2.1)

We begin by introducing some notation: Ft denotes the history of yt up to time t, Ft = (y1; ; yt)0, y denotes the whole sample of observations with a sample size of N , y = (y1; y2; ; yn)0. Let us also de...ne = ( 1 p; ; 0; 1; ; T 1; T )0 as

the vector containing all unobserved stochastic roots over the time T period. Similarly

de...ne the vector = 1 p; ; 0; 1; ; T 1; T 0 associated with . De...ne also

initial = ( 1 p; ; 0)0, = 1; ; p 0 and = ( 1; ; l)0. The error precisions

are denoted as h" =

2 "

and

h

=

2.

=

; ; ; ; ; 2"; 2 stands for the vector

containing all the parameters of interest. Note that t determines the degree of persistence

and varies stochastically in the GSTUR process.

Note that the process is stationary (I(0)) if t < 1 and not stationary if t 1. Note also that the random walk (RW) model is nested within the GSTUR model at the point

where = 0 and 2 = 0, such that t will be always equal to 1. Hence, ( ; t; ) are parameters of special interest.

2.1 Bayesian Model Estimation

With few exceptions detailed below, we adopt the prior speci...cation proposed in Jones

and Marriott (1999) (JM hereafter):

N ; V , f ; g N ; V and

N ; V . Since t is restricted to be a stationary AR(p) process, the inverse characteristic roots of the polynomial:

(z) = 1 1z

pzp

should all lie outside of the unit circle. Let 1 (kz k > 1) be an indicator function for the

event that i : i = 1; is p( ) = (C) 1 fN

; p jointly satisfy the stationarity condition. The prior density of

;V
i

i

1 (kz k > 1), where fN (:) is a multivariate normal density

3

and C is the normalizing constant. The prior densities for error precisions are chosen as

p(h") = f " "; " and p(h ) = f Gamma distribution.

; ;where f ( ) denotes the density of the

Table (1) shows our choice for prior parameters in the empirical application. The pa-

rameter varies around ln 0:9 with a small variance V and is independent of 2 (unlike

in JM, where

j 2 s fN (0; 2)). Besides, JM selected `di§use'priors for

2 "

and

2 that

merely indicate that 0 <

2 "

<

1

and

0

<

2 < 1. Instead, we want a prior that captures

the prior belief that t varies slowly over time. Accordingly, the prior for 2 puts most of

the probability mass on small values. We ...x the prior parameters of

2 "

so

that

the

prior

probability of extremely large values is small.

Table 1: Summarized Prior Properties in GSTUR

parameters Selected Values in the Prior

ln 0:9

V 0:12

i

1
i

V 0:1 i

h"

" 1:1

0:2
"

h 1:5 2:5

0 0

V

(0; ; 0)0 V

104eye(2) 104eye(i)

Given the above prior information, we are able to derive the conditional posterior distributions that can be used in the MCMC algorithm. To facilitate computations, we will work with the augmented likelihood, such that the posterior for can be written as:

N
p ( ; j y) / p( ; ) p (yt j ; ; Ft 1)
t=2
All conditional posterior densities have standard forms and can be sampled directly, except for that corresponding to t, which is non-standard (see Appendix for the detail form of this density). JM applied a ratio of uniforms method (see Devroye, 1986) to sample
t. As the posterior conditional of t is similar to a normal density, the Metropolis-Hastings (M-H) algorithm can be implemented to draw values of t. As shown in the empirical section, the proposed Metropolis-within-Gibbs algorithm exhibits fast convergence. The following MCMC procedure can be used to simulate from the posterior distribution in the GSTUR model. The exact expressions for the parameters of the conditional posteriors can be found in the appendix.
Algorithm 1: Posterior Simulator of GSTUR-Implementations of Gibbs and MH Sampling Algorithms

1. Give initial values for 2"; 2; ; ; ; ; 2. Repeat the steps a g during S iterations.

(a) Sample

2 "

from

(b) Sample 2 from

(c) Sample from

2 "

j

y;

;

;

;

;

;

2

, which has density f

1 "

2 j y; ; ; ; ;

;

2 "

, which

has

density f

1

j y;

;

;

;

;

2 "

;

2 , which has density fN

"; " ; ;V

4

(d) Sample from j y; ; ; ; ; 2"; 2 , which has density fN ; V truncated to the stationary region. If satis...es the stationary condition kzjk > 1,
continue to step e. Otherwise draw the whole vector again.

(e) Sample t from p t j y; ; ; ; ; 2"; 2; t using the independent chain MH algorithm, in which a univariate t-density is chosen as the candidate generating density. Note that we use the notation t = ( 1 p; :::; t 1; t+1; :::; T 1; T )0

(f) Sample

from

j y; ; ; ;

;

2 "

;

2, using the density fMN

;V

(g) Sample

from

j y; ; ; ;

;

2 "

;

2, using the density fMN

;V

2.2 Bayesian Model Comparison

The most important aspects in model speci...cation relate to the existence of a deterministic time trend (whether = 0), the time variation in (whether is time-invariant) and the number of lags in the measurement equation (the value of l). The Bayesian approach provides a compelling framework to tackle model uncertainty (e.g. Kass and Ra§rey, 1995) and over-parameterization (e.g. Koop and Potter, 1999). According to Kass and Raftery (1995), the Bayes Factor Bij that compares model Mi and model Mj is expressed as

Bij

=

p (yjMi) p (yjMj)

(2.2)

where p (yjMi) is the marginal likelihood in model Mi. The strength of evidence in favour of model Mi versus Mj can be evaluated following the recommendations of Kass and Ra§rey (1995), which are summarized in Table (2):

Table 2: Bayes factor scale comparing model i with model j

log10Bij Bij

01

13

Evidence against model j Not worth more than a bare mention

13 35

3 20 20 150

Positive Strong

>5

> 150

Very Strong

As the GSTUR model is highly dimensional, the marginal likelihood of the GSTUR model cannot be obtained with a straightforward analytical integration method. In the case where a Gibbs Sampler is already implemented and all the full posterior conditional densities are known, it is possible to approximate the marginal likelihood of each competing model using the posterior draws and the approach introduced by Chib (1995).
The idea of the Chib method starts from the basic `marginal likelihood identity'. The marginal density of y = (y2; :::; yn)0 can be written as:

n
p(y) = p( )t=2p(yt j ) p( j y)

(2.3)

where the numerator is the product of the sampling density and the prior density (including the integrating constant C) and the denominator is the posterior density of . The constant C can be evaluated by simulating from the untruncated prior of , and calculating the

5

proportion of times that the draws verify the stationarity condition (e.g. Judge et al. (1985,

pp.128)). The conditional posterior density of is also subject to truncation and so we

explain how to calculate the corresponding normalizing constant. As the above `marginal

likelihood identity'holds for any , say , the log marginal likelihood can be approximated

as: Xn

ln p(y) / ln p(yt j ; Ft 1) + ln [p( )] ln [p( j y)]

(2.4)

t=2

where p( ) is easily obtained by evaluating the prior densities at 1. For greater accuracy should be a point of high posterior density. In this paper it is chosen to be the posterior
mean. The posterior ordinates ln p( j y) can be obtained using a marginal/conditional decomposition together with the outputs from the original and subsequent `reduced MCMC runs'. Using the marginal/conditional decomposition:

p( ; ;

; h ; ; ; h" j y) / p ( j y) p h j y; j y; ; h p( j y; ; h ; )
p(h" j y; ; h ; ; )p( j y;

;h ;

; ; h") (2.5)

The ...rst term p ( outputs as
p(

j y) in Equation (2.5) can be estimated from the MCMC algorithm

1 PS

j y) '

p(

S s=1

j y; (s); (s); h(s); (s); (s); h("s); (s))

(2.6)

The same calculation is done to obtain p h j y; , but the draws come from a reduced

MCMC run. The reduced MCMC run consists in running again Algorithm 1, but ...xing

to be equal to the posterior mean in every iteration. The other components on the

right hand of Equation (2.5) can be approximated in an analogous manner using draws

from reduced MCMC runs with the appropriate variables ...xed to the corresponding values

in . The normalizing constant p( j y; ; ; h ; ; ; ; h") can be approximated by the number of draws that verify the stationarity restriction.

As shown in appendix B, the method of auxiliary particle ...ltering (APF) (Pitt and Pn
Shephard (1999)) can be adapted to estimate the value of the likelihood ln p(yt j ; Ft 1).
t=2
Thus, the marginal likelihood identity (2.3) allows us to estimate the log marginal likelihood

of the GSTUR model with or without restrictions. We also would like to compare the simpler

linear Random Walk (RW) model with the GSTUR model. The marginal likelihood of the

RW model can be evaluated analytically:

Z

pRW (y) =

p(yj

2" )p(

2" )d

2 "

(2.7)

In the RW model,

2 "

is

the

only

parameter

that

has

to

be

estimated.

If

h"

=

" 2 and the

prior chosen for h" is a Gamma distribution h" s " "; " , the marginal likelihood of

the RW model would depend only on the values of

" and

. For the purpose of model
"

comparison, it is sensible to choose the same prior in competing models for the common

parameters. Thus, the values of

" and

" will be chosen to be the same as those for

2 "

in the GSTUR model (see Table 1).

1 The exact mathematical expression for the prior densities can be found in the Appendix.

6

3 Empirical Illustrations with Generalised STUR
An application to the series of Standard & Poor 500 indices (S&P500) indicates that, once we allow for stochastic unit roots, a deterministic time trend might exists in the S&P500 series. A further application to U.K. /U.S. long-run exchange rate indicates that changes in persistence coincide with monetary events. Finally, using the UK ination series, we demonstrate that the GSTUR captures well the ination dynamics and we assess the outof-sample prediction error.
3.1 Empirical Results with Stock Price
We use the S&P500 annual data set, measured in logarithms, for the period 1877 to 1988. This data set has been previously tested for an exact Unit Root, deterministic time trend and changing persistence (see Nelson and Plosser 1982, Kwiatkowski et al. 1992, Gil-Alana and Robinson 1997). This data set has also been used by Jones and Marriott (1999) to estimate the original Stochastic Unit Root model (the simplest form of the GSTUR in equation 1.4 and 1.5). Here, in addition to estimate the more general GSTUR model, we test hypotheses using posterior probabilities.
3.1.1 Estimation
To ensure that the e§ects of the starting values in the MCMC algorithms are insigni...cant, we take 25; 000 draws after discarding the initial 5; 000. The MCMC convergence diagnostic results from the Numerical Standard Errors (NSE)2 and the Convergence Diagnostic values (CD) show that the number of iterations used is more than su¢ cient. The correlogram (autocorrelation function) plots serial correlations of the draws from the posterior simulator. Fig (1 and 2) indicate that, for all the parameters of interest, there is no signi...cant autocorrelation at lag lengths larger than 15. Thus, the quick decaying autocorrelation indicates quick movements in the sampled draws and fast convergence.

Table 3: Estimates: GSTUR with an Application to SP500

P rior

P osterior

M ean StDev M ean StDev

ln 0:9 0:12

0:1176 0:0678

CD N SE15 M edian 0:1168 0:0031 0:1155

:95HP DI 0:2315 0:0104

2-

- 0:0382 0:0122 0:2324 0:0002 0:0360 0:0227 0:0613

2 "

-

1y

0

- 0:1160 0:0159 0:6118 0:0001 0:1147 0:0926 0:1445
y 0:1079 0:1321 1:2492 0:0008 0:1096 0:109 0:3234 106 0:7649 0:3969 0:2616 0:0035 0:7709 0:107 1:4092

0 106 0:0345 0:0057 0:192 0 0:0346 0:0252 0:0438

10

106 0:2528 0:2109 0:1585 0:0021 0:2516 0:0931 0:6003

y : 1 f N (0; 1) 1 (kzjk > 1) where 1 (A) is the indicator function for the event A : see Table (1) for prior descriptions

The summary statistics of Table (3) reports the estimated results and e¢ ciency diagnostics of the MCMC algorithm. According to the CD value and NSE values, the MCMC algorithm converges for all the parameters of interest. The posterior estimates show that
2 The number of lags used to calculate NSE is 15% of the size of the sample.

7

Figure 1: SP500 with GSTUR: Posterior Draws of

,

2 "

and

2

8

Figure 2: SP500 with GSTUR: Posterior Draws 1, , , and 1 9

ML using SP500 with RW under Different apha&beta

marginal likelihood from RW

50

0

-50

-100 5

45

34

2 1

3
2 1

 00



Figure 3: log Marginal Likelihood of RW with an Application of SP500

parameters are substantially di§erent from zero. A negative and small 2 suggests that the S&P500 series could be a process with Stochastic Unit Roots.

3.1.2 Model Selection

Imposing = 0 or = = 0 a§ects the estimates of stochastic roots signi...cantly. As

pointed out by Koop (1994), restricting the deterministic time trend to be zero forces any

trend behavior to manifest itself stochastically, biasing the tests in favour of stochastic

nonstationarity. Considering the problem of over-parameterization, it is also important to

decide which parameters should be included in a good ...tting model. Table (4) presents

the estimated log marginal likelihood values. For a given value of l (the lag length in the

measurement equation (1.2)), these values do not vary much with p (the lag length in the

transition equation (1.3)). In contrast, log marginal likelihood values vary substantially

with l for a given p. Thus, the lag length in the measurement equation is more important

than the lag length in the transition equation.

To compare the highly parameterized nonlinear GSTUR model with the simple linear RW

model, we calculate the marginal likelihood for the RW model. Because the marginal likeli-

hood from the RW model depends on the values of

" and

in the prior (
"

2 "

"

"; " ),

we choose a range of values of

" and

to calculate the marginal likelihood for a simple
"

prior robust analysis. Both

" and

start from 0:1 to 5 with a step of 0:01.
"

From Fig (3), the log marginal likelihood of a Random Walk model is maximized at

46:2606 with

" = 5 and

= 5. If the values are chosen as
"

" = 1:1 and

= 0:2,
"

which are the same as those in the prior of

2 "

f"

"; " in the GSTUR model, the

log marginal likelihood is 34:413. Given that, as argued above, we choose the same prior

for the common parameter " 2, the Bayes Factors between the RW and the GSTUR model

(with l = 1, =6 0) with a deterministic time trend ( 6= 0) can be calculated as:

BFRW :GST UR

=

p(MRW ) p(MGST UR)

=

exp( exp(

34:413) 0:2384) = 1: 439 3

10 15

According to Table (2), there is very strong evidence in favour of the GSTUR model when

10

compared to the RW model. We may conclude that the sample series has a 99.9% probability of being a stochastic unit root process.
To visualize the changes in persistence over the sample period (t = 1878 1988), the estimated time-varying roots t from the GSTUR model are plotted below the S&P 500 data. The estimates of the roots t vary under di§erent speci...cations of the constant and the deterministic time trend . Fig (4) plots the estimated stochastic roots for the GSTUR (p = 1; l = 1) model with deterministic trend ( =6 0) but no constant ( = 0). Fig (5) plots the same for the unrestricted GSTUR (p = 1; l = 1) model ( =6 0; 6= 0).
Annual Stock Price: SP500
5 4 3 2
1878 1888 1898 1908 1918 1928 1938 1948 1958 1968 1978 1988
t Plot with p=1 l=0   0
1
0.9
0.8
0.7 1878 1888 1898 1908 1918 1928 1938 1948 1958 1968 1978 1988
Figure 4: GSTUR with 6= 0 : Time-Varying Roots of SP500 1878-1988
In Figures (4 and 5) we observe that the roots go above unity occasionally. That is, the roots of the Stock prices series vary around E [exp ( )] in the stationary region for most of the time, but go beyond 1 at certain time points, exhibiting an explosive behaviour. This may explain why Nelson and Plosser (1982), Kwiatkowski et al. (1992) all ...nd signi...cant evidence in favor of a Unit Root in the S&P 500 series.
3.2 Empirical Results with Long-run Real Exchange Rate
Another empirical application for the GSTUR model is to analyze the real exchange rates. We use the monthly U.K./U.S. real exchange rates from January 1885 to February 1995, with a sample size of 1; 322 over a 111-year period. This data has been analyzed by Engel and Kim (1999) with a state space model. They applied an Augmented Dickey-Fuller (ADF) test and rejected the unit root at the 5 percent level.
In this section, a restricted GSTUR model ( = = 0, p = 1 and l = 1) is used. The algorithm uses 25; 000 iterations with the ...rst 5; 000 discarded. The e¢ ciency of the
11

Annual Stock Price: SP500
5 4 3 2
1878 1888 1898 1908 1918 1928 1938 1948 1958 1968 1978 1988
t Plot with p=1 l=0   0 and   0
1
0.9
0.8
0.7 1878 1888 1898 1908 1918 1928 1938 1948 1958 1968 1978 1988
Figure 5: GSTUR with 6= 0 6= 0 : Time-Varying Roots of SP500 1878-1988
algorithm can be assessed with the CD and NSE values. Table (5) reports the estimated results and diagnostics of the MCMC.
Figure (6) plots the U.K./U.S. real exchange rates, nominal exchange rates and estimated roots over the 111 year span. The range of the stochastic unit roots is narrow (from 0:98 1:015), and the variance of the stochastic unit roots is small. For most of the time the roots are below one, which indicates the series is stationary. However, at certain time points the roots jump to or above one. These points are marked with u, and indicate nonstationary and/or explosive behaviors. Engel and Kim (1999) provide a description of the historical monetary events within the 111-year span and Figure 6 marks these events with vertical bars. Note that there is a correlation between the historical events and the u marks.
3.3 Empirical Results with UK ination
The third empirical application with the GSTUR model is to analyze the quarterly U.K. ination series. Figure (7) plots the Quarterly UK RPI Ination series from 1957 Q1 to 2007 Q1. The UK experienced very high ination in the 1970's and 1980's. The ination rates were controlled to vary within a small range after the introduction of `ination targeting' in the 1990s. The ...rst three fourths of samples and the last quarter of samples in the data series behave quite di§erently in terms of the mean and variance.
Figure (8) plots the estimated stochastic roots by ...tting the ination data series with a GSTUR model without a constant or trend, with a lag length selected at 7. The + sign on Figure (8) marks the points at which the roots jump above one. The pattern of the stochastic roots before 1993 looks very di§erent from that after 1993. Before 1993 the
12

UK/US Norminal Exchange Rates with Monetary Events 5.5 5 4.5 4 3.5 3 2.5 2 1.5 1
85 00 95 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95
UK/US log Real Exchange Rate with Roots Above 1 4.4 3.9 3.4 2.9 2.4 1.9
85 90 95 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95
Estimated Stochastic Unit Roots with Monetary Events 1.015 1.01 1.005 1 0.995 0.99 0.985 0.98
85 90 95 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95
Figure 6: U.K./U.S. Long Run Exchange Rates and Estimated Stochastic Unit Roots
13

Figure 7: Plot of UK ination series: 1957 Q1- 2007 Q1
stochastic roots jump above 1 frequently. However, the roots stayed below unity after 1993. The result from estimating a GSTUR model with UK ination data provides good evidence of a changing persistence in the ination underlying process, which is consistent with the ...ndings of Watson and Stock (2007): "the variance of permanent disturbances to ination has changed considerably over time". Also, on the plot of the estimated roots a clear break in 1991 can be observed.
In the out-of-sample forecasting exercise we will compare the GSTUR model with linear models (i.e. AR and RW models). We will obtain one-step-ahead forecasts for the period 2004 Q4 to 2007 Q1. In the ...rst exercise we will calibrate the models using observations from 1957Q1. In the second we will use only observations after the independence of the Bank of England, which is the period when ination dynamics are simpler and could potentially be captured by a linear stationary model (e.g. AR model).
We also construct density forecast for each model. The density forecasts are represented graphically as a set of prediction intervals covering 10, 20,..., 90 percent of the probability distribution, with lighter shades for the outer bands. They are constructed in such a way that the boundaries of the intervals are the 5th, 10th,...,95th percentiles. Note that intervals are not always symmetric around the mode, which is represented with the darkest blue. With multiple-step ahead forecasts, the forecast intervals "fan out" as the forecast horizon increases. Since we focus only on one-step ahead forecasts, there are no fan out e§ects.
3.3.1 Full sample
We present the descriptive statistics of the forecast distributions in tables, which include the mean, mode, median, variance and 95% percentile of the forecast distributions. The marginal likelihood of each model is calculated conditional on the observations before the forecast. With lag length ...xed at 7, Tables 6, 7,8 and 9 show the forecasts and marginal likelihood values for the GSTUR model subject to alternative restrictions on the constant and trend. Table (10) shows the same for the RW model.
Table (11) presents the MSFE for all entertained models with di§erent speci...cations. The GSTUR model with lag length 7 and a constant with no trend receives the highest marginal likelihood and provides the best point forecast in terms of MSFE. It is signi...cant
14

UK inflation Rates 35 30 25 15 10
5 0 1958 63 68 73 78 83 88 93 98 2003

1.02 1.01
1 0.99 0.98 0.97 0.96 0.95
1958

Estimated Stochastic Unit Roots from GSnoCT lag=7 63 68 73 78 83 88 93 98 2003

Figure 8: Simulated Roots Using the GSTUR model with No Constant or Trend with lag length at 7

that almost all speci...cations for the GSTUR model have substantially lower MFSFE than the RW model.
Figures 9.a, 9.b and 9.c show the density forecast plots for 3 models3: GSTUR with constant and lag length of 7, GSTUR with trend and lag length of 7, and RW model. From Figure 9.a and Figure 9.b, a GSTUR model with trend generates larger forecast variances than a model with a constant. From the forecast results, the GSTUR with a constant and trend does not improve forecast accuracy over two of the restricted GSTUR models (i.e. without constant or without trend). Moreover, the forecast variances from the GSTUR models with constant and trend are 3 times larger than those from the GSTUR model with only a constant. Thus, forecast variance and Mean Square Forecast Error (MSFE) values point in the same direction as the marginal likelihood values. Therefore, the posterior model probability of the unrestricted GSTUR model will be low and it might be better to exclude it from the forecasting averaging in this case.
3 Density forecasts for other models are in the Appendix.

15

Density Plot Using the Full Sample: GSTUR p=1 l=7 with Cons 7

6

5

4

3

2

1

0 -1 04Q3

Density Forecast Mode Realized Value
Q4 05Q1 05Q2 05Q3 05Q4 06Q1 06Q2 06Q3 06Q4 07Q1

Fig 9.a GSTUR p=1 l=7 with Cons

Density Plot Using the Full Sample: GSTUR p=1 l=7 with Trend 8

7

6

5

4

3

2

1

0

-1 -2 04Q3

Density Forecast Mode Realized Value
Q4 05Q1 05Q2 05Q3 05Q4 06Q1 06Q2 06Q3 06Q4 07Q1

Fig 9.b GSTUR p=1 l=7 with Trend

Density Plot Using the Full Sample: RW model 7
Density Forecast Mode 6 Realized Value
5
4
3
2
1
0 04Q3 Q4 05Q1 05Q2 05Q3 05Q4 06Q1 06Q2 06Q3 06Q4 07Q1
Fig 9.c RW model

16

3.3.2 Small sample We carry out exactly the same exercise as in Section 3.3.1 but using only observations from 1999Q4. For example, to forecast ination in 2004 Q4 we estimate the models using the period (1999 Q4 - 2004 Q3), which is a sample size of 20. The one-step ahead forecasting is carried out repeatedly 10 times with a rolling window to achieve 10 forecasts for the period 2004 Q4 to 2007Q1.
Tables (12) and (13) provide descriptive statistics of the forecast distributions using the GSTUR without a constant or trend at lag 4, and the RW model. Figures 10.a, and 10.b plot the forecast densities for the GSTUR without constant or trend at lag 5, and the RW model.
Density Plot Using the Small Sample: GSTUR p=1 l=5 with NO Cons or Trend 10
Density Forecast Mode Realized Value 8
6
4
2
0
-2 04Q3 Q4 05Q1 05Q2 05Q3 05Q4 06Q1 06Q2 06Q3 06Q4 07Q1
Figure 10.a: Small Sample with GSTUR no CT, lag=5
Density Plot Using the Small Sample: RW model 5 4.5 4 3.5 3 2.5 2 1.5 1
Density Forecast Mode 0.5 Realized Value
0 04Q3 Q4 05Q1 05Q2 05Q3 05Q4 06Q1 06Q2 06Q3 06Q4 07Q1
Figure 10.b: Small sample RW
According to the MSFE value in Table (14), a GSTUR without a constant or trend and 4 lags provides the best point forecasts. Thus, although the data series exhibit simple dynamics that could potentially be well capured by a linear model, the nonlinear GSTUR model still provides better point forecasts than a RW model or a stationary AR(5) model.
17

This indicates that the GSTUR model could capture the underlying dynamics of ination not only when the data exhibits nonlinear dynamics, but also when the data dynamics are linear. However, using the small sample as opposed to the full sample does not improve on the point forecast accuracy of the GSTUR model (see Tables (11) and (14)), but it does improve the performance of the RW model.
If we look into Figure 10.a and Table (12), the variance of the forecast distribution is very large in the ...rst 2-3 forecast periods. The big variances indicate big forecast uncertainties. However, after the size of sample increases slightly, the forecasting variances decrease. Thus, the big forecast uncertainty may be due to the small size of the sample. Compared to results in Table (9), where the same model speci...cation was applied to a larger sample, the forecast variances are much larger.
Therefore, the GSTUR outperforms the RW model in both the full sample and short sample case. In the case of forecasting using the GSTUR model, it seems better to estimate the model using a large sample even if it contains a structural break. That is, using a small but more homogeneous sample might result in big forecasting uncertainties and errors.
4 Conclusions
The GSTUR is a exible nonlinear model which can sucessfully capture the properties of some macroeconomic time series. It allows for changes in persistence and therefore can provide a better understanding on the sources of macroeconomic uctuations as well as help to identify structural breaks. In this paper we have developed an MCMC algorithm for Bayesian parameter estimation and model comparison4 and found that these computational methods worked satisfactorily when applied to real data. In particular the methods can be used to assess the evidence in favour of a deterministic trend, which is important for forecasting purposes.
This paper revisits the dispute concerning the existence of a deterministic time trend in the S&P 500 series, which is part of the extended Nelson and Plosser's data set. An analysis using the GSTUR model suggests that the persistence has shifted over time. Among the competing models, the GSTUR with a deterministic time trend has the highest marginal likelihood, which indicates a support for the deterministic time trend. Therefore, excluding the possibility of a deterministic trend may provide misleading inference. We propose that the underlying process of the S&P 500 series should be modelled with a more realistic approach, such as a combination of a deterministic time trend and a time varying persistence with roots varying stochastically.
A simple analysis of the monthly U.K./U.S. long run real exchange rates over the 111-year span suggests that a GSTUR model may help to resolve the PPP puzzle. The estimated time varying stochastic roots of the series suggest that important monetary events are connected to the shifts in the persistence of the real exchange rates.
Lastly, using UK ination data the GSTUR class models are better in providing out-ofsample forecasts than the RW model. Using di§erent sample sizes and periods to calibrate the model, the GSTUR model outperforms the RW model in terms of out-of-sample forecasting accuracy. Hence, the nonlinear GSTUR models are not only resilient to shifts or shocks in the economic system, but are also able to capture the dynamics in the underlying process of ination. In this sense, we propose modelling the ination dynamics using
4 The Matlab code for estimation, model comparison, MCMC diagnosis, likelihood evaluation and estimation of is available from the authors upon request.
18

a GSTUR process as it may be able to accommodate breaks in persistence and provide accurate forecasts.

A Prior and Posterior Densities

According to the elicited priors, prior densities are expressed as follows

11

p

j ;V

= (2 V

)1=2 exp

( 2V

)2

where

p( j

;V

)

=

jV (2

j 1=2 )l=2

exp

= ( 1; ; l)0.

1 2

0
V

1

p( j

;V

)

=

jV (2

j 1=2 )2=2

exp

1 2

(

p( i j

1

;V ) = i i C 2V

1=2 exp

i

0
V
1 2V
i

1 i

)
2
i

where i : i = 1; ; p jointly satisfy the stationary condition and the normalizing constant of prior p( ) over the restricted region is C.

p h" j

"; "

=

1 "(
"

") h" "

1 exp

phj ; =

1 h 1 exp

! h"
"
! h

0

For the values of

;V ;

;V ;

;V ;

;V
i

;
i

";

;
"

;

, refer to Table (1).

The data series is denoted as y = (y1 l; ; y1; ; yn)0 with a sample size of T = n + l,

where the ...rst l + 1 values (y1 l; ; y1)0 are treated as the starting values and the initial

values of is denoted as initial = ( 2 p; :::; 1)0, in which all elements equal to 0. We also

denote t = ( 2 p; :::; t 1; t+1; :::; n 1; n)0.The joint density of the is given by the

sequence of conditionals as

Qn p ( j ) = p ( tj t; )

t=2

Since

= 1

0
Pp
i i=1

19

t= t =t = (t

Pp 0+ i t i
i=1

Pp Pp

1

i+

i ti

i=1 i=1

Pp ) i( t i
i=1

)

As we assume t s fN 0; 2 , then we have

(

p( t j

t; ) = q 1 exp 22

1 22

(t

Pp ) i( t i
i=1

)
2
)

and p( j

Qn

t; ) =

p ( tj t; )

t=2 (

1 / n 1 exp
2 22

1 Pn 2 2 t=2 ( t

Pp ) i( t i
i=1

)
2
) (a.1)

Given the likelihood function of p (yj ; )

p (yj ; ) = (2

8

1
n1
2") 2

>>>>>>><> exp :>>>>>>>>

0 @BBBB

yt t

1 Pn

2

2
" t=2

Pl

exp( t)yt 1

i 4 yt i

i=1

[1 exp( t)]

Pl

exp( t)t + exp( t)

i

i=1

9 12 >>>>>>>>= CCCCA >>>>>>>>;

(a.2)

The posterior is proportional to the product of prior and likelihood. With the speci...ed priors p ( ) = p ; ; ; ; ; 2"; 2 and via the Bayes Theorem, the joint posterior density for ( ; ) is then

Qn

p ( ; j y) /

p (yt j ; ; Ft 1) p ( ; )

t=2

Qn Qn / p ( tj t; ) p ( ) p (yt j ; ; Ft 1)

t=2
(2

8 t=2

1 <>>>>>>>>

n1
2") 2

exp >>>>>>>:>

0 BBBB@

yt t

1 Pn

2

2
" t=2

Pl

exp( t)yt 1

i 4 yt i

i=1

[1 exp( t)]

Pl

exp( t)t + exp( t)

i

9 12 >>>>>>>>= ACCCC >>>>>>>>;

(

1 n 1 exp
2 22

1 Pn

2

2 t=2

(

t

i=1
Pp ) i( t i
i=1

)
2
) (a.3)

20

Then, we are able to develop the full conditional densities for the parameters of interest.

1. If we denote h" =

1
2

,

and

"

where

V

b

:= ( ; ), the posterior conditionals
= V 1h" 1 + X0X 1 h" 1 = V 1 + X0Xh" 1 = V V 1h" 1 + X0X b = (X0X) 1 X0Y

fN ; V ,

From (1.1), (1.3) and (1.2), the regression of are with the following equation

yt exp( t)yt 1 = [1 exp( t)] +

Pl i 4 yt i
i=1
t exp( t)t + exp( t)

Pl i + "t
i=1

If we take left hand side of (a.4) as Y

(a.4)

Y = yt exp( t)yt 1 and the right hand side of (a.4) as X

Pl i 4 yt i
i=1

Pl

X = 1 exp( t); t exp( t)t + exp( t)

i

i=1

where t = 2; tion

; n, Regression Equation (a.4) became a simple linear regression equaY = X + "t

The posterior of follows a normal distribution fN ; V . See Koop (2003 pp.3637) for details.

2. The posterior conditionals fMN ; V . The derivation of posterior conditionals is similar to that of where
V = V 1h" 1 + X 0X 1 h" 1 = V 1 + X 0X h" 1
= V V 1h" 1 + X 0X b
b = (X 0X ) 1 X 0Y

The regression of is with the following equation:
Pl (yt t) exp( t) [yt 1 t + ] = i (4yt i
i=1

) + "t

21

(a.5)

if we denote

Y = (yt

t) exp( t) [yt 1

t+ ]

where t = 2;

X = (4yt 1 ; ; n, Equation (a.5) became

; 4yt i

)

Y = X + "t

Then, we have posterior of follows a multivariate normal distribution fMN ; V , where and V can be obtained straight forward.

3. The posterior conditionals of error precision h" s f " "; " . According to the prior density of h"

n1

p(h"

j

y) /

h" 2 2 n1
2

exp

h" (Y

X

0
) (Y

2

("

/

hn
"

2

1

+

"

1 exp

11

h"

+ (Y X 2

"

/ h" " 1 exp

h"
"

X

)

1

"
"

( ") h" " #)

1 exp

0
) (Y X )

! h"
"

"=

n1 "+ 2

1 "

=

11 + 2 (Y

X

0
) (Y

X

)

"

4. The posterior conditionals of

fN ; V

To calculate the posterior of , collect all the parameters together

p( j ; ;h ) 8 >< h Pn
/ exp :> 2 t=2 ( t

80

/

<>>> exp >>>:

h 2

@BBB

2

Pp

2

2

9 =>

) i( t i
i=1

)

2 V >;

" 2 Pn
t=2

1

Pp
i i=1

Pn Pp

t iti t=2 i=1

2

+

h

1 V

#

Pp 1 i +h V
i=1

19 CACC>>>>=>;>

thus variance:

1=h

V

= Pn (1

Pp
i=1

i)2 + 1=h V

t=2

22

From the joint posterior density function, it is easy to get the full conditional density of , which is with a mean of

Pp Pn

Pp

1i

t iti +

=

i=1 t=2
Pn

i=1
Pp 2

1 i + 1=h V

t=2 i=1

=h V

5. The posterior conditionals of i

As the chosen prior for i is fN

; V and
ii

=

1;

; p 0 are jointly to meet

the stationary condition, it is straight forward to derive the posterior conditionals for i :

i = 1;

; p i fN

; V , with mean
ii

"

Pn Pp

(tj

) (t

)

k( t k

t=2
=
i

2 =V

k=6 j

Pn

+(
1 t=2

t

j

)2

# 2
)+V 1 1

and variance

V= i

2

Pn

2 =V

+(
i t=2

t

j

)2

The derivation for 1 are as follows:

8

<> 1 Pn

p( 1

j

y) / exp :>

2

2 t=2

(

t

Pp ) i( t i
i=1

2 1 Pp )
2 i=1

8 <> 1 Pn / exp >: 2 2 t=2 ( t

Pp ) k( t k
k=2

) 1( t 1

82

/

>>< exp >>:

1 22

664

22 1V

+

1

Pn

21 (t1

t=2

2 1

Pn

(

t

1

t=2

)(t

2
)2 2 1 V 1 1
Pp ) k( t k
k=2

i

2

9 >=

i

V i

;>

21

2

9 >=

)

1

2V 1

;>

39 ) 577=>>;>>

Then we can have the variance

and the mean

V= 1

2

Pn

2 =V

+(
1 t=2

t

1

)2

Pn (t1
t=2
=
1

" ) (t

Pp ) k( t k
k6=1

Pn

2 =V

+(
1 t=2

t

1

)2

# 2
)+V 1 1

23

The derivations are all the same for i = 1; 6. The posterior conditionals for h

; p.

p (h j ;

;) /

1 h 1 exp

( exp

h Pn 2 t=2 ( t
(

/ h + n2 1 1 exp

h

/h

() 1 exp h

! n1 h h2
n1
(2 ) 2

Pp ) i( t i
i=1

1 1 Pn

+ 2 t=2

(

t

)
2
)
Pp ) i( t i
i=1

!)
2
)

= 1=

+n 1 1 2

1 1 Pn

+ 2 t=2

(

t

Pp ) i( t i
i=1

2
)

7. The remaining conditionals that are needed for the t are described as follows:

The conditional densities for t are nonstandard and given by the following expression

p t j ; ; 2"; 2; ; ; ; t; y

20

Pl 12

/

exp 6664

2 t
2

1 2 "

@BBBe

t

t

i4
i=1
t1

t i CACC

# ( t) 22

3

t

( t) # ( t)

27757

where t = yt

t

and # ( ) is a function of i

( t) is a function of ; i;

t; p and t

Derivations are as follows:

p( t j ;

(

t; y) / exp

1

2

2 "

) Pl 2 t i4 t i e t t 1
i=1

( exp

1 Pn

2

2 t=2

(

t

A)

Pp 2

)

i( t i

)

i=1

B

24

Next, we can rearrange it to make it looks nicer, rearrange into the form in Marriott's paper

A/

0

2 t
2

1 2 "

B@BBe

t

Pl 12

t

i4
i=1
t1

t i ACCC

when p = 1

1 Pn

B/

2

2 [(
t=2

t

For t from 2 to n 1

) 1( t 1

)]2

B / [( t

)

/

2 t

1+

2 1

1 ( ht 1 2 t (1

)]2 + [( t+1

) 1 (i t

1)2 + 1 ( t 1 + t+1)

/ t2# ( t) 2 t ( t)

)]2 +

where and For t = n

#(

t) = 1 +

2 1

( t) = (1 1)2 + 1 ( t 1 + t+1)

B / [( t

) 1( t 1

/ 2t # ( t) 2 t ( t)

)]2

where

# ( t) = 1

and ( t) = 1 t 1 + (1 1)

When p 2, the whole derivation procedure is the same and we summarize it in Tables 15 and 16, which are also available in Jones and Marriott (1999)
Since part B can be approximated using a t-density, we used Independent Chain M-H algorithm to sample t. To generate draws with high acceptance probabilities, the selected candidate generating density should have tails at least as fat as that of the posterior. We have chosen the degree of freedom as = 1 in the t-density, which allows the t-density to have very fat tails.

B EVALUATION OF THE LIKELIHOOD

According to Equation (1.4), yt is a function of latent variable

evolves calculation of

Z

p (yt j ; Ft 1) = p(yt; t j ; Ft 1)d t Z

= p (yt j t; ; Ft 1) p ( t j

t, thus ln p(yt j ; Ft 1) d t

; Ft 1) (b.1)

25

As t is non-observable, the exact integrals are hard to obtain. However, with the help of

Monte Carlo averaging p (yt j

t;

; Ft 1) over the large sample of draws of

1t ; :::;

M t

from

p ( t j ; Ft 1), we could have an approximation of p (yt j ; Ft 1) from the following:

p (yt j

1 XM ; Ft 1) ' M p

yt j

(tg);

g=1

; Ft 1

(b.2)

However, a sample of size M

(

1 t

;

;

M t

)

from

p(

tj

sample (

1 t

1;

;

M t

1)

from

p

(

t

1j

; Ft 1) as

Z

; Ft 1) can be obtained using a

p ( t j ; Ft 1) = p ( t j t 1; ; Ft 1) p ( t 1 j ; Ft 1) d t 1

(b.3)

An Auxiliary Particle Filter (APF) method introduced in Pitt and Shephard (1999) is

applied here to get samples from p ( t 1 j ; Ft 1).

The algorithm to evaluate the likelihood can be described as:

Algorithm: Estimate the log Likelihood for the marginal likelihood using

Auxiliary Particle Filter

First, at time t, we call the lags of t as t = ( t 1; ; t p)0. The lags of 2 denoted

as

(g) 2

:

g

=

1;

; M , which are the initial values that can be either set as a M p zeros

matrix or a sample of M

draws (

(1) 2

;

;

(M 2

)

)0

from

the

conditional

prior

p(

2j

). In

our empirical application,

(g) 2

:

g

=

1;

; M is set as a M p zeros matrix and M is set

as 3; 000.

1. t starts from 2.

(a) For each

(g) t

,

g

=

1;

; M , sample a value

4(g) t

using

the

transition

density:

4(g) t

fN (

(g) t

;

2)

Note that

4(g) t

is

a

draw

from

p(

tj

;

t).

(b) An estimate of the likelihood ordinate p(ytj ; Ft 1) is given by:

p^(ytj

1 XM ; Ft 1) = M p(ytj

;

4(g) t

;

F

t

1)

g=1

(b.4)

2. For each g = 1;

;M

de...ne

^

g t

=

E(

g t

j

g t

)

=

g t

and calculate:

wg

=

p(yt

j

^

g t

;

; Ft 1)

g

=

PMwg
j=1

wj

g are the ...rst-stage weights. Get R draws (k1; ; kR) from the discrete distribution de...ned on the integers (1; ; M ) with probabilities 1; ; M , where R is set as larg as 5M . This step is to get R samples from the importance function g ( t; k j ; Ft) by simulating the index with probability g. Note that each value of kr is used to

26

indicate a value of

(kr ) t

(and

of

^

kr t

)

and

kr .

Explicitly,

step

2

is

using

the

importance

function g ( )

g ( t; k j

; Ft)

/

p

yt

j

E

k
t

j

;
t

; Ft 1 p

tj

;

k t

k

k = 1; ; M

to get a sample of R draws.

3. For each

(kr t

)

,

r

=

1;

with

; R, draw a scalar t (r) using the transition density p( tj ; t)

(r) t

fN (

kr t

;

2)

(b.5)

Note that

(r) t

:

r

=

1;

; R and (kr : r = 1;

density g( t; krj ; Ft; t)

; R) is a sample from the joint

4. Resample the R 1 vector ...ned as:

(r) t

:

r

=

1;

0
; R M times with probabilities r de-

wr

=

p(ytj p(ytj

; Ft 1; t r)

; Ft

1;

^

kr t

)

r

=

PMwr
r=1

wr

(b.6)

r is the second-stage weights. Then, the resampled M 1 vector, which contains val-

ues (

(1) t

;

;

(M t

)

)0

is

(approximately)

distributed

as

p(

tj

; Ft;

t). These second-

stage weights are associated with the conditional likelihood by the importance function

g ( ). Stacking this sampled ( (t1);

;

(M t

))0

on

(g) t

:

g

=

1;

; M . We have the

updated lags of

g t+1

=

t(g);

(g) t1

;

;

(g) t (p 1)

: g = 1;

;M

5. Fix t = t + 1 go to step 1(a) to get

4(g) t+1

from

g t+1

in

step

4.

Note that

4(g) t+1

are samples from p( t4+(1g)j

; Ft;

g t+1

)

and

following

1(b)

to

get

p^(yt+1j

; Ft)5 , until

t = n.

6. Finally, the estimate of the log likelihood is

XN log pb(y j ) = log pb(yt j ; Ft 1)
t=2

5 An estimate of p(yt+1j ; Ft) is given by:

p^(yt+1j

1 XM

; Ft) =

M

p(yt+1 j
g=1

; Ft; 4t+(1g))

(b.7)

27

References
[1] Busetti, F and A. M. R. Taylor. (2004): "Tests of Stationarity Against a Change in Persistence", Journal of Econometrics, 123, 33-66.
[2] Caner, M and B. E. Hansen. (2001): "Threshold Autoregression with a Unit Root", Econometrica, 69, 1555-1596.
[3] Carlin, B P. and S, Chib. (1995): "Bayesian Model Choice Via Markov Chain Monte Carlo Methods", Journal of the Royal Statistical Society.Series B (Methodological), 57, 473-484.
[4] Chib, S. (1995): "Marginal Likelihood from the Gibbs Output", Journal of the American Statistical Association, 90, 1313-1321.
[5] Devroye, L. (1986): Non-Uniform Random Variants Generation, Springer-Verlag.
[6] Engel, C. and C-J. Kim. (1999): "The Long-Run U.S. /U.K. Real Exchange Rate", Journal of Money Credit Bank, 31, 335-356.
[7] Geweke, J (1989): "Bayesian Inference in Econometric Models using Monte Carlo Integration", Econometrica, 57, 1317-1339.
[8] Gil-Alana, L.A. and P.M.Robinson. (1997): "Testing of Unit Root and Other Nonstationary Hypotheses in Macroeconomic Time Series", Journal of Econometrics, 80, 241-268.
[9] Granger, C. W. J. and N. R. Swanson. (1997): "An Introduction to Stochastic UnitRoot Processes", Journal of Econometrics, 80, 35-62.
[10] Harvey, D I.; S. J. Leybourne and A. M. R. Taylor. (2006): "Modi...ed Tests for a Change in Persistence", Journal of Econometrics, 134, 441-469.
[11] Jones, C. R. and M. J. Marriott. (1999): "A Bayesian Analysis of Stochastic Unit Root Models", Bayesian Statistics, 6, 785-794.
[12] Judge, G. G. (1985): The Theory and Practice of Econometrics, Wiely.
[13] Kapetanios, G; Y. Shin and A. Snell. (2003): "Testing for a Unit Root in the Nonlinear STAR Framework", Journal of Econometrics, 112, 359-379.
[14] Kass, R. E. and A. E. Raftery. (1995): "Bayes Factors", Journal of the American Statistical Association, 90, 773-795.
[15] Kim, J.Y. (2000): "Detection of Change in Persistence of a Linear Time Series", Journal of Econometrics, 95, 97-116.
[16] ≠, and R. B. Amador. (2002/8): "Corrigendum to Detection of Change in Persistence of a Linear Time Series", Journal of Econometrics, 109, 389-392.
[17] Koop, G. (1994/7): "An Objective Bayesian Analysis of Common Stochastic Trends in International Stock Prices and Exchange Rates", Journal of Empirical Finance, 1, 343-364.
28

[18] ≠, E. Ley; J. Osiewalski and M. F. J. Steel. (1997/0): "Bayesian Analysis of Long Memory and Persistence using ARFIMA Models", Journal of Econometrics, 76, 149169.
[19] ≠, and S. M. Potter. (1999/2): "Bayes Factors and Nonlinearity: Evidence from Economic Time Series", Journal of Econometrics, 88, 251-281.
[20] ≠, (2003): Bayesian Econometrics, Wiely. [21] Kwiatkowski, D.; P. C. B. Phillips; P. Schmidt and Y. Shin. (1992): "Testing the
Null Hypothesis of Stationary Against the Alternative of a Unit Root", Journal of Econometrics, 54, 159-178. [22] Nelson, C. R. and C. I. Plosser. (1982): "Trends and Random Walks in Macroeconomic Time Series", Journal of Monetary Economics, 10, 139-162. [23] Newbold, P.; S. Leybourne and M. E. Wohar. (2001/0): "Trend-Stationarity, Di§erence-Stationarity, Or neither: Further Diagnostic Tests with an Application to U.S. Real GNP, 1875-1993", Journal of Economics and Business, 53, 85-102. [24] Pitt, M. K. and N. Shephard. (1999): "Filtering Via Simulation: Auxiliary Particle Filters", Journal of the American Statistical Association, 94, 590-599. [25] van Dijk, D.; Tervirta T. and P. H. Franses. (2002): "Smooth Transition Autoregressive Models -- A Survey of Recent Developments", Econometric Reviews, 21, 1-47. [26] Watson, M. and J.H. Stock. (2007/1): "Why has ination become harder to forecast?", Journal of Money Credit and Banking, 39, 3-33.
29

Table 4: log Marginal Likelihood with a GSTUR class of Models

6= 0; =6 0 6= 0; = 0 = 0; 6= 0 = = 0

(a) p = 3

l = 0 -25.1406

-27.935

-4.7795

-66.5449

l = 1 -29.1619

-31.2879

-8.9852

-75.0414

l = 2 -36.9802

-39.3019

-16.77

-82.308

l = 3 -45.9399

-47.1458

-24.9254

-91.1269

(b) p = 2

l = 0 -23.9927

-26.4499

-2.7145

-62.7711

l = 1 -28.3142

-30.2792

-7.3366

-71.3285

l = 2 -35.5217

-37.6665

-14.7954

-79.0727

l = 3 -44.2955

-45.3416

-22.3381

-87.3335

(c) p = 1

l = 0 -21.6808

-23.4512

-0.2384

-58.3054

l = 1 -26.0272

-27.51

-4.6843

-66.8312

l = 2 -33.4339

-34.7273

-11.6567

-74.8015

l = 3 -41.5651

-42.8262

-20.1654

-83.4481

Table 5: Estimates: GSTUR with U.K./U.S.Real Exchange Rates

P rior

P osterior

M ean St:Dev M ean St:Dev CD N SE:15 M edian 95%P osterior Band

ln 0:9 0:12

0:0211 0:0510 0:0204 0:0006 0:0090 0:1330 0:0276

2 0:0002 0:0002 0:1093 0:0000 0:0001 0:0000 0:0006

2 "

0:0507 0:0020 0:2337 0:0000 0:0506 0:0475 0:0540

1y 10

y 0:4375 0:4855 0:3223 0:0112 0:5488 0:5100 0:9812 106 0:9461 0:0555 1:0901 0:0018 0:9553 0:8416 1:0204

y : 1 f N (0; 1) 1 (kzjk > 1) where 1 (A) is the indicator function for the event A : see Table (1) for description

Table 6: Full Sample: Forecast of Ination Rates with GSTUR p=1 lag=7, with Cons but

no trend

Density forecast

95% percentile

TrueV mean mode median var

2.5% 97.5% ML

04Q4 3.41 3.4473 3.4641 3.4678 2.3629 0.3503 6.4170 -352.3575

05Q1 3.17 3.6497 3.4105 3.6404 2.3106 0.6555 6.5878 -353.0102

05Q2 3.01 3.0566 2.9506 3.0788 2.3005 0.0463 6.0156 -354.2753

05Q3 2.77 2.8924 3.1352 2.9094 2.2411 -0.1031 5.8153 -354.7319

05Q4 2.38 2.7027 2.6055 2.7053 2.2093 -0.2603 5.6205 -355.5625

06Q1 2.39 2.4528 2.1412 2.4615 2.3062 -0.5945 5.3539 -355.3517

06Q2 2.93 2.5122 2.4391 2.5308 2.2691 -0.4665 5.4442 -356.4967

06Q3 3.44 3.2976 3.4792 3.3287 2.2441 0.3076 6.1903 -357.4588

06Q4 3.99 3.8949 3.8879 3.8882 2.2007 1.0022 6.8075 -358.1957

07Q1 4.55 4.2758 4.1319 4.2646 2.1512 1.4102 7.1587 -359.5171

30

Table 7: Full Sample:Forecast of Ination Rates GSTUR p=1 lag=7, with Trend but no

constant

Density forecast

95% percentile

TrueV mean mode median var

2.5% 97.5% ML

04Q4 3.41 3.4579 3.7104 3.4859 5.0357 -0.9718 7.8211 -353.1912

05Q1 3.17 3.6604 4.3045 3.6745 4.8655 -0.7848 7.9603 -353.3196

05Q2 3.01 3.0333 3.0516 3.0747 4.8347 -1.3921 7.3122 -354.7268

05Q3 2.77 2.9140 2.3840 2.9129 4.9697 -1.4481 7.2283 -355.2979

05Q4 2.38 2.6934 2.1711 2.7160 4.8236 -1.7071 6.9173 -355.7200

06Q1 2.39 2.4618 3.2145 2.5098 4.7927 -1.9426 6.7368 -357.0372

06Q2 2.93 2.4877 2.2645 2.5214 4.8843 -1.9635 6.7197 -356.9981

06Q3 3.44 3.3093 3.3314 3.3162 4.7115 -0.8873 7.4957 -358.2469

06Q4 3.99 3.9386 4.2814 3.9692 4.6509 -0.3474 8.1169 -359.1952

07Q1 4.55 4.2630 4.1427 4.2527 4.6849 -0.0208 8.5130 -359.5879

Table 8: Full Sample:Forecast of Ination Rates GSTUR p=1 lag=7, with Cons and Trend

Density forecast

95% percentile

TrueV mean mode median var

2.5% 97.5% ML

04Q4 3.41 3.3710 3.0160 3.3726 5.1045 -1.0801 7.7927 -371.5125

05Q1 3.17 3.5712 3.3444 3.5603 4.8717 -0.7559 7.9076 -371.6482

05Q2 3.01 2.9770 2.9319 2.9936 5.0968 -1.5731 7.3929 -373.0897

05Q3 2.77 2.8352 2.6938 2.8375 4.8633 -1.5448 7.2819 -373.7779

05Q4 2.38 2.6127 2.7139 2.6177 4.8633 -1.7980 6.9545 -374.3405

06Q1 2.39 2.3813 2.6158 2.3939 4.8722 -1.9687 6.8146 -375.0120

06Q2 2.93 2.4049 2.5049 2.4214 4.6854 -1.8906 6.6591 -376.3249

06Q3 3.44 3.2422 3.1517 3.2371 4.6031 -0.9151 7.4469 -376.6760

06Q4 3.99 3.8293 3.2524 3.8079 4.7046 -0.4466 8.1211 -377.4532

07Q1 4.55 4.1903 3.7276 4.1493 4.8626 -0.1740 8.5739 -377.6779

Table 9: Full Sample:Forecast of Ination Rates GSTUR p=1 lag=7, with no constant and

no trend

Density forecast

95% percentile

TrueV mean mode median var

2.5% 97.5% ML

04Q4 3.41 3.3019 3.2785 3.2873 1.3394 1.0434 5.6003 -371.6062

05Q1 3.17 3.5136 3.4988 3.5027 1.3256 1.2888 5.7846 -372.8042

05Q2 3.01 2.9127 2.9394 2.9143 1.3573 0.6187 5.1845 -373.9598

05Q3 2.77 2.7799 2.8126 2.7943 1.3070 0.5191 5.0124 -374.0565

05Q4 2.38 2.5471 2.7391 2.5524 1.3011 0.2777 4.7503 -374.9762

06Q1 2.39 2.3026 2.3909 2.2996 1.2759 0.0885 4.5290 -376.0596

06Q2 2.93 2.3468 2.3034 2.3451 1.2611 0.1315 4.5934 -376.5732

06Q3 3.44 3.2019 2.9417 3.2035 1.2965 0.9976 5.4668 -377.4902

06Q4 3.99 3.8128 3.7586 3.8165 1.3260 1.5399 6.0955 -378.3621

07Q1 4.55 4.1529 4.2001 4.1578 1.4009 1.8331 6.4591 -379.0650

31

04Q4 05Q1 05Q2 05Q3 05Q4 06Q1 06Q2 06Q3 06Q4 07Q1

Table 10: Full Sample:Forecast of Ination Rates with RW

Density forecast TrueV mean mode median var

95% percentile 2.5% 97.5% MLint

3.41 3.0622 3.1431 3.0621 1.7639 0.4768 5.6970 -326.3807

3.17 3.3812 3.2015 3.3809 1.7659 0.7460 5.9757 -327.6197

3.01 3.1427 3.0835 3.1522 1.7383 0.5364 5.7155 -328.8455

2.77 2.9569 3.3010 2.9656 1.7503 0.3468 5.5289 -330.0599

2.38 2.7248 2.9000 2.7137 1.7352 0.1650 5.2896 -331.2808

2.39 2.3576 2.4409 2.3599 1.6912 -0.1798 4.9368 -332.5264

2.93 2.3538 2.1036 2.3551 1.7082 -0.1845 4.9080 -333.7261

3.44 2.9042 3.0401 2.8988 1.7034 0.3594 5.4745 -335.0075

3.99 3.4046 3.4777 3.4000 1.7146 0.8560 5.9740 -336.2780

4.55 3.9267 3.7495 3.9250 1.6873 1.4048 6.4646 -337.5590

Table 11: Full Sample: MSFE of Statistical Forecasting Models

GSTUR: Constant no trend

l=0 l=1 l=4 l=5 l=7

0.1331 0.0706 0.058 0.0618 0.0578

GSTUR: Trend no constant

l=0 l=1 l=4 l=5 l=7

0.1302 0.0746 0.0553 0.0609 0.0605

GSTUR: Constant and Trend l = 0 l = 1 l = 4 l = 5 l = 7

0.1386 0.0792 0.0636 0.0627 0.0629

GSTUR: No constant no Trend l = 0 l = 1 l = 4 l = 5 l = 7

0.1539 0.0863 0.0683 0.073 0.0692

RW: 0.1535

Table 12: Forecast of Ination Rates in Small Sample GSTUR p=1 lag=4 with NO CT

Density forecast

95% percentile

TrueV mean mode median var

2.5% 97.5% ML

04Q4 3.41 3.2421 3.2512 2.9327 9.8394 -1.0104 9.3728 -57.6152

05Q1 3.17 3.5453 3.4519 3.2298 11.5308 -0.7222 9.3931 -59.1707

05Q2 3.01 2.8288 2.2086 2.6251 5.3872 -1.0143 7.8445 -59.7249

05Q3 2.77 2.5340 2.2455 2.3474 5.3090 -1.0860 7.1594 -60.9709

05Q4 2.38 2.3056 1.5037 2.1885 4.0578 -1.0392 6.4187 -61.9506

06Q1 2.39 2.0845 1.5565 1.9986 3.2559 -1.1018 5.7060 -63.0631

06Q2 2.93 2.2427 1.8924 2.1438 2.7698 -0.7267 5.7828 -63.4988

06Q3 3.44 3.1293 3.0842 3.0280 3.3382 -0.0801 6.9634 -64.4533

06Q4 3.99 3.7835 2.9821 3.6232 3.9126 0.5318 7.8785 -65.5945

07Q1 4.55 4.2063 3.6027 4.0548 4.0159 0.8269 8.7411 -66.8588

32

Table 13: Forecast of Ination Rates in Small Sample with a RW Model

Density forecast

95% percentile

TrueV mean mode median var

2.5% 97.5% ML

04Q4 3.41 3.1451 3.2226 3.1420 0.2371 2.2008 4.1109 -22.5721

05Q1 3.17 3.4810 3.5361 3.4828 0.2271 2.5568 4.4162 -23.3848

05Q2 3.01 3.2054 3.3324 3.2045 0.2224 2.2774 4.1262 -24.1493

05Q3 2.77 3.0373 3.0795 3.0407 0.2121 2.1385 3.9318 -24.8684

05Q4 2.38 2.7842 2.7233 2.7796 0.2071 1.8956 3.6782 -25.5950

06Q1 2.39 2.3743 2.3500 2.3750 0.2057 1.4912 3.2556 -26.3884

06Q2 2.93 2.3840 2.3264 2.3798 0.1905 1.5343 3.2477 -27.0319

06Q3 3.44 2.9398 2.9109 2.9399 0.2021 2.0505 3.8161 -27.9311

06Q4 3.99 3.4850 3.4733 3.4821 0.1999 2.6054 4.3591 -28.7960

07Q1 4.55 4.0753 4.0877 4.0747 0.2003 3.2104 4.9480 -29.6969

Table 14: Small Sample: MSFE of Statistical Forecasting Models

RW GSnoCT:l = 5 GSnoCT:l = 1 GSnoCT:l = 4 AR(5)

0.1335 0.1268

0.1021

0.0987

0.1879

Table 15: Appendix: Functions for Sampling apha (a)

values for # ( ) p = 1

t t 2 [2; n 1]
t=n

#( )

1+

2 1

1

t
t 2 [2; n t=n

values for ( ) p = 1 ()
1] 1 ( t 1+ t+1) + 1 n 1+ (1

(1 1)

1)2

33

t t 2 [2; n p]
t=n 1 t=n
t t 2 (n p; n

Table 16: Appendix: Functions for Sampling apha(b)

values for # ( ) p > 2

t #( )

t 2 [2; n p] t 2 (n p; n 1]

Pp 1+ i
i=1
nPt 1+ i
i=1

t=n

1

p( t p+

values for

pP1 t+p) +
i=1

i

( )p>2 ( )!
pPi j i+j ( t i+ t+i) +
j=1

Pp 1i
i=1

pP1
k k=1

1 k+1

t k + p n p 1+ 1 n+

Pp i N i+
i=1

Pp 1i
i=1

(1

Pp

1) 1

i

i=1

values for ( ) p > 3

()

!

pP1 min(nPt;p k)

2]

n t n+ p t p+

k

m k+m t k

k=1

m=1

n Pt 1 +
k=1

n Pt k
k m k+m m=1

t+k +

Pp 1i
i=1

nPt 1k
k=1

2

34

SFB 649 Discussion Paper Series 2010
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "Volatility Investing with Variance Swaps" by Wolfgang Karl H‰rdle and Elena Silyakova, January 2010.
002 "Partial Linear Quantile Regression and Bootstrap Confidence Bands" by Wolfgang Karl H‰rdle, Ya'acov Ritov and Song Song, January 2010.
003 "Uniform confidence bands for pricing kernels" by Wolfgang Karl H‰rdle, Yarema Okhrin and Weining Wang, January 2010.
004 "Bayesian Inference in a Stochastic Volatility Nelson-Siegel Model" by Nikolaus Hautsch and Fuyu Yang, January 2010.
005 "The Impact of Macroeconomic News on Quote Adjustments, Noise, and Informational Volatility" by Nikolaus Hautsch, Dieter Hess and David Veredas, January 2010.
006 "Bayesian Estimation and Model Selection in the Generalised Stochastic Unit Root Model" by Fuyu Yang and Roberto Leon-Gonzalez, January 2010.

