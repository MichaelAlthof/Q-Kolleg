BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2008-067
Testing Multiplicative Error Models Using Conditional Moment Tests
Nikolaus Hautsch*
*Humboldt-Universität zu Berlin, Germany
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universität zu Berlin Spandauer Straße 1, D-10178 Berlin

Testing Multiplicative Error Models Using Conditional Moment Tests
Nikolaus Hautsch
Humboldt-Universit¨at zu Berlin, CASE, CFS, QPL
November 2008
Abstract We suggest a robust form of conditional moment test as a constructive test for functional misspecification in multiplicative error models. The proposed test has power solely against violations of the conditional mean restriction but is not affected by any other type of model misspecification. Monte-Carlo investigations show that an appropriate choice of weighting function induces high power against various alternatives. We illustrate how to adapt the framework to test also out-of-sample moment restrictions, such as orthogonalities of prediction errors. Keywords: Robust Conditional Moment Tests, Finite Sample Properties, Multiplicative Error Models, Prediction Errors JEL Classification: C12, C22, C52
1 Introduction
The multiplicative error model (MEM) as discussed by Engle (2002) has become a workhorse for the modelling of serially dependent positive-valued random variables in financial time series. Though several specification tests for MEMs have been proposed in the recent literature, only a few approaches address the problem of explicitly testing the validity of the imposed conditional mean restriction. The latter condition is a prerequisite for consistent parameter estimation using quasi maximum likelihood (see Engle, 2000, and Drost and Werker, 2004). Meitz and Ter¨asvirta (2006) introduced various Lagrange multiplier (LM) tests against different forms of functional misspecification. These tests are constructive and have optimal power against specific (local) alternatives. More general approaches are
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
Institute for Statistics and Econometrics, School of Business and Economics as well as Center for Applied Statistics and Economics (CASE), Humboldt-Universita¨t zu Berlin, Center for Financial Studies (CFS), Frankfurt, and Quantitative Products Laboratory (QPL), Berlin. Address: Spandauer Str. 1, D-10099 Berlin, Germany. Email: Nikolaus.Hautsch@wiwi.hu-berlin.de. Tel: +49 30 20935711, fax: +49 30 20935712.
1

omnibus tests (see de Jong, 1996, or Hong and Lee, 2003), which are generally consistent but typically have quite poor power properties in finite samples.
In this paper, we evaluate the performance of classical CM tests as a flexible alternative allowing to bridge the gap between generally inconsistent tests with optimal power against local alternatives (such as LM tests) and asymptotically consistent tests with poor finitesample properties. In particular, we suggest a robust form of Newey's (1985) conditional moment (CM) test which is asymptotically only sensitive to violations of the underlying conditional mean restriction but is not sensitive to any other type of model misspecification. Evaluating the finite-sample properties based on a Monte-Carlo study we show that the test has good power properties against various forms of misspecification if the imposed conditioning information is appropriately chosen. In this sense, CM tests serve as a flexible diagnostic tool replenishing the existing literature. We illustrate that the proposed framework is straightforwardly adapted to test also out-of-sample conditional moment restrictions such as the orthogonality of (out-of-sample) forecasting errors and possible predictors. In this context, CM tests can provide information on how to improve the forecasting power of MEM specifications.
The remainder of the paper is organized as follows. Section 2 introduces the MEM and illustrates how to construct robust tests for in-sample and out-of-sample CM restrictions. In Section 3, we present the results of a Monte-Carlo study analyzing the finite-sample properties of CM tests in the given context. Finally, Section 4 concludes.
2 Conditional Moment Tests for Multiplicative Error Models
2.1 Model Framework and Assumptions
Let {yt}, t = 1, . . . , T , denote a non-negative (scalar) random variable representing, e.g., price volatilities, trading intensities, volumes or trading costs. In general form, the MEM is given by
yt = µtt, E[t|Ft-1] = 1,
where Ft denotes the information set up to t, µt := µt() = E [yt|Ft-1] is a non-negative conditionally deterministic process given Ft-1, and  is a p × 1 parameter vector. A lin-
mn
ear MEM(m,n) specification is given by µt =  + jyt-j + jµt-j, where  > 0,
j=1 j=1
j  0, j  0.1 It resembles the conditional variance equation of a GARCH model (Bollerslev, 1986) as long as yt denotes the squared (de-meaned) log return. Alternatively, if yt
1For a survey on extended specifications, see, e.g., Bauwens and Hautsch (2008).
2

corresponds to a (financial) duration, such as, e.g., the time between consecutive trades,

the model is referred to an ACD specification as introduced by Engle and Russell (1998).

Multivariate MEMs have been discussed by Manganelli (2005), Engle and Gallo (2006) and

Hautsch (2008).

Define t := t(), t = 1 . . . , T , as the s × 1 vector of conditional moment functions with

the property E[t|wt] = 0, where wt is a s × q matrix of instruments. Correspondingly, we

obtain the q × 1 vector of unconditional moment functions as t := t() := wtt. Moreover,

we define the q × 1 vector of sample moments T := T -1

T t=1

t

.

In

the

MEM

framework,

natural choices for t are (yt - µt) or (yt/µt - 1) allowing to test the null hypotheses

H0 : E[yt - µt|wt] = 0 or H0 : E[yt/µt - 1|wt] = 0.

We assume that  is estimated by pseudo maximum likelihood (PML) using the exponential

log likelihood function L() = -

T t=1

(ln

µt

+

yt/µt).2

Correspondingly, we denote the

p × 1 vector st := st() as the score associated with the t-th log likelihood contribution.

Accordingly,

we

define

the

T

×p

matrix

s

:=

s()

:=

(s1, . . . , sT )

and

H()

:=

L() 

denotes

the Hessian of the pseudo log likelihood. Furthermore, we make the following assumptions:

(A1) t(0) follows a stationary and ergodic process with 0 defining the true parameter.

(A2) t() is continuous differentiable in  with E[t()] < .

(A3) T p E[t] and T -1

T t=1

t()/



p E [t(0)/ ].

(A4) T 1/2

T -1 T -1

T t=1

t

T t=1

st

d N (0, ) with  denoting a positive semi-definite covariance

matrix of dimension p + q.

(A5) For some neighborhood N of 0: E[sup ||H()||] < .
N
2.2 A Robust Form of the Conditional Moment Test

In this section, we suggest a form of Newey's (1985) conditional moment test which is robust to any misspecification other than violations of the conditional mean restriction, as, e.g., distributional misspecification or conditional heteroscedasticity in the scores. The asymptotic distribution of T 1/2^T is derived by expanding ^T around 0 using the mean
2Obviously, we could also allow for alternative consistent (extremum) estimators, as, e.g., the semiparametrically efficient estimator proposed by Drost and Werker (2004).

3

value theorem,

TT

T 1/2^T = T 1/2 T -1 t(0) + plim T -1 t()/ (^ - 0) ,

t=1

T 

t=1

where  := 0 + (^ - 0), 0    1. With ^ being a PML estimator, we have

T
T 1/2(^ - 0) = - T -1H() -1 T -1/2 st(0).
t=1

Substituting back into (1) yields

(1)

TT

T

T 1/2^T = T -1/2 t(0) - plim T -1 t()/ T 1/2H()-1 st(0).

t=1

T 

t=1

t=1

This expression can be re-written as

(2)

T 1/2^T = B

T -1/2 T -1/2

T t=1

t(0)

T t=1

st(0

)

,

(3)

where the q × (p + q) matrix B is given by

B = Iq ...

T

plim T -1 t()/

T 

t=1

T -1H() -1 ,

(4)

and Iq denotes a (q × q) identity matrix. Then, we yield T 1/2^T d N (0, BB ) and thus

T [^T (BB )-1^T ] a 2q.

(5)

Under the given assumptions, we have  =

T j=-T

j

=

0 +

Tj=1(j + j), where

j := E[t(0)t-j(0) ] and (yt, 0) := t := (t(0), st(0)) is the (q + p) × 1 vector of

moment restrictions and scores in t. Then,  can be consistently estimated by a kernel-based

estimator

T -1
^ = k(j/q(T ))^j,
j=-T +1

(6)

where k(·) is a kernel function and q(T ) is a bandwidth depending on T . Natural choices are
Bartlett kernels, quadratic spectral kernels or Parzen kernels as, e.g., suggested by Newey
and West (1987) and Andrews (1991).
Estimating the matrix B requires consistently estimating H() by the empirical Hessian which is ensured by the dominance condition (A5). Moreover, plim T -1 t t()/ can
T 
be consistently estimated by

TT

T -1 t(^)/ = T -1

wtt(^)/ + t(^)wt/ ,

t=1 t=1

4

where

t(^)/ =

-yts^t/(yt - µ^t) -s^tµ^2t /(yt - µ^t)

in case of H0, in case of H0.

Note that in case of i.i.d. observations,  is consistently estimated by T -1^t, ^t, whereas
plim t  (·)/ can be consistently estimated by the outer product between score and
T 
moment vector (see Tauchen, 1985, or Newey, 1985). Then, we get the well-known expres-

sion (see, e.g., Pagan and Vella, 1989)

T [^T (BB )-1^T ] =  R(R R - R s(s s)-1s R)-1R ,

(7)

where  is a (T × 1) vector of ones and R is the T × q matrix with t as t-th element.

2.3 Testing Out-of-Sample Moment Restrictions

The framework outlined above is straightforwardly extended to test the orthogonality of (out-of-sample) moment restrictions,

E[t|wT1] = 0, t = T1 + 1, . . . , T,

(8)

where  is consistently estimated using the sample t = 1, . . . , T1, and predictions are computed from T1 + 1 to T capturing a period of T2 := T - T1 observations. Then, s := (s1, . . . , sT1) is a T1 × p matrix, and R := (T1+1, . . . , T ) is a T2 × q matrix. Mimicking the proceeding above and assuming that

T2-1/2

T2 t=1

t(0)

T1-1/2

T1 t=1

st(0)

T1 T2

d N (0, ~ ),

~ =

~  ~ s

~ s ~ ss

,

yields

T2[^T2 (B~~ B~ )-1^T2 ] a q2,

where ^T2 := T2-1

T2 t=1

t(^)

and

B~ = Iq ...

T2

plim T2-1 t()/ (T2-1H())-1 .

T2

t=1

The elements of ~ can be consistently estimated by

^~  = T2+1 k(j/q(T2))^,j,
j=-T2+1

where ^,j = T2-1 have ~ s p 0q×p.

T2 t=1

^t^t-j

,

^ ss,j

=

T1-1

~^ ss = T1+1 k(j/q(T1))^ss,j,
j=-T1+1

T1 t=1

s^t s^t-j T1 /T2 ,

whereas

for

T1,

T2,



,

we

5

3 A Monte Carlo Study on Small Sample Properties

In order to gain deeper insights into the size and power properties of the proposed test, we conduct a Monte Carlo study. We draw samples of size 3000 which is still relatively small for high-frequency financial data and allows us to study the finite-sample properties. Each Monte Carlo experiment is repeated 500 times. We use 5 data generating processes (DGPs) based on the following MEM specifications ensuring E[µt] = 1:

µt = 0.1 + 0.1yt-1 + 0.8µt-1

µt = exp(0.137 + 0.3t-1 + 0.8 ln µt-1)

µt = (0.05µt-1 + 0.5)t-1 + 0.8µt-1

µt = exp(-0.18 + 0.5t-1 - 0.48|t-1 - 1| + 0.8 ln µt-1)



0.05 

+

0.20yt-1

+

0.85µt-1



µt = 0.10 + 0.05yt-1 + 0.90µt-1

0.20 + 0.03yt-1 + 0.80µt-1

if yt-1  0.25, if yt-1  (0.25, 1.5], if yt-1 > 1.5,

(9) (10) (11) (12)
(13)

where yt = µtt, t  Exp(1). Eq. (9) represents a linear MEM (Engle and Russell, 1998), (10) is a logarithmic MEM (Bauwens and Giot, 2000), whereas (11) includes innovations both multiplicatively and additively (Hautsch, 2004). Furthermore, eq. (12) allows for a kinked news impact function (Dufour and Engle, 2000) whereas (13) corresponds to a threshold specification as proposed and estimated by Zhang, Russell, and Tsay (2001).

Table 1: Choice of weighting functions wt in the CM tests.

C M1 C M2 C M3 C M4 C M5 C M6 C M7 C M8 C M9 C M10 C M11 C M12

zt,1 = 1l {t-1<1}, 1l {t-1<1}t-1, 1l {t-11}t-1

zt,2 = zt,1, 1l {t-2<1}, 1l {t-2<1}t-2, 1l {t-21}t-2

zt,3 = 1l {yt-1<1}, 1l {yt-1<1}yt-1, 1l {yt-11}yt-1

zt,4 = zt,3, 1l {yt-2<1}, 1l {yt-2<1}yt-2, 1l {yt-21}yt-2 CM tests

wt,1 = yt-1, wt,2 = wt,1,

yt2-1 , yt-2,

yt3-1 , yt2-2 ,

t-1, yt3-2 ,

t2-1 , t-2,

t3-1 t2-2 ,

t3-2

wt,3 = yt-1, zt,1

wt,4 = yt-1, yt-2, zt,2

wt,5 = t-1, zt,3

wt,6 = t-1, t-2, zt,4

wt,7 = zt,1, zt,3

wt,8 = zt,2, zt,4

wt,9 = (yt-1, yt-2, . . . , yt-10)

wt,10 = (t-1, t-2, . . . , t-10)

bins for i-1 and i-2 : [0, 0.1), [0.1, 0.2), [0.2, 0.5), [0.5, 0.8), [0.8, 1), [1.2, 1.5), [1.5, 2), [2, 3), [3, )

bins for yi-1 and yi-2 : [0, 0.1), [0.1, 0.2), [0.2, 0.5), [0.5, 0.8), [0.8, 1), [1.2, 1.5), [1.5, 2), [2, 3), [3, )

6

For each data generating process (DGP), we estimate a (linear) MEM(1,1) specification µt =  + yt-1 + µt-1. We use the conditional moment function t = yt/µt - 1 and 12 weighting functions wt,i, i = 1, . . . , 12, based on functions of past durations, innovations, and indicator variables indicating possible nonlinear news impact effects (see Table 1). The CM tests are computed using a Bartlett kernel with optimal bandwidth to estimate  (see Newey and West, 1987). As a benchmark we compute a consistent integrated conditional moment (ICM) test as proposed by de Jong (1996). Here, we choose a setting which allows us to consistently test against any possible alternative involving 10 lags.3

Table 2: Rejection frequencies of the individual CM tests (see Table 1). Size of simulated samples:
3000. Number of replications: 500. Estimated model: MEM(1,1).

C M1 C M2 C M3 C M4 C M5 C M6 C M7 C M8 C M9 C M10 C M11 C M12 ICM

DGP (9) 5% 10% 0.066 0.126 0.076 0.142 0.074 0.146 0.070 0.148 0.068 0.138 0.064 0.136 0.074 0.116 0.076 0.130 0.072 0.120 0.068 0.122 0.064 0.104 0.066 0.126 0.010 0.022

DGP (10) 5% 10% 1.000 1.000 0.994 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.998 1.000 0.996 1.000 1.000 1.000 1.000 1.000 0.930 0.952

DGP (11) 5% 10% 0.498 0.605 0.526 0.670 0.454 0.591 0.443 0.584 0.464 0.581 0.436 0.584 0.485 0.591 0.447 0.567 0.488 0.601 0.440 0.564 0.519 0.615 0.450 0.574 0.175 0.251

DGP (12) 5% 10% 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.014 0.034

DGP (13) 5% 10% 0.140 0.212 0.132 0.210 0.156 0.250 0.162 0.246 0.168 0.254 0.162 0.266 0.182 0.282 0.186 0.284 0.168 0.274 0.188 0.286 0.210 0.314 0.222 0.338 0.840 0.872

Table 2 gives the rejection rates of the individual tests. The first column shows the size since the estimated model and the DGP coincide. We find that the CM tests tend to be slightly oversized for the given sample size whereas the ICM test is strongly undersized. The power of the CM tests is generally quite high and increases with the strength of the deviation from linearity in µt. Consequently, the tests have very high power against the DGPs (10) or (12). Lower rejection rates are shown for tests against additive stochastic components (DGP (11)) and regime switching behavior (DGP (13)). Both forms of misspecification are hard to detect since the deviation from a linear MEM is not too severe. In this sense, the test outcomes are quite promising. Overall, we find the highest power for conditional moment tests based on weighting functions which are particularly sensitive against nonlinearities in the news response function. These specifications seem to have power against a wide range of
3We compute the test based on different choices of underlying test functionals and tuning parameters as discussed by de Jong (1996) and observe that the test outcomes are very robust in this respect. Hence, the reported figures can be considered to be representative for various designs of the test.
7

possible misspecifications. In contrast, the power properties of the ICM test are very poor. This is a general finding for omnibus tests and is also confirmed by Meitz and Ter¨asvirta (2006) regarding the spectral density test proposed by Hong and Lee (2003).
4 Conclusions
We have proposed a robust form of Newey's (1985) conditional moment test for functional misspecification in multiplicative error models. The proposed test is robust to any potential misspecification other than those violating the conditional mean restriction. It is shown that the proposed framework is easily adapted to test also out-of-sample moment restrictions. A Monte-Carlo study shows that the test has significantly better power properties as a corresponding consistent conditional moment test. The results indicate that an appropriate choice of the weighting functions induces consistency against a wide range of misspecification while preserving reasonable power properties in finite samples. Consequently, in real applications, CM tests seem to be clearly preferable compared to omnibus tests. As a result, we see them as valuable complements to LM type tests as proposed by Meitz and Tera¨svirta (2006). Both kind of tests serve as constructive tests in the sense of Godfrey (1996) allowing to detect possible sources of model misspecification.
References
Andrews, D. (1991): "Heteroscedasticity and Autocorrelation Consistent Covariance Matrix Estimation," Econometrica, 59, 817­858.
Bauwens, L., and P. Giot (2000): "The Logarithmic ACD Model: An Application to the Bid/Ask Quote Process of two NYSE Stocks," Annales d'Economie et de Statistique, 60, 117­149.
Bauwens, L., and N. Hautsch (2008): Modelling Financial High Frequency Data Using Point ProcessesHandbook of Financial Time Series. T. G. Andersen, R. A. Davis, J.-P. Kreiss and T. Mikosch (eds.), Springer.
Bollerslev, T. (1986): "Generalized Autoregressive Conditional Heteroskedasticity," Journal of Econometrics, 31, 307­327.
de Jong, R. M. (1996): "The Bierens Test under Data Dependence," Journal of Econometrics, 72, 1­32.
Drost, F. C., and B. J. M. Werker (2004): "Semiparametric Duration Models," Journal of Business and Economic Statistics, 22, 40­50.
Dufour, A., and R. F. Engle (2000): "The ACD Model: Predictability of the Time between Consecutive Trades," Working Paper, ISMA Centre, University of Reading.
8

Engle, R. F. (2000): "The Econometrics of Ultra-High-Frequency Data," Econometrica, 68, 1, 1­22. (2002): "New Frontiers for ARCH Models," Journal of Applied Econometrics, 17, 425­446.
Engle, R. F., and G. M. Gallo (2006): "A Multiple Indicators Model for Volatility Using Intra-Daily Data," Journal of Econometrics, 131, 3­27.
Engle, R. F., and J. R. Russell (1998): "Autoregressive Conditional Duration: A New Model for Irregularly Spaced Transaction Data," Econometrica, 66, 1127­1162.
Godfrey, L. G. (1996): "Misspecification Tests and their Use in Econometrics," Journal of Statistical Planning and Inference, 49, 241­260.
Hautsch, N. (2004): Modelling Irregularly Spaced Financial Data, vol. 539 of Lecture Notes in Economics and Mathematical Systems. Springer, Berlin. (2008): "Capturing common components in high-frequency financial time series: A multivariate stochastic multiplicative error model," Journal of Economic Dynamics & Control, 32, 3978­4009.
Hong, Y., and T.-H. Lee (2003): "Diagnostic Checking for the Adequacy of Nonlinear Time Series Models," Econometric Theory, 19, 1065­1121.
Manganelli, S. (2005): "Duration, Volume and Volatility Impact of Trades," Journal of Financial Markets, 8, 377­399.
Meitz, M., and T. Tera¨svirta (2006): "Evaluating Models of Autoregressive Conditional Duration," Journal of Business & Economic Statistics, 24, 104­124.
Newey, W. (1985): "Maximum Likelihood Specification Testing and Conditional Moment Tests," Econometrica, 5, 1047­1070.
Newey, W. K., and K. D. West (1987): "A Simple, Positive Semidefinite, Heteroskedasticity and Autocorrelation Consistent Covariance Matrix," Econometrica, 55, 703­708.
Pagan, A., and F. Vella (1989): "Diagnostic Tests for Models Based on Individual Data: A Survey," Journal of Applied Econometrics, 4, 29­59.
Tauchen, G. (1985): "Diagnostic Testing and Evaluation of Maximum Likelihood Models," Journal of econometrics, 30, 415­443.
Zhang, M. Y., J. Russell, and R. S. Tsay (2001): "A Nonlinear Autoregressive Conditional Duration Model with Applications to Financial Transaction Data," Journal of Econometrics, 104, 179­207.
9

SFB 649 Discussion Paper Series 2008
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.

001 "Testing Monotonicity of Pricing Kernels" by Yuri Golubev, Wolfgang

Härdle and Roman Timonfeev, January 2008.

002 "Adaptive pointwise estimation in time-inhomogeneous time-series

models" by Pavel Cizek, Wolfgang Härdle and Vladimir Spokoiny,

January 2008.

003 "The Bayesian Additive Classification Tree Applied to Credit Risk

Modelling" by Junni L. Zhang and Wolfgang Härdle, January 2008.

004 "Independent Component Analysis Via Copula Techniques" by Ray-Bing

Chen, Meihui Guo, Wolfgang Härdle and Shih-Feng

Huang, January

2008.

005 "The Default Risk of Firms Examined with Smooth Support Vector

Machines" by Wolfgang Härdle, Yuh-Jye Lee, Dorothea Schäfer

and Yi-Ren Yeh, January 2008.

006 "Value-at-Risk and Expected Shortfall when there is long range

dependence" by Wolfgang Härdle and Julius Mungo, Januray 2008.

007 "A Consistent Nonparametric Test for Causality in Quantile" by

Kiho Jeong and Wolfgang Härdle, January 2008.

008 "Do Legal Standards Affect Ethical Concerns of Consumers?" by Dirk

Engelmann and Dorothea Kübler, January 2008.

009 "Recursive Portfolio Selection with Decision Trees" by Anton Andriyashin,

Wolfgang Härdle and Roman Timofeev, January 2008.

010 "Do Public Banks have a Competitive Advantage?" by Astrid Matthey,

January 2008.

011 "Don't aim too high: the potential costs of high aspirations" by Astrid

Matthey and Nadja Dwenger, January 2008.

012 "Visualizing exploratory factor analysis models" by Sigbert Klinke and

Cornelia Wagner, January 2008.

013 "House Prices and Replacement Cost: A Micro-Level Analysis" by Rainer

Schulz and Axel Werwatz, January 2008.

014 "Support Vector Regression Based GARCH Model with Application to

Forecasting Volatility of Financial Returns" by Shiyi Chen, Kiho Jeong and

Wolfgang Härdle, January 2008.

015 "Structural Constant Conditional Correlation" by Enzo Weber, January

2008.

016 "Estimating Investment Equations in Imperfect Capital Markets" by Silke

Hüttel, Oliver Mußhoff, Martin Odening and Nataliya Zinych, January

2008.

017 "Adaptive Forecasting of the EURIBOR Swap Term Structure" by Oliver

Blaskowitz and Helmut Herwatz, January 2008.

018 "Solving, Estimating and Selecting Nonlinear Dynamic Models without

the Curse of Dimensionality" by Viktor Winschel and Markus Krätzig,

February 2008.

019 "The Accuracy of Long-term Real Estate Valuations" by Rainer Schulz,

Markus Staiber, Martin Wersing and Axel Werwatz, February 2008.

020 "The Impact of International Outsourcing on Labour Market Dynamics in

Germany" by Ronald Bachmann and Sebastian Braun, February 2008.

021 "Preferences for Collective versus Individualised Wage Setting" by Tito

Boeri and Michael C. Burda, February 2008.

SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

022 "Lumpy Labor Adjustment as a Propagation Mechanism of Business Cycles" by Fang Yao, February 2008.
023 "Family Management, Family Ownership and Downsizing: Evidence from S&P 500 Firms" by Jörn Hendrich Block, February 2008.
024 "Skill Specific Unemployment with Imperfect Substitution of Skills" by Runli Xie, March 2008.
025 "Price Adjustment to News with Uncertain Precision" by Nikolaus Hautsch, Dieter Hess and Christoph Müller, March 2008.
026 "Information and Beliefs in a Repeated Normal-form Game" by Dietmar Fehr, Dorothea Kübler and David Danz, March 2008.
027 "The Stochastic Fluctuation of the Quantile Regression Curve" by Wolfgang Härdle and Song Song, March 2008.
028 "Are stewardship and valuation usefulness compatible or alternative objectives of financial accounting?" by Joachim Gassen, March 2008.
029 "Genetic Codes of Mergers, Post Merger Technology Evolution and Why Mergers Fail" by Alexander Cuntz, April 2008.
030 "Using R, LaTeX and Wiki for an Arabic e-learning platform" by Taleb Ahmad, Wolfgang Härdle, Sigbert Klinke and Shafeeqah Al Awadhi, April 2008.
031 "Beyond the business cycle ­ factors driving aggregate mortality rates" by Katja Hanewald, April 2008.
032 "Against All Odds? National Sentiment and Wagering on European Football" by Sebastian Braun and Michael Kvasnicka, April 2008.
033 "Are CEOs in Family Firms Paid Like Bureaucrats? Evidence from Bayesian and Frequentist Analyses" by Jörn Hendrich Block, April 2008.
034 "JBendge: An Object-Oriented System for Solving, Estimating and Selecting Nonlinear Dynamic Models" by Viktor Winschel and Markus Krätzig, April 2008.
035 "Stock Picking via Nonsymmetrically Pruned Binary Decision Trees" by Anton Andriyashin, May 2008.
036 "Expected Inflation, Expected Stock Returns, and Money Illusion: What can we learn from Survey Expectations?" by Maik Schmeling and Andreas Schrimpf, May 2008.
037 "The Impact of Individual Investment Behavior for Retirement Welfare: Evidence from the United States and Germany" by Thomas Post, Helmut Gründl, Joan T. Schmit and Anja Zimmer, May 2008.
038 "Dynamic Semiparametric Factor Models in Risk Neutral Density Estimation" by Enzo Giacomini, Wolfgang Härdle and Volker Krätschmer, May 2008.
039 "Can Education Save Europe From High Unemployment?" by Nicole Walter and Runli Xie, June 2008.
040 "Solow Residuals without Capital Stocks" by Michael C. Burda and Battista Severgnini, August 2008.
041 "Unionization, Stochastic Dominance, and Compression of the Wage Distribution: Evidence from Germany" by Michael C. Burda, Bernd Fitzenberger, Alexander Lembcke and Thorsten Vogel, March 2008
042 "Gruppenvergleiche bei hypothetischen Konstrukten ­ Die Prüfung der Übereinstimmung von Messmodellen mit der Strukturgleichungsmethodik" by Dirk Temme and Lutz Hildebrandt, June 2008.
043 "Modeling Dependencies in Finance using Copulae" by Wolfgang Härdle, Ostap Okhrin and Yarema Okhrin, June 2008.
044 "Numerics of Implied Binomial Trees" by Wolfgang Härdle and Alena Mysickova, June 2008.
SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

045 "Measuring and Modeling Risk Using High-Frequency Data" by Wolfgang Härdle, Nikolaus Hautsch and Uta Pigorsch, June 2008.
046 "Links between sustainability-related innovation and sustainability management" by Marcus Wagner, June 2008.
047 "Modelling High-Frequency Volatility and Liquidity Using Multiplicative Error Models" by Nikolaus Hautsch and Vahidin Jeleskovic, July 2008.
048 "Macro Wine in Financial Skins: The Oil-FX Interdependence" by Enzo Weber, July 2008.
049 "Simultaneous Stochastic Volatility Transmission Across American Equity Markets" by Enzo Weber, July 2008.
050 "A semiparametric factor model for electricity forward curve dynamics" by Szymon Borak and Rafal Weron, July 2008.
051 "Recurrent Support Vector Regreson for a Nonlinear ARMA Model with Applications to Forecasting Financial Returns" by Shiyi Chen, Kiho Jeong and Wolfgang K. Härdle, July 2008.
052 "Bayesian Demographic Modeling and Forecasting: An Application to U.S. Mortality" by Wolfgang Reichmuth and Samad Sarferaz, July 2008.
053 "Yield Curve Factors, Term Structure Volatility, and Bond Risk Premia" by Nikolaus Hautsch and Yangguoyi Ou, July 2008.
054 "The Natural Rate Hypothesis and Real Determinacy" by Alexander MeyerGohde, July 2008.
055 "Technology sourcing by large incumbents through acquisition of small firms" by Marcus Wagner, July 2008.
056 "Lumpy Labor Adjustment as a Propagation Mechanism of Business Cycle" by Fang Yao, August 2008.
057 "Measuring changes in preferences and perception due to the entry of a new brand with choice data" by Lutz Hildebrandt and Lea Kalweit, August 2008.
058 "Statistics E-learning Platforms: Evaluation Case Studies" by Taleb Ahmad and Wolfgang Härdle, August 2008.
059 "The Influence of the Business Cycle on Mortality" by Wolfgang H. Reichmuth and Samad Sarferaz, September 2008.
060 "Matching Theory and Data: Bayesian Vector Autoregression and Dynamic Stochastic General Equilibrium Models" by Alexander Kriwoluzky, September 2008.
061 "Eine Analyse der Dimensionen des Fortune-Reputationsindex" by Lutz Hildebrandt, Henning Kreis and Joachim Schwalbach, September 2008.
062 "Nonlinear Modeling of Target Leverage with Latent Determinant Variables ­ New Evidence on the Trade-off Theory" by Ralf Sabiwalsky, September 2008.
063 "Discrete-Time Stochastic Volatility Models and MCMC-Based Statistical Inference" by Nikolaus Hautsch and Yangguoyi Ou, September 2008.
064 "A note on the model selection risk for ANOVA based adaptive forecasting of the EURIBOR swap term structure" by Oliver Blaskowitz and Helmut Herwartz, October 2008.
065 "When, How Fast and by How Much do Trade Costs change in the EURO Area?" by Helmut Herwartz and Henning Weber, October 2008.
066 "The U.S. Business Cycle, 1867-1995: Dynamic Factor Analysis vs. Reconstructed National Accounts" by Albrecht Ritschl, Samad Sarferaz and Martin Uebele, November 2008.
067 "Testing Multiplicative Error Models Using Conditional Moment Tests" by Nikolaus Hautsch, November 2008.
SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

