BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2016-033
Functional Principal Component Analysis
for Derivatives of Multivariate Curves
Maria Grith* Wolfgang K. Härdle*
Alois Kneip*² Heiko Wagner*²
* Humboldt-Universität zu Berlin, Germany *² Rheinische Friedrich-Wilhelms-Universität Bonn, Germany
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universität zu Berlin Spandauer Straße 1, D-10178 Berlin

Functional Principal Component Analysis for Derivatives of Multivariate Curves
Maria Grith,1 Wolfgang K. Härdle,1,2 Alois Kneip 3 and Heiko Wagner 3
1 Ladislaus von Bortkiewicz Chair of Statistics and C.A.S.E. - Center for Applied Statistics and Economics, School of Business and Economics, Humboldt-Universität zu Berlin, Spandauer Straße 1, 10178 Berlin, Germany 2 Sim Kee Boon Institute for Financial Economics, Singapore Management University, 81 Victoria Street, Singapore 188065 3 Institute for Financial Economics and Statistics, Department of Economics, Rheinische Friedrich-Wilhelms-Universität Bonn, Adenauerallee 24-26, 53113 Bonn
Abstract We present two methods based on functional principal component analysis (FPCA) for the estimation of smooth derivatives of a sample of random functions, which are observed in a more than one-dimensional domain. We apply eigenvalue decomposition to a) the dual covariance matrix of the derivatives, and b) the dual covariance matrix of the observed curves. To handle noisy data from discrete observations, we rely on local polynomial regressions. If curves are contained in a finite-dimensional function space, the second method performs better asymptotically. We apply our methodology in a simulation and empirical study, in which we estimate state price density (SPD) surfaces from call option prices. We identify three main components, which can be interpreted as volatility, skewness and tail factors. We also find evidence for term structure variation. Keywords: functional principal component, dual method, derivatives, multivariate functions, state price densities JEL codes: C13, C14, G13
Financial support from the German Research Foundation for the joint project no. 70102424 "Functional Principal Components for Derivatives and Higher Dimensions", between Humboldt-Universität zu Berlin and Rheinische Friedrich-Wilhelms-Universität Bonn, is gratefully acknowledged. We would like to thank as well the Collaborative Research Center 649 "Economic Risk" for providing the data and the International Research Training Group (IRTG) 1792 "High-Dimensional Non-Stationary Time Series Analysis", Humboldt-Universität zu Berlin for additional funding.

1 Introduction
Over the last two decades functional data analysis became a popular tool to handle data entities that are random functions. Usually, discrete and noisy versions of them are observed. Oftentimes, these entities are multivariate functions, i.e., functions with more than one-dimensional domain. Examples include brain activity recordings generated during fMRI or EEG experiments (van Bömmel et al. (2014), Majer et al. (2015)). In a variety of applications though, the object of interest is not directly observable but can be recovered from the observed data by means of derivative. Typical examples of financial applications are functionals retrieved from the observed prices, such as implied risk neutral or state price density (Grith et al. (2012)), pricing kernel (Grith et al. (2013)) or market price of risk (Härdle and Lopez-Cabrera (2012)). Motivated by such data analysis situations, we address the problem of estimating derivatives of multivariate functions from existing discrete and noisy data.
Functions, which are objects of an infinite-dimensional vector space, require specific methods that allow a good approximation of their variability with a small number of components. FPCA is a convenient tool to address this task because it allows us to explain complicated data structures with only a few orthogonal principal components that fulfill the optimal basis property in terms of its L2 accuracy. These components are given by the Karhunen-Loève theorem, see for instance Bosq (2000). In addition, the corresponding principal loadings to this basis system can be used to study the variability of the observed phenomena. An important contribution in the treatment of the finite-dimensional PCA was done by Dauxois et al. (1982), followed by subsequent studies that fostered the applicability of the method to samples of observed noisy curves. Besse and Ramsay (1986), among others, derived theoretical results for observations that are affected by additive errors. Some of the most important contributions for the extension of the PCA to functional data belong to Cardot et al. (1999), Cardot et al. (2007), Ferraty and Vieu (2006), Mas (2002) and Mas (2008). Simple, onedimensional spatial curves are well understood from both numerical and theoretical perspectives and FPCA is easy to implement in this case. Multivariate objects, with more complicated spatial and temporal correlation structures, or not directly observable functions of these objects, such as derivatives, lack a sound theoretical framework. Furthermore, computational issues are considerable in higher-dimensional domain.
To our best knowledge, FPCA for derivatives has been tackled by Hall et al. (2009) and Liu and Müller (2009). The first study handles one-dimensional directional derivatives and gradients. The second paper analyses a particular setup in one-dimensional domain where the observations are sparse. This method is applicable to non-sparse data but can be computationally inefficient when dealing with large amounts of observations per curve. For the study of observed functions, there are a series of empirical studies for the two-dimensional domain case, see Cont and da Fonseca (2002) for an application close to our empirical study. Further proposals to implement FPCA in more than two dimensions to analyze functions, rather than their derivatives, have been done particularly in the area of brain imaging, see for instance, Zipunnikov et al. (2011) who implement multilevel FPCA (Staicu and Carroll (2010), Di et al. (2009)) to analyze brain images of different groups of individuals. However, a thorough derivation of statistical properties of the estimators is missing in these works.
2

In this paper, we aim to fill in the existent gaps in the literature on FPCA for the study of derivatives of multivariate functions. We present two alternative approaches to obtain the derivatives. The paper is organized as follows: the theoretical framework, estimation procedure and statistical properties are derived through Section 2. Our empirical study in Section 3 is guided by the estimation and the dynamics analysis of the option implied state price densities. It includes a simulation study and a real data example.

2 Methodology
2.1 Two approaches to the derivatives of multivariate functions using FPCA
In this section, we review FPCA from a technical point of view and make the reader familiar with our notation.
Let X be a centered smooth random function in L2([0, 1]g ), where g denotes the spatial dimension, with finite second moment [0,1]g E X (t )2 d t <  for t = (t1, . . . , tg ) . The underlying dependence structure can be characterized by the covariance function (t , v) d=ef E X (t )X (v) and the corresponding covariance operator 

()(t ) =

(t , v)(v)d v.

[0,1]g

Mercer's lemma guarantees the existence of a set of eigenvalues 1  2  . . . and a corresponding system of orthonormal eigenfunctions 1, 2, . . . called functional principal components such that


(1) (t , v) = r r (t )r (v),
r =1

where the eigenvalues and eigenfunctions satisfy (r )(t ) = r r (t ). Moreover,

 r =1

r

=

[0,1]g (t , t )d t . The Karhunen-Loève decomposition for the random func-

tion X gives


(2) X (t ) = r r (t ),
r =1

where the loadings r are random variables defined as r = [0,1]g X (t )r (t )d t that satisfy E r2 = r , as well as E r s = 0 for r = s. Throughout the paper the following notation for the derivatives of a function X will be used

(3)

X (d)(t ) d=ef

|d | t d

X (t)

=

d1 t1d1

···

dg

t

dg g

X (t1, . . ., tg ),

for d = (d1, ..., dg ) and d j  N the partial derivative in the spatial direction j = 1, . . ., g .

We denote |d | =

g j =1

|d

j

|

and

require

that

X

is

at

least

|d | + 1

times

continuously

dif-

ferentiable.

Building on equations (1) and (2), we consider two approaches to model a decomposition for derivatives X (d). The first one is stated in terms of the KarhunenLoève decomposition applied to their covariance function. We define (d)(t , v) d=ef

3

E X (d)(t )X (d)(v) and (1d)  2(d)  . . . be the corresponding eigenvalues. The principal components r(d), r = 1, 2, . . . are solutions to

(4) [0,1]g (d)(t , v )r(d)(v )d v = (rd)(rd)(t ).
For nonderivatives |d | = 0, we introduce the following notation (r0)(t )  r (t ). Similarly to equation (2), the decomposition of X (d) in terms of principal components (rd)(t ) is given by

(5) X (d)(t ) = r(d)(rd)(t ),
r =1
for r(d) = [0,1]g X (d)(t )(rd)(t )d t . A different way to think about a decomposition for derivatives, is to take the deriva-
tives of the functional principal components in (2)

(6) X (d)(t ) = r (rd)(t ),
r =1
where the d -th derivative of the r -th eigenfunction is the solution to

(7)

|d | [0,1]g v d

(t , v )r (v ) d v = r (rd)(t ).

In general, for |d | > 0 it holds that (rd)(t ) = (rd)(t ), but both basis systems span

the same function space. In particular, there always exists a projection with ar p =

(pd), r(d) = [0,1]g (pd)(t )(rd)(t )d t such that

 r =1

ar

p

(rd

)(t

)

=

(pd

)

(t

).

However,

if

we

consider a truncation of (2) after a finite number of components this is no longer true

in general. An advantage of using (rd) instead of (rd) is that the decomposition gives

orthonormal basis that fulfill the best basis property, such that for any fixed L  N and

every other orthonormal basis system 

LL

(8)

E ||X (d) -

X (d), (rd) r(d)||  E ||X (d) -

X (d), r r ||.

r =1 r =1

This guarantees that by using (rd), r = 1, . . ., L we always achieve the best L dimensional subset selection in terms of the L2 error function. In the next section we show
that estimating the basis functions with such property comes at the cost of inferior
rate of convergence. However, if the true underlying structure lies in a L-dimensional
function space, which is equivalent to a factor model setup, the advantage of deriv-
ing the best L-orthogonal basis vanishes, because it is possible to derive a basis system with the same features using span((d)). This is achieved by performing a spectral decomposition of the finite-dimensional function space of (rd), r = 1, . . ., L to get an orthonormal basis system fulfilling (8).

2.2 Sample inference
Let X1, . . ., XN  L2([0, 1]g ) be a sample of i.i.d. realizations of the smooth random function X . The empirical approximation for the covariance function based on the

4

N curves is given by the sample counterpart

(9)

^ (d)(t , v )

=

1 N

N

X

(d i

)

(t

)X

(d i

)(v

)

i =1

and for the covariance operator by

(10)

^ (Nd)^ (rd)(t ) = [0,1]g ^ (d)(t , v )^ r(d)(v )d v,

where the eigenfunction ^ (rd) corresponds to the r -th eigenvalue of ^ (Nd). For inference, it holds that ||(r) - ^ (r)|| = Op (N -1/2) and |(r) - ^ r()| = Op (N -1/2), see for instance Dauxois et al. (1982) or Hall and Hosseini-Nasab (2006). The loadings corre-
sponding to each realization Xi can be estimated via the empirical eigenfunctions as ^(rdi ) = [0,1]g Xi(d)(t )^ r(d)(t )d t .

2.3 The model

In most applications, the curves are only observed at discrete points and data is noisy.
To model these aspects, we assume that each curve in the sample is observed at independent randomly-distributed points ti = (ti1, . . ., tiTi ) , tik  [0, 1]g , k = 1, . . ., Ti , i = 1, . . ., N from a continuous distribution with density f such that inf f (t ) > 0. We
t [0,1]g
assume that

(11)


Yi (ti k ) = Xi (ti k ) + i k = r i r (ti k ) + i k ,
r =1

where ik are i.i.d. random variables with E ik = 0, Var ik = 2i and ik is independent of Xi .

2.4 Estimation procedure

1. Dual method-- An alternative to the Karhunen-Loève decomposition relies on
the duality relation between the row and column space. The method was first used
in a functional context by Kneip and Utikal (2001) to estimate density functions and
later adapted by Benko et al. (2009) for general functions. Let  = (1, . . ., g ) , j  N, || <   m and M () be the dual matrix of ^ ()(t , v) from (9) consisting of entries

(12)

Mi(j ) =

[0,1]g

X

() i

(t

)X

j()(t

)d

t

.

Let

l

() r

be

the

eigenvalues

of

matrix

M ()

and

p

() r

=

(p

() 1r

,

.

.

.

,

p N(r)

)

be

the

correspond-

ing eigenvectors. For  = d , the estimators for the quantities in the right-hand side of

equations (4) and (5) are given by

(13)

^ r(d)(t ) =

1 l r(d )

N

pi(dr

)

X

(d i

)

(t

)

,

^ (rd

)

=

i =1

l r(d ) N

and ^r(di ) =

l

(d r

)

p

(d ir

)

.

5

Important for the representation given in equation (6) are the eigenvalues and eigen-

vectors of M (0) denoted by lr d=ef lr(0), pr d=ef pr(0) and the corresponding orthonormal basis ^r d=ef ^ r(0) and loadings ^r i d=ef ^(r0i). It is straightforward to derive

(14)

^r(d)(t ) =

1 lr

N

pi

r

X

(d i

)(t

).

i =1

2. Quadratic integrated regression -- Before deriving estimators of M (0) and M (d)

using the model from Section 2.3, we outline some results needed to construct these

estimators. For any vectors a, b  Rg and c  Ng , we define |a| d=ef

g j =1

|a j |,

a-1

d=ef

(a1-1, . . ., ag-1)

,

ab

d=ef

a

b1 1

×...×

a

bg g

,

a



b

d=ef

(a1b1, . . ., ag

bg

)

and c! d=ef c1! × . . . × cg !.

Consider a curve Y observed at points t = t1, . . . , tT , generated as in equation (11).

Let k = (k1, . . ., kg ) , kl  N and consider a multivariate local polynomial estimator ^(t )  R that solves

(15)

 2

T

min Y (tl ) -

k (t )(tl - t )k  KB (tl - t ).

(t ) l =1

0|k |

KB is any non-negative, symmetric and bounded multivariate kernel function and B a g × g bandwidth matrix. For simplicity, we assume that B has main diagonal entries

b = (b1, . . ., bg ) and zero elsewhere.
As noted by Fan et al. (1997) the solution of the minimization problem (15) can also be represented using a weight function WT , see Appendix 5.2, such that

T

(16)

X^

() b

(t

)

=

!^

(t

)

=

!

WT (tl - t )  b-1 Y (tl ).

l =1

Local polynomial regression estimators are better suited to estimate integrals like

(12) than other kernel estimators, e.g., Nadaraya-Watson or Gasser-Müller estimator,

since the bias and variance are of the same order of magnitude near the boundary as

well as in the interior, see for instance Fan and Gijbels (1992). We propose the following estimator for the squared integrated functions [0,1]g X ()(t )2d t

(17)

TT

, =

[0,1]g

!2

k =1

WT
l =1

(tk - t )  b-1

WT

(tl - t )  b-1

Y (tl )Y (tk )d t

-!2^ 2

T

[0,1]g

WT
k =1

(tk - t )  b-1

2
dt.

where ^ 2 is a consistent estimator of 2. The second term is introduced to cancel the bias in E Y 2(tk ) = X (tk )2 + 2.

Lemma 2.1 Under Assumptions 5.1- 5.4, X is m  2|| times continuously differen-

tiable, the local polynomial regression is of order  with ||   < m and |^ 2 - 2| =

OP (T -1/2). As T

  and max(b)+1b-  0,

log(T ) T b1×...×bg

 0 as T b1 × . . . × bg b4  

(18)

Et ,Y

,

-

X ()(t )2d t = Op
[0,1]g

max(b)+1b-

+

T

1 3/2(b2b1 ×

..

.

×

bg

)

11 Vart,Y (,) = Op T 2b1 × . . . × bg b4 + T ,

6

where Et,Y denotes the conditional expectation and Vart,Y the conditional variance given t , Y . The proof of Lemma 2.1 is given in Appendix 5.2.

3. Estimation of M (0) and M (d) -- The curves Yi in equation (11) are assumed to be observed at different random points. For uniformly sampled points t1, . . ., tT  [0, 1]g

with

T

=

i

min
1,...,N

Ti

,

we

replace

the

integrals

in

(17)

with

the

Riemann

sums,

such

that



M^ i(j )

=

!2 !2

Ti k =1

Tj l =1

w

T 

(ti

k

,

t

j

l

,

b

)Y

j

(t

j

l

)Yi

(ti

k

)

Ti k =1

Ti l =1

w

T 

(ti

k

,

ti

l

,

b

)Yi

(ti

l

)Yi

(ti

k

)

-

^ i2

Ti k =1

w

T 

(ti

k

,

t

i

k

,

b

)

if i = j if i = j.

where

w

T 

(ti

k

,

t

j

l

,

b)

:=

T -1

T m=1

WT

(ti k - tm )  b-1

WT

(t j l - tm)  b-1 . The esti-

mator for M (0) is given by setting  = (0, . . ., 0) and the estimator for M (d) by  = d .

There are two possible sources of error in the construction of the estimator M^ ().

One is coming from smoothing noisy curves at a common grid, and has been analyzed

in Lemma (2.1). The other one is from approximating the integral in (17) by a sum, see

equation above. In Appendix (5.3) we show that the error of the integral approximation is of order T -1/2.

Proposition 2.2 Under the requirements of Lemma 2.1

 1/2

|Mi(j ) - M^ i(j )| = OP max(b)+1b- +

11 T 2b1 × . . . × bg b4 + T

.

By Proposition 2.2, estimating M (d) gives an asymptotic higher bias and also a higher variance than estimating M (0). This effect becomes more pronounced in higher di-
mensional domain. However, by using local polynomial regression with large polynomial order  one can still get parametric rates within each method.

Remark 2.3 Under the assumptions of Lemma 2.1 and using Proposition 2.2 we can

estimate

M ()

such

that

if

m

>





g 2

-

1

+

3

g +4

1

g l =1

l

then |Mi(j ) - M^ i(j )| = OP (1/

T ).

g l =1

l

,

b

=

T -

with

1 2(+1-

g l =1

l

)



We can see that the orders of polynomial expansion and the bandwidths for estimating M () will differ for  = (0, . . ., 0) and  = d . In particular, the estimator of M (d) re-
quires higher smoothness assumptions via m > , and a higher bandwidth to achieve the same parametric convergence rate as the estimator for M (0).
In Lemma 2.1 it is required that |i2 - ^ 2i| = Op (T -1/2), which ensures parametric rates of convergence for M^ () under the conditions of Remark 2.3. By Assumption 5.2, in the univariate case, a simple class of estimators for 2i, which achieve the desired convergence rate, are given by successive differentiation, see von Neumann et al.
(1941) and Rice (1984). However, as pointed out in Munk et al. (2005), difference esti-
mators are no longer consistent for g  4 due to the curse of dimensionality. A possi-
ble solution is to generalize the kernel based variance estimator proposed by Hall and
Marron (1990) for the multidimensional domain

(19)

 2

^ i2

=

1 vi

Ti Ti
Yi (ti l ) - wi lk Y
l =1 k=1

(tik )

,

7

where wi lk = Kr,H (ti l - ti k )/

Ti k =1

Kr,H

(ti

l

- tik)

and

vi

=

Ti

-2

l wilk +

l ,k wi2l k and

Kr,H is a g -dimensional product kernel of order r with bandwidth matrix H . Munk

et al. (2005) show that if 4r > g and if the elements of the diagonal matrix H are of

order O (T -2/(4r +g )) then the estimator ^ i in equation (19) achieves parametric rates

of convergence.

Note that if the curves are observed at a common random grid with T = Ti = T j , i , j = 1, . . ., N , a simple estimator for M (0) is constructed by replacing the integrals
with Riemann sums in (12). This estimator is given by

(20)



M~ i(0j )

=



1
T 1

T

T l =1

Yi

(tl )Y j

(tl )

if

i

=

j

T k =1

Yi

(tl )2

- ^ i2

if

i

=

j

.

In Appendix (5.3) we verify that the convergence rate of M~ i(0j) does not depend on g .
When working with more than one spatial dimension, in practice data is often
recorded using an equidistant grid with T points in each direction. For our approach, this strategy will not improve the convergence rate of M~ (0) due to the curse of dimen-
sionality. If it is possible to influence how data is recorded, we recommend using a
common random grid, which keeps computing time and the storage space for data to a minimum and still gives parametric convergence rates for the estimator of Mi(0j). If T N equation (20), gives a straightforward explanation why the dual matrix is
preferable to derive the eigendecomposition of the covariance operator, because tak-
ing sums has a computational cost that is linear.

4. Estimating the basis functions -- We keep notations  = d to refer to the specification in equation (5) and  = (0, . . ., 0) to (6). A spectral decomposition of M^ () is applied to obtain the eigenvalues l^r() and eigenvectors p^r() for r, j = 1, . . ., N . This gives straightforward empirical counterparts ^ (r,T) = l^r()/N and ^(rj),T = l^r()p^r(j).
To estimate r(d) and r(d), a suitable estimator for Xi(d), r, j = 1, . . ., N is needed. We use a local polynomial kernel estimator, denoted X^i(,dh), similarly to (16), with a polynomial of order p and bandwidth vector h = (h1, . . ., hg ). Here, h is not equal to b, the bandwidth used to smooth the entries of the M^ (0) and M^ (d) matrix. In fact, we
show below that the optimal order for the bandwidth vector h differs asymptotically
from that of b derived in the previous section. An advantage of using local polynomial
estimators, compared for example to spline or wavelet estimators, is that the bias and
variance can be derived analytically. For the univariate case these results can be found
in Fan and Gijbels (1996) and for the multivariate case in Masry (1996) and Gu et al.
(2015). We summarize them in terms of order of convergence below

(21)

Et ,Y

X

(d j

)(t

)

-

X^

j(d,h)(t

)

= Op (max(h)p+1h-d )

Vart ,Y

X^ j(d,h)(t ) = Op

1 T h1 × . . . × hg h2d

.

8

Using these results, it follows that for max(h)p+1h-d  0,

max(h)p+1T h-d

-1
0

as T   and p chosen such that p - |d | is odd



Et ,Y

 



1

l

() r

N i =1

p

() ir

Xi(d)(t ) - X^i(,dh)(t )

= 

1

l

() r

N

p

() jr

Bias

j =1

X^

(d ) j ,h

(t

)

+Op

max(h)p+1h-d

=Op (max(h)p+1h-d )



Vart ,Y

 



1 lr()

i

N =1

pi(r )

X^ i(,dh) (t

) 

=

l

1
() r

N j =1

p

() jr

2
Var

X^ j(d,h)(t )

+Op

1 N T h1 × . . . × hg h2d

1 =Op N T h1 × . . . × hg h2d .

In the next Proposition we show that under certain assumptions the asymptotic mean squared error of ^ r(d,T) and ^r(d,T) is dominated by these two terms.

Proposition 2.4 Under the requirements of Lemma 2.1, Assumptions 5.6 and 5.7,
Remark 2.3, and for sin=rf|r - s | > 0, r, s = 1, . . ., N and max(h)p+1h-d  0 with N T h1 . . .hg h2d   as T, N   we obtain

a) |r(d)(t ) - ^r(d,T) (t )| = Op max(h)p+1h-d + Op (N T h1 × . . . × hg h2d )-1/2

b) |^ r(d)(t ) - ^ (rd,T) (t )| = Op max(h)p+1h-d + Op (N T h1 × . . . × hg h2d )-1/2

A proof of Proposition 2.4 is provided in Appendix 5.4. As a consequence, the resulting global optimal bandwidth is given by hr,opt = Op (N T )-1/(g +2p+2) . Even if the optimal bandwidth for both approaches and each basis function is of the same order of magnitude, the values of the actual bandwidths may differ. A simple rule of thumb for the choice of bandwidths in practice is given in Section 3.1.

2.5 Properties under a factor model structure

Often, the variability of curves can be expressed with only a few basis functions mod-
eled by a truncation of (2) after L basis functions. If a true factor model with L components is assumed, the basis representation to reconstruct X (d) is arbitrary, in the
sense that

(22)

L Ld
X (d)(t ) = r (rd)(t ) = (rd)(rd)(t ).
r =1 r =1

Here L is always an upper bound for Ld . The reason for this is that by taking derivatives it is possible that (rd)(t ) = 0 or that there exits some ar  RL-1 such that (rd)(t ) =
s=r asr (sd)(t ). Based on the methodology described in Section 2.4, the two estimators for deriva-
tives are given by

(23)

X^

(d ) i ,F P

C

A

1

(t

)

d=ef

r

L =1

^i

r,T

^(rd,T)

(t

)



X^

(d ) i ,F P

C

A2

(t

)

d=ef

Ld r =1

^i(dr,)T

^ (rd,T)

(t

).

9

Proposition 2.5 Assume that a factor model with L factors holds for X . For N T -1  0, together with the requirements of Proposition 2.4, the true curves can be reconstructed

a)

|X

(d i

)(t

)

-

X^

(d ) i ,F P

C

A

1

(t

)|

=

Op

T -1/2 + max(h)p+1h-d + (N T h1 × . . . × hg h2d )-1/2

b)

|X

(d i

)(t

)

-

X^

(d ) i ,F P

C

A2

(t

)|

=

Op

T -1/2 + max(h)p+1h-d + (N T h1 × . . . × hg h2d )-1/2

.

A proof of Proposition (2.5) is given in Appendix (5.5). Compared with the conver-

gence rates of the individual curves estimators, see (21), the variance of our estima-

tors reduces not only in T but also in N . Equations (13) and (14) can be interpreted as

an average over N curves for only a finite number of L components. The intuition be-

hind it is that only those components are truncated that are related to the error term

and thus a more accurate fit is possible. If N increases at a certain rate, it is possible to

get close to parametric rates. Such rates are not possible when smoothing the curves

individually.

For

the

estimation

of

X^

(d ) i ,F P

C

A2

,

as

illustrated

in

Remark

2.3,

additional

assumptions

on the smoothness of the curves are needed to achieve the same rates of convergence

for the estimators M^ (d) and M^ (0). With raising g and |d | it is required that the true

curves

become

much

smoother

which

makes

the

applicability

of

estimating

X^

(d ) i ,F P

C

A2

limited for certain applications. In contrast, the estimation of M (0) still gives almost

parametric rates if less smooth curves are assumed. In addition, if the sample size is small, using a high degree polynomial needed to estimate M (d) might lead to unre-

liable results. To learn more about these issues, we check the performance of both

approaches in a simulation study in Section 3.2 using different sample sizes.

3 Application to state price densities implied from option prices
In this section we analyze the state price densities (SPDs) implied by the stock index option prices. As state dependent contingent claims, options contain information about the risk factors driving the underlying asset price process and give information about expectations and risk patterns on the market. Mathematically, SPDs are equivalent martingale measures for the stock index and their existence is guaranteed in the absence of arbitrage plus some technical conditions. In mathematical-finance terminology they are known as risk neutral densities (RNDs). A very restrictive model, with log-normal marginals for the asset price, is the Black-Scholes model. This model results in log-normal SPDs that correspond to a constant implied volatility surface across strikes and maturity. This feature is inconsistent with the empirically documented volatility smile or skew and the term structure, see Rubinstein (1985). Therefore, richer specifications for the option dynamics have to be used. Most of earlier works adopt a static viewpoint; they estimate curves separately at different moments in time, see the methodology reviews by Bahra (1997), Jackwerth (1999) and Bliss and Panigirtzoglou (2002). In order to exploit the information content from all data available, it is reasonable to consider them as collection of curves.
The relation between the SPDs and the European call prices has been demonstrated by Breeden and Litzenberger (1987) and Banz (1978) for a continuum of strike prices spanning the possible range of future realizations of the underlying asset. For a fixed maturity, the SPD is proportional to the second derivative of the European call

10

options with respect to the strike price. In this case, SPDs are one-dimensional func-
tions. A two-dimensional point of view can be adopted if maturities are taken as an
additional argument and the SPDs are viewed as a family of curves. Let C : R2 0  R denote the price function of a European call option with strike
price k and maturity  such that


(24) C (k, ) = exp (-r) (s - k)+q(s, ) d s,
0

where r is the annualized risk free interest rate for maturity , s the unknown price of the underlying asset at maturity, k the strike price and q the state price density of s. One can show that

2C (k, )

(25)

q(s, ) = exp (r)

k 2

.
k=s

Let s0 be the asset price at the moment of pricing and assume it to be fixed. Then by the no-arbitrage condition, the forward price for maturity  is


(26) F = sq(s, )d s = s0 exp(r).
0

Suppose that the call price is homogeneous of degree one in the strike price. Then

(27) C (k, ) = FC (k/F, ).

If we denote m = k/F the moneyness, it is easy to verify that

2C (k, ) 1 2C (m, )

(28)

k 2

= F

m2 .

Then one can show that for d = (2, 0) , C (d)(m, )|m=s/F = q(s/s0, ) = s0q(s, ). In practice, it is preferable to work with densities of returns instead of prices when analyzing them jointly because prices are not stationary. Also, notice that call price curves are not centered. This leads to an additional additive term in equations (4) and (6), which refers to the population mean. We show in the next section how to handle this in practice. For our application, X will refer to the rescaled call price C (m, ). Therein, we also assume that the index i = 1, . . . , N refers to ordered time-points.
The code used to generate the results reported in this section is published online at www.github.com/QuantLet/FPCA and www.quantlet.de. The data used in the empirical study is available from the authors upon request.

3.1 Implementation

1. Centering the observed curves -- Throughout the paper it is assumed that the

curves are centered. To satisfy this assumption, we subtract the empirical mean

X¯ ()(tk )

=

1 N

N i =1

X^

() i ,b

(tk

)

from

the

the

observed

call

prices

to

obtained

centered

curves. A centered version M (),  = (0, d ) is given by

(29)

M

() ij

=

M^ i(j )

-

1 T

T k =1

X¯

()(tk

)

X^

() i ,b

(tk

)

+

X¯

()(tk

)X^

j(,b)(tk

)

-

X¯

()

(tk

)2

.

11

It is still possible to improve the centering the curves. One possibility is to use a dif-

ferent bandwidth to compute the mean because averaging will necessarily lower the

variance.

Secondly,

by

the

arguments

of

Section

2.4,

the

1 T

T k =1

X¯

()(tk

)2

term

can

be

improved accordingly to Lemma 2.1 by subtracting ^  weighted by suitable parame-

ters. We decide to omit these fine tunings in our application because it would involve a

significant amount of additional computational effort for only minor improvements.

2. Bandwidth selection -- To get parametric rates of convergence for M^ (d) related to Remark 2.3 we choose  = 7 and b between O (T -1/10) and O (T -1/12). The choice of b to estimate M^ (0) is similar, with the difference that  > 0, we choose  = 1 and b has to lie between O (T -1/3) and O (T -1/5). We use a simple criteria to choose the
bandwidth because by Proposition 2.4 the dominating error depends mainly on the
choice of h. Let tik = (tik1, . . .tikg ), then the bandwidth for direction j is determined

by b j = (maxk (tik j ) - mink (tik j ))Ti . When estimating state price densities tik = (ik , mik ) and Ti is replaced by the cardinality of i = {i1, . . .iTi } and mi respectively. In the estimation of M^ (d) we set  = -1/10 and  = -1/3 for M^ (0).
The choice of bandwidths h is a crucial parameter for the quality of the estimators.
To derive an estimator for the bandwidths first note that in the univariate case (g = 1)
the theoretical optimal univariate asymptotic bandwidth for the r -th basis is given by

(30)

 1/(2p+3)

hrd,o,pt = Cd,p (K ) T -1 

1 0

iN=1(pi(r ))22i (t ) fi (t )-1d t 

1 0

N i =1

pi(r )

X

(p i

+1)(t

)

2
dt

 

,

C

d

,p

(K

)

=


 

(p 2(p

+ +

1)!2(2d 1 - d ){

+ 1) u p +1

K K

2 p,d
 d ,p

(t )d t
j
(t )d t }2

1/(2p
 

+3)

.

Like in the conventional local polynomial smoothing case Cd,p (K ) does not depend on the curves and is an easily computable constant. It only depends on the chosen

kernel, the order of the derivative and the order of the polynomial, see for instance

Fan and Gijbels (1996).

For our bandwidth estimator we treat every dimension separately, similar to choos-

ing an optimal an optimal bandwidth for derivatives in the univariate case, and cor-

rect for the asymptotic order, see Section 2.4. In practice, we can not use equation

(30) to determine the optimal bandwidth because some variables are unknown and

only discrete points are observed. As a rule-of-thumb, we replace these unknown vari-

ables

with

empirical

quantities:

estimates

of

p

(0) ir

from

M^ (0)

and

of

pi(dr )

from

M^ (d).

With these approximations, a feasible rule for computing the optimal bandwidth in

direction j for the r -th basis function h jr is given by

(31)



h

d , j r,r

ot

=

T 

-1

fj

1 0

1/(g +2p+2)

Cd2p,p+3^ 2



N i =1

p^i(r )

X~

(p +1) i

(t

j

)

2

d

t

j

 

.

In our application as well as our simulation we have g = 2, d = (0, 2) and do a third order local polynomial regression. The integrals are approximated by Riemann sums.

12

· The density of the observed points is approximated by a uniform distribution with f1 = maxi,j (i j ) - mini,j (i j ) and f2 = maxi,j (mi j ) - mini,j (mi j ).
· To get a rough estimator for Xi(p+1) based on Xi , we use a polynomial regression. For our application, we take p = 3 and are thus interested in estimates for Xi(4)(m) and Xi(4)(). We expect the curves to be more complex in the moneyness direction than in the maturity direction and we adjust the degree of the polynomials to reflect this issue. The estimates are then given by

(32)

59

ai

=

arg

min
ai

Xi (m, ) - ai 0 + ai l ml + ai l (l-5)
l =1 l =6

X~i(4)(m) =24ai4 + 120ai5m

X~i(4)() =24ai9.

· To estimate the variance for each curve we use the kernel approach given in (19) using a Epanechnikov kernel with a bandwidth of T -2/(4+g ) for each spatial
direction. In addition, these estimates are used to correct for the diagonal bias when M^ (0) and M^ (d) are estimated. In (31) the average over all ^ i is used.

We use the product of Gaussian kernel functions to construct local polynomial es-

timators. We can verify from Proposition 2.4 that the optimal bandwidth h decreases

in N . By using a global bandwidth and a compact kernel the matrix given in equation

(45) may become singular when N is large and T is small.

In our simulation and application we use the mean optimal hid,r,ot = L-1

L r =1

hidr,,r

ot

for each ^(rd), ^ r(d) to reduce computation time. Since we demean the sample in (29),

finally we add N -1

N i =1

X^

(d ) i ,hid,r,ot

to

the

resulting

truncated

decomposition

to

derive

the

final estimate.

3. Estimation of the number of components-- In Section 2.5 we assumed that the
number of components is given. In general, the number of basis functions needed is unknown a priori. For the case |d | = 0 there exists a wide range of criteria that can be adapted to our case to determine the upper bound L. The easiest way to determine
the number of components is by choosing the model accuracy by an amount of vari-
ance explained by the eigenvalues. In (71) we show that under the conditions from Proposition 2.4 ^ (rd) -^ (rd,T) = Op (N -1/2T -1/2 +T -1) and r(d) -^ (rd) = Op (N -1/2). The assumptions in Corollary 1 from Bai and Ng (2002) can be adapted to our case and give several criteria for finding L or Ld by generalizing Mallows (1973) Cp criteria for panel data settings. These criteria imply minimizing the sum of squared residuals when k
factors are estimated and penalizing the overfitting. One such formulation suggests
choosing the number of factors using the criteria

(33)



NN

PC ()(k) = min 
k N,k L max

^ (r)
r =k+1

+k

^ (r)
r =Lmax



log(C

2 N

T

)

C

2 N

T

,

for the constant CNT = min( N , T ) and a prespecified Lmax < min(N , T ). Bai and Ng (2002) propose information criteria that do not depend on the choice of Lmax. We

13

consider the above modified version

(34)



IC ()(k) = min log
k N,k L

1 N

N
^ r()
r =k+1

+k

log(C

2 N

T

)

C

2 N

T

.

Here using  = (0, . . ., 0) will give L while using  = d will give the factors Ld . Another possibility for the choice of number of components is to compute the vari-
ance explained by each nonorthogonal basis by

(35)

Var(^(rd,T) ^(rd,T) ) = ^(rd,T) , ^r(d,T) ^ r .

We can sort the variances in decreasing order and use either equation (33) or (34) to select the number of components.

3.2 Simulation Study

We investigate the finite sample behavior of our estimators in a simulation study,

which is guided by the real data application in Section 3.3. Simulated SPDs are mod-

eled as mixtures of G components, q(m, ) =

G l =1

w

l

q

l

(m,

),

where

ql

are

fixed

ba-

sis functions and wl are random weights. For fixed  we consider ql (·, ) to be a log-

normal density functions, with mean

µl

-

1 2

2l



and

variance

2l ,

and

simulate

weights wil with

G l =1

wil

=

1,

where

i

=

1, . . . , N

is

the

index

for

the

day,

then

(36)

G
qi (m, ) = wil l =1 m

1

 

exp

-

1

 

log

(m)

-

µl

-

1 2

2l

2



 

.

2l2

 2 

l 

  

Following Brigo and Mercurio (2002) the prices of call options for these SPDs are

G
(37) Ci (m, ) = exp (-ri) wil exp(µl )(y1) - m(y2)
l =1

where

y1

=

log

m-1 + l

µl

+

1 2

2l




,

y2

=

log

m-1 + l

µl

-

1 2

2l





and  is the standard

normal

cdf.

This representation corresponds to a factor model in which the mixture components

are densities associated with a particular state of nature and the loadings are equiva-

lent with probabilities of states.

We illustrate the finite sample behavior for G = 3 with µ1 = 0.4, µ2 = 0.7, µ3 = 0.1, and 1 = 0.5, 2 = 0.3, 3 = 0.3. The loadings are simulated from the positive halfstandard normal distribution, then standardized to sum up to one. One can verify

that the correlation matrix for the loadings is

 1 -0.5 -0.5
R =  -0.5 1 -0.5  , 
-0.5 -0.5 1

which is singular with rank(R) = 2. As a result, the covariance operator of the SPD curves has L = G - 1 nonzero eingenvalues. In this example, using a mixture of three factors means that only two principal components are necessary to explain the variance in the true curves.

14

T 50

250

N X^·(d) Mean Var Med IQR Mean Var Med IQR

F PC A1 0.1876 0.0367 0.1300 0.1325 0.0780 0.0025 0.0643 0.0546

10 F PC A2 0.2238 0.1212 0.1295 0.1466 0.0762 0.0026 0.0630 0.0518

I nd i v. 0.2709 0.0900 0.1928 0.1838 0.1105 0.0054 0.0916 0.0708

F PC A1 0.0917 0.0066 0.0680 0.0580 0.0404 0.0006 0.0336 0.0223 25 F PC A2 0.1553 0.0966 0.0878 0.0887 0.0586 0.0016 0.0489 0.0406
I nd i v. 0.2691 0.0995 0.1889 0.1848 0.1111 0.0052 0.0916 0.0719

Table 1. Results of the simulation described in Section 3.2 with different values for T and N . F PC A1 and F PC A2 are superior in sense of MSE over the individual estimation of the derivatives
in each setting. F PC A1 is better than F PC A2 except for N = 10, T = 250. For F PC A1 and F PC A2 the estimation improves with raising N and T . These results support our asymptotic
results given by Proposition 2.2 and 2.5.
FPCAsimulation

Without loss of generality, we set ri = 0, for each day i = i , . . . , N . We construct a random grid for each observed curve Xi by simulating points tik = (mik , ik ), k = 1, . . ., T from a uniform distribution with continuous support [0.5, 1.8] × [0.2, 0.7]. Fi-
nally, we record noisy discrete observations of the call functions with additive error term i.i.d. ik  N(0, 0.12).

The true SPDs given by equation (36) are used to verify the performance of

X^

(d ) FPC

A1

,

X^

(d ) FPC

A2

and

of

the

individually

estimated

curves

X^

(d ) Ind

i

v.

,

in

terms

of

mean

in-

tegrated squared error (MSE), i.e., T -1

T k =1

X (d)(ti k ) - X^·(d)(ti k )

2
, for d = (2, 0). For

evaluation we generate a common grid of 256 points from a uniform distribution. To

derive the optimal bandwidth in each case we stick to the rule-of-thumb approach

presented in Section 3.1. The bandwidth for the individually smoothed curve i is de-
rived by replacing p^i(r ) in (31) by one and zero otherwise. The performance is recorded for sample sizes N of 10 and 25 with T observations per day of size 50 and 250. This

procedure is repeated 500 times to get reliable results, mean, variance and the inter

quartile distance based at the MSE of the repetitions are given in Table 1.

Both FPCA based approaches give better estimates for the derivative of the call functions than an individually applied local polynomial estimator of the individual curves. Both the mean and the median of the MSE are smaller which is a result of the additional average over N for the basis functions as given by Proposition 2.5. However, the F PC A1 method performs decisively better for small T than the other two both in terms of mean and standard deviation of the mean squared error. In addition F PC A1 benefits more from increasing N than F PC A2. With small T for F PC A2 and individual smoothing the variability of MSE is much bigger than for F PC A1 while the median of F PC A1 and F PC A2 are comparable. This means individual smoothing and F PC A2 must behave much worse than F PC A1 in some instances while F PC A1 was able to stabilize the estimates. To get the same effect using F PC A2 a much bigger T is needed. A possible explanation for this behavior is given by Proposition 2.2. The rates of convergence for the estimators of the dual matrix entries rely on T . Thus in finite sample, when T is small, the estimated loadings might be biased.

15

3.3 Real Data Example
1. Data description --We use settlement European call option prices written on the underlying DAX 30 stock index. These prices are computed by EUREX at the close of each trading day as an average of the intraday transaction prices. The data range is ten years, between January 2, 2002 and December 3, 2011, and includes 2557 days. The expiration dates of the options are set on the third Friday of the month. Therefore, on a particular day, option prices with only a few maturities are available, see Figure 1. The distance between two consecutive observed maturities is higher for more distant expiration dates, while the distance between two consecutive strike prices is relatively constant. Methods that analyze curves jointly are generally better tailored to this type of data, because they provide better estimates at grid points with only a few observations available of the individual curves. We include call options with maturity between one day and one year. The sample contains prices of options with an average of six maturities and sixty-five strikes per day.
By assuming 'sticky' coordinates for the daily observations, in accordance with equation (27), we divide the strike and the call prices within one day by the stock index forward price to ensure that the observation points are in the same range. Afterwards, we apply the estimation methodology described in Section 2 to the rescaled call prices as a function of moneyness and maturity. Our proxy for the risk-free interest rates are the EURIBOR rates, which are listed daily for several maturities. We apply a linear interpolation to calculate the rate values for desired maturities.
2. Estimation results -- We report the results for the loadings estimated by spectral decomposition of dual covariance matrix for option price functions, and the estimates of the second partial derivative of the functional principal components. The first eigenvalue of the dual covariance matrix M^ (0) for the call option surfaces has a dominant explanatory power. The order of magnitude of the following eigenvalues decreases by a factor of ten for every few additional components. To detect the relative contribution of consecutive components, we construct the ratio of two adjacent estimated eigenvalues in descending order, see Ahn and Horenstein (2013). The first two terms are dominating the sequence and there are spikes at the fourth and seventh component ratio. PC (0) criterion suggests at least seven components, see values of k for Lmax  7 in Table 2. IC (0) criterion, which does not depend on the truncation parameter Lmax , suggests seven components.

r , Lmax 1 2 3 4 5 6 7 8 9 10

^r,T × 106 133.29 18.90 2.69 1.62 0.49 0.34 0.26 0.09 0.08 0.05

^ r,T /^ r +1,T

7.05 7.01 1.66 3.28 1.44 1.31 2.83 1.18 1.70 1.35

k(PC (0))

-

- - - - -7899

k(I C (0))

-

- ----7---

Table 2. Estimated eigenvalues and eigenvalue ratios. Number of factors by PC (0) criterion FPCArealdata

16

Call prices

15-Jun-2007 0.5

18-Jun-2007 0.5

Call prices

0

0.5

0.75

1

1.25

Moneyness

1.5

0

0.25 0.5 0.75 1 Maturity

100

0

-100 1 0.75 0.5 0.25 Maturity

0

0.5 0.751 1.251.5 Moneyness

/^2;T

0

0.5

0.75

1

1.25

Moneyness

1.5

0

0.25 0.5 0.75 1 Maturity

Green: 15-Jun-2007. Red: 18-Jun-2007

0

-0.02

-0.04

-0.06 2002 2004 2006 2008 2010 2012

Figure 1. The effect of expiration date on the level of estimated loadings ^2,T FPCAexpiration

.^(2;dT)

A closer look at the dynamics of the loadings ^2,T shows an unusual behavior between mid-February 2007 through mid-June 2008. This interval spans the financial crisis and extends until the end of the recession in the Euro Area, according to the Center for Economic and Policy Research (CEPR) recession indicator. The loadings are extremely volatile and display a particular time regularity of jumps. We identify these jumps with the Mondays following an expiration date (options expire at a monthly frequency, always on a Friday). Figure 1 highlights the dynamics of ^2,T on and following an expiration day. After roughly two weeks, the loadings revert to a 'normal' level. During this period, for small maturities, there are only few observations available for call prices with strikes larger than the current stock index. In addition, the absence of a call string with close enough time to maturity on the following trading Monday, introduces bias in the estimated smooth call surface for grid values outside the observation points range. The shape of the second estimated component ^2(d,T) , displayed in Figure 1, suggests that it is related to variations of the short end of the SPD term structure. A similar behavior of the loadings are observed for a few other components we investigated: ^4,T , ^5,T and ^6,T . Their variances remain important even if we exclude the interval with large jumps from the sample. The corresponding components have similar shape features to the three components we discuss below. We argue that they impact the option prices and SPDs when jumps in the underlying occur, and that they related to the asymmetric behavior of the option prices along the maturity direction.
The estimated components ^(1d,T) , ^(3d,T) and ^(7d,T) together with their loadings are displayed in Figure 2. They describe three types of asymmetry present in the dynamics of the SPDs. The first component, is similar in shape to the empirical mean of the SPD. It has a long left tail, specific to the negatively skewed densities and a peak located at a value of moneyness slightly above one. For positive levels of the loadings, this compo-
17

.^(7;dT) .^(3;dT) .^(1;dT) /^3;T /^1;T
/^7;T

200

0

-200 1 0.75 0.5 0.25
Maturity

0

100

0

-100 1 0.75 0.5 0.25
Maturity

0

1000

0

-1000 1 0.75 0.5 0.25
Maturity

0

0.5 0.751 1.251.5 Moneyness

0.04 0.02
0 -0.02 -0.04 -0.06
2002 2004 2006 2008 2010 2012

0.5 0.751 1.251.5 Moneyness

0.01 0.005
0 -0.005
-0.01 -0.015
2002 2004 2006 2008 2010 2012
# 10 -3 2

1

0

0.5 0.751 1.251.5 Moneyness

-1
-2 2002 2004 2006 2008 2010 2012

Figure 2. Estimated components ^1(d,T) , ^(3d,T) and ^(7d,T) and their loadings obtained by the decomposition of the dual covariance matrix M^ (0)
FPCAcomponents

nent increases the mass of SPD around the mode and decreases the values in the tails. We find that this component is related to the time-varying volatility of the index returns. The next component, ^3(d,T) has a 'valley-hill' pattern, which shifts mass around the central region of the density. A positive shock in the direction of this components increases the negative skewness, and a large negative shock can reverse the sign of the SPD skewness. This component is interpreted as a skewness factor. The last component, ^(7d,T) takes negative values in the left tail and displays a prominent positive valued peak at the right of the mode of the empirical SPD mean. This component represents a tail factor, and we show that its loading can be interpreted as the volatility of volatility index.
The functional principal components of the reduced model r {1,3,7} ^r,T ^r(d,T) resemble closely the three components displayed in Figure 2. Further analysis shows that when including any additional component to the reduced representation, the shape of the orthogonal basis changes to some extent. The loadings of all orthogonalized components become 'contaminated' with jumps. Moreover, all the loadings estimated by decomposing M^ (d), for d = (2, 0) feature the jump-behavior outlined
18

above, between mid-February 2007 and mid-September 2008. For those reasons, M^ (0)
decomposition enables a better interpretation of the components, by separating the
continuous and discontinuous sources of variation in the SPDs. We show next that the first estimated component ^1(d,T) is related to the expected
variance under a risk neutral measure Q, which admits the density q. Under this mea-
sure, the prices are martingales. Equations (6) and (26) yield

(38)

EQi si +/Fi exp(r i  )


= mq~(m, )d m + ir
0 r =1


mr(d)(m, )d m = 1,
0

where q~ is the population mean. The computation of the second moment gives

(39)

VarQi si +/si exp(r i  )2

=


m2q~(m, )d m + ir
0 r =1


m2r(d)(m, )d m - 1.
0

We consider the empirical version of Equation (39), for  = 1 month. Instead of computing the integrals, based on our estimates of q~ and (d), we assume them to be unknown coefficients in a linear regression, in which the empirical loadings are used as
explanatory variables of the real-data proxy for the standardized variance. In the numerator, we use the squared VDAX index multiplied by . This index is computed by Deutsche Börse AG from the prices of call and put options and reflects market expecta-
tion under the risk neutral measure of the 30 day ahead square root implied variance
for the DAX 30 log-returns, which is then annualized. Duan and Yeh (2010) show that
squared volatility index is a good approximation of the expected risk-neutral volatility
when the jumps are small. While the volatility index refers to the standard deviation
of the log-returns under the risk neutral measure, it can still be used in the regression because the transformation q(log m, ) = mq(m, ) maintains the linear-relationship between the dependent and explanatory variables. We find that the most important component in the regression is ^1,T (adjusted R-squared in the univariate regression is 93.97%). When including ^3,T as an additional regressor, it increases the adjusted R-squared to 94.06%, while ^7,T has a negative marginal contribution to the goodness of fit of multivariate regression.
No skewness index is readily available, and we take a simple measure instead, Pearson's skewness coefficient. In terms of equations (38) and (39), for a fixed maturity , it is equal to

1 - arg max q(m, ) (40) m .
VarQi si+/si / exp(ri)
Since the first component ^1(d,T) is unimodal (as it is also ^(2d,T) ), the SPD mode is mostly affected by the loadings of the third component ^(3d,T) (and to some extend by those of the seventh component ^7(d,T) ).

3. Dynamic analysis of the loadings -- In this section, we investigate the dynamics of the loadings in the reduced model. The partial autocorrelation function of all

19

three time series display a salient spike at the first lag. This suggests that an autore-
gressive or perhaps an integrated model of order one might be appropriate to rep-
resent their dynamics. Their serial autocorrelations decay slowly, similarly to the in-
tegrated processes that feature a stochastic trend. Unit root and stationarity test re-
sults (not reported here) are ambiguous. When the null hypothesis assumes the ex-
istence of a unit root (augmented Dickey-Fuller unit-root test, Phillips-Perron test,
variance-ratio test for random walk) the tests reject the null, while stationary tests
that have the unit root hypothesis as an alternative (KPSS test, Leybourne-McCabe
stationarity test) favor the alternative. Based on these results, we further investigate
if the loadings are fractionally integrated of order   (0, 1), which is typical to longmemory processes. We employ Lo (1991)'s modified R/S~ (range over standard deviation) rescaled statistic V~N , for a time series sample of N observations. The denominator of the statistic is computed as the square root of Newey and West (1987) estimator of the long run variance of the time series. For a maximum lag q = [N 1/4] = 9, we obtain V~N,1(9) = 5.1582, V~N,3(9) = 4.5248 and V~N,7(9) = 4.9893, with 95% confidence interval (0, 809, 1, 862). The tests reject the hypothesis that loadings have
short-memory. We also apply Geweke and Porter-Hudak (1983) log-periodogram regression model to estimate the Hurst exponent. The estimates are H1GPH = 1.3736, H3GPH = 1.1761 and H7GPH = 1.1433 for the cutoff [N 1/2] = 50. The 95% confidence interval (0.2981, 0.7019) for the the GPH estimator is calculated using a bootstrap-
ping procedure proposed by Weron (2002). These estimates imply an order of integration ^Gr PH = HrGPH - 0.5, r = 1, 3, 7. It is known that in the presence of large autoregressive or moving average terms, ^Gr PH is biased upwards. In general, these models are nontrivial to estimate by other methods. Furthermore, fractionally integrated pro-
cesses lack a clear economic interpretation. Therefore, instead of including a large
number of autoregressive terms we use a parsimonious AR(1) model with time vary-
ing coefficients to approximate the long memory process. This is appropriate also for
  (1/2, 1), when the loadings are not stationary, see Comte and Renault (1998). We consider the following law of motion for the loadings

(41)

^i r,T = br ^i -1r,T + ei r , Var(ei r ) = 2er ,

where br is the autoregressive coefficient, r = 1, 3, 7. We reestimate equation (41) daily on a moving window of 250 observation using OLS. This adaptive estimation proce-
dure helps detect the possible sources of non-stationarity in the estimated loadings,
by allowing the autoregressive coefficient and the error variance to vary over time.
The upper left panel of Figure 3 displays the estimated autoregressive coefficients. ^1,T is very persistent (b^1 is close to one) for most of the time, except 2004. Interestingly, b^3 is relatively small between 2003-2006 and increases significantly thereafter, suggesting a possible regime shift. b^7 is relatively high and its variation seems sensitive to the changes in the other two parameters.
In addition, we compute the time-varying correlations between the error terms in
each loading equation. These correspond to the non-diagonal entries of the empirical
error covariance matrix for a vector autoregressive model of order one VAR(1) fitted
to the loadings, with diagonal autoregressive coefficient matrix. The two lower panels
of Figure 3 illustrate the results. The error correlation of the skewness with the volatil-
ity and the tail factor loadings move closely together, suggesting a strong relationship
between the volatility and the tail factors. We focus on cor r (e^1, e^3), which describes

20

^b1 (black), ^b3 (red) and ^b7 (blue) 1
0.8
0.6
0.4
0.2 2002 2004 2006 2008 2010 2012 corr(e^1; e^3) (green) and !corr(e^3; e^7) (magenta) 1

#10-3<^e1 (black), <^e3 (red) and <^e7 (blue) 5 4 3 2 1 0 2002 2004 2006 2008 2010 2012
corr(e^1; e^7) (orange) and <^IV (light blue) 1 20

0 0 10

-1 2002 2004 2006 2008 2010 2012

-1 0 2002 2004 2006 2008 2010 2012

Figure 3. Time varying autoregressive coefficients, standard deviations of the error, pairwise error correlations from fitting a univariate AR(1) model to each loading; and time varying standard deviation of the VDAX volatility index estimated daily with a moving window of 250 observations
FPCAloadings

the dynamic relationship between the changes in SDP volatility and skewness. Most of the time, the plotted correlation is negative, meaning that positive changes in the SPD variance are associated on average with increases in the negative skewness. The negative correlation between an asset return and its changes of volatility is generally known as the leverage effect. The correlation reverses sign and becomes positive between 2007-2009. This means that when volatility increases, there is a change in the concentration mass in the left side of the density, in the area of medium-ranged negative returns. We identify this behavior with the implied volatility skew puzzle, as documented by Constantinides and Lian (2015). The authors rationalize this behavior through the reduction in put option supply from credit-constrained market makers together with an increase in the demand for OTM puts required for hedging purposed, see net buying pressure in Bollen and Whaley (2004), Gârleanu et al. (2009).
Typically, the error correlation cor r (e^1, e^7) is negative. Its magnitude decreases and reaches values close to zero in 2009. In the lower right panel of Figure 3, we also plot the 250-observation standard deviation ^ IV of the VDAX implied volatility index. The two time-series are strongly correlated (the correlation coefficient is 90.78% ). This suggests that the tail component can be interpreted as the volatility of volatility risk factor. Similar interpretations were proposed in Du and Kapadia (2012), Huang and Shaliastovich (2014) or Park (2015), who use different measures of the volatility-ofvolatility implied by VIX (the implied volatility index of the S&P 500) as a tail risk indicator. The tail factor takes highest positive values during the financial crisis, consistent with fat tail and high risk hypothesis.
To verify the stability of the results reported, we repeat the regression analysis by including a constant in equation (41). The root mean square error does not decrease

21

significantly. We also estimate the model by including the lagged values of the other two loadings as additional explanatory variables. Some of the estimated autoregressive coefficients take value above one. Independently of these modeling choices, the estimated error covariances are very similar to those shown in Figure 3. These suggest that changes in the correlation sign for the levels is due to the error term correlation structure and not to changes in the lagged cross-term interactions.
Several stylized facts emerge from the moving window estimation of autoregressive models for the loadings that summarize the dynamics of SPDs. When volatility is small, the innovations to the volatility, skewness and volatility of volatility loading equations are very strongly correlated. When volatility increases, the correlation structure changes. In particular, the leverage parameter changes sign during the financial crises. By including volatility of volatility as an additional factor, see also Huang and Shaliastovich (2014), our study distinguishes between the volatility induced skewness through the leverage effect and by the volatility of volatility induced skewness, see also Feunou and Tédongap (2012). These findings may have important consequences for the formulation of stochastic volatility models for option pricing. The empirical evidence suggests that the option markets include sources of variation that may not be present in the underlying's dynamics, such as frictions between option demand for hedging purposes and credit constrains for refinancing. It may be possible to formulate a model in which the changes in error correlations modify endogenously, possibly by controlling for the credit availability on the market.
4 Conclusions
In this paper, we describe two methods for representing derivatives of multivariate curves using FPCA techniques. First, spectral decomposition is applied to the dual covariance matrix of derivatives. Secondly, the dual covariance of the original curves is considered, and derivatives are obtained by differentiation of the functional principal components of the covariance operator. Thus, the second approach expresses the dynamics of derivatives in terms of uncorrelated loadings but the basis functions are no longer orthonormal. We demonstrate that when an underlying factor model is assumed, estimating curve derivatives from observed discrete and noisy data using a low-dimensional representation, the second method performs better both asymptotically and in finite sample.
In the empirical study, we show that the second method provides accurate results for understanding the time variability of implied SPDs. We apply this analysis to DAX 30 index option data observed at daily frequency. Three main factors are identified, which could be linked to the diffusion processes of the stochastic volatility models. The first factor is strongly connected to the risk-neutral variance, conditional upon that no jumps occur. The second factor is related to the time varying conditional skewness induced by the leverage effect. We find that this component of negative skewness declines during the financial crises, possibly as a result of the credit crunch. Timevarying volatility of volatility constitutes an additional risk channel, which manifests as negative tail risk. Further factors are related to the term structure and jump component risk.
22

5 Appendix

5.1 Assumptions summary

Assumption 5.1 The curves Yi , i = 1, . . ., N are observed at a random grid ti1, . . ., tiTi , ti j  [0, 1]g having a common bounded and continuously differentiable density f with support supp( f ) = [0, 1]g and the integrand u  supp( f ) and inf f (u) > 0.
u
Assumption 5.2 E(ik ) = 0, Var(ik ) = i2 > 0 and ik are independent of Xi , and E 4ik < , i , k.

Assumption 5.3

Let

KB (u)

=

1 b1 ×...×b g

K (u

 b).

K

is a product kernel based on symmet-

ric univariate kernels. B is a diagonal matrix with b = (b1, . . ., bg ) at the diagonal.

The kernel K is bounded and has compact support on [-1, 1]g such that for u  Rg

uuT K (u)d u = µ(K )I where µ(K ) = 0 is a scalar and I is the g × g identity matrix.

Conditions 2 and 3 from Masry (1996) are fulfilled.

Assumption 5.4  -

g l =1

dl

and

p

-

g l =1

dl

are

odd.

Assumption 5.5 |^ 2i - 2i| = OP (T -1/2)

Assumption 5.6 We require that it holds

(42)

sup sup |r(d)(t )| <  , sup sup |r(d)(t )| < 

r N t [0,1]g

r N t [0,1]g

(43)


E

(ri) 2 (si ) 2

<,




E

r(i) 2 (si )(qi) < ,  = (0, d )

r =1 s=1

q=1 s=1

for all r  N.

Assumption 5.7 We require that the eigenvalues are distinguishable such that for any

T and N and fixed r  1, . . ., L there exists 0 < C1,r < , 0 < C2,r  C3,r <  such that

(44)

N C 2,r



l

() r



N C 3,r

s

min
=1,...,N ;s=r

|lr()

-

l

s()|



N

C

1,r

.

5.2 Proof of Lemma 2.1

1. Univariate case (g=1) -- In the following proof we use d instead of . As

noted by Ruppert and Wand (1994) equation (16) can be stated up to a vanish-

ing constant using equivalent kernels. Equivalent kernels can be understand as an

asymptotic version of WdT . Let el be a vector of length  with 1 at the l + 1 posi-

tion and zero else. Then WdT (t ) evaluates the function at point u and is defined as

(T bd+1)-1edT ST (u)-1(1, t , . . ., t )T K (t ). ST (u) is a  ×  matrix with entries ST,k (u) =

(T b)-1

T l =1

K

tl -u b

(

tl

-u b

)k

such

that

ST,0(u) ST,1(u) . . . ST,(u) 

(45)

ST

(u

)

=

S    

T,1(u) ...

ST,2(u) ...

... ...

ST,+1 ...



 

.





ST,(u) ST,+1(u) . . . ST,2(u)

23

Accordingly

(46)

1T

E(ST,k (u)) =(T b)-1

K

0 l =1

x -u b

x-u k f (x)d x
b

=b-1

1+u x K

xk f (x)d x =

(1+u)b-1
K (t ) t k f (t b)d t .

u bb

ub-1

Since K (t ) has compact support and is bounded, for a point at the left boundary

with c  0 u is of the form u = cb and at the right boundary u = 1 - cb respectively. We

define Sk,c =

 -c

tkK

(t )d t

and

Sk,c

=

c -

t

k

K

(t

)d

t

respectively

and

for

interior

points

Sk =

 -

t

k

K

(t

)d

t.

Further

we

construct

the

p

×

p

Matrix

corresponding

to

(45)

with



(47)

S(u) = Sc = (S j +l,c )0j,l

, u is a boundary point .

S = (S j +l )0j,l , u is an interior point

The

equivalent

kernel

is

then

defined

as

K

u d ,

(t

)

=

edT

S(u)-1(1,

t

,.

.

.,

t

 )T

K

(t

)

and

the

estimator can be rewritten as

(48)

X^

(d b

)

(u)

=

d !d (u)

=

T

f

d! (u )b d +1

T
Kdu,
l =1

tl - u b

Y (tl ){1 + OP (1)}.

The only difference between WdT and Kdu, is that ST (u) is been replaced by f (u)S(u).

Regarding

Masry

(1996)

we

can

further

state

that

with

a

bandwidth

fulfilling

l og (T ) Tb



0

we

have uniformly in u  [0, 1] that ST (u)-1



S(u)-1 f (u)

almost

surely as

T

 .

We will

drop the u index concerning the equivalent kernel from now on.

By construction, the equivalent kernel fulfills that using the Kronecker-Delta 

(49)

uk

K

 d ,

(u)

d

u

=

d

,k

0  d,k  .

As mentioned by Fan et al. (1997), the design of the kernel automatically adapts to the boundary which gives the same order of convergence for the interior and boundary points, see Ruppert and Wand (1994). The estimator can be rewritten as

TT
d !2 WdT
j =1 l =1

tj -u b

WdT

tl - u b

Y (tl )Y (t j )d u

(50)

=

T

2

f

d !2 (u )2 b 2d +2

T l =1

T j =1

Kd,

tj -u b

Kd,

tl - u b

Y (tl )Y (t j ){1 + OP (1)}d u.

24

For the expectation we get

(51)

E d,|t1, . . ., tT

1 TT

=

0

d !2 WdT
j =1 l =1

tj -u b

WdT

tl - u b

X (tl )X (t j )d u

+ d !2 2 - ^ 2

1T
WdT
0 j =1

tj -u

2
du

b

=

d !2

1 0

1 0

1 0

f (x)f (y) b2(d+1) f (z)2

K

 d ,

x-z b

K

 d ,

y -z b

X (x)X (y)d xd yd z

1 +OP T 3/2b2d+1 {1 + OP (1)}

1
= X (d)(z)X (d)(z)d z
0

d ! 1 b+1

+2 ( + 1)! 0

bd

1

0

u+1K

 d ,

(u)

d

u

X (+1)(z)X (d)(z)d z

d !2 1 b2+2 + ( + 1)!2 0 b2d

12
0 u+1Kd, (u) d u X (+1)(z)X (+1)(z)d z

1 +OP T 3/2b2d+1 {1 + OP (1)}

These results where obtained by substitution with x = z + ub, y = z + vb and using a  + 1 order Taylor expansion of X (z + ub) and X (z + vb) together with (49). We get [0,1]g X (u)2d u - E(d,|t1, . . ., tT ) = Op b+1-d + T 3/2b2d+1 -1 .
First note that using the second mean value integration theorem there exits some c  (0, 1) and we can write

(52)

f (z)-2Kd,

y -z b

K

 d ,

x-z b

d z = f (c)-2

Kd,

y -z b

Kd,

x-z b

dz.

We introduce a kernel convolution with

(53)

K

C d ,

y -x

d=ef

Kd, y - z Kd, (x - z) d z

and

thus

using

z

=

u b

(54)

KdC,

y -x b

=

K

 d ,

y -z
b

K

 d ,

x -z
b

dz =

b-1Kd,

y -u b

Kd,

x -u b

du.

Note that the integral over KdC, is computed over an parallelogram D bounded by the

lines

x+y

=

2,

x

+y

=

0, x - y

=

1,

x

-y

=

-1.

Using

the

substitution

x

=

v +u 2

b,

y

=

u-v 2

b

(55)

D KdC,

y -x b

b dydx =
2

2 0

1
-1 KdC,

v +u -u +v 2

dvdu =b

K

C d ,

(v

)

d

v.

25

Note that the variance can be decomposed

(56)Var d,|t1, . . ., tT

(57)

d !4 = T 4(b4d+2) f (c)4

T
KdC, (0)2 Var(Y (tl )2)
l =1

(58)

TT
+ 2 Var(KdC,
l =1 k=l

tl - tk b

Y (tl )Y (tk ))

(59)

TT T
+ 4 Cov(KdC,
l =1 k=l k =k

tk - tl b

Y (tk )Y (tl ), KdC,

tl - tk b

Y (tl )Y (tk ))



(60)

TT T T

+ 24

Cov(K

C d ,

l =1 k=l k =k l =k

tl - tk b

Y (tl )Y (tk ), KdC,

tl - tk b

 Y (tl )Y (tk ))


1 (61) + OP T .

Expression

(60)

vanishes

and

(57)

given

by

T

d !4 3(b4d+2) f

(c )4

KdC, (0)2 Var(Y (y)2) f (y)d y{1+

OP (T -1)} is dominated by (58) because

(62)

T

2d !4 4 (b 4d +2 )

f

(c )4

T l =1

T k =l

K

C d ,

tl - tk b

2
Var(Y (tl )Y (tk ))

=

T

2d !4 4 (b 4d +2 )

f

(c )4

T l =1

T k =l

K

C d ,

tl - tk b

2

E(Y (tl )2Y (tk )2) - E(Y (tl )Y (tk ))2

2d !4 (4 + 22 X (x)2) f (x)2d x = T 2b4d+1 f (c)4

K dC, (u )

2
du +OP

1 T 2b4d+1

.

Before looking at expression (59), note that with m  2d

d !2 b 2d +1

KdC,

x-y b

X (x)d xd y

(63)

d !2 = b2d

Kd, (m) Kd, (z) X y + (m - z)b d zd md y

1
=(-1)d X (2d)(y)d y + OP (1)
0

by performing two Taylor expansions with mb first and then -zb.

26

We can thus derive for expression (59) that

TT T

H (T )

Cov(KdC,

l =1 k=l k =k

tk - tl b

Y

(tk

)Y

(tl

),

K

C d ,

tl - tk b

Y (tl )Y (tk ))

TT T

=H (T )

K

C d ,

l =1 k=l k =k

tk - tl b

KdC,

tl - tk b

E Y (tk )Y (tl )2Y (tk )

- E Y (tk )Y (tl ) E Y (tl )Y (tk )

TT T

=H (T )

KdC,

l =1 k=1 k =1

tk - tl b

K

C d ,

tl - tk b

X (tk )2 X (tk )

-

T

2d !4 4(b4d+2) f

(c )4

TT

K

C d ,

k=1 k =1

tl - tk b

2
X (tk )2 X (tk )

42 =
T f (c)

X (2d)(y )X (2d)(y )d y - OP

1 T 2(b4d+1)

,

where

H (T )

d=ef

4d !4 T 4(b4d+2) f

(c )4

.

Thus

Var

d,|t1, . . ., tT

= OP

1 T 2(b4d+1)

.

2. Multivariate case (g > 1) -- The same strategy also works in the multivariate
case by using multivariate Taylor series. Using the multi-index notation introduces in section 2.4 and a = (a1, ..., ag ), al  N+ a multivariate taylor series of degree k <  is given by

(64)

X (x

-u

 b)

=

0|a|k

X

(a)(x) (u
a!

 b)a

+OP

uk+1 max(b)k+1

.

Using the equivalent kernel by Ruppert and Wand (1994) extended to the case and us-

ing Masry (1996) we can further state that with a bandwidth fulfilling

l og (T ) T b1×...×bg

0

we

have

uniformly

in

u

 [0, 1]g

that

ST (u)-1



S(u)-1 f (u)

almost

surely

as

T

 .

Furthermore, the multivariate equivalent kernel has the properties that with v =

(v1, . . ., vg ), vl  N+

(65) uv Kd, (u) d u = d,v , |v|  , 0  di i = 1, . . .g .

Let c be the position of max(b) in b and ~ be a vector of length g which is  + 1 at the c - t h position and 0 else. Then for the bias

E d,|t1, . . ., tT

= X (d)(z)X (d)(z)d z
[0,1]g

(66)

d ! max(b)+1

+2 ( + 1)! [0,1]g

bd

u~

K

 d ,

(u

)

d

u

X (~)(z)X (d)(z)d z



max(b)+1

1

+OP

bd

+ T 3/2(b2d b1 × . . . × bg )

{1 + OP (1)} 

27

Further note that for the convoluted kernel we get

KdC, (y - x)  b-1

=

(b1

×

.

.

.

×

bg

)-1K

 d ,

(y - u)  b-1

K

 d ,

(x - u)  b-1

du.

Accordingly, we get for the multivariate equivalent of expression (58) that

T

4

f

(c

2d !4 )4(b12 × . .

.

×

bg2

b4d

)

l

T =1

T k =l

K

C d ,

(tl - tk )  b-1

2
V ar (Y (tl )Y (tk ))

2d !4 (4 + 22 X (x)2) f (x)2d x = T 2 f (c)4b1 × . . . × bg b4d

K dC, (u )

2
d u{1 + OP (1)}

and because we assume that m  2|d | we get for the multivariate equivalent of expression (59) that

TT T

A(T )

Cov(K

C d ,

(tk - tl )  b-1

Y (tk )Y (tl ), KdC,

(tl - tk )  b-1

Y (tl )Y (tk ))

l =1 k=l k =k

TT T

=A(T )

KdC, (tk - tl )  b-1 KdC, (tl - tk )  b-1 X (tk )2 X (tk )

l =1 k=l k =k

42 =
T f (c)

X (2d)(y )X (2d)(y )d y + OP

1 T 2(b4d b1 × . . . × bg )

where

A(T

)

d=ef

4d !4

T

4

(b4d

b12

×...×b

2 g

)

f

(c )4

.

5.3 Proof of Proposition 2.2

1. Asymptotic results-- We first have look at the estimator M~ (0) for the special case when a common random grid is present. The only error here comes from approximating the integral in equation (12) with a sum.

Mi(0j ) - M~ i(0j ) =

[0,1]g

Xi (t )X j (t )d t

-

1 T

T
Yi (ti l )Y j (t j l ) +
l =1

I (i

=

j )^ 2i 

(67)

1T = [0,1]g Xi (t )X j (t )d t - T l=1 Xi (tl ) + i l

X j (tl ) + j l + I (i = j )^ 2i

1T

=

[0,1]g

Xi (t )X j (t )d t

-

T

Xi (tl )X j (tl )
l =1

-

1 T

T
Xi (tl )j l
l =1

-

1 T

T
X j (tl )i l
l =1

-

1 T

Ti
i l j l
l =1

+ I (i

=

j )^ i2.

By construction, it hold that E il j l = 0, i = j , E il 2 = i2 and E Yi (tl )j l = 0.

All

sums

for

example

1 T

T l =1

Xi

(tl )X

j

(tl

)

are

the

corresponding

empirical

estimator

for the mean, i.e., [0,1]g Xi (t )X j (t )d t = E Xi X j . By the law of large numbers, it con-

verges in probability to the theoretical mean as T  . Using the central limit theo-

rem we can further state that

[0,1]g

X

i

(t

)X

j

(t

)d

t

-

1 T

T l =1

Xi

(tl

)X

j

(tl

)

is

approximately

28

normal, which gives an error of order T -1/2 regardless of dimension g . By requiring that ^ i is also T -1/2 consistent we get T -1/2 for all elements.
To understand M^ (0) we investigate two possible sources of error in the construc-
tion of the estimator. One coming from interpolation and smoothing at a common
grid and the other from approximating the integral with a sum. First note that by the same arguments as for M~ (0) the error of the integral approximation is of order T -1/2.
Besides the error for the off diagonal elements is smaller than for the diagonal, thus
the leading error source is given by Lemma 2.1. The same arguments also work to derive asymptotic results for M^ (d).

5.4 Proof of Proposition 2.4

Under the assumptions of Proposition 2.4 together with the requirements of Lemma 2.2 for  = (0, d ) and the setup of Remark 2.3

(68)

||M^ () - M ()||  tr M^ () - M ()

1/2

M^ () - M ()

= Op N T -1/2 .

Given that

T l =1

pl(r )

=

0,

T l =1

p

() lr

2
= 1 r and applying Cauchy-Schwarz inequality

gives

N l =1

|p

l(r )|

=

O

N 1/2

. This together with Lemma A from Kneip and Utikal (2001)

leads to

(69)

E

p

() r

2
(M^ () - M ())pr() = Op

N T

We are now ready to make a statement about the basis that span the factor space.

1 lr()

N i =1

pi(r )

X

(d i

)(t

)

-

1 l^r()

N i =1

p^i(r )

X^

(d ) i ,h

(t

)

(70)  



1 lr()

N i =1

pi(r )

X

(d i

)(t

)

-

X^

i(,dh)(t

)

N
+ 
i =1

1 lr()

p

() ir

-

1 l^r()

p^i(r )

 

X^

i(,dh)(t

)

.

The first term is discussed in equation (2.4). Therefore we take a look at the second term here. As a consequence of Assumption (5.7), Lemma A (a) from Kneip and Utikal (2001) together with equation (69) gives

(71) lr() - l^r() = (pr())T (M^ () - M ())pr()) + Op (N T -1) = Op (N 1/2T -1/2 + N T -1),

where (72)

1 -
l^r()

1 =

l

() r

lr() - l^r() l^r() lr()( l^r() +

= Op T -1/2N -1 + T -1N -1/2 . lr())

Using Lemma A (b) from Kneip and Utikal (2001) we further get

(73)

|p^i(r ) - pi(r )| = Op (N T )-1/2 and ||p^r() - pr()|| = Op T -1/2 .

29

Putting all results together for the second term gives


N
 
i =1

1 lr()

p

() ir

-



1 l^r()

p^i(r )

 

X^

i(,dh)(t

)

=


N
= 
i =1

1 -
lr()



1 l^r()

 

p^i(r )

X^ i(,dh) (t

)

+

1N

l

() r

i =1

p^i(r )

-

p

() ir

X^i(,dh)(t )

(74)

 


1 -

l

() r



1  
l^r()

N
|pi(r )|
i =1

X^i(,dh)(t )



1

+ -



l

() r



1  
l^r()

||p^r() - pr()||

X^i(,dh)(t )

+

1 ||p^r() - pr()|| lr()

X^

(d ) i ,h

(t

)

=Op (N T )-1/2 X^i(,dh)(t ) - Xi(,dh)(t ) + Xi(,dh)(t )

Op (N T )-1/2 (Bias X^ j(d,h)(t ) +

Var

X^

(d ) j ,h

(t

)

+

Xi(,dh)(t ) ).

Using Cauchy-Schwarz and equation (72) we see that first term is of order (N T )-1/2.
For the second term remember that lr() is of order N together with (73) this also leads to order (N T )-1/2. Inserting the right hand side, equation (70) becomes

Op max(h)p+1h-d + Op (N T h1 . . .hg h2d )-1/2 + Op (N T )-1/2 Op max(h)p+1h-d + Op (N T )-1/2 Op (T h1 . . .hg h2d )-1/2 + Op (N T )-1/2 = Op max(h)p+1h-d + Op (N T h1 . . .hg h2d )-1/2 .

5.5 Proof of Proposition 2.5 Note that

(75)

l

(v r

)

-

l^r(v

)

=

(l

(v r

)

-

l^r(v

))(

lr(v) +

l^r(v))-1 = Op (T -1/2 + N 1/2T -1),

together with (73) gives

(76)

^i r - ^i r,T = lr(v)pi(vr ) - l^r(v)p^i(vr )

=

lr(v) -

l^r(v) pi(vr ) -

l^r(v )

p^i(vr

)

-

p

(v ir

)

= Op (T -1/2 + N 1/2T -1).

Using Proposition 2.4 it follows that

(77)

KK
|Yi (t ) - Y^i (t )| = | ^i r ^(rv)(t ) - ^i r,T ^(rv,T) (t )|
r =1 r =1 K
=| (^i r - ^i r,T )^r + ^i r,T (^r - ^r,T )|
r =1
=Op T -1/2 + N 1/2T -1 + max(h)p+1h-d + (N T h1 × . . . × hg h2d )-1/2 .

30

References
S. C. Ahn and A. R. Horenstein. Eigenvalue ratio test for the number of factors. Econometrica, 81(3):1203­1227, 2013.
B. Bahra. Implied risk-neutral probability density functions from option prices : theory and application. 1997.
J. Bai and S. Ng. Determining the Number of Factors in Approximate Factor Models. Econometrica, 70(1):191­221, 2002.
R. W. Banz. Prices for State-contingent Claims : Some Estimates and Applications. The Journal of Business, 51(4):653­672, 1978.
M. Benko, W. Härdle, and A. Kneip. Common functional principal components. The Annals of Statistics, 37(1):1­34, Februar 2009.
P. Besse and J. Ramsay. Principal components analysis of sampled functions. Psychometrika, 51(2):285­311, 1986.
R. R. Bliss and N. Panigirtzoglou. Testing the stability of implied probability density functions. Journal of Banking & Finance, 26(2-3):381­422, Mar. 2002.
N. P. B. Bollen and R. E. Whaley. Does Net Buying Pressure Affect the Shape of Implied Volatility Functions? Journal of Finance, 59:711­753, 2004.
D. Bosq. Linear processes in function spaces. Springer, 2000.
D. T. Breeden and R. H. Litzenberger. Prices of state-contingent claims implicit in option prices. Journal of Business, 51:621­651, 1987.
D. Brigo and F. Mercurio. Lognormal-mixture dynamics and calibration to market volatility smiles. International Journal of Theoretical and Applied Finance, 5:427­ 446, 2002.
H. Cardot, F. Ferraty, and P. Sarda. Functional linear model. Statistics & Probability Letters, 45(1):11­22, 1999.
H. Cardot, A. Mas, and P. Sarda. Clt in functional linear regression models. Probability Theory and Related Fields, 138(3-4):325­361, 2007.
F. Comte and E. Renault. Long memory in continuous-time stochastic volatility models. Mathematical Finance, 8(4):291­323, 1998.
G. M. Constantinides and L. Lian. The Supply and Demand of S&P 500 Put Options. SSRN Electronic Journal, 2015.
R. Cont and J. da Fonseca. Dynamics of implied volatility surfaces. Quantitative Finance, 2(1):45--60, 2002.
J. Dauxois, A. Pousse, and Y. Romain. Asymptotic theory for the principal component analysis of a vector random function: Some applications to statistical inference. Journal of Multivariate Analysis, 12:136­154, 1982.
31

C. Di, C. Crainiceanu, B. Caffo, and N. Punjabi. Multilevel functional principal component analysis. The annals of applied statistics, 3(1):458, 2009.
J. Du and N. Kapadia. Tail and volatility indices from option prices. Working paper, 2012.
J. C. Duan and C. Y. Yeh. Jump and volatility risk premiums implied by VIX. Journal of Economic Dynamics and Control, 34(11):2232­2244, 2010.
J. Fan and I. Gijbels. Variable bandwidth and local linear regression smoothers. The Annals of Statistics, 20(4):pp. 2008­2036, 1992.
J. Fan and I. Gijbels. Local polynomial modelling and its applications. Chapman and Hall, London, 1996.
J. Fan, T. Gasser, I. Gijbels, M. Brockmann, and J. Engel. Local polynomial regression: Optimal kernels and asymptotic minimax efficiency. Annals of the Institute of Statistical Mathematics, 49(1):79­99, 1997.
F. Ferraty and P. Vieu. Nonparametric functional data analysis, theory and practice. Springer, 2006.
B. Feunou and R. Tédongap. A Stochastic Volatility Model With Conditional Skewness. Journal of Business & Economic Statistics, 30(4):576­591, 2012.
N. Gârleanu, L. H. Pedersen, and A. M. Poteshman. Demand-based option pricing. Review of Financial Studies, 22:4259­4299, 2009.
J. Geweke and S. Porter-Hudak. The Estimation and Application of Long Memory Time Series Models. Journal of Time Series Analysis, 4(4):221­238, 1983.
M. Grith, W. K. Härdle, and M. Schienle. Handbook of Computational Finance, chapter Nonparametric Estimation of Risk-Neutral Densities, pages 277­305. Springer Verlag, 2012.
M. Grith, W. K. Härdle, and J. Park. Shape invariant modeling of pricing kernels and risk aversion. Journal of Financial Econometrics, 11:370­399, 2013.
J. Gu, Q. Li, and J.-C. Yang. Multivariate local polynomial kernel estimators: Leading bias and asymptotic distribution. Econometric Reviews, 34(6-7):978­1009, 2015.
P. Hall and M. Hosseini-Nasab. On properties of functional principal components analysis. Journal of The Royal Statistical Society Series B, 68(1):109­126, 2006.
P. Hall and J. S. Marron. On variance estimation in nonparametric regression. Biometrika, 77(2):pp. 415­419, 1990.
P. Hall, H.-G. Müller, and F. Yao. Estimation of functional derivatives. The Annals of Statistics, 37(6A):3307­3329, 2009.
K. W. Härdle and B. Lopez-Cabrera. The implied market price of weather risk. Applied Mathematical Finance, 19(1):59­95, 2012.
32

D. Huang and I. Shaliastovich. Volatility-of-Volatility Risk. University of Pennsylvania Preprint, 2014.
J. C. Jackwerth. Option-implied risk-neutral distributions and implied binomial trees: a literature review. Journal of Derivatives, 2:66­82, 1999.
A. Kneip and K. J. Utikal. Inference for Density Families Using Functional Principal Component Analysis. Journal of the American Statistical Association, 96(454):519­ 542, Juni 2001.
B. Liu and H.-G. Müller. Estimating derivatives for samples of sparsely observed functions, with application to online auction dynamics. Journal of the American Statistical Association, 104(486):704­717, 2009.
A. W. Lo. Long-Term Memory in Stock Market Prices. Econometrica, 59:pp. 1279­1313, 1991.
P. Majer, P. Mohr, H. Heekeren, and K. W. Härdle. Portfolio decisions and brain reactions via the cead method. Psychometrika, pages 1­23, 2015.
C. Mallows. Some comments on cp . Technometrics, 15:661­675, 1973.
A. Mas. Weak convergence for the covariance operators of a hilbertian linear process. Stochastic Processes and their Applications, 99(1):117 ­ 135, 2002.
A. Mas. Local functional principal component analysis. Complex Analysis and Operator Theory, 2(1):135­167, 2008.
E. Masry. Multivariate local polynomial regression for time series: Uniform strong consistency and rates. J. Time Ser. Anal, 17:571­599, 1996.
A. Munk, N. Bissantz, T. Wagner, and G. Freitag. On difference-based variance estimation in nonparametric regression when the covariate is high dimensional. Journal of the Royal Statistical Society Series B, 67(1):19­41, 2005.
W. K. Newey and K. D. West. A Simple, Positive Semi-definite, Heteroskedasticity and Autocorrelation Consistent Covariance Matrix. Econometrica (1986-1998), 55(3): 703­708, 1987.
Y. H. Park. Volatility-of-volatility and tail risk hedging returns. Journal of Financial Markets, 26:38­63, 2015.
J. Rice. Bandwidth choice for nonparametric regression. The Annals of Statistics, 1984.
M. Rubinstein. Nonparametric Tests of Alternative Option Pricing Models Using All Reported Trades and Quotes on the 30 Most Active CBOE Option Classes from August 23, 1976 through August 31, 1978. The Journal of Finance, 40(2):455­480, 1985.
D. Ruppert and M. P. Wand. Multivariate locally weighted least squares regression. Annals of Statistics, 22(3):1346­1370, 1994.
C. M. Staicu, A.M.and Crainiceanu and R. J. Carroll. Fast methods for spatially correlated multilevel functional data. Biostatistics, 11(2):177­194, 2010.
33

A. van Bömmel, S. Song, P. Majer, P. N. C. Mohr, H. R. Heekeren, and W. K. Härdle. Risk Patterns and Correlated Brain Activities. Multidimensional Statistical Analysis of fMRI Data in Economic Decision Making Study. Psychometrika, 79(3):489­514, 2014.
J. von Neumann, R. H. Kent, H. R. Bellinson, and B. I. Hart. The mean square successive difference. The Annals of Mathematical Statistics, 12(2):pp. 153­162, 1941.
R. Weron. Estimating long-range dependence: finite sample properties and confidence intervals. Physica A: Statistical Mechanics and its Applications, 312(1-2):285­ 299, 2002.
V. Zipunnikov, B. C. Caffo, D. M. Yousem, C. Davatzikos, B. S. Schwartz, and C. M. Crainiceanu. Functional principal component model for high-dimensional brain imaging. NeuroImage, 58(3):772­784, 2011.
34

SFB 649 Discussion Paper Series 2016
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "Downside risk and stock returns: An empirical analysis of the long-run and short-run dynamics from the G-7 Countries" by Cathy Yi-Hsuan Chen, Thomas C. Chiang and Wolfgang Karl Härdle, January 2016.
002 "Uncertainty and Employment Dynamics in the Euro Area and the US" by Aleksei Netsunajev and Katharina Glass, January 2016.
003 "College Admissions with Entrance Exams: Centralized versus Decentralized" by Isa E. Hafalir, Rustamdjan Hakimov, Dorothea Kübler and Morimitsu Kurino, January 2016.
004 "Leveraged ETF options implied volatility paradox: a statistical study" by Wolfgang Karl Härdle, Sergey Nasekin and Zhiwu Hong, February 2016.
005 "The German Labor Market Miracle, 2003 -2015: An Assessment" by Michael C. Burda, February 2016.
006 "What Derives the Bond Portfolio Value-at-Risk: Information Roles of Macroeconomic and Financial Stress Factors" by Anthony H. Tu and Cathy Yi-Hsuan Chen, February 2016.
007 "Budget-neutral fiscal rules targeting inflation differentials" by Maren Brede, February 2016.
008 "Measuring the benefit from reducing income inequality in terms of GDP" by Simon Voigts, February 2016.
009 "Solving DSGE Portfolio Choice Models with Asymmetric Countries" by Grzegorz R. Dlugoszek, February 2016.
010 "No Role for the Hartz Reforms? Demand and Supply Factors in the German Labor Market, 1993-2014" by Michael C. Burda and Stefanie Seele, February 2016.
011 "Cognitive Load Increases Risk Aversion" by Holger Gerhardt, Guido P. Biele, Hauke R. Heekeren, and Harald Uhlig, March 2016.
012 "Neighborhood Effects in Wind Farm Performance: An Econometric Approach" by Matthias Ritter, Simone Pieralli and Martin Odening, March 2016.
013 "The importance of time-varying parameters in new Keynesian models with zero lower bound" by Julien Albertini and Hong Lan, March 2016.
014 "Aggregate Employment, Job Polarization and Inequalities: A Transatlantic Perspective" by Julien Albertini and Jean Olivier Hairault, March 2016.
015 "The Anchoring of Inflation Expectations in the Short and in the Long Run" by Dieter Nautz, Aleksei Netsunajev and Till Strohsal, March 2016.
016 "Irrational Exuberance and Herding in Financial Markets" by Christopher Boortz, March 2016.
017 "Calculating Joint Confidence Bands for Impulse Response Functions using Highest Density Regions" by Helmut Lütkepohl, Anna StaszewskaBystrova and Peter Winker, March 2016.
018 "Factorisable Sparse Tail Event Curves with Expectiles" by Wolfgang K. Härdle, Chen Huang and Shih-Kang Chao, March 2016.
019 "International dynamics of inflation expectations" by Aleksei Netsunajev and Lars Winkelmann, May 2016.
020 "Academic Ranking Scales in Economics: Prediction and Imdputation" by Alona Zharova, Andrija Mihoci and Wolfgang Karl Härdle, May 2016.
SFSBF6B4694, 9S,pSapnadnaduaeureSrtrSatßraeß1e, 1D,-D10-1107187B8eBrleinrlin htthpt:t/p/:/s/fbs6fb4694.w9.iwwiiw.hiu.h-bue-brleinrl.idne.de
ThTishrisesreasercahrcwhawsassupsuppoprtoerdtebdybtyhethDeeDuetsucthseche ForFsocrhsuchnugnsgesgmeeminesicnhsachftatfht rtohuroguhgthhethSeFSBF6B4694"9Ec"oEnconmoimc RicisRki"s.k".

SFB 649 Discussion Paper Series 2016
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
021 "CRIX or evaluating blockchain based currencies" by Simon Trimborn and Wolfgang Karl Härdle, May 2016.
022 "Towards a national indicator for urban green space provision and environmental inequalities in Germany: Method and findings" by Henry Wüstemann, Dennis Kalisch, June 2016.
023 "A Mortality Model for Multi-populations: A Semi-Parametric Approach" by Lei Fang, Wolfgang K. Härdle and Juhyun Park, June 2016.
024 "Simultaneous Inference for the Partially Linear Model with a Multivariate Unknown Function when the Covariates are Measured with Errors" by Kun Ho Kim, Shih-Kang Chao and Wolfgang K. Härdle, August 2016.
025 "Forecasting Limit Order Book Liquidity Supply-Demand Curves with Functional AutoRegressive Dynamics" by Ying Chen, Wee Song Chua and Wolfgang K. Härdle, August 2016.
026 "VAT multipliers and pass-through dynamics" by Simon Voigts, August 2016.
027 "Can a Bonus Overcome Moral Hazard? An Experiment on Voluntary Payments, Competition, and Reputation in Markets for Expert Services" by Vera Angelova and Tobias Regner, August 2016.
028 "Relative Performance of Liability Rules: Experimental Evidence" by Vera Angelova, Giuseppe Attanasi, Yolande Hiriart, August 2016.
029 "What renders financial advisors less treacherous? On commissions and reciprocity" by Vera Angelova, August 2016.
030 "Do voluntary payments to advisors improve the quality of financial advice? An experimental sender-receiver game" by Vera Angelova and Tobias Regner, August 2016.
031 "A first econometric analysis of the CRIX family" by Shi Chen, Cathy YiHsuan Chen, Wolfgang Karl Härdle, TM Lee and Bobby Ong, August 2016.
032 "Specification Testing in Nonparametric Instrumental Quantile Regression" by Christoph Breunig, August 2016.
033 "Functional Principal Component Analysis for Derivatives of Multivariate Curves" by Maria Grith, Wolfgang K. Härdle, Alois Kneip and Heiko Wagner, August 2016.
SFSBF6B4694, 9S,pSapnadnaduaeureSrtrSatßraeß1e, 1D,-D10-1107187B8eBrleinrlin htthpt:t/p/:/s/fbs6fb4694.w9.iwwiiw.hiu.h-bue-brleinrl.idne.de
ThTishrisesreasrecahrcwhawsassupsuppoprtoerdtebdybtyhethDeeDuetsucthseche ForFsocrhsuchnugnsgesgmeeminesicnhsachftatfht rtohuroguhgthhethSeFSBF6B4694"9Ec"oEnconmoimc RicisRki"s.k".

