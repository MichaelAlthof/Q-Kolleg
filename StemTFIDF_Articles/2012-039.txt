BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2012-039
Volatility of price indices for heterogeneous goods
Fabian Y.R.P. Bocart* Christian M. Hafner*
* Institut de statistique, Université catholique de Louvain, Belgium
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universität zu Berlin Spandauer Straße 1, D-10178 Berlin

Volatility of price indices for heterogeneous goods

Fabian Y.R.P. Bocart

Christian M. Hafner

May 23, 2012

Abstract
Price indices for heterogenous goods such as real estate or fine art constitute crucial information for institutional or private investors considering alternative investments in times of financial markets turmoil. Classical mean-variance analysis of alternative investments has been hampered by the lack of a systematic treatment of volatility in these markets. This may seem surprising as derivatives on subsets of the traded goods require a precise modelling and estimation of the underlying volatility. For example, in art markets, auction houses often give price guarantees to the seller that resemble put options. In this paper we propose a hedonic regression framework which explicitly defines an underlying stochastic process for the price index, allowing to treat the volatility parameter as the object of interest. The model can be estimated using maximum likelihood in combination with the Kalman filter. We derive theoretical properties of the volatility estimator and show that it outperforms the standard estimator. We show that extensions to allow for time-varying volatility are straightforward using a local-likelihood approach. In an application to a large data set of international blue chip artists, we show that volatility of the art market, although generally lower than that of financial markets, has risen over the last years and, in particular, during the recent European debt crisis.

Keywords: Volatility, heterogenous goods, hedonic regression, random effects
JEL classification: C14, C43, Z11
Institut de statistique, Universit´e catholique de Louvain, Belgium. Corresponding author. Institut de statistique and CORE, Universit´e catholique de Louvain, Voie du Roman Pays, 20, 1348 Louvain-la-Neuve, Belgium. This research was supported by the Deutsche Akademische Auslandsdienst and Deutsche Forschungsgemeinschaft through the SFB 649 Economic Risk. We would like to thank Christian Gouri´eroux, Wolfgang H¨ardle, and seminar participants at the Deutsche Statistische Woche in Leipzig, Weierstrass Institute Berlin, Humboldt-University Berlin, University of Cologne and CREST/Paris for helpful discussions and comments. A large part of the paper was written while the second author was visiting the Institute of statistics and econometric at Humboldt-University, whose hospitality is gratefully acknowledged.

1 Introduction
Over the last two decades, there has been a growing interest among scholars, business practitioners, and policy makers in price indices tracking the financial performance of a basket of heterogeneous goods. These price indices have typically been developed for physical assets that can be considered as investments, such as housing, art, wine, as well as many other collectibles (musical instruments, watches, jewelry, etc.). In addition to managing all risks specific to physical assets (forgery, theft, destruction, etc.), investors in physical assets must deal with the risks common to all financial investments: market risks, liquidity risks and counterparty risks. Obviously, prior to modelling and managing these financial risks, a pre-requisite is to have an estimate of the underlying time series of prices and volatility of returns.
Returns of baskets of physical assets need to be indirectly estimated because of the presence of heterogeneity in the series. Generally, two methodologies are used to cope with this problem: the repeat sale methodology (RSM) and the hedonic regression. Some advantages and disadvantages of hedonic regression as compared to RSM for estimating returns in the art market are discussed in Ginsburgh et al. (2006). Dorsey et al. (2010) discuss hedonic versus repeat-sales indices in the real estate market of Los Angeles and San Diego metropolitan areas. RSM can be viewed as a nested case of hedonic regression and consists of computing average returns of identical goods sold through time. A major critique is that RSM focuses on a small, biased sample of goods (see Collins et al., 2009). RSM has been used to develop real-estate price indices by Case and Shiller (1987) and Goetzmann (1992). Pesando (1993), Goetzmann (1993) and Mei and Moses (2002) use RSM to estimate returns in the art market.
The hedonic approach is to regress the price of each good on its characteristics, in order to control for variations due to observable differences between heterogeneous goods. The classical approach is to include time dummy variables in the regression, whose coefficients constitute the basis for building an index. Hedonic regression has been extensively used to build price indices. A few examples are de la Barre et al. (1994), Collins et al. (2009), Hodgson and Vorkink (2004), Renneboog and Spaenjers (2010) and Bocart and Hafner (2011) for art markets, Schulz and Werwatz (2004) and Gouri´eroux and Laferrere (2009) for real estate, Combris et al. (1997) and Fogarty (2006) for wine and Graddy and Margolis (2011) for violins.
The choice of an initial functional form to model returns is frequently debated in the literature. Empirically, Hansen (2009) finds that hedonic and repeat-sales methods provide similar estimates of price growth of Australian real estate when the sample is large. Dorsey et al. (2010) suggest that hedonic regression methods perform better at a local level to track prices of real estate in Los Angeles and San Diego. For the art market, Ginsburgh et al. (2006) show that
1

hedonic regression performs better than RSM when the sample size is small, while giving very similar results in large samples.
The goal of this article is to challenge the classical methodology of constructing the index using ordinary least squares (OLS), implicitly assuming deterministic prices, which is incoherent with a subsequent modelling of prices and returns as a stochastic process. Similar to the discussion of fixed versus random effects in the literature on panel data, we show that parameter estimation is more efficient exploiting the structure of a hypothesized random process. In particular, for an assumed random walk or stationary autoregressive process for the underlying market index, we derive explicitly the efficiency gains that can be achieved with maximum likelihood estimation compared to OLS. Since the parameters of interest are the variances of the two error components, these efficiency gains are equivalent to a more precise estimation of idiosyncratic and market volatility.
Interpreting the hedonic regression as an unbalanced panel model with time effects rather than individual effects, we further show that the fact of having an unbalanced panel deteriorates the properties of the estimators compared to the case of balanced panels with the same average number of observations, but that this negative effect disappears as the average number of observations per period increases. It should be understood that data of heterogeneous asset prices are typically highly unbalanced. In art markets, for example, sales are concentrated in spring and fall, with very few observations in summer.
Having in mind the large swings of volatility in financial markets, especially in crisis times, it is doubtful whether markets for heterogeneous goods have constant volatility. We therefore suggest a nonparametric extension of our model, allowing idiosyncratic and market volatility to be a smooth function of time that captures long-run trends in volatility. The functions can be conveniently estimated by local maximum likelihood.
We apply our methodology to the market of highly traded artworks in the period from 2000 to 2011. An ongoing debate about the diversification benefits of art in a portfolio has been taking place since Baumol (1986), and we contribute to this literature by explicitly delivering information about the associated risks of investing in this market. Our results suggest that long-run volatility of art followed a similar pattern as in financial markets, increasing during the financial crisis 2008/09 and the recent European debt crisis. On the other hand, the price trend seems to have been opposite during these two crises: While the trend was negative during the crisis following the Lehman Brothers bankruptcy, it was positive during the debt crisis. The latter observation might suggest that investors are increasingly considering art as an asset yielding diversification benefits in their portfolio during crisis times. Further studies using more data and explicitly modelling correlations between various markets for alternative investments
2

are needed to confirm this result. The remainder of the paper is organised as follows. In Section 2, the basic model is presented.
The third section introduces maximum likelihood estimation and compares efficiency of MLE with OLS. Section 4 discusses three extensions of the basic model, and Section 5 elaborates the results by applying the methodologies to empirical data on the art market. The last section closes this paper with final conclusions.

2 The model

As hedonic regression can be viewed as a generalization of the RSM approach, we consider an initial model that complies with the definition of a fully specified hedonic regression. However, the proposed estimation procedure can equally be applied to the RSM case.
Let there be N observed transactions and pi denote the price of sale i. The logarithm of this price is usually modelled by the following hedonic regression model,

TK
Yi = log pi = tdit + kXik + ui,
t=1 k=1

i = 1, ..., N.

(1)

The variable dit is a dummy taking the value 1 if the object i was sold in period t, and 0 otherwise. The parameters t will be used to construct the pricing index. The parameters k are the coefficients of the explanatory variables, including a constant intercept term.
The time index t = 1 corresponds to the first period of the series and is used as benchmark. For identification, we set 1 equal to zero. The K variables Xik are all characteristics of the object i that have an impact on its price. For example, for a housing price index this would be variables such as the number of bathrooms and a dummy for a swimming-pool, for an art price index it would be the height, surface, and dummies for the artists, subject, etc. The price index, with base 100 in t = 1 is then defined as

Indext = 100 exp(t),

(2)

possibly corrected by a bias correction factor (see Jones and Zanola, 2010). The regression (1) is generally estimated using Ordinary Least Squares (OLS). OLS es-
timators are efficient when errors ui are normally distributed with constant variance, i.e., ui  N (0, u2). Empirical data, however, often violate this assumption. Hodgson and Vorkink (2004) and Sec¸kin and Atukeren (2006) focus on the normality part and propose a semipara-
metric estimator of the index based on a nonparametric error distribution, while maintaining

3

the assumption that ui is i.i.d. and, hence, homoskedastic. Furthermore, t is, by model assumption, a deterministic parameter rather than a stochastic
process. To that extent, price indices built using OLS procedure cannot be interpreted as a random motion such as stock indices observed in financial markets. Nevertheless, it is standard practice to estimate t as if it was a deterministic parameter, and then continue working with the estimated t as if it was a realization of a stochastic process. As we will see, this methodological incoherence has important consequences for the properties of volatility estimators.
Note that model (1) can be written equivalently in the form

Yit = t + Xit + uit, t = 1, . . . , T ; i = 1, . . . nt

(3)

where Yit is the log price of the i-th sale at time t, and nt is the number of sales at time t. The vector Xit contains the K explanatory variables of the i-th sale at time t, and  is a (K × 1) parameter vector. This model can be viewed as an unbalanced panel model with time effects.
Individual effects are absent because the object of the i-th transaction at time t is not necessarily the same as the object of the i-th transaction at time t, t = t. In fact, the ordering of the sales
at a given time t is irrelevant as long as the error term uit is i.i.d. across sales. As is well known from the panel literature, the common OLS estimator of the hedonic
regression (1) is equivalent to the fixed effects estimators ^F E and ^F E of (3). Defining the (nt × 1) vector at = (1, . . . , 1), these are given by ^F E = ( t XtQtXt)-1 t XtQtYt and

^t

=

1 nt

nt
(Yit
i=1

- Xit^F E),

t = 2, . . . , T

(4)

where Qt = Int - atat /nt is the projection matrix taking deviations with respect to time means.

For example, a typical element of the matrix QtXt is Xit - X¯t, where X¯t =

nt i=1

Xit/nt.

The

fixed effects estimator has the advantage of being consistent even if Xt is endogenous with respect

to time. However, it is inefficient under random effects, and as we will see this inefficiency is

particularly strong for our object of interest, i.e., the volatility of t. As an alternative, a random effects approach would assume that t  N (0, 2 ), which yields
the possibility to directly estimate volatility 2 of the underlying random process. Identification
is achieved by setting the expectation of t to zero, so that the restriction 1 = 0 is not needed.

Stacking for each t the observations Yit into a (nt × 1) column vector Yt, and the explanatory variables into a (K × nt), matrix Xt, the model can be written compactly as

Yt = Xt + att + ut, t = 1, . . . , T, i = 1, . . . nt

(5)

4

where ut = (u1t, . . . , unt,t). As in classical random effects models, we now need to impose
exogeneity of the regressors with respect to the time component, i.e., E[t|X] = 0. This allows to consider t = att +ut as a composite error term with variance t = atat2 +u2Int, and estimate  in the regression Yt = Xt + t by feasible GLS, ^GLS = ( t Xt^ t-1Xt)-1 t Xt^ -t 1Yt, where ^ t is a consistent estimator of t. In order to test the validity of the exogeneity assumption, a
Hausman-type test statistic can be constructed as

H = (^F E - ^GLS )(VF E - VGLS )-1(^F E - ^GLS ),

(6)

where VGLS = ( t Xt^ t-1Xt)-1, and VF E = ^u2( t XtQtXt)-1. Under the null hypothesis, H has an asymptotic 2 distribution with K degrees of freedom. If the null is not rejected, then

the exogeneity assumption of X would appear reasonable and ^GLS is consistent and efficient.

In

a

second

step,

the

realizations

of

t

can

be

estimated

by

^t

=

1 nt

in=t 1(Yit - Xit^GLS ).

These ^t will have a mean close to zero, but ^1 is not necessarily close to zero. One can apply

the adjustment ^t - ^1, t = 1, . . . , T , if the usual standardization 1 = 0 is required in order to

obtain an index value of 100 at the beginning of the sample.

We now extend the classical random effects model by introducing assumptions about the

dynamics of t. In particular, we will assume an autoregressive process or order one, AR(1),

including the random walk as a special case:

t = t-1 + t,

(7)

with ||  1 and 0 = 0. The system (5)-(7) is a state space representation. If one imposes a normality assumption on both error terms, maximum likelihood and the Kalman filter can be applied to efficiently estimate the state variables t. This will be discussed in Section 3.
Before that, however, let us discuss in this dynamic framework the properties of the fixed effects estimator for t and the implied estimators of u2 and 2. Let us assume for simplicity that  is known. For example, a typical choice would be to set  = 1, meaning that log-prices follow a random walk, and the sequence t represents the returns. One could estimate , assuming stationarity, in a two step procedure where in a first step, consistent fixed effects estimates of t are obtained, and in a second step, the AR(1) model (7) is estimated. It is however more common to directly assume a random walk for log-prices, which also simplifies the analysis of volatility estimators. Possible model extensions, allowing e.g. for autocorrelations of returns t, are delegated to Section 4.
Our assumptions are summarized in the following.
(A1) The error terms uit and t are mutually independent, i.i.d. with mean zero, variances u2

5

and 2, respectively, and finite fourth moments.

(A2) The number of observations, nt, is a positive integer i.i.d. random variable, satisfying P (nt  2) > 0.

Consider the following estimator of u2:

^u2 =

1-

1 T

T t=1

1 nt

-1

1 T

T t=1

1 nt

nt
(Yit - ^t - Xit^)2
i=1

If n1 = n2 = . . . = nT = N , then the estimator is given by

^u2

=

(N

1 -

1)T

T

N
(Yit - ^t - Xit^)2

t=1 i=1

Estimated returns, ^t say, are obtained by ^t = ^t - ^t-1, and the variance of returns is

estimated by

^2

=

1 T

T
(^t
t=1

-

T

-1

T j=1

^j )2

-

(1

+

2)^u2

1 T

T t=1

1 nt

For the particular case nt = N, t = 1, . . . , T , and  = 0, this estimator becomes

^2

=

1 T

TT
(^t - T -1 ^j )2 -
t=1 j=1

1 N

^u2

which is the well known variance estimator in panel data analysis with time and cross section units reversed, see e.g. equation (3.10) of Arellano (2003).

Proposition

1

Under

(A1)

and

(A2),

^u2

and

^2

are

 T -consistent

estimators

of

u2

and

2,

respectively.

We can further derive the asymptotic distribution of the OLS estimator of  = (u2, 2), but need an additional distributional assumption.
(A1') The error terms uit and t are mutually independent with uit  N (0, u2) and t  N (0, 2). Clearly, (A1') encompasses and substitutes (A1).
(A3) E[|uit|4+] <  and E[|t|4+] < , for  > 0.

6

Proposition 2 Under (A1'),(A2) and (A3),

 T

(^

-

)

d

N

0,

2u4

lim
T 

E[T

]

,

T =

uu,T uv,T

uv,T vv,T

where

uu,T uv,T vv,T

=

T -1 T -1

T t=1

(nt

-

1)/nt2

Tt=1(nt - 1)/nt

2,

=

-(1

+

2)uu,T

1 T

T t=1

1 nt

,

=

2 u2

+

1 nt

+

2 nt-1

2

+

22 n2t-1

+ (1 + 2)2uu,T

1T 1 T t=1 nt

2

+

Var(

1 nt

)

(8) (9) (10)

For the balanced case, i.e., nt = N, a.s., t = 1, . . . , T , this result reduces to



1

T

=



=

 -

N -1
(1+2 ) N (N -1)

2 u2

+

-

(1+2 ) N (N -1)

2

1+2 N

+

22 N2

+


(1+2)2 
N 2(N -1)

 Note that for the large N , large T case, we would obtain N T (^u2 - u2) d N (0, 2u2) and limN,T  Cov(^u2, ^2) = 0. Hence, both variance estimators are independent if sufficient crosssectional data is available. However, N T (^2 - 2) diverges since additional cross-sectional data does not increase the information about 2. In order to assess the effects of an unbalanced panel on the efficiency compared with the
balanced panel case, let us assume that nt - 1 follows a Poisson distribution with parameter , P o(). Figure 2 plots the relative efficiencies of the estimators of u2 and 2, calculated as the ratio of the asymptotic variances under the assumption of a fixed design with N = 1 + 
(numerator), and an unbalanced P o() design (denominator). While this relative efficiency only
depends on the distribution of nt for u2, it depends on the population parameters u2 and 2 for the estimation of 2. For the calculation, we used u2 = 1 and 2 = 0.01, which corresponds to typical empirical estimates (see Section 5). Clearly, the unbalanced design decreases the

efficiency of both estimators, but the relative inefficiency disappears as the average number of observations, given by 1 + , increases.

7

Figure 1: Relative efficiency of the estimators of u2 (solid line) and 2 (dashed line), calculated as the ratio of the asymptotic variances under the assumption of a fixed de-
sign (numerator), and an unbalanced design with Poisson distribution (denominator).
The abscissa represents the parameter  of the Poisson distribution.

3 Maximum likelihood estimation

To estimate model (5)-(7), we propose a maximum likelihood estimator combined with the
Kalman filter to recover the underlying state variables. The composite error term it = uit + t can be obtained as it = Yit - Xit^GLS. One can
write the model (5) as

Yit = Xit + it, t = 1, . . . , T ; i = 1, . . . nt

(11)

The joint model (5)-(7) then reads compactly

t = att + ut t = t-1 + t,

(12) (13)

where t = (1t, . . . , nt,t). This linear Gaussian state space representation (12)-(13) allows us to estimate the underlying t, for given parameter estimates, using the Kalman filter. This will

8

be shown in the following. Note that

(t|1, . . . , t-1)  N (t|t-1, (t|t - 1)) (t|1, . . . , t)  N (t|t, (t|t))
(t|1, . . . , t-1)  N (t|t-1, (t|t - 1))

(14) (15) (16)

For a given set of parameters, the conditional means and variances can be obtained using the following Kalman recursions:

1. Prediction step (t = 1, . . . , T )

t|t-1 = t-1|t-1 2 (t|t - 1) = 22 (t - 1|t - 1) + 2
t|t-1 = att|t-1 (t|t - 1) = at2 (t|t - 1)at + u2Int
2. Correction step (t = 1, . . . , T )

(17) (18) (19) (20)

t|t = t|t-1 + 2 (t|t - 1)at - 1(t|t - 1)(t - t|t-1) 2 (t|t) = 2 (t|t - 1) - 4 (t|t - 1)at - 1(t|t - 1)at

(21) (22)

3. Smoothing step (t = T - 1, T - 2, . . . , 1) To estimate the underlying state t, one uses the full sample information (t = 1, . . . , T ).

t|T

=

t|t

+



2 2 (t

(t|t) + 1|t)

t+1|T - t+1|t

2 (t|T )

=

2

(t|t)

+

2

4 4 (t

(t|t) + 1|t)

2 (t + 1|T ) - 2 (t + 1|t)

(23) (24)

Parameter estimation can be achieved in an efficient and straightforward way by maximum
likelihood. Denote the parameter vector by  = (2, u2) and define the parameter space  = { : 2 > 0, u2 > 0}. If stationarity is imposed on the AR(1) model in (7), that is, || < 1,

9

then  could be included in  and be jointly estimated with 2 and u2. We do not discuss this possibility further, however, since we want explicitly to allow for the unit root case,  = 1.
Let et() = t - t|t-1 and t() = (t|t - 1). Then, the log-likelihood, up to an additive constant, can be written as

L()

=

-

1 2

T t=1

ln(|t()|) + et()t()-1et()

and the maximum likelihood estimator is defined as

(25)

^ = arg max L(),

with parameter space  = R2+. The maximization problem has no analytical solution, but numerical methods can be used conveniently. In large dimensions, computational problems may arise due to the optimization of a function that involves frequent calculation of the determinant and inverse of high dimensional matrices. We can exploit however the particular structure of t to obtain explicit formulas that largely facilitate the optimization. It can easily be shown that |t| = u2(nt-1)(ntt-1 + u2) and t-1 = (ntt-1 + u2)-1atat /nt + (Int - atat /nt)/u2, where t = 22(t|t) + 2. Using these expressions in (25) reduces computational costs substantially.
The term , the estimated standard deviation of , corresponds to the volatility of returns of the underlying portfolio.
In order to obtain asymptotic theory, we need the following additional assumption.

(A4) Assume that 0, the true parameter vector, is an interior point of .

Proposition 3 Under (A1'), (A2), (A3) and (A4), the MLE of  is consistent and asymptotically normally distributed,

 T

(^

-

0)

d

N

0, lim
T 

I() -1 T

where

I ()

=

-E

2 ln L() 

=

1T 2 t=1

vec(t) 

(t-1



t-1

)

vec(t) 

+

2E

et 

t-1

et 

Analytical expressions for the derivatives used to calculate I() are provided in Appendix B.

10

Finally, for the special case  = 0, we obtain t = 2atat + u2Int, et() = t, et()/ = 0, and vec(t)/ = (vec(Int), at ). Straightforward calculations show that, for this special case,
I() reduces to

I ()

=

T 2u4

 N

-

1

+

(N

2 u2

+ 1)-2

N

(N

2 u2

+ 1)-2

N

(N

2 u2

N

2(N

2 u2

+ 1)-2 + 1)-2

 

,

yielding the asymptotic covariance matrix

lim
T 

I () T



-1

=

2u4

1

 -

N -1
1 N (N -1)



2 u2

+

-
1 N

N

1 (N -1) 2
+N

1 2(N

-1)



(26)

Comparing (26) with (2), we see that for the special case  = 0, the MLE estimator has the

same asymptotic distribution as the OLS estimator and, hence, both estimators are asymptot-

ically equivalent. If  = 0, however, the estimators are different. In the following we discuss

their efficiency.

We consider several scenarios in order to compare the efficiency of the OLS and maximum

likelihood estimators of volatility. Since log prices are usually assumed to follow a random walk,

we set  = 1. Moreover, we assume that it are observed directly, in order to focus on the estimation of  without needing to estimate . It may be expected that MLE of  is even more

efficient relative to OLS if  is estimated jointly with .

To further simplify the analysis, note that only the ratio of u2 and 2 is of interest, since the scaling of the data it is irrelevant. Hence, we set u to one without loss of generality.
We assume a balanced panel with N = 5, 10, 20 and 50 observations per period. Define the

asymptotic relative efficiency as

lim
T 

Var(^M LE ) Var(^OLS )

which, if MLE is more efficient than OLS, is a number between 0 and 1. Table 1 reports the

asymptotic relative efficiencies.
Note that in all situations, the OLS estimator of u2 is almost as efficient as the ML estimator. However, this is not the case for our parameter of interest, the variance of index returns, 2. Here, the efficiency loss of OLS is remarkable in cases where  is small, even if N is large. Figure 2 depicts the relative efficiencies of the estimator of 2. Clearly, for 2 close enough to zero, the relative efficiency is arbitrarily small no matter how large N . This motivates the ML

estimator, knowing that small values of  are empirically relevant as we will see in Section 5.

11

Table 1: Asymptotic relative efficiency of ^OLS w.r.t. ^MLE.

2 N = 5

N = 10

N = 20

N = 50

^2 ^u2 ^2 ^u2 ^2 ^u2 ^2 ^u2

0.1 0.0225 0.9341 0.0588 0.9912 0.1213 0.9993 0.2725 1.0000

0.2 0.1162 0.9880 0.2258 0.9998 0.3880 0.9998 0.6617 0.9998

0.3 0.2481 0.9998 0.4175 0.9991 0.6241 0.9992 0.8538 0.9997

0.4 0.3806 0.9975 0.5801 0.9973 0.7728 0.9987 0.9272 0.9997

0.5 0.4958 0.9919 0.6973 0.9956 0.8543 0.9984 0.9558 0.9996

0.6 0.5881 0.9865 0.7749 0.9944 0.8975 0.9981 0.9680 0.9996

0.7 0.6582 0.9819 0.8241 0.9935 0.9208 0.9980 0.9738 0.9996

0.8 0.7098 0.9782 0.8550 0.9928 0.9337 0.9979 0.9766 0.9996

0.9 0.7469 0.9752 0.8745 0.9923 0.9411 0.9978 0.9782 0.9996

1 0.7733 0.9729 0.8870 0.9919 0.9455 0.9977 0.9791 0.9996

Figure 2: Asymptotic relative efficiency of the estimator of 2 using OLS versus MLE. The value of 2 is on the abscissa, u2 and  are fixed at 1. The curves are for N = 5 (solid), N = 10 (long dashed) and N = 20 (short dashed).
12

4 Model extensions
In this section we will discuss three possible extensions of the model: First, the inclusion of a drift term in the random walk characterizing market prices. Second, the possibility of autocorrelation in returns. And finally, allowing for time-varying volatility.
4.1 Non-zero mean of returns
Instead of assuming a random walk with mean zero for t, we could add a constant drift parameter  and replace (13) by t =  + t-1 + t. The only change in the Kalman filter would be in equation (17), which would be replaced by t|t-1 =  + t-1|t-1. The drift  would have to be estimated by MLE, jointly with u and . Alternatively, one could detrend the data in a first step and instead of (11) estimate Yit = Xit + t + it by OLS. The composite error it = t + uit would then have, by construction, mean zero without linear time trend. Returns would be estimated by adding the OLS estimate of  to the residuals ^t. This latter procedure would be convenient but less efficient than the former.
Rather than explicitly modelling non-zero means of returns, it should be noted that the Kalman filter of the model without drift at least partially captures a potential non-zero mean of returns, which would end up in a non-zero mean of residuals ^t. To see this, consider the updating equation for t, (21). If the Kalman filter without drift is used but the true model contains a drift, then the prediction error t - t|t-1 is equal to  + ut. Straightforward calculations show that the second term on the right hand side of (21) would be given by
nt2 (t|t - 1) + atut nt2 (t|t - 1) + u2
which, conditional on nt and letting nt increase, converges to  in probability. Hence, (21) corrects the predicted t by the neglected , if the cross-section information is sufficiently large. For the estimated t it therefore does not make a difference whether or not a trend is included. An explicit estimation of  would have the advantage of possible inference concerning the drift term, but it does not matter for the subsequent modelling and estimation of volatility.
4.2 Autocorrelation of returns
Markets for heterogenous goods may deliver returns that are serially correlated. For real estate markets, this has been motivated by Schulz and Werwatz (2004). It is possible to extend our basic model to account for serial correlation. Consider, for example, the random walk t = t-1 + t, where now t itself follows an AR(1) model, t = t-1 + vt, with || < 1 and vt white noise. This
13

can be written as an AR(2) model with parameter constraints, i.e., t = (1 + )t-1 - t-2 + vt. We can then define a new state vector (t, t-1) and a transition equation

t = 1 +  -

t-1

10

t-1 + vt

t-2

0

The Kalman filter equations can then be extended easily to this case. The parameter  could be estimated jointly with the other model parameters by maximum likelihood.
In the empirical part, we will estimate the model without autocorrelation of returns, and then test for residual autocorrelation using standard Portmanteau-type tests.

4.3 Time-varying volatility
With the enormous experience on time-varying volatility in financial and other markets, it seems doubtful that markets with heterogenous goods have constant volatility. Having information on possibly time-varying volatility, for example by rejecting the hypothesis of an absence of structural breaks, one may want to generalize the above model to allow for time-varying volatility. It is a priori difficult to guess which pattern volatility may follow. One could assume, as Hodgson and Vorkink (2004) suggest, that returns follow a GARCH type process, as it has been standard for financial markets. There are however three drawbacks of this approach. First, data sets of heterogenous markets typically have a much smaller time dimension, which renders estimation imprecise and highly dependent on starting values. Second, due to the high degree of time-aggregation, short term fluctuations of volatility may have been averaged out such that GARCH effects become insignificant, as it is also the case in Hodgson and Vorkink (2004). Third, estimation of the GARCH part could only feasibly be done in a second step, having estimated first the index returns, e.g. by OLS. This two-step procedure is inefficient, and it would be desirable to develop a framework where the model components can be estimated in one step.
In the following, we propose a nonparametric extension of the model presented in Section 3, letting both market and idiosyncratic volatility be unknown functions of time that can be estimated with nonparametric methods. The approach is similar in spirit to the estimation of long-run trends of volatility in financial markets, as in the spline GARCH model of Engle and Rangel (2008).
We can regard  = (u2, 2) as a smooth function of time, ( ), and obtain an estimate thereof via the local maximum likelihood approach, which has been discussed in a unified framework by Fan, Farmen and Gijbels (1998). In the following we apply their main ideas to our problem.

14

The local likelihood estimator is defined as

( ) = argmax{L( |  )},

where  = ( ) and

L(

|



)

=

-

1 2

T

ln(|t()|) + et()t()-1et() K

t- h

t=1

(27)

which gives estimates of time-varying idiosyncratic and market volatility. This approach fits locally a constant to the unknown volatilities, weighted by a kernel function K and bandwidth h. One could extend this approach to local polynomial fitting, often giving more precise estimates especially at the boundaries of the support. Furthermore, one can estimate bias and variance of the estimator by fitting locally a polynomial of higher order. For the local constant estimator it suffices to fit, in a second step, a local linear model where the term t(( )) in (27) is replaced by t(( ) + ( )(t -  )), where ( ) is the first derivative of  evaluated at  . Similarly, et(( )) is replaced by et(( ) + ( )(t -  )). The resulting local likelihood function is more precise than (27) and permits to obtain bias and variance estimates. The pilot bandwidth to compute the local linear estimator can be chosen according to the extended residual squares criterion, and the optimal bandwidth for the local constant estimator minimizes the estimated mean squared error, integrated over time.
Finally, pointwise confidence intervals can be obtained by invoking asymptotic normality of the local constant likelihood estimator and using the estimates of its bias and variance.

5 Volatility of the art market
A set of data provided by Artnet AG1 and Tutela Capital S.A.2 is used to illustrate the method-
ology. It concerns artworks sold at auction between January 2001 and December 2011 and
consists of 11'521 paintings made by 40 artists who had the biggest volume of sales at auction in 2008 and 20093.
1A provider of data related to art. www.artnet.com 2A company specialized in managing art as an asset class. www.tutelacapital.com 3These artists are Jean-Michel Basquiat (1960-1988), George Braque (1882-1963), Alexander Calder (18981976), Mark Chagall (1887-1985), Edgar Degas (1834-1917), Kees van Dongen (1877-1968), Raoul Dufy (18771953), Max Ernst (1891-1976), Lucio Fontana (1899-1968), Sam Francis (1923-1994), Paul Gauguin (1848-1903), Childe Hassam (1859-1935), Damien Hirst (1965-), Alexej von Jawlensky (1864-1941), Wassily Kandisky (18661944), Ernst Ludwig Kirchner (1880-1938), Paul Klee (1879-1940), Willem de Kooning (1904-1997), Yayoi Kusama (1929-), Rene Magritte (1898-1967), Henri Matisse (1869-1954), Joan Miro (1893-1983), Claude Monet (18401926), Henry Moore (1831-1895), Edvard Munch (1863-1944), Emil Nolde (1867-1956), Pablo Picasso (1881-1973),

15

First, logged prices are regressed on available characteristics using ordinary least squares

(OLS) without time dummies. The explanatory variables are the artist's name (40 levels), the

medium used by the artist (35 levels), the height and width of the artwork in cm, the nationality

of the artist (14 levels), the estimated date when the artwork was realized, the auction house

where the sale took place (97 levels), whether the price in the database includes the buyer's

premium or not, and the country in which the sale happened. We applied three methods to

select variables: stepwise forward, stepwise backward and autometrics4, all with a 5% significance

level. The backward selection kept 119 variables in the model, the forward selection 102, and the

autometrics procedure kept 111 variables. 89 variables are common to the forward and backward

selection, 80 variables are common to the forward and autometrics selection procedures, while

90 variables are common to the backward and autometrics procedures. Results of estimated

returns and volatilities are robust to the choice of the selection procedure, and we therefore only

report the results for the autometrics procedure. The adjusted R2 for all three selected models

is about 60%. The final estimation results are summarized in Tables 5 to 9 in Appendix D. To

economize on space, only the OLS estimates are reported, the GLS estimates being very close to

these. For the selected model, we also calculated the fixed effects OLS estimator, i.e., the OLS

estimator of the model including time dummies. The Hausman test in (6) takes the value 2.28,

which is insignificant at 1%, hence supporting our assumption of exogeneity of X. Furthermore,

as indicated by the variance inflation factors given in Table 9, the final model does not encounter

problems due to multicollinearity.

The estimated t are computed using the fixed effects (OLS) and MLE estimators. Figure

3 plots the index on a semi-annual basis with both methodologies, while Figure 4 depicts the

corresponding returns. Apart from the last semester, where less observations were available, both

estimates are almost indistinguishable. This reflects the fact that both estimators are consistent

under exogeneity of X, and we are having several hundreds of observations per period.

The mean of estimated returns, T -1

T t=1

^t,

is

0.0713

for

OLS

and

0.0666

for

MLE,

corre-

sponding to annualized returns of about 14% (OLS) and 13% (MLE), substantially higher than

the mean annualized returns for the S&P 500 over the same period (about 0% annual return).

The pattern of the estimated index and its returns is remarkable. Negative returns of 2008

to 2009 reflect the direct impact of the banking crisis on the art market. Several concurring

factors contribute to explain the drop in prices. First, a negative shock on demand for art as

a consumption good may have hit the auction market, as the number of ultra-high net worth

Camille Pissarro (1831-1903), Richard Prince (1949-), Pierre-Auguste Renoir (1841-1919), Gerhard Richter (1932-
1984), Mark Rothko (1903-1970), Egon Schiele (1890-1918), Alfred Sisley (1839-1899), Henri de Toulouse-Lautrec
(1864-1901), Maurice de Vlaminck (1876-1958), Edouard Vuillard (1868-1940), Andy Warhol (1928-1987). 4See appendix C for an explanation of the autometrics procedure.

16

Figure 3: Semi-annual price index for blue chip artists. The index is set to 100 in the second semester of 2000. The solid line corresponds to the fixed effects estimator (4), the dashed one to the smoothed estimator t|T of the Kalman filter using MLE.
Figure 4: Semi-annual returns for blue chip artists. The solid line corresponds to the OLS estimator ^t - ^t-1, the dashed one to the estimator t|T - t-1|T of the Kalman filter using MLE.
17

individuals dropped in 2008 and 2009. Goetzmann et al. (2010) showed the positive relationship between top-income and art prices. Second, another negative shock on demand came from banks and financial institutions that may have frozen their acquisitions. Indeed, at a time of corporate jets and bonuses being under scrutiny in government-controlled banks, acquisition or sponsoring of luxury goods such as artworks by bailed-out financial institutions may have been seen as an undesirable spending. Third, risks of large liquidation of banking collection may have put pressure on prices as failed and bailed-out banks were expected to sell their collections. After Lehman Brothers in 2008, RBS and Bank of Ireland announced that they would liquidate parts of their collection in 2009 and 2010. Although these collections were considered relatively small (less than 50 million USD), risks of a major collection being liquidated did exist and could have materialized. UBS in particular, host of a very large art collection (more than 35'000 artworks according to their website) suffered a massive loss in 2008. The bank is well known for sponsoring many art-related activities (including the world-class fair Art Basel) but precipitately shut down in April 2009 its unit that advised wealthy Swiss clients on acquiring art. This decision may have been seen by art market participants as a move towards divestment from the art market.
In 2011, a different pattern took place with large, positive returns. As the European debt crisis spread, fearful investors may have become eager to diversify their portfolios in safe-haven assets such as investment grade art. The safe haven properties of artworks (especially blue chips artworks) may have surpassed their consumption properties, triggering a rally similar to the one experienced by gold. Oosterlinck (2010) showed that in the specific case of World War II (an example of a major global crisis), art outperformed all other asset classes except gold, as one of a few viable investment goods in a highly uncertain environment. On the other hand, however, the positive spike in the second semester of 2011 may have been distorted by extreme events in the market at that time. Sotheby's November auctions of contemporary art saw artworks by Gerhard Richter and by Sam Francis be hammered at extraordinary price levels for these artists. Only 71 artworks are used to estimate returns for the second semester of 2011, of which 12 are by Francis and Richter. Further studies with more complete data sets will have to investigate whether the recent surge is genuine or not.
We now turn to the volatility estimation. Table 2 reports the estimation results for the full sample. As expected, market volatility is much lower than idiosyncratic volatility, but the OLS estimate of market volatility is about 8% higher than the corresponding MLE estimate. It is likely that OLS, being less efficient than MLE and not taking into account the time variation of t, overestimates market volatility. In order to see whether our distributional assumptions of the error terms are reasonable, we show in Table 3 summary statistics of the estimated residuals. The Jarque-Bera normality test does not reject normality for t, it does so however for uit,
18

mainly due to the high kurtosis. This is similar to financial markets, where leptokurtosis is

often still present in residuals, even after standardizing with volatility estimates. In our case,

the non-normality of uit implies that the Kalman filter used in MLE is not fully efficient. Even

though we do not expect major gains in efficiency using more general filtering algorithms, this

may be a line of future research.

Table 4 reports empirical autocorrelations ^(h) of estimated residuals ^t and portmanteau

statistics of order h, Q(h) = T 2

h i=1

(T

-

i)-1^(h)2.

Under H0 of white noise, Q(h) has an

asymptotic 2 distribution with h degrees of freedom. The empirical p-values indicate that we

do not reject the null, which confirms our modelling approach.

In order to gauge parameter stability, we estimate the model additionally for two subsamples,

results of which are reported in Table 2. Obviously, both estimated idiosyncratic and market

volatilities are lower in the first subsample than in the second. A formal test of parameter

constancy, H0 : u2,1 = u2,2, 2,1 = 2,2, is the likelihood ratio test. Let Li denote the loglikelihood of the ith subsample. Then, the LR statistic is given by LR = 2(L1 + L2 - L) and has under the null an asymptotic 2 distribution with two degrees of freedom. In our case, the LR

statistic takes the value 7.7626, the corresponding p-value is 0.0206, and parameter stability is

rejected. We therefore turn to extensions of the basic model allowing for time-varying volatilities.

Full sample
01/200101/2006 02/200602/2011

OLS MLE OLS MLE OLS MLE

u 1.2332 (0.0962) 1.2062 (0.0399) 1.1870 (0.0970) 1.1660 (0.0690) 1.2756 (0.0962) 1.2332 (0.0465)

 0.0471 (0.0132) 0.0438 (0.0207) 0.0162 (0.0118) 0.0206 (0.0111) 0.0793 (0.0178) 0.0637 (0.0439)

log likelihood -6873.8531 -2694.3886 -4175.5832

Table 2: Parameter estimates of the static model using OLS and MLE. The first column reports the mean of estimated returns ^t. Asymptotic standard errors are given in parentheses.

We estimate a model with smoothly time-varying idiosyncratic and market volatilities using the local likelihood estimator of Section 4.3 with Gaussian kernel and bandwidth chosen as the minimizer of the estimated mean integrated squared error. Figure 5 depicts the estimate of idiosyncratic volatility, u( ), which shows an increasing trend in the second part of the sample, but overall the variation seems minor considering the scale of the estimate. The increase from 2006 to 2011 is about 20%. Pointwise 95% confidence bands are slightly wider around 2005 due to less available data in that year.

19

mean std.dev. skewness kurtosis

JB

t OLS 0.0713 0.2316 MLE 0.0666 0.1861

1.2740 5.4149 0.5858 3.5420

11.29 1.52

uit OLS 0.0000 1.0970 -0.2806 8.1747 13007.02 MLE 0.0585 1.1112 -0.3156 8.2852 13187.51

Table 3: Summary statistics for ^t and u^it in the constant volatility model. JB is the Jarque-Bera test statistic, which under normality has an asymptotic 22 distribution.

h ACF(h)
Q(h) p-value

1 0.1837 0.8120 0.3675

2 -0.0543 0.8864 0.6420

3 -0.3112 3.4487 0.3275

4 -0.1550 4.1180 0.3903

Table 4: Autocorrelation function of order h of residuals ^t, corresponding Portmanteau statistics Q(h) and p-values.

Figure 6 shows the local likelihood estimate of market volatility, ( ). Recall from Table 2 that the constant likelihood estimate is 0.0438. We now see a much smaller estimate at the beginning of the sample, around 2002 and 2003, which then increases and remains at about the same level of 0.04 between 2005 and 2008. After the financial crisis 2008/09, the estimate of market volatility increased further and reached levels around 0.2 in 2011. The wide 95% pointwise confidence bands at the end of the sample indicate however that this estimate is highly imprecise.
6 Conclusion
The widespread use of the hedonic regression methodology in the economics of heterogeneous goods has led academics and business practitioners to devise risk metrics from price indices as if they were directly measured. We have shown that the standard deviation of estimated returns overestimates market volatility and needs to be corrected by taking into account the idiosyncratic volatility. We have further shown that in a framework where the market index follows a random walk, or a stationary autoregressive process, important efficiency gains of the volatility estimator can be obtained by using maximum likelihood in combination with the Kalman filter. As an extension, we propose a nonparametric approach to allow for time-varying volatility.
The application to a blue chips art market has shown that returns declined during the
20

Figure 5: Idiosyncratic volatility of the blue chips art market, estimated by local maximum likelihood.
Figure 6: Market volatility of the blue chips art market, estimated by local maximum likelihood.
21

financial crisis 2008/09 but increased during the recent European debt crisis. We may suspect art to be considered as a safe haven in crisis times, but our dataset needs to be augmented to confirm this for the recent debt crisis. One of the reasons why prices fell in 2008/09 was that important collections of failed banks such as Lehman Brothers had to be sold, putting pressure on supply, while demand from high net worth individuals was dropping. On the other hand, market volatility has in both crises increased substantially, similar to the financial markets. In future work, one may model explicitly time-varying correlations between art, financial and other assets to gauge the diversification benefits of including alternative assets in the portfolio. The modelling framework developed in this paper naturally permits to include other assets and estimate time-varying correlations, which is not feasible in classical OLS estimation.
On the econometrics side, future work may consider more general filters than the Kalman filter to accomodate departures from normality in the error terms. Further efficiency gains may be expected.

Appendix A: Proofs

Proof of Proposition 1. The first part of the proposition concerns the estimator of u2. We

have

^t

=

t

+ u¯t,

with

u¯t

=

1 nt

nt i=1

uit

,

and hence Yit - Xit - ^t

= uit - u¯t.

Consider the

expression

1 T

T t=1

1 nt

nt
(Yit - Xit - ^t)2
i=1

=

1 T

T t=1

1 nt

nt
(uit - u¯t)2
i=1

=

u2

+

1 T

T t=1

1 nt

nt

(ui2t

-

u2 )

-

2 T

i=1

T t=1

1 n2t

nt

u2it

-

2 T

i=1

T t=1

1 nt2

nt i=1

uitujt

+

1 T

j=i

T
u¯t2
t=1

The second and fourth terms are the means of independent r.v. with mean zero and finite

variance by Assumption (A1). Hence, the Chebychev weak law of large numbers applies to these

terms,

which

are

Op(T -1/2).

In

the

same

vein,

1 T

T1 t=1 n2t

nt i=1

ui2t

=

u2E[nt-1] + Op(T -1/2)

and

1 T

T t=1

u¯t2

= u2E[nt-1]+Op(T -1/2).

Thus, we have

1 T

T1 t=1 nt

nt i=1

(Yit

-

^t

)2

=

u2(1-E[n-t 1])+

Op(T -1/2). It immediately follows that ^u2 = u2 + Op(T -1/2), as stated.

The second part of the proposition concerns the estimator of 2. Note that ^t = t +

u¯t - u¯t-1,

where

we

denote

u¯t

=

1 nt

nt i=1

uit,

with

u¯t



N (0, u2/nt).

Consider the naive

estimator

1 T

T t=1

(^t

-

1 T

T j=1

^j

)2

=

1 T

T t=1

t2

+

1 T

T t=1

u¯t2

+

2 T

T t=2

u¯t2-1

+

Op(T -1/2).

22

Since

1 T

T t=1

u¯t2

p

u2 E[nt-1 ],

we

have

1 T

T

(^t

-

1 T

t=1

T
^j)2 = 2 + (1 + 2)u2E[nt-1] + Op(T -1/2)
j=1

and

it

follows

using

the

first

part

of

the

proposition

that

the

estimator

^2

is

 T -consistent,

as

stated.

Q.E.D.

Proof of Proposition 2.

Asymptotic normality follows from an application of the Liapounov central limit theorem.

By Proposition 1, the estimators are asymptotically unbiased. It remains to compute the

asymptotic variance. Define the information set generated by the number of observations by

NT NT

]=) +E(n[V1,anr2(, .T. .^,u2n)T|N).TT].hTenh,ewfiershtatveermtheisvazerriaonsciencdeecEo[m^u2po|sNitTio]n=Varu2(.

T ^u2) = Var(E[ The second term

T ^u2 is

|

 E[Var( T

^u2 )|NT

]

=

2u4

T -1

T -1

Tt=1(nt - 1)/n2t tT=1(nt - 1)/nt

2,

which delivers uu,T . Next, the covariance is given by

 Cov( T

^u2 ,

 T

^2)

=

 Cov( T

^u2 ,

1 T

T t=1

^t2)

-

(1

+

2

 )Cov( T

^u2 ,

^u2

1 T

T t=1

1 nt

)

It is straightforward to show that the first term on the right hand side is zero. The covariance in the second term is given by

 Cov( T

^u2 ,

^u2

1 T

T t=1

1 nt

)

=

 E[Var( T

^u2 |NT

)

1 T

T t=1

1 nt

]

=

2u4 E

T -1 T -1

tT=1(nt - 1)/nt2

T t=1

(nt

-

1)/nt

1 2T

T t=1

1 nt

,

which gives uv,T .

1 T

WjT=e1n^ojw)2p=rov1eTthetTe=x1p^rt2e-ssionTf(oT1r

the

asymptotic

variance

of

^2.

First

note

that

1 T

Tt=1(^t

T j=1

^j2)2,

where

the

second

term

on

the

right

hand

side

- is

Op(T -1/2) and, hence, asymptotically negligible. We have

lim
T 

 Var( T

^2)

=

lim
T 

Var(

1 T

T t=1

^t2)

+

(1

+

2)2

lim
T 

Var(^u2

1 T

T t=1

1 nt

)

(28)

since again the covariance term disappears. Note first that ^t2 = t2 + u¯2t + 2u¯2t-1 + 2tu¯t -

23

2tu¯t-1 - 2u¯tu¯t-1. All terms are mutually orthogonal and, by assumption, t  N (0, 2) and u¯t  N (0, u2/nt). Hence, Var(^t2|NT ) = 24 +2u4/nt2 +24u4/n2t-1 +42u2/nt +422u2/nt-1 + 42u4/(ntnt-1) = 2u4(2/u2 + 1/nt + 2/nt-1)2. Next, Cov(^t2, ^t2-1|NT ) = 2u42/n2t-1, and Cov(^t2, ^t2- |NT ) = 0, | |  2. Therefore, we have



Var( 1 T

T t=1

^t2|NT

)

=

2u4

1 T

T 
t=2

2 u2

+

1 nt

+

2 nt-1



2

+

22  n2t-1 

Furthermore, Var(E[ 1
T
2)2Var(1/nt). Hence,

T t=1

^t2|NT

])

=

Var( 1
T

Tt=1(2 + u2/nt + 2u2/nt-1)) = u4(1 +



Var( 1 T

T

^t2)

=

2u4

1 T

t=1

T E
t=2

2 u2

+

1 nt

+

2 nt-1



2

+

22  n2t-1 

+

u4 (1

+

2)2Var(1/nt)

Finally, we have for the variance in the second term of (28):

Var(^u2

1 T

T t=1

1 nt

|NT

)

=

2u4

1 T
1 T

T nt-1 t=1 n2t T nt-1 2 t=1 nt

1T 1 T t=1 nt

2

and

Var(E[^u2

1 T

T t=1

1 nt

|NT

])

= u4 Var(1/nt ).

Putting the pieces of (28) together, we obtain

the stated result for limT  Var( T ^2).

Q.E.D.

Proof of Proposition 3.

Since  is known but possibly equal to one, in which case {t} would be non-stationary,

classical theory on the estimation of state space models does not directly apply. As noted by

Pagan (1980), however, the theory remains valid in the unit root case if the model is locally

asymptotically identified in the sense of Kohn (1978). A necessary and sufficient condition for

0 to be locally asymptotically identified is that limT (I(0)/T )-1 be non-singular. In our

model we can directly check for this condition to hold. The sum in I() contains two terms, the

second of which, 2E

et 

-t 1

et 

is positive semi-definite. It suffices to show that the first term,

 vec(t )


(t-1



-t 1)

vec(t)


,

is

positive

definite.

Similar

to

Proposition

1

of

Pagan

(1980),

we

have

vec(t) 

(t-1



-t 1)

vec(t) 



2min(t-1)t

where

t

=

 vec(t )




vec(t)


,

min(·)

denotes

the

smallest

eigenvalue,

and

where



means

that

the left hand side matrix minus the right hand side matrix is p.s.d. Due to the particular

structure of our model, we have min = u2 > 0, by assumption. Hence, it suffices to show that

24

t is p.d. Using the expressions in Appendix B, and denoting Xt = t2/u2 and Yt = t2/2,

we can write

t = nt

ntXt2 + 2Xt + 1 (Yt + 1)(ntXt + 1)

(Yt + 1)(ntXt + 1) nt(Yt + 1)2

It follows immediately that |t| > 0 if and only if nt > 1, which happens with positive probability

by assumption. Hence, limT  T -1

T t=1

t

is

positive

definite

almost

surely,

which

implies

that

limT (I(0)/T )-1 is positive definite almost surely. This shows asymptotic local identifiability

of the model.

The remaining conditions of Theorem 4 of Pagan (1980) hold trivially, as at is uniformly bounded from above and non-stochastic, the state space form is uniformly completely observable

and uniformly completely controllable. Finally, for asymptotic normality we need that 0 is an interior point of . Then, consistency and asymptotic normality follow by Theorem 4 of Pagan

(1980). The form of the information matrix is standard for state space models, see e.g. Lu¨tkepohl

(1993, p.437).

Appendix B: Information matrix
To simplify the notation, we denote t := t|t and t2 := 2(t|t). The model in (5)-(7) can then be written as

et = t - att-1 t = t-1 + t-1at-t 1et t = att-1at + u2Int t2 = t-1 - t2-1att-1at

where t = 2t2 + 2. Let  = (u2, 2) and  = (1, 0). Then,

et 

=

-at

t-1 

t 

=





t-1 

+

t-1 

at -t 1et

- t-1

vec(t) 

(-t 1et



t-1at)

-

att-1

et 

t2 

=

t-1 

1 - 2t-1at-t 1at

+

t2-1

vec(t) 

(-t 1at



t-1at)

vec(t) 

=

(at



at)

t-1 

+

vec(Int )

25

Some expressions can be simplified by observing that, due to the particular structure of the model, at-t 1at = nt/(ntt-1 + u2). For example, this leads to

t2 

=

t-1

u4

 (ntt-1 + u2)2

+ att-2att2-1

Appendix C: Autometrics

Autometrics (Doornik, 2009) is an implementation of the general-to-specific modelling approach (see e.g. Hendry and Krolzig, 1999) based on several steps: First, a General Unrestricted Model (GUM) is defined. This set constitutes the base prior to model reduction. Second, each insignificant variable at a 5% confidence level offers a reduction path and each sub-path offers other reduction paths. If there are k insignificant variables in the GUM, then 2k possible models need to be considered. For each sub-path, an F-test is made on the removed variables. At this step, variables meeting the test may be reintroduced in the model even if they are not significant in the final model. Several diagnostics are made, including a Chow test, in order to check the model's stability. If the tests fail, another reduction path is selected. As the amount of paths is considerable, the Autometrics algorithm uses rules to select which models are worth going through the selection procedure: it automatically discards sub-paths of failed deletion, eliminates bunches of variables instead of taking them off one-by-one, and, once a variable is deemed "highly insignificant", all paths containing this variable are discarded (at the risk of eliminating viable solutions).

Appendix D: Tables

26

Table 5: Regression autometrics I

Estimate Std. Error t-statistic

Intercept

17.28

1.31 13.22

Artists

Basquiat

1.63

0.09 18.31

Braque - 0.22

0.10 - 2.26

Chagall

0.46

0.08 5.44

Dufy - 0.85

0.08 - 10.93

Ernst - 0.90

0.08 - 10.62

Gauguin

1.13

0.15 7.72

Hassam

1.28

0.13 9.66

Judd

0.75

0.27 2.81

Kandinsky

0.86

0.15 5.73

Kooning

1.69

0.10 16.70

Matisse

1.20

0.11 10.98

Monet

1.22

0.09 14.19

Moore

- 2.14

0.20 - 10.71

Picasso

0.92

0.07 12.44

Pissarro

0.55

0.09 6.31

Prince

1.06

0.10 10.27

Richter

- 1.11

0.07 - 15.00

Rothko

2.82

0.14 20.00

Sisley

0.64

0.10 6.12

Vlaminck

- 1.31

0.06 - 20.65

Vuillard

- 0.69

0.09 - 7.65

Warhol

1.80

0.06 28.53

ZaoWouKi

- 0.96

0.10 - 9.43

Nationality of the artist

U.S.A.

- 2.32

0.08 - 28.26

Italy

- 0.43

0.09 - 4.53

Great Britain

- 1.68

0.13 - 13.35

The Netherlands - 0.75

0.08 - 9.12

France

- 0.59

0.07 - 8.50

Japan

- 2.20

0.09 - 23.91

Russia - 0.42

0.09 - 4.91

P r(> |t|) 2.00E-16
2.00E-16 2.36E-02 5.57E-08 2.00E-16 2.00E-16 1.27E-14 2.00E-16 4.92E-03 1.03E-08 2.00E-16 2.00E-16 2.00E-16 2.00E-16 2.00E-16 2.96E-10 2.00E-16 2.00E-16 2.00E-16 9.65E-10 2.00E-16 2.10E-14 2.00E-16 2.00E-16
2.00E-16 6.01E-06 2.00E-16 2.00E-16 2.00E-16 2.00E-16 9.46E-07

***
*** *
*** *** *** *** *** ** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***
*** *** *** *** *** *** ***

27

Table 6: Regression autometrics II

Estimate Std. Error t-statistic

Date of creation of the artwork

WorkDate

- 0.00

0.00 - 4.99

Medium used

acrylic

0.55

0.06 9.30

autograph - 2.72

0.42 - 6.52

Brush - 0.82

0.14 - 5.74

butterflies and enamel on canvas

1.33

0.15 9.04

Casein

2.40

0.37 6.49

color - 2.04

0.20 - 10.07

flies and resin on canvas

1.35

0.45 3.00

gloss and household paint

1.19

0.19 6.22

handcolored - 3.28

0.44 - 7.40

House Paint

0.78

0.14 5.51

inkjet print and acrylic

2.11

0.34 6.28

Lacquer

0.93

0.34 2.73

latex paint

1.43

0.42 3.41

litograph - 2.52

0.54 - 4.64

Oil 0.90

0.05 16.42

Oilstick - 0.80

0.21 - 3.89

paint

0.44

0.14 3.23

paste

0.79

0.28 2.85

peinture la colle

1.23

0.36 3.46

Silk - 0.29

0.09 - 3.30

spray

0.67

0.29 2.34

synthentic polymer paint

0.61

0.08 7.43

Tapestry - 3.74

0.20 - 18.69

Tempera

0.45

0.14 3.27

water paint

0.81

0.10 7.89

Size

Height

0.01

0.00 24.27

Width

0.01

0.00 25.95

P r(> |t|)
6.11E-07
2.00E-16 7.26E-11 9.79E-09 2.00E-16 8.85E-11 2.00E-16 2.74E-03 5.30E-10 1.42E-13 3.70E-08 3.46E-10 6.40E-03 6.60E-04 3.60E-06 2.00E-16 1.03E-04 1.23E-03 4.36E-03 5.41E-04 9.60E-04 1.94E-02 1.14E-13 2.00E-16 1.09E-03 3.35E-15
2.00E-16 2.00E-16

***
*** *** *** *** *** ***
** *** *** *** ***
** *** *** *** ***
** ** *** *** * *** *** ** ***
*** ***

28

Table 7: Regression autometrics III: Auction house variables

Estimate Std. Error t-statistic P r(> |t|)

artcurial

0.43

0.11 3.90 9.77E-05

Blomqvist

- 3.30

0.59 - 5.56 2.79E-08

BloomsburyAuctionsNewYork

- 5.22

1.16 - 4.50 6.80E-06

BruunRasmussenBredgadeCopenhagen

1.93

0.52 3.68 2.35E-04

BukowskisStockholm

0.80

0.29 2.80 5.17E-03

ChristiesAmsterdam

1.86

0.59 3.15 1.67E-03

ChristiesDubai

1.08

0.37 2.94 3.33E-03

ChristiesEast

- 1.33

0.37 - 3.60 3.23E-04

ChristiesLondon

1.08

0.05 20.30 2.00E-16

ChristiesMilan

1.00

0.33 3.05 2.31E-03

ChristiesNewYork

0.49

0.06 8.37 2.00E-16

ChristiesParis

0.91

0.09 9.61 2.00E-16

ChristiesTaipei

- 1.51

0.46 - 3.28 1.03E-03

ClaudeAguttes

0.55

0.19 2.87 4.10E-03

Dorotheum

1.54

0.70 2.19 2.86E-02

DuMouchellesFineArtsAuctioneers

- 3.68

0.38 - 9.68 2.00E-16

FarsettiArte

1.41

0.33 4.30 1.76E-05

FinarteMilan

1.64

0.65 2.54 1.11E-02

GalerieKornfeld

0.78

0.11 7.26 4.28E-13

HauswedellandNolte

- 0.77

0.21 - 3.66 2.52E-04

imKinsky

1.92

0.73 2.64 8.43E-03

KAuction

1.10

0.25 4.36 1.33E-05

KettererKunstMunchen

1.14

0.21 5.39 7.13E-08

KollerAuktionenAG

0.57

0.20 2.84 4.55E-03

Lempertz

0.76

0.18 4.29 1.78E-05

MatsartAuctioneersandAppraisers

0.63

0.24 2.66 7.82E-03

MillonandCornettedeSaintCyr

- 1.16

0.27 - 4.38 1.22E-05

OsenatScp

1.60

0.48 3.31 9.29E-04

PandolfiniCasaDAste

1.88

0.86 2.18 2.91E-02

PhillipsdePuryandCompanyLondon

1.31

0.13 9.77 2.00E-16

PiasaArtcurial

0.72

0.34 2.11 3.50E-02

PolyInternationalAuctionCoLtd

1.67

0.37 4.47 7.80E-06

PorroandC

1.51

0.41 3.69 2.25E-04

SeoulAuction

1.64

0.20 8.15 4.11E-16

SothebysAmsterdam

1.42

0.62 2.30 2.14E-02

SothebysArcade

- 1.57

0.39 - 4.03 5.72E-05

SothebysLondon

1.09

0.05 20.92 2.00E-16

SothebysMilan

1.45

0.30 4.88 1.08E-06

SothebysNewYork

0.44

0.06 7.48 8.00E-14

SothebysParis

1.10

0.14 7.97 1.76E-15

VanHamKunstauktionen

0.78

0.25 3.15 1.66E-03

VillaGrisebachAuktionenGmbH

1.14

0.17 6.61 4.03E-11

*** *** *** *** ** ** ** *** *** ** *** *** ** **
* *** ***
* *** *** ** *** *** ** *** ** *** ***
* ***
* *** *** ***
* *** *** *** *** *** ** ***

29

Table 8: Regression autometrics IV

Estimate Std. Error t-statistic

fees charged by auction house

HAMMER

- 0.16

0.05 - 3.65

Country of sale

Austria Denmark

- 1.37 - 2.22

0.67 - 2.04 0.49 - 4.58

Germany - 0.90

0.15 - 6.17

Hong Kong

1.19

0.12 9.98

Italy

- 0.72

0.27 - 2.66

Japan

0.71

0.08 8.64

Norway

1.92

0.46 4.21

Taiwan The Netherlands

1.31 - 1.88

0.16 8.10 0.53 - 3.58

U.S.A.

0.61

0.07 9.13

P r(> |t|)
2.65E-04
4.18E-02 4.72E-06 7.21E-10 2.00E-16 7.75E-03 2.00E-16 2.52E-05 6.19E-16 3.45E-04 2.00E-16

***
* *** *** ***
** *** *** *** *** ***

Table 9: Regression autometrics: diagnostics

Number of selected variables R2
Adjusted R2

111 61% 60%

Maximum variance inflation factor

16.10

Mean variance inflation factor

2.70

Proportion of p-values < 1%

93%

Standard deviation of residuals

1.15

Skewness of residuals

- 0.23

Kurtosis of residuals

7.28

p-value Jarque Bera normality test < 2.2e-16

30

References
Arellano, M., 2003. Panel Data Econometrics. Oxford University Press.
Baumol, W., 1986. Unnatural Value: Or Art Investment as Floating Crap Game. American Economic Review, American Economic Association, vol. 76(2), pages 10-14.
Bocart, F., Oosterlinck, K., 2011. Discoveries of fakes: Their impact on the art market. Economics Letters 113(2), 99-102.
Bocart, F., Hafner, C., 2011. Econometric analysis of volatile art markets. Computational Statistics and Data Analysis doi:10.1016/j.csda.2011.10.019
Case, K., Shiller, R., 1987. Prices of single-family homes since 1970: new indexes for four cities.New England Economic Review Federal Reserve Bank of Boston, 45-56.
Chanel, O., Gerard-Varet, L., Ginsburgh, V., 1996. The relevance of hedonic price indices: the case of paintings. Journal of Cultural Economics 20, 1-24.
Collins, A., Scorcu, A.E., Zanola, R., 2009. Reconsidering hedonic art price indexes. Economics Letters, Elsevier 104(2), 57-60.
Combris, P., Lecocq S., Visser M., 1997. Estimation of a Hedonic Price Equation for Bordeaux Wine: Does Quality Matter? The Economic Journal 107(441) 390-402.
de la Barre M., Docclo S., Ginsburgh V., 1994. Returns of Impressionist, Modern and Contemporary European Paintings 1962-1991. Annales d'economie et de statistique 35, 143-181.
Doornik J., 2009. Autometrics. In Castle, J., and Shephard, N. (eds.), The Methodology and Practice of Econometrics. Oxford: Oxford University Press.
Dorsey R., Hu H., Mayer W., Wang H., 2010. Hedonic versus repeat-sales housing price indexes for measuring the recent boom-bust cycle, Journal of Housing Economics. 19 7593
Duan, N., 1983. Smearing Estimate: A Nonparametric Retransformation Method. Journal of the American Statistical Association 78, 605-610.
Engle, R.F., Rangel, G., 2008. The spline GARCH model for low frequency volatility and its global macroeconomic causes. Review of Financial Studies 21, 1187-1222.
Fan, J., Farmen, M., Gijbels, I., 1998. Local maximum likelihood estimation and inference. Journal of the Royal Statistical Society, Series B, 60, 591-608.
31

Fogarty, J., 2006. The return to Australian fine wine. European Review of Agricultural Economics 33(4) 542-561.
Frey, B., Eichenberger, R., 1995. On the Return of Art Investment Return Analyses. Journal of Cultural Economics 19, 207-220.
Ginsburgh, V., Mei, J., Moses, M., 2006. On The Computation of Price Indices, in: Ginsburgh, V., Throsby, D. (Eds), Handbook of the economics of art and culture, Elsevier, pp. 948-979.
Goetzmann, W., 1992. The Accuracy of Real Estate Indices: Repeat Sale Estimators. Journal of Real Estate Finance and Economics 5, 5-53.
Goetzmann, W., 1993. Accounting for Taste: Art and the Financial Markets Over Three Centuries. American Economic Review 83, 1370-1376.
Gouri´eroux, C., Laferrere, A., 2009, Managing hedonic housing price indexes: The French experience. Journal of Housing Economics 18, 206-213.
Graddy, K., Margolis, P., 2011. Fiddling with Value: Violins as an Investment? Economic Inquiry 49(4), 1083-1097.
Greenleaf, E. A., Rao, A. G., Sinha, A. R., 1993. Guarantees in Auctions: The Auction House As Negotiator and Managerial Decision Maker. Management Science 39, 1130-1145.
Hansen, J., 2009. Australian House Prices: A Comparison of Hedonic and Repeat-Sales Measures The Economic Record 85(269), 132145
Hendry, D., Krolzig H.-M., 1999. Improving on 'Data mining reconsidered'by KD Hoover and SJ Perez. The Econometrics Journal 2(2), 202-219.
Hodgson, D., Vorkink, K., 2004. Asset Pricing Theory and the Valuation of Canadian Paintings. The Canadian Journal of Economics 37, 629-655.
Jones, A.M., Zanola, R., 2010. Retransformation bias in the adjacent price index. POLIS Working Papers n178.
Kohn, R., Local and global identification and strong consistency in time series models, Journal of Econometrics 8, 269-294.
Lu¨tkepohl, H., 1993. Introduction to Multiple Time Series Analysis. Springer Verlag, Berlin.
32

McAndrew, C., Thompson, R., 2007. The collateral value of fine art. Journal of Banking and Finance 31, 589-607.
Mei, J., Moses, M., 2002. Art as an Investment and the Underperformance of Masterpieces. The American Economic Review 92, 1656-1668.
Pagan, A., 1980. Some identification and estimation results for regression models with stochastically varying coefficients, Journal of Econometrics, 13, 341-363.
Pesando, J., 1993. Art as an Investment: The Market for Modern Prints. American Economic Review 83, 1075-1089.
Renneboog, L., Spaenjers, C., 2010. Buying Beauty: On Prices and Returns in the Art Market. Tilburg University, Center for Economic Research Discussion Paper 2009-15.
Schulz, R. and Werwatz, A., 2004. A state space model for Berlin house prices: Estimation and economic interpretation. Journal of Real Estate Finance and Economics, 28, 37-57.
Scorcu, A.E., Zanola, R., 2010. The Right Price for Art Collectibles. A Quantile Hedonic Regression Investigation of Picasso Paintings. Working Paper Series Rimini Centre for Economic Analysis 01 10.
Seckin, A., Atukeren, E., 2006. Art and the Economy: A First Look at the Market for Paintings in Turkey. Economics Bulletin 26, 1-13.
33

SFB 649 Discussion Paper Series 2012
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "HMM in dynamic HAC models" by Wolfgang Karl Härdle, Ostap Okhrin and Weining Wang, January 2012.
002 "Dynamic Activity Analysis Model Based Win-Win Development Forecasting Under the Environmental Regulation in China" by Shiyi Chen and Wolfgang Karl Härdle, January 2012.
003 "A Donsker Theorem for Lévy Measures" by Richard Nickl and Markus Reiß, January 2012.
004 "Computational Statistics (Journal)" by Wolfgang Karl Härdle, Yuichi Mori and Jürgen Symanzik, January 2012.
005 "Implementing quotas in university admissions: An experimental analysis" by Sebastian Braun, Nadja Dwenger, Dorothea Kübler and Alexander Westkamp, January 2012.
006 "Quantile Regression in Risk Calibration" by Shih-Kang Chao, Wolfgang Karl Härdle and Weining Wang, January 2012.
007 "Total Work and Gender: Facts and Possible Explanations" by Michael Burda, Daniel S. Hamermesh and Philippe Weil, February 2012.
008 "Does Basel II Pillar 3 Risk Exposure Data help to Identify Risky Banks?" by Ralf Sabiwalsky, February 2012.
009 "Comparability Effects of Mandatory IFRS Adoption" by Stefano Cascino and Joachim Gassen, February 2012.
010 "Fair Value Reclassifications of Financial Assets during the Financial Crisis" by Jannis Bischof, Ulf Brüggemann and Holger Daske, February 2012.
011 "Intended and unintended consequences of mandatory IFRS adoption: A review of extant evidence and suggestions for future research" by Ulf Brüggemann, Jörg-Markus Hitz and Thorsten Sellhorn, February 2012.
012 "Confidence sets in nonparametric calibration of exponential Lévy models" by Jakob Söhl, February 2012.
013 "The Polarization of Employment in German Local Labor Markets" by Charlotte Senftleben and Hanna Wielandt, February 2012.
014 "On the Dark Side of the Market: Identifying and Analyzing Hidden Order Placements" by Nikolaus Hautsch and Ruihong Huang, February 2012.
015 "Existence and Uniqueness of Perturbation Solutions to DSGE Models" by Hong Lan and Alexander Meyer-Gohde, February 2012.
016 "Nonparametric adaptive estimation of linear functionals for low frequency observed Lévy processes" by Johanna Kappus, February 2012.
017 "Option calibration of exponential Lévy models: Implementation and empirical results" by Jakob Söhl und Mathias Trabs, February 2012.
018 "Managerial Overconfidence and Corporate Risk Management" by Tim R. Adam, Chitru S. Fernando and Evgenia Golubeva, February 2012.
019 "Why Do Firms Engage in Selective Hedging?" by Tim R. Adam, Chitru S. Fernando and Jesus M. Salas, February 2012.
020 "A Slab in the Face: Building Quality and Neighborhood Effects" by Rainer Schulz and Martin Wersing, February 2012.
021 "A Strategy Perspective on the Performance Relevance of the CFO" by Andreas Venus and Andreas Engelen, February 2012.
022 "Assessing the Anchoring of Inflation Expectations" by Till Strohsal and Lars Winkelmann, February 2012.
SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

SFB 649 Discussion Paper Series 2012
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
023 "Hidden Liquidity: Determinants and Impact" by Gökhan Cebiroglu and Ulrich Horst, March 2012.
024 "Bye Bye, G.I. - The Impact of the U.S. Military Drawdown on Local German Labor Markets" by Jan Peter aus dem Moore and Alexandra Spitz-Oener, March 2012.
025 "Is socially responsible investing just screening? Evidence from mutual funds" by Markus Hirschberger, Ralph E. Steuer, Sebastian Utz and Maximilian Wimmer, March 2012.
026 "Explaining regional unemployment differences in Germany: a spatial panel data analysis" by Franziska Lottmann, March 2012.
027 "Forecast based Pricing of Weather Derivatives" by Wolfgang Karl Härdle, Brenda López-Cabrera and Matthias Ritter, March 2012.
028 "Does umbrella branding really work? Investigating cross-category brand loyalty" by Nadja Silberhorn and Lutz Hildebrandt, April 2012.
029 "Statistical Modelling of Temperature Risk" by Zografia Anastasiadou, and Brenda López-Cabrera, April 2012.
030 "Support Vector Machines with Evolutionary Feature Selection for Default Prediction" by Wolfgang Karl Härdle, Dedy Dwi Prastyo and Christian Hafner, April 2012.
031 "Local Adaptive Multiplicative Error Models for High-Frequency Forecasts" by Wolfgang Karl Härdle, Nikolaus Hautsch and Andrija Mihoci, April 2012.
032 "Copula Dynamics in CDOs." by Barbara Choro-Tomczyk, Wolfgang Karl Härdle and Ludger Overbeck, May 2012.
033 "Simultaneous Statistical Inference in Dynamic Factor Models" by Thorsten Dickhaus, May 2012.
034 "Realized Copula" by Matthias R. Fengler and Ostap Okhrin, Mai 2012. 035 "Correlated Trades and Herd Behavior in the Stock Market" by Simon
Jurkatis, Stephanie Kremer and Dieter Nautz, May 2012 036 "Hierarchical Archimedean Copulae: The HAC Package" by Ostap Okhrin
and Alexander Ristig, May 2012. 037 "Do Japanese Stock Prices Reflect Macro Fundamentals?" by Wenjuan
Chen and Anton Velinov, May 2012. 038 "The Aging Investor: Insights from Neuroeconomics" by Peter N. C. Mohr
and Hauke R. Heekeren, May 2012. 039 "Volatility of price indices for heterogeneous goods" by Fabian Y.R.P.
Bocart and Christian M. Hafner, May 2012.
SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

