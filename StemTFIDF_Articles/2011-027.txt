BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2011-027
Estimation of the characteristics of a LÈvy
process observed at arbitrary frequency
Johanna Kappus* Markus Reiﬂ*
* Humboldt-Universit‰t zu Berlin, Germany
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universit‰t zu Berlin Spandauer Straﬂe 1, D-10178 Berlin

Estimation of the characteristics of a L¥evy process observed at arbitrary frequency

Johanna Kappus 
Institute of Mathematics Humboldt-Universit®at zu Berlin
kappus@math.hu-berlin.de

Markus Reiﬂ
Institute of Mathematics Humboldt-Universit®at zu Berlin
mreiss@math.hu-berlin.de

Abstract
A L¥evy process is observed at time points of distance  until time T . We construct an estimator of the L¥evy-Khinchine characteristics of the process and derive optimal rates of convergence simultaneously in T and . Thereby, we encompass the usual low- and high-frequency assumptions and obtain also asymptotics in the mid-frequency regime.
Key words and Phrases: Jump process, L¥evy measure, deconvolution problem, statistical inverse problem AMS subject classification: 62M05, 60G51, 62G05 JEL subject classification: C14, C22
1 Introduction
L¥evy processes are the main building blocks for stochastic continuous-time jump models, which become more and more popular in applications. One important task is thus to provide estimation methods for the characteristics of a L¥evy process.
There exist two fundamentally different estimation approaches, depending on the nature of observations. If we can assume high-frequency observations of the L¥evy process, we can discretize a natural estimator based on continuous-time observations, where the jumps and the diffusion part are observed directly [9, 7, 5]. Alternatively, the low-frequency setting is considered where the observation distance does not tend to zero and even asymptotically we cannot observe the diffusion and the jumps directly. Not surprisingly, in that case we face a more complicated inference problem leading to a deconvolution-type inverse problem [14, 4, 12, 11]. A very similar structure occurs in the estimation for L¥evy-Ornstein-Uhlenbeck processes [13] and in the calibration of financial derivatives (European options) to L¥evy models [2].
The financial support from the Deutsche Forschungsgemeinschaft via SFB 649 "O® konomisches Risiko", Humboldt-Universita®t zu Berlin, is gratefully acknowledged.
1

Here, we want to bridge the gap between high- and low-frequency estimation methods by allowing the time distance  between observations to remain constant or to converge to zero at an arbitrary speed. First results into that direction have been obtained by [4] for specific models. In any case, the observation time T tends to infinity because only this allows identification of the drift and the jump part in the limit. We extend the approach for general L¥evy processes by [14] to arbitrary observation distances .
First we introduce the setup in Section 2. Then in Section 3 we propose our estimator based on a minimum-distance criterion. The correct distance relies upon uniform convergence properties of the empirical characteristic function. The main result is an asymptotic upper bound for the estimator of the jump measure. Particularly interesting is the fact that we recover simultaneously the convergence rates for the high- and low-frequency setup, without any prescription for the estimator. As a minimax lower bound proves, also our intermediate (mid-frequency) risk bounds are asymptotically optimal. All proofs are postponed to Section 4.

2 Statistical model and estimation strategy

A L¥evy process (Xt, t 0) is observed at the n equidistant time points , ∑ ∑ ∑ , n = T . It is well known that the characteristic function of X has the form
(u) = E eiuX = e(u),

where the characteristic exponent  reads as

(u) = iub - 2 u2 + 2

eiux - 1 - iux1(|x|  1) ( dx),

with volatility   0, drift b  R and jump measure , where  is a -finite Borel measure on R with R \{0}(x2  1)( dx) < . Throughout the text we shall assume that X1 has finite moments up to order 4 +  for some positive constant . Then
we even have (cf. Thm. 25.3 [15])

x2( dx) < .
R \{0}

We can thus give the following reparametrization of the characteristic exponent in terms of the finite measure ( dx) := 20( dx) + x2( dx) and b := b + x 1(|x| > 1)( dx):

eiux - 1 - iux

(u) = iub +
R

x2

( dx),

where the integrand is continuously extended to -u2/2 at x = 0. The L¥evy process

is fully described by the parameters b (which is equal to the mean value of X1) and . The motivation for considering the above parametrization comes from the following fundamental result (see e.g. Theorem 8.7 in [15]):

2.1 with

Proposition. Let the corresponding

P(b,) and P(bn,n characteristics. Then

) nN
weak

denote infinitely divisible laws convergence P(bn,n )  P(b,)

takes place if and only if bn  b and n  .

2

Using the fact that the increments of a L¥evy process are independent and identically distributed, we can define the empirical characteristic function

1 ^,T (u) := n

n

e .iu(Xk-X(k-1))

k=1

(2.1)

Pointwise convergence of ^,T to  suggests to choose the estimators of the param-

eters of interest such that the corresponding characteristic function approximately

minimizes the distance to the empirical characteristic function. Consequently, we

define

^b,T , ^,T := arginf(~b,~) d ^,T ,  ∑; ~b, ~

(2.2)

for an appropriate choice of the metric d. It was shown in [14] that for equidistant observations with  fixed, the estimators of b and  defined according to (2.2) are strongly consistent under rather general conditions on the choice of the metric d. Moreover, optimal rates of convergence are obtained if b and  are chosen to fit the weighted empirical characteristic function and its first and second derivative.
The motivation for considering not only the characteristic function, but also its derivatives comes from the fact that the Fourier transform of the finite measure  can be expressed as

which gives and in terms of :

F(u) := eiux( dx) = - (u),
R

F (u)

=

1(u)2 1(u)2

-

1 (u) , 1(u)

F (u)

=

1 

(u)2 (u)2

-

(u) (u)

(2.3) (2.4)

Note that by formula (2.3) and (2.4) there is a strong resemblance of the problem
of estimating  with a deconvolution problem. The optimal rates of convergence depend on the decay behaviour of the characteristic function.
To obtain an estimator which is rate optimal for T   with arbitrary obser-
vation distance , the appropriate choice of a distance function will have to depend on . Because of the moment sizes E[X2k] = O(1k) (see p.9 for a proof), it turns out that the distance function

2

d (, ) :=

-

1k 2

k=0

(k) - (k) L(w)

(2.5)

is appropriate, where
f L(w) := sup |f (u)| w(u)
uR
for a weight function w : R  R+ specified later. Since we cannot guarantee that the infimum is always attained, our estimators ^b,T and ^,T are chosen such that

d ^,T ,  ∑; ^b,T , ^,T

inf d (^,T ,  (∑; b, )) + T
(b, )

(2.6)

with T = o

1/2

T

-

1 2

. In what follows, we will use the notation

,T :=  ∑; ^b,T , ^,T .

3

3 Rate optimality of the estimation procedure

3.1 Convergence of the empirical characteristic function

The main technical tool needed to prove rate optimality in T and  is the following result giving control of the weighted empirical characteristic function on the whole real line uniformly in . In an abstract sense, the statement below will tell us that the Donsker property holds for the empirical characteristic function uniformly over the class of distributions (P)1 , where P denotes the distribution of X.
Let the normalized version of the k-th derivative of the empirical characteristic function process be defined by

C(k,)T

(u)

:=

n-

1 2

-

k1 2

n

dk duk

j=1

e - Eiu(Xj-X(j-1)) eiuX

.

(3.1)

We can now formulate the main result of this section, which is proved in Section 4.

3.1 Theorem. For k  N0 let X be a L¥evy process with finite (2k + )-th moment and choose w(u) = (log(e+ | u |))-1/2- for some constants ,  > 0. Then for
C(k,)T , defined by (3.1), we have

sup E
n1,1

C(k,)T L(w) < .

With the distance d defined according to (2.5), the above theorem tells us that in terms of T , the empirical characteristic function ^,T satisfies

E

-

1 2

d

(^,T

,

)

=

O(T

-

1 2

).

(3.2)

An application of the triangle inequality gives
d (,T , )  2d (^,T , ) + o(1/2T -1/2),
so (3.2) remains true if we replace the empirical characteristic function ^,T by the minimum distance fit ,T .

3.2 Asymptotic risk bounds

We are now ready to prove upper bounds for convergence in probability. We consider in particular the following decay scenarios for the characteristic function:

a) The characteristic function of X satisfies |(u)|  Ce-c|u|

(3.3)

for some 0    2 and C, c > 0. This is equivalent to stating that X posesses at most a supersmooth density with parameters c and  (if a density exists at all).
Any infinitely divisible distribution having nonzero Gaussian part is supersmooth with  = 2. Examples of distributions which are supersmooth with

4

 < 2 are tempered stable laws with index of stability  (e.g. [6], Chapter 4.5). Note that stable distributions do not fit in our setting, as they do not match the required moment condition. Normal inverse Gaussian processes which fulfill (3.3) with  = 1 have been used for financial modelling, see e.g. [1]. Another example of processes in finance matching condition (3.3) with  = 1 are Meixner-processes, see e.g. [16].
b) We have at most polynomial decay of the characteristic function:

|(u)|  C (1 + |u|)-

(3.4)

for C > 0 and  0. This means that if X possesses a density at all, this can be no smoother than ordinary smooth with parameter .
Typical examples of infinitely divisible random variables with ordinary smooth densities are Gamma distributions. Compound Poisson distributions, which do not posess a distributional density, fulfill (3.4) for  = 0. Another typical example of processes fulfilling (3.4) are variance gamma processes, which have been used to model the logarithm of stock prices, see, for example [3].

Inspired by the weak convergence in Proposition 2.1, the performance of the estimator of the finite measure  is measured by an integral criterion. For s > 0 define the space of test functions

Fs := f  L1(R) : |Ff (u)| (1 + |u|)s du < 1. .

The corresponding loss for an estimator ^ of  is then defined to be

s (^, ) := sup f d - f d^ .
f Fs
3.2 Theorem. Assume E |X|4+ <  for some  > 0. Let ^,T and ^b,T be defined according to (2.6). Then

E |^b,T - b| = O

T

-

1 2

.

For ^,T , we obtain the following rates of convergence in probability: a) For distributions with tail behaviour |(u)|  Ce-c|u| we have

s ^,T ,  = OP

log T 

-

s 



T

-

1 2

.

Especially,

the

parametric

rate

T

-

1 2

,

is

attained

for

T





and

simultane-

ously T  0 provided

T = O

T-

 2s

log

T

.

b) For distributions with tail behaviour |(u)|  C(1 + |u|)- we have

s ^,T , 

= OP

T-

s 2

s(1/2+)
(log(e + T )) 



T

-

1 2

.

5

Especially,

the

parametric

rate

T

-

1 2

,

is

attained

for

T





under

the

non-

asymptotic condition

s

T

<

. 

By standard parametric theory, all parameters cannot be estimated at a better rate than T -1/2. Therefore the next result shows that our rates of convergence are
minimax optimal (at least up to a logarithmic factor for (b)) within a nonparametric
class.

3.3 Theorem (Minimax lower bounds). Let us introduce the following nonparametric classes for :

A(C, c, ) : = B(C, ) : =

 : |(u)|  Ce-c|u|  : |(u)|  C(1 + |u|)- .

Then we obtain the following minimax lower bounds uniformly for |b|  B, where B is some positive constant:

 > 0 : lim inf inf

T  T (0,1]

T ,T

sup Pb,
 A(C,c,)

log T T

s





T

1 2

s T ,T ,  >  > 0,

 > 0 : lim inf inf
T  ,T T (0,1]

sup Pb,
 B(C,)

Ts 2T





1 2

s

T ,T , 

>

> 0,

where the infimum is taken over all estimators T ,T of  based on observations of X with distance T up to time T .

The proof follows along the same lines as the proof in [14], but the control of the dependence on  requires additional and rather tedious calculations, whence it is omitted.

3.3 Discussion
The convergence rates for  can be understood in terms of a deconvolution or statistical inverse problem. The degree of ill-posedness, i.e. the amplification of the noise, is governed by the decay of the characteristic function . For fixed  and the exponential decay of  in (a) we therefore face a severely ill-posed problem with logarithmic rates of convergence. On the other hand, the risk is smaller for smoother test functions. If we had looked also at analytic test functions, where the Fourier transform decays exponentially fast, then we would also in (a) obtain polynomial rates for fixed . Observe that our estimator does neither rely on the knowledge of the decay behaviour of the unknown characteristic function nor on the test function class considered nor on the asymptotics of the observation distance.
The parametric rate is always attained when the smoothness of the test function sufficiently counterbalances the ill-posedness of the problem. It is remarkable that in all cases a condition on the observation distance of the type  = O(T -p) suffices. In the polynomial decay case (b) the ill-posedness is of degree  which is smaller than the smoothness s exactly under the condition  < s/ and we need not assume high-frequency observations. Very roughly and intuitively, there

6

is an analogy with estimating the derivative of order  of a regression function
and calculating the integral with an s-smooth test function of compact support,
which by partial integration equals the integral of the regression function itself with an (s - )-smooth test function. This L2-continuous linear functional can
be estimated with a parametric rate, see e.g. [10]. Like in [9], we might consider the model that  possesses a density g  Cr
which we want to estimate. The kernel smoothing argument in [14] then yields in
the polynomial decay case (b) a convergence rate for the pointwise risk of order O(hr + h--1/2T -1/2) (modulo a log factor, which is suppressed in the follow-
ing), where h denotes the kernel bandwidth. An optimal bandwidth choice yields the rate O(T -r/(2r+2+1)). Under this loss we attain the high-frequency rate of convergence O(T -r/(2r+1)) under the condition  c(log T )-1 with c > 0 suffi-
ciently small. This logarithmic decay condition should be compared to [7] and [5]
where in the compound Poisson case a polynomial condition is required for the
critical observation distance .

4 Proofs

4.1 Proof of Theorem 3.1
We start by recalling some definitions from empirical process theory. Let a probability space (X, A, P) be given. For measurable functions u, l : X  R, the set

[l, u] := {h : X  R | l  h  u}

is called an -bracket, if

(u - l)2dP < 2.

Given some class F of measurable, real-valued functions on X, we denote by N[ ] , F, L2(P) the minimal number of -brackets which are needed to cover F.
The entropy integral is defined by

1

J[ ] , F, L2(P) :=

log N[ ] , F, L2(P) 2 d.

0

Finally, a function F  0 is called an envelope function for F, if

f  F : |f |  F.

Proof of Theorem 3.1 . We decompose C(k,)T in its real and imaginary part and introduce the set of functions

Fk :=

-

1k 2

dk duk

cos ux : u  R



-

1k 2

dk duk

sin ux : u  R

.

Denote by P the distribution of X. An application of Corollary 19.35 in [17] gives for any  > 0:

sup E C(k,)T L(w) < CJ[ ] E F 2(X) , F(k), L2(P) ,
T

(4.1)

7

for any envelope function F = Fk of Fk and a universal constant C which does not depend on . It is shown in [14] that the right hand side of 4.1 is finite. To
make the result uniform in , it remains to consider the behaviour of the entropy
integral for   (0, 1] varying. To cover Fk with brackets of size , we define for grid points u,j specified later
the bracket functions

g±,j (z)

=

-

1k 2

w(u,j )

dk duk

cos(u,j z)

±

|z|k

I[-M

.M

]

(z

)±-

1k 2

|z

|k

I[-M

,M

]c

(z

)

and

h±,j (z)

=

-

1k 2

w(u,j )

dk duk

sin(u,j z)

±

|z|k

I[-M.M

]

(z

)±-

1k 2

|z

|k

I[-M,M

]c

(z

),

with M := M (, , k) := inf m : -(1k)E|X|2kI{|X|>m}  2 .
By definition of M , the size of the brackets is E g+,j (X) - g-,j (X) 2  42 -(1k)EX2k + 1 .

For   1, the expression on the right is uniformly bounded above by c2 for some
c > 0. This is obvious for k = 0. For k  1, this is a consequence of the well known fact that E X2k  c for some c > 0, which is seen by using the formula

E X2k

=

i-2k (2k) (0)

=

i-2k

d2k du2k

e(u)

.
u=0

An analogous argument gives:

E h+,j (X) - h-,j (X) 2  c2.

For

a

function

gu(∑)

:=

-

1k 2

w(u)

k uk

cos(u∑)



Fk

to

be

contained

in

[g-,j ,

g+,j ],

we have to ensure

|w(u)

dk duk

cos(uz)

-

dk w(u,j ) duk

cos(u,j z)|



|z|k

z  [-M, M ].

(4.2)

With the estimate

|w(u) cos(uz) - w(uj) cos(ujz)|I[-M,M](z)  (w(u) + w(uj)) 
|w(u) cos(uz) - w(u) cos(ujz)| I[-M,M](z) + |w(u) cos(ujz) - w(uj) cos(ujz)| I[-M,M](z)  (w(u) + w(uj))  (M |u - uj| + Lip(w)|u - uj|) ,

where Lip(w) is the Lipschitz-constant of w, and with the analogous inequality for the sine-function, (4.2) is seen to hold for any u  R such that

min {|u - u,j|(Lip(w) + M ), w(u) + w(u,j)}  .

8

Hence to cover Fk with brackets of P-size c2, we need grid points u1, ∑ ∑ ∑ , uJ()

such

that

w(u1)



 2

,

w(uJ () )



 2

and

|uj

- uj+1| 

 Lip(w)+M

(,,k)

.

For

the

minimal number J() of c-brackets needed to cover F,k, this yields the estimate

J()  2U ()(Lip(w) + M (, , k))/,

with

U () := inf

u



R

:

w(u)



 2

exp - for some  < 2.

The generalized Markov inequality yields for some c > 0:

M (, , k)  E |X|2k+ /1k2 1/ < c -2/ .

The second inequality applies the fact that we have the moment bound E |X|2k+ = O (), which is a consequence of Theorem 1.1 in [8].
The entropy with bracketing is

log

N[

](,

F,k ,

L2(P))



log

U

(

 c

)

+

log

c (Lip(w) + M (/c, , k)) 

.

The upper limit in the entropy integral appearing in (4.1), E[F2 ,k(X)], is again bounded above uniformly in  < 1. We have thus shown that up to some universal constant

sup sup E C(k,)T L(w)
1 T
11
 log(U ()) d +
00

log Lip(w)/ + -(2/+1) d.

(4.3)

Now (4.3) is finite since log U () - for some  < 2. This completes the proof.

4.2 Proof of Theorem 3.2
To prove the upper bounds, we establish a number of technical lemmas giving control on the characteristic exponent and its derivatives. First, we formulate a result which connects the tail behaviour of the characteristic function (which corresponds to the smoothnes of the density) to the jump activity round the origin, extending a result from [14]:
4.1 Lemma. Let an infinitely divisible law with characteristics (b, 0, ) be given such that its characteristic function satisfies
|(u)|  Ce-c|u|
for some 0 <  < 2 and C, c > 0. Then for any  >  the integral
1
|x| ( dx)
-1
is finite.
9

Proof. Setting  := inf1<x2 (1 - cos x) > 0, we have the series of inequalities

1
|x| ( dx) =

|x| ( dx)

-1 m=0 {2-(m+1)<|x|2-m}



 -1 2- m 1 - cos(2m+1x) ( dx)

m=0



= -1

2- m -Re(2m+1)

m=0



 -1 2c

2-( -)m - log C

2- m < .

m=0

m=0

4.2 Lemma. In the situation of the preceding lemma, let   [1, 2) and assume finite moments for the law of order  > . Then the following bound on the derivative of the characteristic exponent holds for   (, 2):

u  R : | (u)|  K(1 + |u| -1)

(4.4)

for some K > 0.

For  < 1 the derivative of the characteristic exponent is always uniformly

bounded:

sup | (u)| < .

(4.5)

uR

Proof. Since the diffusion part is zero by assumption, we obtain

| (u)| = ib + i eiux - 1 x( dx)

(4.6)

 |b| + (2  |ux|) |x|( dx)  |b| + 22- |u| -1 |x| ( dx).

(4.7) (4.8)

and the integral appearing in (4.8) is finite by Lemma 4.1 together with the moment assumption. We have thus shown (4.4). To see (4.5) , we can estimate

| (u)|  |b| + 2 |x|( dx)

(4.9)

and this expression is finite for  < 1 by Lemma 4.1.

Next, we focus on the exponential decay behaviour. We first need a result concerning the minimum distance fit of the characteristic function.

4.3 Lemma. Let |(u)|  Ce-c|u| . With

11

log T  log T 

I,T := [-U,T , U,T ] := - 3

, 3

.

10

we find for any observation distance  = T  (0, 1]

lim P
T 

u  I,T

:

|,T (u)|



C e-cu 2

= 1.

Proof. øFrom Theorem 3.1 we infer by Markov's inequality

P

u  I,T

: |,T (u)|

<

C e-c|u| 2



P

u  I,T

:

|,T (u) - (u)| >

C e-c|u| 2

=

P

sup
uI,T

|,T (u)

-

(u)|

2 ec|u| C

>

1



w(U,T

)-1

2 C

e|U,T

|



1 2

O

T

-

1 2

.

The choice of U,T ensures that this expression tends to zero for T  , whatever  is.

Let  := (u) denote the characteristic exponent of the true characteristic function  and ,T the characteristic exponent of the minimum distance fit ,T . The next two results give control on the deviation of ,T from  and of its second derivatives.
4.4 Lemma. Let |(u)|  Ce-c|u| . With K > 0 from (4.4) the following bound in probability is valid:

sup ,T (u) - (u)

uI,T w(u)-1ec|u|

1

+



1 2

K

(1

+

|u|

 2

)

=

OP(T

-

1 2

).

(4.10)

Moreover,

sup
uI,T

,T (u) w(u)-1ec|u| K(1

+

|u|

 2

)

=

OP(1).

(4.11)

Proof. We have, with probability tending to one, for all u  U;T :

,T (u) - (u)

=

,T (u) - (u) ,T (u) (u)



|,T (u) - (u)| + |,T (u)|

,T (u)

|,T (u) - (u)| |,T (u)|



ec|u|

w(u)-1

+

K

(1

+

|u|

 2

)ec|u|

w(u)-1

1 2

-

1 2

d

(,T

,



)

,

where the last inequality is a consequence of Lemma 4.2 and Lemma 4.3. Another application of Theorem 3.1 gives (4.10). Now (4.11) follows from (4.10), using Lemma 4.4 and the estimate

,T (u)  |(u)| + ,T (u) - (u) .

11

4.5 Lemma. Let |(u)|  Ce-c|u| . For the second derivative of the characteristic exponent we have

sup ,T (u) - (u) = OP(1).
uR
Moreover, we can give the following bound in probability uniformly on I,T :

sup ,T (u) - (u)

uI,T Cec|u| w(u)-1

1

+



1 2

(1

+

|u|

 2

)

+



3 2

(1

+

|u|)

= OP

T

-

1 2

(4.12)

Proof. To see the first statement of the lemma, recall that the second derivative of the characteristic exponent is always bounded above:

u  R : |(u)| =  -2 + eiuxx2( dx)   2 + |x|2( dx) < .

Then apply the series of inequalities

,T (u) - (u)  4 |(0)| + ,T (0) - (0)  4 |(0)| + ,T (0) - (0) + (,T (0))2 - ((0))2 = 4 |(0)| + ,T (0) - (0) + 2 |(0)| ,T (0) - (0) + ,T (0) - (0) 2

=

OP

1

+

T

-

1 2

+

T

-

1 2

+ T -1

= OP (1) .

Next, (4.12) can be seen by estimating

,T (u) - (u)

=

,T (u) - ,T (u)

,T (u)

2

-

(u) (u)

+ ((u))2



,T (u) - (u) |(u)|

+

,T (u)

|,T (u) - (u)| |(u)|

+ ,T (u) + (u) ,T (u) - (u) .

The desired bound is an immediate consequence of Lemma 4.4.

For distributions with characteristic functions decaying at most polynomially, we can prove auxiliary results analogous to Lemmas 4.1-4.5. As the proofs run in a completely analogous way, we omit the details and only state the main result:

4.6 Lemma. Let |(u)|  C(1 + |u|)-. Define

I,T :=

-T

1 2

(log(e

+

T

))-

1/2+2 

, +T

1 2

(log

T

)-

1/2+2 

.

Then we have

sup
uI,T

,T (u) - (u) C(1 + |u|)w(u)-1

=

OP

T

-

1 2

.

12

The proof of the upper bound result can now easily be obtained as a consequence of the preceding lemmas.
Proof of Theorem 3.2: The result for ^b,T is an immediate consequence of Theorem 3.1, using |^b,T - b| = -1|,T (0) - (0)|. For the estimator of , applying Parseval's identity, the loss satisfies

s ^,T , 

= sup f (x)^,T ( dx) - f (x)( dx)
f Fs

1 = sup
2 f Fs

Ff (u) F^,T (u) - F(u) du

 1 sup 2 f Fs

1

|Ff (u)| 

(u) - ,T (u)

du



1 sup (1 + |u|)-s 1

2 uR



,T (u) - (u)

.

By an application of Lemma 4.5 and Lemma 4.6, we can estimate a) for |(u)|  Ce-c|u| :

sup (1 + |u|)-s 1

uR



,T (u) - (u)

 sup (1 + |u|)-s
uI,T

1

+



1 2

(1

+

|u|

 2

)

+

3 2

(1

+

|u|)

e-c|u| w(u)

= OP

T

-

1 2



log T 

-

s 

.

OP

T

-

1 2

 (1 + U,T )-s

b) for |(u)|  C(1 + |u|)-:

sup (1 + |u|)-s 1 uR 

,T (u) - (u)

=

OP

T-

s 2

s(1/2+)
(log (e + T )) 



T

-

1 2

.

4.3 Acknowledgement
We want to thank two anonymous referees and one editor for careful reading and helpful comments.
References
[1] Ole E. Barndorff-Nielsen. Processes of normal inverse Gaussian type. Finance Stoch., 2(1):41≠68, 1998.
[2] Denis Belomestny and Markus Reiﬂ. Spectral calibration of exponential L¥evy models. Finance Stoch., 10(4):449≠474, 2006.
13

[3] Peter Carr and Dillip Madan. Option valuation using the fast Fourier transform. Journal of Computational Finance, 2:61≠73, 1998.
[4] Fabienne Comte and Valentine Genon-Catalot. Nonparametric adaptive estimation for pure jump L¥evy processes. Annales de l'I. H. P., Probability and Statistics (to appear).
[5] Fabienne Comte and Valentine Genon-Catalot. Nonparametric estimation for pure jump L¥evy processes based on high frequency data. Stochastic processes and their applications (to appear).
[6] Rama Cont and Peter Tankov. Financial modelling with jump processes. Chapman & Hall/CRC Financial Mathematics Series. Boca Raton, 2004.
[7] Jos¥e Figueroa-Lopez. Nonparametric estimation for L¥evy models based on discrete sampling. IMS Lecture Notes of the 3rd E.L. Lehmann Symposium, 57:117≠146, 2009.
[8] Jos¥e E. Figueroa-L¥opez. Small-time moment asymptotics for L¥evy processes. Stat. Probab. Lett., 78(18):3355≠3365, 2008.
[9] Jos¥e E. Figueroa-L¥opez and Christian Houdr¥e. Risk bounds for the nonparametric estimation of L¥evy processes. Gin¥e, Evarist (ed.) et al., High dimensional probability. Institute of Mathematical Statistics Lecture Notes - Monograph Series 51, 96-116, 2006.
[10] L. Goldstein and K. Messer. Optimal plug-in estimators for nonparametric functional estimation. Ann. Statist., 20(3):1306≠1328, 1992.
[11] Shota Gugushvili. Nonparametric estimation for discretely sampled L¥evy processes. arXiv:0908.3121v2, 2009.
[12] Shota Gugushvili. Nonparametric estimation of the characteristic triplet of a discretely observed L¥evy process. J. Nonparametric Stat., 21(3):321≠343, 2009.
[13] Geurt Jongbloed, Frank H. van der Meulen, and Aad.W. van der Vaart. Nonparametric inference for L¥evy-driven Ornstein-Uhlenbeck processes. Bernoulli, 11(5):759≠791, 2005.
[14] Michael Neumann and Markus Reiﬂ. Nonparametric estimation for L¥evy processes from low frequency observations. Bernoulli, 15(1):223≠248, 2009.
[15] Ken-Iti Sato. L¥evy processes and infinitely divisible distributions. Cambridge University Press, 1999.
[16] Wim Schoutens and Jozef L. Teugels. L¥evy processes, polynomials and martingales. Commun. Stat., Stochastic Models, 14(1-2):335≠349, 1998.
[17] Aad W. Van der Vaart. Asymptotic statistics. Cambridge University Press, 1998.
14

SFB 649 Discussion Paper Series 2011
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "Localising temperature risk" by Wolfgang Karl H‰rdle, Brenda LÛpez Cabrera, Ostap Okhrin and Weining Wang, January 2011.
002 "A Confidence Corridor for Sparse Longitudinal Data Curves" by Shuzhuan Zheng, Lijian Yang and Wolfgang Karl H‰rdle, January 2011.
003 "Mean Volatility Regressions" by Lu Lin, Feng Li, Lixing Zhu and Wolfgang Karl H‰rdle, January 2011.
004 "A Confidence Corridor for Expectile Functions" by Esra Akdeniz Duran, Mengmeng Guo and Wolfgang Karl H‰rdle, January 2011.
005 "Local Quantile Regression" by Wolfgang Karl H‰rdle, Vladimir Spokoiny and Weining Wang, January 2011.
006 "Sticky Information and Determinacy" by Alexander Meyer-Gohde, January 2011.
007 "Mean-Variance Cointegration and the Expectations Hypothesis" by Till Strohsal and Enzo Weber, February 2011.
008 "Monetary Policy, Trend Inflation and Inflation Persistence" by Fang Yao, February 2011.
009 "Exclusion in the All-Pay Auction: An Experimental Investigation" by Dietmar Fehr and Julia Schmid, February 2011.
010 "Unwillingness to Pay for Privacy: A Field Experiment" by Alastair R. Beresford, Dorothea K¸bler and Sˆren Preibusch, February 2011.
011 "Human Capital Formation on Skill-Specific Labor Markets" by Runli Xie, February 2011.
012 "A strategic mediator who is biased into the same direction as the expert can improve information transmission" by Lydia Mechtenberg and Johannes M¸nster, March 2011.
013 "Spatial Risk Premium on Weather Derivatives and Hedging Weather Exposure in Electricity" by Wolfgang Karl H‰rdle and Maria Osipenko, March 2011.
014 "Difference based Ridge and Liu type Estimators in Semiparametric Regression Models" by Esra Akdeniz Duran, Wolfgang Karl H‰rdle and Maria Osipenko, March 2011.
015 "Short-Term Herding of Institutional Traders: New Evidence from the German Stock Market" by Stephanie Kremer and Dieter Nautz, March 2011.
016 "Oracally Efficient Two-Step Estimation of Generalized Additive Model" by Rong Liu, Lijian Yang and Wolfgang Karl H‰rdle, March 2011.
017 "The Law of Attraction: Bilateral Search and Horizontal Heterogeneity" by Dirk Hofmann and Salmai Qari, March 2011.
018 "Can crop yield risk be globally diversified?" by Xiaoliang Liu, Wei Xu and Martin Odening, March 2011.
019 "What Drives the Relationship Between Inflation and Price Dispersion? Market Power vs. Price Rigidity" by Sascha Becker, March 2011.
020 "How Computational Statistics Became the Backbone of Modern Data Science" by James E. Gentle, Wolfgang H‰rdle and Yuichi Mori, May 2011.
021 "Customer Reactions in Out-of-Stock Situations ≠ Do promotion-induced phantom positions alleviate the similarity substitution hypothesis?" by Jana Luisa Diels and Nicole Wiebach, May 2011.
SFB 649, Ziegelstraﬂe 13a, D-10117 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

SFB 649 Discussion Paper Series 2011
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
022 "Extreme value models in a conditional duration intensity framework" by Rodrigo Herrera and Bernhard Schipp, May 2011.
023 "Forecasting Corporate Distress in the Asian and Pacific Region" by Russ Moro, Wolfgang H‰rdle, Saeideh Aliakbari and Linda Hoffmann, May 2011.
024 "Identifying the Effect of Temporal Work Flexibility on Parental Time with Children" by Juliane Scheffel, May 2011.
025 "How do Unusual Working Schedules Affect Social Life?" by Juliane Scheffel, May 2011.
026 "Compensation of Unusual Working Schedules" by Juliane Scheffel, May 2011.
027 "Estimation of the characteristics of a LÈvy process observed at arbitrary frequency" by Johanna Kappus and Markus Reiﬂ, May 2011.
SFB 649, Ziegelstraﬂe 13a, D-10117 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

